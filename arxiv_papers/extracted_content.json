[
  {
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "text": "RewardModelsareMetricsinaTrenchCoat-Preprint\nREWARD MODELS ARE METRICS IN A TRENCH COAT\nSebastianGehrmann\nBloomberg\nsgehrmann8@bloomberg.net\nABSTRACT\nTheemergenceofreinforcementlearninginpost-trainingoflargelanguagemod-\nels has sparked significant interest in reward models. Reward models assess the\nquality of sampled model outputs to generate training signals. This task is also\nperformed by evaluation metrics that monitor the performance of an AI model.\nWefindthatthetworesearchareasaremostlyseparate,leadingtoredundantter-\nminologyandrepeatedpitfalls. Commonchallengesincludesusceptibilitytospu-\nrious correlations, impact on downstream reward hacking, methods to improve\ndata quality, and approaches to meta-evaluation. Our position paper argues that\naclosercollaborationbetweenthefieldscanhelpovercometheseissues. Tothat\nend, we show how metrics outperform reward models on specific tasks and pro-\nvide an extensive survey of the two areas. Grounded in this survey, we point to\nmultiple research topics in which closer alignment can improve reward models\nandmetricsinareassuchaspreferenceelicitationmethods,avoidanceofspurious\ncorrelationsandrewardhacking,andcalibration-awaremeta-evaluation.\n1 INTRODUCTION\nReinforcement learning (RL) plays a major role in post-training, aligning, and adapting large lan-\nguagemodels(LLMs)toabroadrangeoftasks(OpenAI,2025;Comanicietal.,2025;xAI,2025;\nKimi et al., 2025; Guo et al., 2025). Scaling laws apply to reinforcement learning from human\nfeedback (RLHF, Christiano et al., 2017) similarly as to the rest of the training stack (Bai et al.,\n2022a). Assuch,scalablealternativestohumanfeedbackhavebecomepopular,eitherintheform\nofverifiablerewards(Lambertetal.,2024)orintheformofmodelsthatassessthequalityofmodel\noutputs(Lietal.,2018).Developingrobustandreliablerewardmodelsiscrucial,asthedownstream\nRLmodelscanexperiencerewardhacking(Amodeietal.,2016), optimizingforspuriouscorrela-\ntions in the reward model rather than learning the intended behavior. To overcome these issues,\nrewardmodelshaveexperiencedsignificantresearchinterest.\nIn parallel to research on reward models, model-based evaluation of generated text has similarly\nseen a surge in interest, enabling a switch from “traditional” lexical metrics like BLEU (Papineni\netal.,2002)andROUGE(Lin,2004)tolearnedmodels(Maetal.,2018;2019)andprompt-based\napproachesreferredtoasLLM-as-a-judge(Zhengetal.,2023). Thetwofieldspresenttwosidesof\nthe same coin: while reward models assess output quality to directly improve models, evaluation\nmetricsassessoutputqualitytoidentifypotentialareasofimprovement. Bothfieldsseektodevelop\nclassifiers that consume generated content as input and assign a goodness score as output. Both\nfields strongly benefit from rigor, consideration of the sociotechnical context in which a system is\ndeployed,andimprovedcorrelationbetweenmodel-basedjudgmentsandexperthumanraters. The\nkey difference between the two is that while metrics tend to be more specialized, reward models\ntend to assess broad capabilities spanning many tasks. Due to their similarities, one might expect\nthefieldslearnfromandinformeachother,andthatbreakthroughstransferquicklybetweenthem.\nOurpositionpaperarguesthatwhilethisshouldbethecase,itisnot.Instead,theacademicliterature\ninthesefieldsonlyinfrequentlyinformseachotherandthefieldsareactivelydevelopingandusing\ndifferentterminologyforthesamemethods. Whilemetricsarecommonlyusedtogeneratetraining\ndataforrewardmodels(Maliketal.,2025),andarethusinstrumentaltorewardmodelperformance,\nlittleattentionisbeingpaidtowhichmetricsgeneratethatdata. Wedemonstratethisphenomenon\nbyanalyzingthecitationgraphsofpapersineachsub-field,showingthatinter-fieldcitationsaccount\nforfewerthan10%oftotalcitedpapers. Wefurthersupportthisclaimbypresentingresultsfrom\n1\n5202\ntcO\n3\n]LC.sc[\n1v13230.0152:viXra\nRewardModelsareMetricsinaTrenchCoat-Preprint\ntwosmallexperiments: oneinwhichweapplyametrictoarewardmodelingbenchmarkandone\nwhereweapplyrewardmodelingtechniquestoafactualityevaluationbenchmark. Theresultsshow\nthatrewardmodelingapproacheslagbehinddedicatedmetricsforthesespecializedtasks,providing\nopportunitiesforimprovementsandmotivatingcross-testingontheirrespectivebenchmarks.\nMotivatedbythesefindings,weconductanextensivesurveyofthetwofieldsandtheirintersection.\nWelayoutscenariosinwhichwecanuseallthetoolsatourdisposalandshowcasehowitcouldlead\nto better reward models and evaluation metrics. Specifically, we argue that a closer collaboration\ncouldleadtomajorprogressinovercomingrewardhacking,inpreferenceelicitation,andinmeta-\nevaluation. We also discuss areas in which the fields differ and should not interact, and how this\nrelatestoGoodhart’slaw,whichstatesthatameasureceasestobeagoodmeasurewhenitbecomes\natarget. Groundedinthesediscussions,wemakespecificrecommendationstoresearchersworking\nonrewardmodelsandevaluationmetricsonhowtheseparationcanbeovercome.\n2 HOW DID MODERN REWARD MODELS COME ABOUT?\nAspartoftherisingpopularityofdeeplearning,RLstartedtobeexploredfortaskslikestructured\nprediction(Daume´ etal.,2009;Rossetal.,2011), imagerecognition(Mnihetal.,2014;Baetal.,\n2015) and for agents like the Neural Turing Machine (Zaremba & Sutskever, 2015). Successfully\ntrainingamodelviaRLhingesonbeingabletogeneraterewardsignals. Thisincludesbeingable\nto derive the value of intermediate states. As Sutton & Barto (2018) argue, “the most important\ncomponentofalmostallreinforcementlearningalgorithmsweconsiderisamethodforefficiently\nestimatingvalues.”Commentingonthisissue,YannLeCunfamouslycriticizedRLforhavingmuch\nsparserrewardsthanself-supervisedlearningduringhistalk“PredictiveLearning”(LeCun,2016).\nThis issue applies to generated language: generation has a combinatorially large state space with\nitssequentialtokenchoicesfromalargevocabulary,andnosingleobjectivenumbercanrepresents\nthe value of an output (Gehrmann et al., 2023). For that reason, generation models are typically\ntrained via teacher-forcing, a supervised approach that shows the model a ground-truth token at\neachpredictionstep. Thishappensonlyduringtraining, notattest-time. Moreover, whilemodels\nare trained with a cross-entropy objective, they are evaluated via different metrics. Ranzato et al.\n(2016)coinedthetermexposurebiasforthismismatchbetweentrainingandtesttime.\nIftherewasawaytodirectlyoptimizeforthemetric(s)wecareabout,theexposurebiascouldbe\novercome.Evaluationmetricsaredesignedtoactasaproxyforhumanjudgmentsandarethuswell-\nsuitedtoserveasarewardfunction. Whilesomeinference-timemethodsoptimizemetrics(Wise-\nman & Rush, 2016; Freitag et al., 2021b), reinforcement learning is a natural fit to optimize for\nthesemetricsduringtraining. REINFORCE(Williams,1992)andminimumrisktraining(Duda&\nHart, 1974) generate metric-based reward signals using sampled token sequences, and actor-critic\napproaches estimate partial rewards for predicted tokens (Bahdanau et al., 2017). Various instan-\ntiations of these approaches were used for machine translation (Ranzato et al., 2016; Shen et al.,\n2016), image captioning (Rennie et al., 2017), video captioning (Pasunuru & Bansal, 2017), and\nsummarization(Paulusetal.,2018).\nAtthattime,therewardmodelsweremeasuringlexicaloverlapbetweenageneratedsequenceanda\ngroundtruth(e.g.,Papinenietal.,2002;Lin,2004;Vedantametal.,2015).Thesemetricshavewell-\nunderstood drawbacks (e.g., Reiter, 2018; Freitag et al., 2020), especially for RL (Choshen et al.,\n2020). Amongothers,theyleadtorewardhackingwheremodelsgeneratenon-fluentlanguagethat\nmaximizesrewardscores(Amodeietal.,2016). Researchersworkedtoovercometheseissues,for\nexamplebyregularizingthetrainingprocessbycombiningcross-entropylosseswithRLorbyhand-\ncraftingadditionalrewardfunctions(Pasunuru&Bansal,2018;Krys´cin´skietal.,2018;Wuetal.,\n2018a). Theadventofmetricsmeasuringsemanticratherthanlexicalsimilarityledtosignificantly\nreducedreward-hackingsincethenewmodelsavoidedover-optimizingforthegenerationofrelevant\nwordswithoutfluentcontext(Lietal.,2018;Yasuietal.,2019;Scialometal.,2019).1 Thesemodels\nled to a clear path whereby new metrics could be validated and then used as reward models. For\n1ThisisalsorelatedtoGenerativeAdversarialNetworks(Goodfellowetal.,2014)forgeneration(e.g.,Yu\netal.,2017;Wuetal.,2018b)whereadiscriminatordifferentiatesgeneratedtextfromthegroundtruth,thus\nsimilarlygeneratingamodel-basedsignalforhuman-likeness.\n2\nRewardModelsareMetricsinaTrenchCoat-Preprint\n35,000\n30,000\n25,000\n20,000\n15,000\n10,000\n5,000\n0\n2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025\nYear\ntnuoC\nrepaP\nPaper Count Over Time by Field\nEvaluation Metric\nReward Model\nLLM as a Judge\nFigure1: Thefigureshowsthenumberofpublicationsperyearinthethreesubfieldsaccordingto\nakeywordsearchonGoogleScholar. Publicationsonevaluationmetricshaveslowed,eventhough\nresearchonrewardmodelingandLLM-as-a-judgeisquicklyrisinginpopularity. Ifthefieldswere\nactivelylearningfromoneanother,onecouldassumethatmentionsof”evaluationmetrics”should\nbegrowingalongsidethesenewlyemergingfields,buttheyarenot.\nexample, themetricBLEURTwasintroduced(Sellametal.,2020), evaluatedaspartoftheWMT\nMetricssharedtask(Mathuretal.,2020),andthenassessedasrewardmodel(Shuetal.,2021).\nInparalleltotheworkabove,theconceptofreinforcementlearningfromhumanfeedback(RLHF)\nwasintroducedforgameplayingandrobotics(Christianoetal.,2017). Inanessaytitled“Scalable\nagentalignmentviarewardmodeling: aresearchdirection”, Leikeetal.(2018)proposecapturing\nhuman preferences via dedicated reward models. This research culminated in the work on RLHF\nfor summarization (Stiennon et al., 2020) which popularized Proximal Policy Optimization (PPO,\nSchulmanetal.,2017)asRLapproachfortextgeneration. WhileStiennonetal.(2020)analyzed\ncorrelations between ROUGE and their human preference data, they did not use widely accepted\nalignmentmetrics,existinghumanpreferencecorpora,orthesemanticsimilarityevaluationmetrics\ndiscussedabove.InthefollowupworkonInstructGPT(Ouyangetal.,2022),therearenoreferences\ntothegenerationRLliteratureandnoevaluationoftherewardmodel. Subsequentworkintroduced\nthenotionofAIFeedbackasrewardmodels(Baietal.,2022b;Leeetal.,2024a)andarguedthatlan-\nguagemodelprobabilitiescanbedirectlyusedtomodelrewardsinaBradley-Terrymodel(Rafailov\net al., 2023; Bradley & Terry, 1952). Neither draws the connection to the role that perplexity and\nmodelprobabilitiesplayedinexistingevaluations(e.g.,Lewisetal.,2020;Minetal.,2023).\nThisseparationculminatedinbenchmarksforrewardmodels(e.g.,Fricketal.,2025;Lambertetal.,\n2025;Liuetal.,2025c;Zhouetal.,2025)andformetrics(e.g.,Honovichetal.,2022;Clarketal.,\n2023; Freitag et al., 2024) that exist in parallel without meaningful interaction. This raises the\nquestionofwhetherthisdisconnectispartofabroadertrend. Andifthetwofieldswereintegrated\ntighter,wouldwebeinabetterstatetoday? Andwhatshouldonelearnfromtheother?\n3 QUANTIFYING THE RESEARCH FIELD SEPARATION\nFigure1establishestheneedforthisinvestigationbyshowingthenumberofpapersfoundonGoogle\nScholarperyearthatcontaintheexactstrings“EvaluationMetric”,“RewardModel”,and“LLM-as-\na-judge”. Weinclude“LLM-as-a-judge”asanemergingfieldthathassimilarlyexperiencedrapid\ngrowthandwhichalsouseslanguagemodelstoestimatethequalityofgeneratedoutput. Notably,\ndespitetheexponentialgrowthofthetwoemergingtopics,thenumberofpapersmentioningevalu-\nationmetricsdecreasedin2024,withthetrendcontinuinginto2025.\nIf the terminology was merely changing, one would expect the new literature to still build on the\nolder one. For that reason, we empirically study the cause of this phenomenon by conducting a\ncitationanalysis.Weselectupto300papersperfieldperyear(2021–2025)viatheSemanticScholar\nGraph API, with sensitivity checks at 100/200 yielding similar trends (Kinney et al., 2023).2 For\n2Documented at https://api.semanticscholar.org/api-docs/graph. The search results\ninthemaximum300papersforthefirsttwofieldsand8,25,and43papersrespectivelyforLLM-as-a-judge\noverthepastthreeyears.MoredetailsonthisanalysisinAppendixA.\n3\nRewardModelsareMetricsinaTrenchCoat-Preprint\n50\n40 Evaluation Metric\n30\n20\n10 0\n50 40\n30\n20\n10\n0\n]%\nni[\ncipoT\not\nsnoitatiC\nMetric Reward Judge\n100 Evaluation Metric\n75\n50\n25 0\nReward Model 100\n75\n50\n25\n0\n50\n40 LLM as a Judge\n30\n20\n10\n0\n2021 2022 2023 2024 2025\n(a)Thefractionofcitationsfromonefieldto\nanother,basedonkeywordsincitedpapers.\n]%\nni[\neuneV\not\nsnoitatiC\nML NLP Vision Robotics\nReward Model\n100\nLLM as a Judge 75\n50\n25\n0\n2021 2022 2023 2024 2025\n(b)Thefractionofcitationstopapersinvenues\nassociatedwitharesearcharea.\nFigure2: Inouranalysisofcitationdynamicsacrossthethreefields,wefindthatevaluationpapers\ntend to cite other evaluation papers across research fields, while reward model papers mostly cite\neachotherandarehighlyfocusedonmachinelearningvenues. LLM-as-a-judgeworkmostlycites\nMLandNLPvenues,buthaslessclearcitationdynamics.\neach paper, we additionally retrieve its citations, yielding approximately 10,000 citations per year\nforeachfieldtoanalyze.AsaproxytoidentifywhetherapaperinfieldAcitesapaperinfieldB,we\nselectsignalingtermsforeachfield: (1)“metric(s)”, (2)“reward”, “reinforcement”, “policy”, and\n(3)“judge”. Ifanyofthosetermsappearsinthetitleorabstractofacitedpaper,wecountthisasan\ninter-field or intra-field citation. The results in Figure 2a show that evaluation metrics and reward\nmodels are distinct fields, with only few inter-field citations but many intra-field citations. This is\nespeciallypronouncedforrewardmodelswherealmost40%intra-fieldcitations. Thenumbersfor\nevaluation metrics trend lower at around 15–20% which we attribute to the heterogeneity of the\nfield;forexample,papersonmetricsforsummarizationcitesummarizationpapersratherthanonly\nevaluationpapers. LLM-as-a-judgeisanoutlier,withtoofewpaperstodrawdefinitiveconclusions.\nWe find more evidence for the field separation when we analyze the venues of the cited papers.\nFor this, we categorize venues into fields (e.g., ICLR as ML venue) and calculate the percentage\nof citations to papers published in the various fields. The results in Figure 2b reveal that reward\nmodelresearchpredominantlycitesresearchinmachinelearningvenuesandnotNLPandComputer\nVision. Incontrast,evaluationmetricworkisevenlydistributedandLLM-as-a-judgeworkfocuses\non ML and NLP.3 Since all observed trends are stable across years, we conclude that the three\nresearchfieldsarelargelyseparatewithlimitedinteraction.\n4 WHAT CAN ONE LEARN FROM THE OTHER?\nArebuttaltoourpropositionthatthetwofieldsshouldlearnfromeachotheristhatmaybethereis\nlittletolearn. Wethushighlighttwoscenariosinwhichaclosercross-fieldinteractioncouldhave\nchangedconclusionsoryieldedadditionalinsights.\n4.1 METRICSCANPERFORMWELLONREWARDMODELBENCHMARKS\nThe recently introduced RewardBench-M (Gureja et al., 2025) uses a subset of the MAPLE\ndataset (Zhu et al., 2024) to assess reward models on translation evaluation. The task requires\nidentifyingwhichoftwotranslationoutputswasratedhigherbyhumanevaluators. Thedataissplit\nintoaneasyanddifficultsubsetbasedonthedifferenceofhumanscoresofthetwoprovidedtransla-\ntions. Whilealltheirtestedmodelsperformnearlyperfectlyontheeasysubset,Gurejaetal.(2025)\nremarkthat“modelsthatperformwelloneasytaskscanstruggletomaintainthesamelevelofper-\n3Weomitfieldswith≤5%ofcitationsinallyears,includingSpeech,IR,andHCI.Ambiguousvenueslike\npreprintserversorbroadvenueslikeAAAIareexcludedfromthisanalysis.DetailedlistinAppendixC.\n4\nRewardModelsareMetricsinaTrenchCoat-Preprint\nde→en en→de zh→en en→zh\nGPT-4o 71.0 61.0 77.0 80.0\nAyaExpanse32B 62.0 69.0 76.0 79.0\nCOMETKIWI-DA(2022) 59.0 68.0 59.0 86.0\nTable 1: Results on the hard machine translation evaluation subset of RewardBench-M. For non-\nEnglishevaluations,a3yearoldmodelwith550MparametersoutperformsmuchlargerLLMs.\nformanceonhardertranslations,indicatingtheneedformoresophisticatedmechanismstohandle\n[...] challengingscenarios”. However,nomachinetranslationevaluationmetricwasassessedasa\nbaseline. Thus,totestthishypothesis,weevaluatethethree-year-oldmetricCometKiwi(Reietal.,\n2022)whichisbasedonInfoXLM(Chietal.,2021)andhasonly550Mparameters.\nTheresultsofCometKiwialongsidethetwobest-performingmodelsonthechallengingtranslation\ntest set of RewardBench-M (Dang et al., 2024; Hurst et al., 2024) are shown in Table 1. Despite\nitsageandbeingsignificantlysmaller,CometKiwiperformssimilarlyonGermanandoutperforms\ntheothermodelsonChinese,withtheoverallbestevaluationperformanceforthenon-Englishgen-\nerated text, demonstrating that the “sophisticated mechanisms” needed in current reward models\nalreadyexist. Buildingonthisobservation, theMetaMetricsapproach(Anugrahaetal.,2024)has\nbeenevaluatedonthelatestMTmetricssharedtask(Freitagetal.,2024)andontheRewardBench\nleaderboard(Lambertetal.,2025),scoringhighlyinboth,althoughnotwiththesamemodel.\n4.2 REWARDMODELSCANUNDERPERFORMONMETRICSBENCHMARKS\nAnother area in which reward model and metrics benchmarks are aligned in their goals is the as-\nsessment of how well models can assess factuality and attribution. There exist benchmarks for\nmetrics(Honovichetal.,2022),modelperformance(Jacovietal.,2025),andrewardmodels(Malik\netal.,2025)thatassessfactuality. RecentworkdemonstratestheeffectivenessofLLMjudge(and\nreward)models(e.g.,Calderonetal.,2025;Hashemietal.,2024),someevenfindingthatdedicated\nfinetunedevaluationmodelsunderperformLLMjudges(Huangetal.,2025).\nAmongthesebenchmarks,themetricsbenchmarkSEAHORSE(Clarketal.,2023)isthelargestwith\nover100,000humanjudgmentsofsummarizationqualityaspectsacrossmultiplelanguages.Forthis\nexperiment, wepromptvariousLLMswiththesameinstructionsprovidedtohumanannotatorsin\nSEAHORSE to give a binary judgment whether a summary is attributable to an article.4 Due to a\nlack of data availability, we exclude the WikiLingua (Ladhak et al., 2020) subset of SEAHORSE\nandfocusonlyonXLSum(Hasanetal.,2021)andMLSum(Scialometal.,2020),retaining7,793\nofthe18,330testexamples. WereportPearsoncorrelation(ρ)andaccuracy.\nTheresults(Table2)showthatLLMsunderperformthededicatedmodeltrainedonin-domaindata.\nThisremainstrueevenifweassessjudgemodelswithahighreasoningbudgetlikeGemini2.5Pro\nandGPT-5.Infact,thetworeasoningmodelshavean89%agreementrate,higherthantheinter-rater\nagreementof73%reportedinthepaper,indicatingthatthemodelslookforsimilarinputandoutput-\nfeatures to make their prediction. The results are fairly consistent across languages. Interestingly,\nallmodelsscorelowestonEnglishamongtheevaluatedlanguages.\nOverall, our findings disagree with Huang et al. (2025) who show that LLM judges can outper-\nformdedicatedmetricsinsimilarsetups,whileagreeingwithBavarescoetal.(2025)whoshowlow\nLLM judge correlations for summarization evaluation. Multiple explanations exist for the results\npresented here, including annotation artifacts that cause a lower performance of the LLM judge\nsetup. However, wecanconcludethatforevaluatingattributionforsummarization, itremainsun-\nclear whether LLM judges have caught up to dedicated models, a question that requires further\nrigorous study. This conclusion mirrors the argument by Chehbouni et al. (2025) that the “rapid\nand widespread adoption [of LLM judges] may have occurred prematurely”. Moreover, as shown\nin Table 2, the LLM judge setup outperforms a strong Natural Language Inference model (NLI)\nbaseline (Conneau et al., 2018). As such, this setup could still be useful in cases where dedicated\ntrainingdataforarewardmodelorevaluationmetricisunavailable.\n4Weoptimizedperformanceonthevalidationsettominimizetheeffectofthepromptformat.\n5\nRewardModelsareMetricsinaTrenchCoat-Preprint\nρ Acc. %\nROUGE-L 0.13\nmT5 0.43\nXNLI\nmT5 0.59\nSEAHORSE\nGPT-4o 0.47 73.3\nGemini2.0Flash 0.42 72.1\nGemini2.5Flash 0.48 73.8\nClaudeSonnet4 0.45 70.1\n+Reasoning\nGemini2.5Pro 0.50 73.9\nGPT-5 0.47 70.2\nTable 2: Pearson ρ coefficient and binary prediction accuracy on SEAHORSE for identifying\nwhetherasummaryisattributabletoasourcearticle. ThebaselinesarefinetunedmT5 models\nXXL\nbyClarketal.(2023).TheLLM-as-a-judgeapproachisoutperformedbyadedicatedtrainedmetric.\n5 METRICS AND REWARD MODELS ARE (NOT) THE SAME\nMetricsandrewardmodelsbothjudgequalityaspectsofgeneratedcontentwiththegoalofbeing\nalignedwithhumanpreferences. Yet, theyarenotthesame: theycandifferintheirdesign, appli-\ncation, training, and testing. To explore these aspects, we provide a survey of the two fields and\ndiscussthemeswhereacloserinteractioncouldleadtomutuallyhelpfulinsights.\n5.1 DESIGNINGREWARDMODELSANDEVALUATIONMETRICS\nSociotechnicalContextmatters Evaluationmetricstendtobenarrowlyfocusedonspecificqual-\nityaspects.Thesequalityaspectsshouldfollowclearandstandardizeddefinitionssothatthemetrics\nare transferable and produce scores that are understandable across organizations. A lack of trans-\nparencyinhowmetricsaredesignedandthesubsequentlackofreproducibilityhasbeensubjectof\nmuchpastcriticism(Rankeletal.,2013;Post,2018;Gehrmannetal.,2023).\nIn contrast, if a reward model is the provider of training signals during reinforcement learning, it\nmust therefore be able to score a myriad of tasks and output types. As such, modeling human\npreferences encompasses many aspects of preference beyond output quality, including whether a\nmodelcorrectlyrefusesundesiredrequestsoravoidsproducingtoxiclanguage(Baietal.,2022b).\nThesejudgmentsdependonthespecificapplicationthemodelisusedforandthepoliciesgovern-\ning this application. Rewardmodels that measure these application-specific aspects are inherently\nlesstransferrableandtiedtothespecificorganizationsthatdevelopthem(Gehrmannetal.,2025).\nFollowingthisreasoning,theserewardmodelsareinherentlynotcomparabletoanother,whichcalls\nintoquestiontheutilityofnon-specificreward-modelingbenchmarks.\nAspect-alignedrewardmodels Fine-grainedassessmentsof(partial)generationsareareaswith\nextensiverecentworkinRLthatmorecloselyalignwithworkonevaluationmetrics(Gunjaletal.,\n2025; Lightman et al., 2024). It is of particular interest, since a diverse set of reward signals can\nmitigate issues that arise from single-objective optimization (Freitag et al., 2021b; Zhang et al.,\n2024; Fisch et al., 2024). A popular approach for this is to use reward models that score rubrics\ninstead of providing generic preferences (Gunjal et al., 2025). Rubrics are fine-grained evaluation\ncriteria (Arora et al., 2025; Hashemi et al., 2024), similar to those traditionally assessed by dedi-\ncatedmetrics.Rubric-basedpromptedscoring,alongsidelearnedrewardmodels,ismentionedasan\ninstrumentalingredientforpost-trainingofmodelslikeGemini2.5(Comanicietal.,2025).\nSuccessfullyassessingrubricsrequirescleardefinitionsoftheevaluationcategories(Howcroftetal.,\n2020). Yet,evenforpopularconceptslike“hallucinationrate”,definitionscanvarywidely(Maynez\netal.,2020;Rashkinetal.,2023;Jietal.,2023). Increasingtheconsistencyofthesedefinitionswill\nbecrucialasrewardmodelsbecomemorespecific,andthusaredesignedmoresimilartoevaluation\n6\nRewardModelsareMetricsinaTrenchCoat-Preprint\nmetrics where the topic of fine-grained assessments is well-studied (e.g., Eyal et al., 2019; Wang\netal.,2020;Fabbrietal.,2021;Scialometal.,2021;Leeetal.,2024b;Weietal.,2025).\n5.2 TRAININGREWARDMODELSANDEVALUATIONMETRICS\nDataCollection Thedatacollectionmethodologyforanymodelmustbealignedwithitsdesign\ngoals. For reward models, this means reflecting the preferences of the intended audience of the\ndownstream model, which can be extremely broad. Since many aspects of generated text cannot\nbe objectively assessed, this necessitates collecting feedback from diverse sources (Casper et al.,\n2023;Metzetal.,2025). Thecultureandlivedexperienceofraterscanleadtodrasticallydifferent\nsubjectivepreferencejudgments(e.g.,Aroyoetal.,2023;Rastogietal.,2024;2025).\nAnother critical question to consider is whether the selected raters have sufficient expertise, as\nchanges in annotation quality can lead to drastically different insights (Freitag et al., 2021a; Wei\net al., 2024). In many cases, existing metrics and reward models already outperform non-expert\nraters, and only the highest quality annotations can further improve the models (Cui et al., 2023;\nLiuetal.,2024;Wenetal.,2025b). Moreover,Wenetal.(2025a)findthatRLmayproduceerrors\nthat are increasingly difficult for humans to detect. However, hiring raters with expertise to judge\nlong-formgenerationisnotoriouslychallenging(Zhangetal.,2023).\nOptimizationtargets Designaspectssuchasaccesstoagroundtruthandtheoutputformat(pair-\nwise preferences, categorical labels, or continuous scores) influence how models are developed.\nThese choices depend on the downstream use case, and can have significant impact on model ef-\nficacy. For example, reference-less evaluation has improved significantly in recent years but still\nunderperformsreference-basedmetrics(Maetal.,2019;Freitagetal.,2024). Similarresultswere\nfound for LLM-as-a-judge setups (Krumdick et al., 2025). These choices are reflected in bench-\nmarkingpractices;manyrewardmodelsproducepairwisecomparisons,andtheirbenchmarkscon-\nsequently focus on this binary setup (Frick et al., 2025). In contrast, metrics typically generate\ncontinuousoutputs,allowingformoreflexibleevaluation. Byfocusingprimarilyonpairwisejudg-\nments,rewardmodeldevelopmentmaybeignoringthepotentialbenefitsofcontinuousscoring.\nAnother shared goal is the development of lightweight models that can run efficiently alongside\nlarger models during inference or training. Advances in distillation, quantization, parallelization,\nand pruning are therefore highly relevant to both fields. Consequently, approaches to model com-\npressionthatseektotrainstudentmodelstooutperformtheirteacherscanequallybenefitthedevel-\nopmentofbothrewardmodelsandevaluationmetrics(Kimetal.,2024;Sunetal.,2023).\n5.3 TESTINGREWARDMODELSANDEVALUATIONMETRICS\nIdentifying and Debugging Reward Hacking A lack of correlation between reported reward\nmodel and downstream RL model performance has been attributed to limitations of the reward\nmodel(Ivisonetal.,2024;Kimetal.,2025;Wenetal.,2025c). Whentherewardmodeldoesnot\nrobustlygeneralize,orfocusesonspuriouscorrelations,itcanleadtorewardhacking.Amodeietal.\n(2016)describerewardhackingastheprocessof“gaming”flawsintherewardmodeltomaximize\ntherewardswithoutlearningtheintendedbehavior. Thisphenomenonwasempiricallyobservedfor\ntext(Pasunuru&Bansal,2017;Krys´cin´skietal.,2018;Wuetal.,2018a)andnon-textRL(Amodei\n&Clark,2016;Krakovnaetal.,2020;Nagarajanetal.,2021).\nIt is not specific to reward models, as most classification models suffer from spurious correla-\ntions (Ribeiro et al., 2016; McCoy et al., 2019) and spurious correlations were found in reward\nmodels (Liu et al., 2025b) and metrics (Sun et al., 2019). Among the effects, reward models may\nprefer more confident-sounding answers (Leng et al., 2025), exhibit a verbosity bias (Saito et al.,\n2023),focusmoreonstylethancontent(Feueretal.,2025),andresultsmaybeconfoundedbythe\norderinwhichoutputsareshown(Wangetal.,2024).Relatedly,theproblemofsycophancyhasbeen\ncharacterized as modelslearning to match user beliefsover generating truthful responses (Sharma\net al., 2024). Murugadoss et al. (2025) and Hu et al. (2024) further show that the detail of LLM-\nas-a-judge prompts have little influence on its performance, implying that models rely too much\non their implicitly learned quality criteria definitions. These issues motivate work on diagnostic\ndatasets(Gabrieletal.,2021),distractorgeneration(Qiuetal.,2020;Dholeetal.,2023),andmodel\ninterpretability(Jacovietal.,2023),tobecomeawareofandovercomespuriouscorrelations.\n7\nRewardModelsareMetricsinaTrenchCoat-Preprint\nMeta-Evaluation Frameworks The field of meta-evaluation is concerned with the question of\nhowweevaluateevaluators. Callison-Burchetal.(2007)popularizedthispracticeinNLPthrougha\nsharedtaskseriesthatperformsayearlyassessmentofMTmetrics. Meta-evaluationmeasurestwo\naspects: segment-levelandsystem-levelperformance. Ahighsystem-levelperformancemeansthat\nsystemrankingsinaleaderboardaretrustworthy,whilesegment-levelassessmentslookatwhether\nindividualpairsofsystemoutputsarerankedcorrectly. Thesetwomeasuresarenotalwayscorre-\nlated(Wei&Jia,2021),motivatinganapproachthatmatcheshowamodelisused.\nAlgorithmslikeDPO(Rafailovetal.,2023)usetherewardscoredifferencebetweenachosenand\nrejectedmodeloutputastrainingsignal. Thisdirectlymatchesthesegment-levelmeta-evaluation.\nHowever,aknownissueisthatevaluationmetricsareoftennotwell-calibrated(Kocmietal.,2024),\nwhichmaycauseissuesiftheyareappliedasrewardmodels. Moreover,rewardmodelbenchmarks\nlike RewardBench 2 (Lambert et al., 2025; Gureja et al., 2025) do not consider score calibration,\ninsteadreportingoverallaccuracyonthetaskofidentifyingthehighestratedsystemoutput,which\nmorecloselymatchesasystem-levelassessment. Asaresult,calibrationissuesmaybeoverlooked\nifonefocusesonlyonrewardmodelbenchmarkperformance. Thisoversightofsegment-levelas-\nsessmentscouldfurthercontributetothelackofcorrelationbetweenrewardmodelanddownstream\nmodelperformance.Thus,futureworkonrewardmodelbenchmarkingcouldbenefitfromreporting\nsegment-levelratherthansystem-levelperformance,includingassessmentsofscorecalibration.\nMeta-EvaluationTargets Acomplicatingfactorforthemeta-evaluationofrewardmodelsisthe\nbreadth of tasks for which theyneed to assess outputquality. Theirmeta-evaluations thus need to\nstrike a balance of breadth, validity, and relevance. Ivison et al. (2024) suggest that existing re-\nward model benchmarks are too narrow, especially considering their performance variance across\ntasks (Bavaresco et al., 2025). Benchmarks like RewardBench 2 already average multiple cate-\ngories, but the question of how to aggregate sub-category scores into a single ranking becomes\nimportant. Tothatend,Fricketal.(2025)findthatpessimisticrewardmodelevaluationsinsteadof\naverageperformancearemoreindicativeofdownstreammodelperformance,motivatingalternative\nleaderboard designs that focus on finding shortcomings, rather than averaging performance num-\nbers. Theseissuesarefurtherexacerbatedwhenthesystemsthatarebeingevaluatedbyevaluation\nmetrics and reward models improve. As these models become harder to distinguish, biases in the\nevaluationsetupbecomemorenoticeable(Wei&Jia,2021)andtiehandlingproceduresneedtobe\nintroduced(Thompsonetal.,2024;Sunetal.,2025).\n5.4 RECOMMENDATIONS\nWhile developing an unhackable reward model is likely impossible (Skalse et al., 2022), metrics,\nandmoredirectlyrewardmodels,shareasymbioticrelationshipwiththedownstreammodelswhere\nimprovementsinonetranslatetoimprovementsintheother(Gehrmannetal.,2021). Thismeans,\nweshouldstrivetoproducethemostaccurateestimateofhumanpreferences.Tothatend,bothfields\nbenefitfromhavinghigh-qualitytrainingandmeta-evaluationdata. Thisdataneedstobegrounded\nin clear definitions in the sociotechnical context that the to-be-assessed models are deployed in.\nWhileitisunavoidabletointroducespuriouscorrelations,inbothfieldsitiscrucialtoidentifyand\nmeasurethemandtomitigatetheirimpactondownstreamuses.\nModeling choices and optimization targets similarly align between the two fields, whether that is\napplying LLM-as-a-judge, or training classification models on human-curated data. Due to this\noverlap,newlyintroducedmethodsformodelinghumanpreferencesshouldbeevaluatedonmetrics\nand reward model benchmarks alike to paint a more accurate and complete picture of how these\nmethodsperform. Moregenerally,meta-evaluationandthedevelopmentofleaderboardsisanarea\nin which the fields have significantly diverged. They should come together to address the poor\ncorrelationbetweenrewardmodelbenchmarkscoresanddownstreammodelperformance. Shared\nbest practices on tie handling, segment-level correlation measures, conducting model calibration\nassessments,andcollectingtestdatasetswillbenefitbothfields.\nHowever, as reward modeling matures as a field, it will be important to avoid falling into traps\nlikedevelopingdefaultmodelsandbenchmarksthat,despitebeingoutdated,continuetobebroadly\nused (Bommasani & Cardie, 2020). Instead, evaluation research could adopt the practice from\nrewardmodelingofmovingtonewandbetterperformingmodelastheybecomeavailable.\n8\nRewardModelsareMetricsinaTrenchCoat-Preprint\nWhilerewardmodelsandevaluationmetricsshouldbedevelopedusingthesamebestpractices,one\ncannotbeusedtoreplacetheother. AsGoodhart’slawstates,whenameasurebecomesatarget,it\nceasestobeagoodmeasure(Goodhart,1984).Applyingtobothfields,modelsmayperformwellas\naproxyforthedistributionoverhumanpreferencesbutwilldivergeinthetail(i.e.,rarelyseenmodel\ninputs)andmayover-generalizeandfocusonspuriouspatterns(Manheim&Garrabrant,2018;Gao\netal.,2023). Similarargumentsapplytotheutilityofsharedtasksandleaderboardswhichsimilarly\nareafrequenttargetofcriticism(e.g.,Scott&Moore,2006;Ethayarajh&Jurafsky,2020;Thomas\n&Uminsky,2020;Rajietal.,2021;Bowman&Dahl,2021). Ourpracticalrecommendationisthus\nforthefieldstoshareinsightsintomethodologies,butnottocollapseintoonefield.\nAfullcollapsewouldriskcreatingamonoculturewhereonlyafewbenchmarksdictatemodelop-\ntimization, rather than having many different targets (Koch & Peterson, 2024). As Singh et al.\n(2025) state, an “over-reliance on a single leaderboard creates a risk that providers may overfit to\ntheaspectsofleaderboardperformance,withoutgenuinelyadvancingthetechnologyinmeaningful\nways”. Issues with broadly adopted evaluation setups lead to overspecialization and lack of gen-\neralization beyond what a specific leaderboard measures (Liu et al., 2025a; Zouhar et al., 2024).\nBeingtoorigidinhowmeta-evaluationsareconductedcouldalsoexcludenewmethodsfrombeing\ninvestigatedfairly(Perrellaetal.,2024).\nFurthermore,whilemethodsforrewardmodelingmaybeinformedbyinsightsfromevaluationmet-\nric development, the specific reward models may not perform well on the same benchmarks. As\ndiscussed above, reward models are often specific to a sociotechnical context, and would thus not\nperformwellonpublicrewardmodelingbenchmarks. Thismaycauseariftbetweenindustryand\nacademic research where the best reward modeling approaches are not publicly disclosed because\nthey are too entangled within this context. Yet, especially for models that measure human prefer-\nences for whether a model output is considered offensive or undesirable, it is critical to develop\npublicstandardsandbetransparentabouttheunderlyingpoliciesamodelistryingtoenact.\n6 CONCLUSIONS\nIn this work, we have argued that evaluation metrics and reward models share many similarities.\nTheirdevelopersneedtomakethesamechoicesabouttheirinputsandoutputs, theircollectionof\ntraining and validation data, and the resulting models suffer from the same drawbacks. While the\napplicationareasandthespecificchoicesmadeduringdevelopmentmaydiffer, attheircore, both\nseek to model human preferences of model output quality. This supports our thesis that the fields\nshouldlookatandlearnfromeachother’sadvances,ratherthancontinuingtoexistinparallel.\nWe grounded this discussion in a citation analysis that demonstrated that the research fields are\ndevelopingmostlyinisolationfromeachother.Thisseparationoffieldscanleadtomissedopportu-\nnities,therediscoveryofestablishedfindings,andpotentiallyflawedconclusions. Wequantifiedthe\nseparation through two experiments that show that reward models may be lacking when assessed\non domains for which evaluation metrics are already available. We provided an extensive survey\nanddiscussedseveralareasinwhichfutureworkonmetricsandrewardmodels,meta-evaluations,\nandbenchmarkcreationcouldincorporateinsightsfrombothfields. Whilewerecommendagainst\nthedevelopmentofamonoculturewithtoofewrelevantbenchmarks,weencourageresearchersto\nconsiderworkfrombothfieldsandworkonunifyingbothmethodologiesandterminologies.\nBeyondthescopeofthiswork,weacknowledgeeffortsinreinforcementlearningtosolvetaskswith\nverifiablerewards,forexamplemathproblems(Keetal.,2025),forwhichrewardmodelsplayaless\ncentralrole.Inthisdomain,model-basedrewardmodelingapproacheslargelyperformstringmatch-\ning between the verified and generated answer, and thus do not require as complex approaches as\nthosediscussedhere.Trainingmodelsfortheseverifiabledomainscaninducereasoningcapabilities\nandhasledtobroadergeneralization(Guoetal.,2025;Comanicietal.,2025). Whilethisfinding\ndoesnotmakerewardmodelsfornon-verifiabledomainsobsolete,itpresentsapossiblealternative\norparallelpathinwhichrewardmodelsdonotplaysuchacentralrole. Moreover,wenotethatim-\nprovementsinrewardmodelsmaynotalwaystranslateintodownstreammodelimprovements. The\nsuperficial alignment hypothesis by Zhou et al. (2023) poses that the reinforcement learning stage\nprimarily changes ’how’ a model responds, rather than contributing new world knowledge. Thus,\nevenaperfectrewardmodelcannotovercomefundamentalknowledgegapsfrompre-training.\n9\nRewardModelsareMetricsinaTrenchCoat-Preprint\nREFERENCES\nDario Amodei and Jack Clark. Faulty reward functions in the wild. https://openai.com/\nindex/faulty-reward-functions/,2016.\nDarioAmodei,ChrisOlah,JacobSteinhardt,PaulChristiano,JohnSchulman,andDanMane´. Con-\ncreteproblemsinaisafety. arXivpreprintarXiv:1606.06565,2016.\nDavid Anugraha, Garry Kuwanto, Lucky Susanto, Derry Tanti Wijaya, and Genta Winata.\nMetaMetrics-MT: Tuning meta-metrics for machine translation via human preference calibra-\ntion. In Barry Haddow, Tom Kocmi, Philipp Koehn, and Christof Monz (eds.), Proceedings\nof the Ninth Conference on Machine Translation, pp. 459–469, Miami, Florida, USA, Novem-\nber 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.wmt-1.32. URL\nhttps://aclanthology.org/2024.wmt-1.32/.\nRahulK.Arora,JasonWei,RebeccaSoskinHicks,PrestonBowman,JoaquinQuin˜oneroCandela,\nFoivos Tsimpourlas, Michael Sharman, Meghan Shah, Andrea Vallone, Alex Beutel, Johannes\nHeidecke,andKaranSinghal. Healthbench:Evaluatinglargelanguagemodelstowardsimproved\nhumanhealth. CoRR,abs/2505.08775,2025. doi: 10.48550/ARXIV.2505.08775. URLhttps:\n//doi.org/10.48550/arXiv.2505.08775.\nLora Aroyo, Mark Diaz, Christopher Homan, Vinodkumar Prabhakaran, Alex Taylor, and Ding\nWang. Thereasonableeffectivenessofdiverseevaluationdata. arXivpreprintarXiv:2301.09406,\n2023.\nJimmyBa,VolodymyrMnih,andKorayKavukcuoglu. Multipleobjectrecognitionwithvisualat-\ntention. In Yoshua Bengio and Yann LeCun (eds.), 3rd International Conference on Learning\nRepresentations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceed-\nings,2015. URLhttp://arxiv.org/abs/1412.7755.\nDzmitry Bahdanau, Philemon Brakel, Kelvin Xu, Anirudh Goyal, Ryan Lowe, Joelle Pineau,\nAaronC.Courville,andYoshuaBengio.Anactor-criticalgorithmforsequenceprediction.In5th\nInternationalConferenceonLearningRepresentations,ICLR2017,Toulon,France,April24-26,\n2017,ConferenceTrackProceedings.OpenReview.net,2017. URLhttps://openreview.\nnet/forum?id=SJDaqqveg.\nYuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova Dassarma, Dawn\nDrain, Stanislav Fort, Deep Ganguli, T. J. Henighan, Nicholas Joseph, Saurav Kadavath, John\nKernion, Tom Conerly, Sheer El-Showk, Nelson Elhage, Zac Hatfield-Dodds, Danny Hernan-\ndez,TristanHume,ScottJohnston,ShaunaKravec,LianeLovitt,NeelNanda,CatherineOlsson,\nDarioAmodei, TomB.Brown, JackClark, SamMcCandlish, ChrisOlah, BenjaminMann, and\nJaredKaplan. Trainingahelpfulandharmlessassistantwithreinforcementlearningfromhuman\nfeedback. ArXiv,abs/2204.05862,2022a. URLhttps://api.semanticscholar.org/\nCorpusID:248118878.\nYuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones,\nAnna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, Carol Chen, Catherine Ols-\nson, Christopher Olah, Danny Hernandez, Dawn Drain, Deep Ganguli, Dustin Li, Eli Tran-\nJohnson,EthanPerez,JamieKerr,JaredMueller,JeffreyLadish,JoshuaLandau,KamalNdousse,\nKamileLukosiute,LianeLovitt,MichaelSellitto,NelsonElhage,NicholasSchiefer,Noem´ıMer-\ncado, Nova DasSarma, Robert Lasenby, Robin Larson, Sam Ringer, Scott Johnston, Shauna\nKravec, Sheer El Showk, Stanislav Fort, Tamera Lanham, Timothy Telleen-Lawton, Tom Con-\nerly,TomHenighan,TristanHume,SamuelR.Bowman,ZacHatfield-Dodds,BenMann,Dario\nAmodei,NicholasJoseph,SamMcCandlish,TomBrown,andJaredKaplan. ConstitutionalAI:\nharmlessness from AI feedback. CoRR, abs/2212.08073, 2022b. doi: 10.48550/ARXIV.2212.\n08073. URLhttps://doi.org/10.48550/arXiv.2212.08073.\nAnnaBavaresco,RaffaellaBernardi,LeonardoBertolazzi,DesmondElliott,RaquelFerna´ndez,Al-\nbert Gatt, Esam Ghaleb, Mario Giulianelli, Michael Hanna, Alexander Koller, Andre Martins,\nPhilippMondorf,VeraNeplenbroek,SandroPezzelle,BarbaraPlank,DavidSchlangen,Alessan-\ndro Suglia, Aditya K Surikuchi, Ece Takmaz, and Alberto Testoni. LLMs instead of human\njudges? alargescaleempiricalstudyacross20NLPevaluationtasks. InWanxiangChe, Joyce\n10\nRewardModelsareMetricsinaTrenchCoat-Preprint\nNabende,EkaterinaShutova,andMohammadTaherPilehvar(eds.),Proceedingsofthe63rdAn-\nnual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pp.\n238–255, Vienna, Austria, July 2025. Association for Computational Linguistics. ISBN 979-8-\n89176-252-7. doi: 10.18653/v1/2025.acl-short.20. URL https://aclanthology.org/\n2025.acl-short.20/.\nRishi Bommasani and Claire Cardie. Intrinsic evaluation of summarization datasets. In Bonnie\nWebber, Trevor Cohn, Yulan He, and Yang Liu (eds.), Proceedings of the 2020 Conference on\nEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pp.8075–8096,Online,Novem-\nber 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.649.\nURLhttps://aclanthology.org/2020.emnlp-main.649/.\nSamuel R. Bowman and George Dahl. What will it take to fix benchmarking in natural lan-\nguage understanding? In Kristina Toutanova, Anna Rumshisky, Luke Zettlemoyer, Dilek\nHakkani-Tur,IzBeltagy,StevenBethard,RyanCotterell,TanmoyChakraborty,andYichaoZhou\n(eds.), Proceedings of the 2021 Conference of the North American Chapter of the Association\nfor Computational Linguistics: Human Language Technologies, pp. 4843–4855, Online, June\n2021.AssociationforComputationalLinguistics. doi: 10.18653/v1/2021.naacl-main.385. URL\nhttps://aclanthology.org/2021.naacl-main.385/.\nRalphAllanBradleyandMiltonETerry. Rankanalysisofincompleteblockdesigns: I.themethod\nofpairedcomparisons. Biometrika,39(3/4):324–345,1952.\nNitayCalderon,RoiReichart,andRotemDror. ThealternativeannotatortestforLLM-as-a-judge:\nHow to statistically justify replacing human annotators with LLMs. In Wanxiang Che, Joyce\nNabende, Ekaterina Shutova, and Mohammad Taher Pilehvar (eds.), Proceedings of the 63rd\nAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1: LongPapers), pp.\n16051–16081,Vienna,Austria,July2025.AssociationforComputationalLinguistics.ISBN979-\n8-89176-251-0.doi:10.18653/v1/2025.acl-long.782.URLhttps://aclanthology.org/\n2025.acl-long.782/.\nChrisCallison-Burch,CameronFordyce,PhilippKoehn,ChristofMonz,andJoshSchroeder.(meta-\n) evaluation of machine translation. In Chris Callison-Burch, Philipp Koehn, Cameron Shaw\nFordyce,andChristofMonz(eds.),ProceedingsoftheSecondWorkshoponStatisticalMachine\nTranslation, pp. 136–158, Prague, Czech Republic, June 2007. Association for Computational\nLinguistics. URLhttps://aclanthology.org/W07-0718/.\nStephen Casper, Xander Davies, Claudia Shi, Thomas Krendl Gilbert, Je´re´my Scheurer, Javier\nRando,RachelFreedman,TomekKorbak,DavidLindner,PedroFreire,TonyTongWang,Samuel\nMarks, Charbel-Raphael Segerie, Micah Carroll, Andi Peng, Phillip J.K. Christoffersen, Mehul\nDamani, Stewart Slocum, Usman Anwar, Anand Siththaranjan, Max Nadeau, Eric J Michaud,\nJacobPfau,DmitriiKrasheninnikov,XinChen,LauroLangosco,PeterHase,ErdemBiyik,Anca\nDragan, DavidKrueger, DorsaSadigh, andDylanHadfield-Menell. Openproblemsandfunda-\nmental limitations of reinforcement learning from human feedback. Transactions on Machine\nLearning Research, 2023. ISSN 2835-8856. URL https://openreview.net/forum?\nid=bx24KpJ4Eb. SurveyCertification,FeaturedCertification.\nKhaoulaChehbouni,MohammedHaddou,JackieChiKitCheung,andGolnooshFarnadi. Neither\nvalidnorreliable?investigatingtheuseofllmsasjudges.arXivpreprintarXiv:2508.18076,2025.\nZewenChi,LiDong,FuruWei,NanYang,SakshamSinghal,WenhuiWang,XiaSong,Xian-Ling\nMao,HeyanHuang,andMingZhou. InfoXLM:Aninformation-theoreticframeworkforcross-\nlinguallanguagemodelpre-training. InKristinaToutanova,AnnaRumshisky,LukeZettlemoyer,\nDilekHakkani-Tur,IzBeltagy,StevenBethard,RyanCotterell,TanmoyChakraborty,andYichao\nZhou (eds.), Proceedings of the 2021 Conference of the North American Chapter of the Asso-\nciationforComputationalLinguistics: HumanLanguageTechnologies,pp.3576–3588,Online,\nJune 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.280.\nURLhttps://aclanthology.org/2021.naacl-main.280/.\nLeshemChoshen,LiorFox,ZoharAizenbud,andOmriAbend.Ontheweaknessesofreinforcement\nlearningforneuralmachinetranslation. In8thInternationalConferenceonLearningRepresen-\ntations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net, 2020. URL\nhttps://openreview.net/forum?id=H1eCw3EKvH.\n11\nRewardModelsareMetricsinaTrenchCoat-Preprint\nPaul F. Christiano, Jan Leike, Tom B. Brown, Miljan Martic, Shane Legg, and Dario Amodei.\nDeep reinforcement learning from human preferences. In Isabelle Guyon, Ulrike von Luxburg,\nSamy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman Garnett\n(eds.), Advances in Neural Information Processing Systems 30: Annual Conference on Neu-\nral Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, pp.\n4299–4307, 2017. URL https://proceedings.neurips.cc/paper/2017/hash/\nd5e2c0adad503c91f91df240d0cd4e49-Abstract.html.\nElizabethClark,ShrutiRijhwani,SebastianGehrmann,JoshuaMaynez,RoeeAharoni,VitalyNiko-\nlaev,ThibaultSellam,AdityaSiddhant,DipanjanDas,andAnkurParikh. SEAHORSE:Amul-\ntilingual,multifaceteddatasetforsummarizationevaluation. InHoudaBouamor,JuanPino,and\nKalika Bali (eds.), Proceedings of the 2023 Conference on Empirical Methods in Natural Lan-\nguage Processing, pp. 9397–9413, Singapore, December 2023. Association for Computational\nLinguistics.doi:10.18653/v1/2023.emnlp-main.584.URLhttps://aclanthology.org/\n2023.emnlp-main.584/.\nGheorghe Comanici, Eric Bieber, Mike Schaekermann, Ice Pasupat, Noveen Sachdeva, Inderjit\nDhillon, Marcel Blistein, Ori Ram, Dan Zhang, Evan Rosen, et al. Gemini 2.5: Pushing the\nfrontierwithadvancedreasoning,multimodality,longcontext,andnextgenerationagenticcapa-\nbilities. arXivpreprintarXiv:2507.06261,2025.\nAlexis Conneau, Guillaume Lample, Ruty Rinott, Adina Williams, Samuel R. Bowman, Holger\nSchwenk, and Veselin Stoyanov. Xnli: Evaluating cross-lingual sentence representations. In\nConference on Empirical Methods in Natural Language Processing, 2018. URL https://\napi.semanticscholar.org/CorpusID:52271711.\nGanqu Cui, Lifan Yuan, Ning Ding, Guanming Yao, Bingxiang He, Wei Zhu, Yuan Ni, Guotong\nXie, Ruobing Xie, Yankai Lin, et al. Ultrafeedback: Boosting language models with scaled ai\nfeedback. arXivpreprintarXiv:2310.01377,2023.\nJohn Dang, Shivalika Singh, Daniel D’souza, Arash Ahmadian, Alejandro Salamanca, Made-\nline Smith, Aidan Peppin, Sungjin Hong, Manoj Govindassamy, Terrence Zhao, Sandra Kub-\nlik, Meor Amer, Viraat Aryabumi, Jon Ander Campos, Yi-Chern Tan, Tom Kocmi, Florian\nStrub, Nathan Grinsztajn, Yannis Flet-Berliac, Acyr Locatelli, Hangyu Lin, Dwarak Talupuru,\nBharat Venkitesh, David Cairuz, Bowen Yang, Tim Chung, Wei-Yin Ko, Sylvie Shang Shi,\nAmir Shukayev, Sammie Bae, Aleksandra Piktus, Roman Castagne´, Felipe Cruz-Salinas, Ed-\ndie Kim, Lucas Crawhall-Stein, Adrien Morisot, Sudip Roy, Phil Blunsom, Ivan Zhang, Aidan\nGomez, Nick Frosst, Marzieh Fadaee, Beyza Ermis, Ahmet U¨stu¨n, and Sara Hooker. Aya ex-\npanse: Combiningresearchbreakthroughsforanewmultilingualfrontier,2024. URLhttps:\n//arxiv.org/abs/2412.04261.\nHalDaume´,JohnLangford,andDanielMarcu.Search-basedstructuredprediction.MachineLearn-\ning,75(3):297–325,2009. doi:10.1007/S10994-009-5106-X. URLhttps://doi.org/10.\n1007/s10994-009-5106-x.\nKaustubhDhole,VarunGangal,SebastianGehrmann,AadeshGupta,ZhenhaoLi,SaadMahamood,\nAbinayaMahadiran,SimonMille,AshishShrivastava,SamsonTan,TongshangWu,JaschaSohl-\nDickstein, Jinho Choi, Eduard Hovy, Ondˇrej Dusˇek, Sebastian Ruder, Sajant Anand, Nagender\nAneja, Rabin Banjade, Lisa Barthe, Hanna Behnke, Ian Berlot-Attwell, Connor Boyle, Caro-\nline Brun, Marco Antonio Sobrevilla Cabezudo, Samuel Cahyawijaya, Emile Chapuis, Wanx-\niang Che, Mukund Choudhary, Christian Clauss, Pierre Colombo, Filip Cornell, Gautier Da-\ngan, Mayukh Das, Tanay Dixit, Thomas Dopierre, Paul-Alexis Dray, Suchitra Dubey, Tatiana\nEkeinhor, Marco Di Giovanni, Tanya Goyal, Rishabh Gupta, Louanes Hamla, Sang Han, Fab-\nrice Harel-Canada, Antoine Honore´, Ishan Jindal, Przemysław Joniak, Denis Kleyko, Venelin\nKovatchev,KalpeshKrishna,AshutoshKumar,StefanLanger,SeungjaeRyanLee,CoreyJames\nLevinson, Hualou Liang, KaizhaoLiang, ZhexiongLiu, Andrey Lukyanenko, Vukosi Marivate,\nGerard de Melo, Simon Meoni, Maxine Meyer, Afnan Mir, Nafise Sadat Moosavi, Niklas Me-\nunnighoff, Timothy Sum Hon Mun, Kenton Murray, Marcin Namysl, Maria Obedkova, Priti\nOli, Nivranshu Pasricha, Jan Pfister, Richard Plant, Vinay Prabhu, Vasile Pais, Libo Qin, Sha-\nhab Raji, Pawan Kumar Rajpoot, Vikas Raunak, Roy Rinberg, Nicholas Roberts, Juan Diego\nRodriguez, Claude Roux, Vasconcellos Samus, Ananya Sai, Robin Schmidt, Thomas Scialom,\n12\nRewardModelsareMetricsinaTrenchCoat-Preprint\nTshephisho Sefara, Saqib Shamsi, Xudong Shen, Yiwen Shi, Haoyue Shi, Anna Shvets, Nick\nSiegel, Damien Sileo, Jamie Simon, Chandan Singh, Roman Sitelew, Priyank Soni, Taylor\nSorensen,WilliamSoto,AmanSrivastava,AdityaSrivatsa,TonySun,MukundVarma,ATabas-\nsum, Fiona Tan, Ryan Teehan, Mo Tiwari, Marie Tolkiehn, Athena Wang, Zijian Wang, Zi-\njie Wang, Gloria Wang, Fuxuan Wei, Bryan Wilie, Genta Indra Winata, Xinyu Wu, Witold\nWydmanski, Tianbao Xie, Usama Yaseen, Michael Yee, Jing Zhang, and Yue Zhang. NL-\naugmenter: A framework for task-sensitive natural language augmentation. Northern Euro-\npeanJournalofLanguageTechnology,9,2023. doi: 10.3384/nejlt.2000-1533.2023.4725. URL\nhttps://aclanthology.org/2023.nejlt-1.5/.\nRichard O. Duda and Peter E. Hart. Pattern classification and scene analysis. In A\nWiley-Interscience publication, 1974. URL https://api.semanticscholar.org/\nCorpusID:12946615.\nKawin Ethayarajh and Dan Jurafsky. Utility is in the eye of the user: A critique of NLP leader-\nboards. InBonnieWebber,TrevorCohn,YulanHe,andYangLiu(eds.),Proceedingsofthe2020\nConference on Empirical Methods in Natural Language Processing (EMNLP), pp. 4846–4853,\nOnline, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.\nemnlp-main.393. URLhttps://aclanthology.org/2020.emnlp-main.393/.\nMatanEyal,TalBaumel,andMichaelElhadad.Questionansweringasanautomaticevaluationmet-\nric for news article summarization. In Jill Burstein, Christy Doran, and Thamar Solorio (eds.),\nProceedingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforCom-\nputationalLinguistics: HumanLanguageTechnologies, Volume1(LongandShortPapers), pp.\n3938–3948,Minneapolis,Minnesota,June2019.AssociationforComputationalLinguistics. doi:\n10.18653/v1/N19-1395. URLhttps://aclanthology.org/N19-1395/.\nAlexander R. Fabbri, Chien Sheng Wu, Wenhao Liu, and Caiming Xiong. Qafacteval: Improved\nqa-based factual consistency evaluation for summarization. In North American Chapter of the\nAssociationforComputationalLinguistics,2021.URLhttps://api.semanticscholar.\norg/CorpusID:245218667.\nBenjamin Feuer, Micah Goldblum, Teresa Datta, Sanjana Nambiar, Raz Besaleli, Samuel Dooley,\nMaxCembalest,andJohnPDickerson.Styleoutweighssubstance:FailuremodesofLLMjudges\ninalignmentbenchmarking. InTheThirteenthInternationalConferenceonLearningRepresen-\ntations,2025. URLhttps://openreview.net/forum?id=MzHNftnAM1.\nAdamFisch,JacobEisenstein,VickyZayats,AlekhAgarwal,AhmadBeirami,ChiragNagpal,Pete\nShaw, and Jonathan Berant. Robust preference optimization through reward model distillation.\narXivpreprintarXiv:2405.19316,2024.\nMarkusFreitag, DavidGrangier, andIsaacCaswell. BLEUmightbeguiltybutreferencesarenot\ninnocent. In Bonnie Webber, Trevor Cohn, Yulan He, and Yang Liu (eds.), Proceedings of the\n2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pp.61–71,\nOnline, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.\nemnlp-main.5. URLhttps://aclanthology.org/2020.emnlp-main.5/.\nMarkus Freitag, George Foster, David Grangier, Viresh Ratnakar, Qijun Tan, and Wolfgang\nMacherey. Experts, errors, and context: A large-scale study of human evaluation for machine\ntranslation. TransactionsoftheAssociationforComputationalLinguistics,9:1460–1474,2021a.\ndoi: 10.1162/tacl a 00437. URLhttps://aclanthology.org/2021.tacl-1.87/.\nMarkus Freitag, David Grangier, Qijun Tan, and Bowen Liang. High quality rather than high\nmodel probability: Minimum bayes risk decoding with neural metrics. Transactions of\nthe Association for Computational Linguistics, 10:811–825, 2021b. URL https://api.\nsemanticscholar.org/CorpusID:248392447.\nMarkus Freitag, Nitika Mathur, Daniel Deutsch, Chi-Kiu Lo, Eleftherios Avramidis, Ricardo Rei,\nBrian Thompson, Frederic Blain, Tom Kocmi, Jiayi Wang, David Ifeoluwa Adelani, Marianna\nBuchicchio, Chrysoula Zerva, and Alon Lavie. Are LLMs breaking MT metrics? results of\nthe WMT24 metrics shared task. In Barry Haddow, Tom Kocmi, Philipp Koehn, and Christof\nMonz (eds.), Proceedings of the Ninth Conference on Machine Translation, pp. 47–81, Miami,\n13\nRewardModelsareMetricsinaTrenchCoat-Preprint\nFlorida, USA, November 2024. Association for Computational Linguistics. doi: 10.18653/v1/\n2024.wmt-1.2. URLhttps://aclanthology.org/2024.wmt-1.2/.\nEvan Frick, Tianle Li, Connor Chen, Wei-Lin Chiang, Anastasios Nikolas Angelopoulos, Jiantao\nJiao, Banghua Zhu, Joseph E. Gonzalez, and Ion Stoica. How to evaluate reward models for\nRLHF. In The Thirteenth International Conference on Learning Representations, 2025. URL\nhttps://openreview.net/forum?id=cbttLtO94Q.\nSaadiaGabriel,AsliCelikyilmaz,RahulJha,YejinChoi,andJianfengGao. GOFIGURE:Ameta\nevaluationoffactualityinsummarization. InChengqingZong,FeiXia,WenjieLi,andRoberto\nNavigli (eds.), Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,\npp. 478–487, Online, August 2021. Association for Computational Linguistics. doi: 10.18653/\nv1/2021.findings-acl.42. URL https://aclanthology.org/2021.findings-acl.\n42/.\nLeo Gao, John Schulman, and Jacob Hilton. Scaling laws for reward model overoptimization. In\nInternationalConferenceonMachineLearning,pp.10835–10866.PMLR,2023.\nSebastian Gehrmann, Tosin Adewumi, Karmanya Aggarwal, Pawan Sasanka Ammanamanchi,\nAnuoluwapo Aremu, Antoine Bosselut, Khyathi Raghavi Chandu, Miruna-Adriana Clinciu,\nDipanjan Das, Kaustubh Dhole, Wanyu Du, Esin Durmus, Ondˇrej Dusˇek, Chris Chinenye\nEmezue, Varun Gangal, Cristina Garbacea, Tatsunori Hashimoto, Yufang Hou, Yacine Jer-\nnite, Harsh Jhamtani, Yangfeng Ji, Shailza Jolly, Mihir Kale, Dhruv Kumar, Faisal Ladhak,\nAmanMadaan, MounicaMaddela, KhyatiMahajan, SaadMahamood, BodhisattwaPrasadMa-\njumder,PedroHenriqueMartins,AngelinaMcMillan-Major,SimonMille,EmielvanMiltenburg,\nMoin Nadeem, Shashi Narayan, Vitaly Nikolaev, Andre Niyongabo Rubungo, Salomey Osei,\nAnkur Parikh, Laura Perez-Beltrachini, Niranjan Ramesh Rao, Vikas Raunak, Juan Diego Ro-\ndriguez, Sashank Santhanam, Joa˜o Sedoc, Thibault Sellam, Samira Shaikh, Anastasia Shimo-\nrina, Marco Antonio Sobrevilla Cabezudo, Hendrik Strobelt, Nishant Subramani, Wei Xu, Diyi\nYang, Akhila Yerukola, and Jiawei Zhou. The GEM benchmark: Natural language generation,\nits evaluation and metrics. In Antoine Bosselut, Esin Durmus, Varun Prashant Gangal, Sebas-\ntian Gehrmann, Yacine Jernite, Laura Perez-Beltrachini, Samira Shaikh, and Wei Xu (eds.),\nProceedings of the First Workshop on Natural Language Generation, Evaluation, and Metrics\n(GEM), pp. 96–120, Online, August 2021. Association for Computational Linguistics. doi:\n10.18653/v1/2021.gem-1.10. URLhttps://aclanthology.org/2021.gem-1.10/.\nSebastian Gehrmann, Elizabeth Clark, and Thibault Sellam. Repairing the cracked foundation:\nA survey of obstacles in evaluation practices for generated text. Journal Artificial Intelligence\nResearch, 77:103–166, 2023. doi: 10.1613/JAIR.1.13715. URL https://doi.org/10.\n1613/jair.1.13715.\nSebastianGehrmann,ClaireHuang,XianTeng,SergeiYurovski,ArjunBhorkar,NaveenThomas,\nJohn Doucette, David Rosenberg, Mark Dredze, and David Rabinowitz. Understanding\nand mitigating risks of generative ai in financial services. Proceedings of the 2025 ACM\nConference on Fairness, Accountability, and Transparency, 2025. URL https://api.\nsemanticscholar.org/CorpusID:278170940.\nIan J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sher-\njil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In\nZ. Ghahramani, M. Welling, C. Cortes, N. Lawrence, and K.Q. Weinberger (eds.), Ad-\nvances in Neural Information Processing Systems, volume 27. Curran Associates, Inc.,\n2014. URL https://proceedings.neurips.cc/paper_files/paper/2014/\nfile/f033ed80deb0234979a61f95710dbe25-Paper.pdf.\nCharlesAEGoodhart. Problemsofmonetarymanagement: theukexperience. InMonetarytheory\nandpractice: TheUKexperience,pp.91–121.Springer,1984.\nAnisha Gunjal, Anthony Wang, Elaine Lau, Vaskar Nath, Bing Liu, and Sean Hendryx. Rubrics\nas rewards: Reinforcement learning beyond verifiable domains. CoRR, abs/2507.17746, 2025.\ndoi: 10.48550/ARXIV.2507.17746. URL https://doi.org/10.48550/arXiv.2507.\n17746.\n14\nRewardModelsareMetricsinaTrenchCoat-Preprint\nDaya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu,\nShirongMa,PeiyiWang,XiaoBi,etal. Deepseek-r1: Incentivizingreasoningcapabilityinllms\nviareinforcementlearning. arXivpreprintarXiv:2501.12948,2025.\nSrishti Gureja, Lester James Validad Miranda, Shayekh Bin Islam, Rishabh Maheshwary, Drishti\nSharma, Gusti Triandi Winata, Nathan Lambert, Sebastian Ruder, Sara Hooker, and Marzieh\nFadaee. M-RewardBench: Evaluatingrewardmodelsinmultilingualsettings. InWanxiangChe,\nJoyce Nabende, Ekaterina Shutova, and Mohammad Taher Pilehvar (eds.), Proceedings of the\n63rdAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1: LongPapers),\npp. 43–58, Vienna, Austria, July 2025. Association for Computational Linguistics. ISBN 979-\n8-89176-251-0. doi: 10.18653/v1/2025.acl-long.3. URL https://aclanthology.org/\n2025.acl-long.3/.\nTahmid Hasan, Abhik Bhattacharjee, Md. Saiful Islam, Kazi Mubasshir, Yuan-Fang Li, Yong-Bin\nKang, M. Sohel Rahman, and Rifat Shahriyar. XL-sum: Large-scale multilingual abstractive\nsummarization for 44 languages. In Chengqing Zong, Fei Xia, Wenjie Li, and Roberto Navigli\n(eds.),FindingsoftheAssociationforComputationalLinguistics: ACL-IJCNLP2021,pp.4693–\n4703,Online,August2021.AssociationforComputationalLinguistics. doi: 10.18653/v1/2021.\nfindings-acl.413. URLhttps://aclanthology.org/2021.findings-acl.413/.\nHeliaHashemi,JasonEisner,CorbyRosset,BenjaminVanDurme,andChrisKedzie. LLM-rubric:\nA multidimensional, calibrated approach to automated evaluation of natural language texts. In\nLun-WeiKu,AndreMartins,andVivekSrikumar(eds.),Proceedingsofthe62ndAnnualMeeting\nof the Association for Computational Linguistics (Volume 1: Long Papers), pp. 13806–13834,\nBangkok,Thailand,August2024.AssociationforComputationalLinguistics. doi: 10.18653/v1/\n2024.acl-long.745. URLhttps://aclanthology.org/2024.acl-long.745/.\nOrHonovich, RoeeAharoni, JonathanHerzig, HagaiTaitelbaum, DoronKukliansy, VeredCohen,\nThomasScialom,IdanSzpektor,AvinatanHassidim,andYossiMatias.TRUE:Re-evaluatingfac-\ntualconsistencyevaluation. InMarineCarpuat,Marie-CatherinedeMarneffe,andIvanVladimir\nMezaRuiz(eds.),Proceedingsofthe2022ConferenceoftheNorthAmericanChapteroftheAs-\nsociationforComputationalLinguistics: HumanLanguageTechnologies, pp.3905–3920, Seat-\ntle,UnitedStates,July2022.AssociationforComputationalLinguistics. doi: 10.18653/v1/2022.\nnaacl-main.287. URLhttps://aclanthology.org/2022.naacl-main.287/.\nDavid M. Howcroft, Anya Belz, Miruna-Adriana Clinciu, Dimitra Gkatzia, Sadid A. Hasan, Saad\nMahamood,SimonMille,EmielvanMiltenburg,SashankSanthanam,andVerenaRieser.Twenty\nyears of confusion in human evaluation: NLG needs evaluation sheets and standardised defini-\ntions. InBrianDavis,YvetteGraham,JohnKelleher,andYajiSripada(eds.),Proceedingsofthe\n13th International Conference on Natural Language Generation, pp. 169–182, Dublin, Ireland,\nDecember 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.inlg-1.23.\nURLhttps://aclanthology.org/2020.inlg-1.23/.\nXinyu Hu, Mingqi Gao, Sen Hu, Yang Zhang, Yicheng Chen, Teng Xu, and Xiaojun Wan. Are\nLLM-based evaluators confusing NLG quality criteria? In Lun-Wei Ku, Andre Martins, and\nVivek Srikumar (eds.), Proceedings of the 62nd Annual Meeting of the Association for Com-\nputational Linguistics (Volume 1: Long Papers), pp. 9530–9570, Bangkok, Thailand, August\n2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.516. URL\nhttps://aclanthology.org/2024.acl-long.516/.\nHui Huang, Xingyuan Bu, Hongli Zhou, Yingqi Qu, Jing Liu, Muyun Yang, Bing Xu, and Tiejun\nZhao. An empirical study of LLM-as-a-judge for LLM evaluation: Fine-tuned judge model\nis not a general substitute for GPT-4. In Wanxiang Che, Joyce Nabende, Ekaterina Shutova,\nand Mohammad Taher Pilehvar (eds.), Findings of the Association for Computational Lin-\nguistics: ACL 2025, pp. 5880–5895, Vienna, Austria, July 2025. Association for Computa-\ntional Linguistics. ISBN 979-8-89176-256-5. doi: 10.18653/v1/2025.findings-acl.306. URL\nhttps://aclanthology.org/2025.findings-acl.306/.\nAaronHurst,AdamLerer,AdamPGoucher,AdamPerelman,AdityaRamesh,AidanClark,AJOs-\ntrow, Akila Welihinda, Alan Hayes, Alec Radford, et al. Gpt-4o system card. arXiv preprint\narXiv:2410.21276,2024.\n15\nRewardModelsareMetricsinaTrenchCoat-Preprint\nHamish Ivison, Yizhong Wang, Jiacheng Liu, Zeqiu Wu, Valentina Pyatkin, Nathan Lambert,\nNoah A Smith, Yejin Choi, and Hanna Hajishirzi. Unpacking dpo and ppo: Disentangling best\npracticesforlearningfrompreferencefeedback. Advancesinneuralinformationprocessingsys-\ntems,37:36602–36633,2024.\nAlon Jacovi, Jasmijn Bastings, Sebastian Gehrmann, Yoav Goldberg, and Katja Filippova. Diag-\nnosingaiexplanationmethodswithfolkconceptsofbehavior. JournalofArtificialIntelligence\nResearch,78:459–489,2023.\nAlonJacovi,AndrewWang,ChrisAlberti,ConnieTao,JonLipovetz,KateOlszewska,LukasHaas,\nMichelle Liu, Nate Keating, Adam Bloniarz, Carl Saroufim, Corey Fry, Dror Marcus, Doron\nKukliansky,GauravSinghTomar,JamesSwirhun,JinweiXing,LilyWang,MadhuGurumurthy,\nMichaelAaron,MoranAmbar,RachanaFellinger,RuiWang,ZizhaoZhang,SashaGoldshtein,\nand Dipanjan Das. The FACTS grounding leaderboard: Benchmarking llms’ ability to ground\nresponsestolong-forminput. CoRR,abs/2501.03200,2025. doi: 10.48550/ARXIV.2501.03200.\nURLhttps://doi.org/10.48550/arXiv.2501.03200.\nZiwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang,\nAndreaMadotto,andPascaleFung. Surveyofhallucinationinnaturallanguagegeneration. ACM\ncomputingsurveys,55(12):1–38,2023.\nZixuan Ke, Fangkai Jiao, Yifei Ming, Xuan-Phi Nguyen, Austin Xu, Do Xuan Long, Minzhi Li,\nChengwei Qin, Peifeng Wang, Silvio Savarese, et al. A survey of frontiers in llm reasoning:\nInference scaling, learning to reason, and agentic systems. arXiv preprint arXiv:2504.09037,\n2025.\nSeungone Kim, Jamin Shin, Yejin Cho, Joel Jang, Shayne Longpre, Hwaran Lee, Sangdoo Yun,\nSeongjin Shin, Sungdong Kim, James Thorne, and Minjoon Seo. Prometheus: Inducing\nfine-grained evaluation capability in language models. In The Twelfth International Confer-\nence on Learning Representations, 2024. URL https://openreview.net/forum?id=\n8euJaTveKw.\nSunghwan Kim, Dongjin Kang, Taeyoon Kwon, Hyungjoo Chae, Dongha Lee, and Jinyoung\nYeo. Rethinking reward model evaluation through the lens of reward overoptimization. In\nWanxiangChe, JoyceNabende, EkaterinaShutova, andMohammadTaherPilehvar(eds.), Pro-\nceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Vol-\nume 1: Long Papers), pp. 13252–13280, Vienna, Austria, July 2025. Association for Com-\nputational Linguistics. ISBN 979-8-89176-251-0. doi: 10.18653/v1/2025.acl-long.649. URL\nhttps://aclanthology.org/2025.acl-long.649/.\nKimi, Yifan Bai, Yiping Bao, Guanduo Chen, Jiahao Chen, Ningxin Chen, Ruijue Chen, Yanru\nChen, Yuankun Chen, Yutian Chen, et al. Kimi k2: Open agentic intelligence. arXiv preprint\narXiv:2507.20534,2025.\nRodneyMichaelKinney,ChloeAnastasiades,RussellAuthur,IzBeltagy,JonathanBragg,Alexan-\ndraBuraczynski,IsabelCachola,StefanCandra,YoganandChandrasekhar,ArmanCohan,Miles\nCrawford,DougDowney,JasonDunkelberger,OrenEtzioni,RobEvans,SergeyFeldman,Joseph\nGorney, David W. Graham, F.Q. Hu, Regan Huff, Daniel King, Sebastian Kohlmeier, Bailey\nKuehl, Michael Langan, Daniel Lin, Haokun Liu, Kyle Lo, Jaron Lochner, Kelsey MacMil-\nlan, Tyler C. Murray, Christopher Newell, Smita R Rao, Shaurya Rohatgi, Paul Sayre, Zejiang\nShen, Amanpreet Singh, Luca Soldaini, Shivashankar Subramanian, A. Tanaka, Alex D Wade,\nLinda M. Wagner, Lucy Lu Wang, Christopher Wilhelm, Caroline Wu, Jiangjiang Yang, An-\ngele Zamarron, Madeleine van Zuylen, and Daniel S. Weld. The semantic scholar open data\nplatform. ArXiv, abs/2301.10140, 2023. URL https://api.semanticscholar.org/\nCorpusID:256194545.\nBernard J. Koch and David Peterson. From protoscience to epistemic monoculture: How bench-\nmarking set the stage for the deep learning revolution. CoRR, abs/2404.06647, 2024. doi: 10.\n48550/ARXIV.2404.06647. URLhttps://doi.org/10.48550/arXiv.2404.06647.\n16\nRewardModelsareMetricsinaTrenchCoat-Preprint\nTom Kocmi, Vile´m Zouhar, Christian Federmann, and Matt Post. Navigating the metrics maze:\nReconcilingscoremagnitudesandaccuracies. InLun-WeiKu,AndreMartins,andVivekSriku-\nmar (eds.), Proceedings of the 62nd Annual Meeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers), pp. 1999–2014, Bangkok, Thailand, August 2024. Asso-\nciation for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.110. URL https:\n//aclanthology.org/2024.acl-long.110/.\nVictoria Krakovna, Jonathan Uesato, Vladimir Mikulik, Matthew Rahtz, Tom Everitt,\nRamana Kumar, Zac Kenton, Jan Leike, and Shane Legg. Specification gaming:\nthe flip side of ai ingenuity. https://deepmind.google/discover/blog/\nspecification-gaming-the-flip-side-of-ai-ingenuity/,2020.\nMichaelKrumdick,CharlesLovering,VarshiniReddy,SethEbner,andChrisTanner.Nofreelabels:\nLimitationsofllm-as-a-judgewithouthumangrounding.arXivpreprintarXiv:2503.05061,2025.\nWojciechKrys´cin´ski,RomainPaulus,CaimingXiong,andRichardSocher.Improvingabstractionin\ntextsummarization. InEllenRiloff,DavidChiang,JuliaHockenmaier,andJun’ichiTsujii(eds.),\nProceedingsofthe2018ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pp.\n1808–1817, Brussels, Belgium, October-November 2018. Association for Computational Lin-\nguistics. doi: 10.18653/v1/D18-1207. URLhttps://aclanthology.org/D18-1207/.\nFaisalLadhak, EsinDurmus, ClaireCardie, andKathleenMcKeown. WikiLingua: Anewbench-\nmarkdatasetforcross-lingualabstractivesummarization.InTrevorCohn,YulanHe,andYangLiu\n(eds.),FindingsoftheAssociationforComputationalLinguistics: EMNLP2020,pp.4034–4048,\nOnline, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.\nfindings-emnlp.360. URL https://aclanthology.org/2020.findings-emnlp.\n360/.\nNathanLambert,JacobMorrison,ValentinaPyatkin,ShengyiHuang,HamishIvison,FaezeBrah-\nman,LesterJamesVMiranda,AlisaLiu,NouhaDziri,ShaneLyu,etal.Tulu3:Pushingfrontiers\ninopenlanguagemodelpost-training. arXivpreprintarXiv:2411.15124,2024.\nNathanLambert,ValentinaPyatkin,JacobMorrison,LJMiranda,BillYuchenLin,KhyathiChandu,\nNouha Dziri, Sachin Kumar, Tom Zick, Yejin Choi, Noah A. Smith, and Hannaneh Hajishirzi.\nRewardBench: Evaluating reward models for language modeling. In Luis Chiruzzo, Alan Rit-\nter, and Lu Wang (eds.), Findings of the Association for Computational Linguistics: NAACL\n2025, pp. 1755–1797, Albuquerque, New Mexico, April 2025. Association for Computational\nLinguistics. ISBN979-8-89176-195-7. doi: 10.18653/v1/2025.findings-naacl.96. URLhttps:\n//aclanthology.org/2025.findings-naacl.96/.\nYann LeCun. Predictive learning. https://www.youtube.com/watch?v=\nOunt2Y4qxQo&t=1072s,2016.\nHarrisonLee,SamratPhatale,HassanMansoor,ThomasMesnard,JohanFerret,KellieLu,Colton\nBishop,EthanHall,VictorCarbune,AbhinavRastogi,andSushantPrakash. RLAIFvs.RLHF:\nscaling reinforcement learning from human feedback with AI feedback. In Forty-first Interna-\ntionalConferenceonMachineLearning, ICML2024, Vienna, Austria, July21-27, 2024.Open-\nReview.net,2024a. URLhttps://openreview.net/forum?id=uydQ2W41KO.\nYukyungLee,JoonghoonKim,JaeheeKim,HyowonCho,JaewookKang,PilsungKang,andNa-\njoungKim. Checkeval: Areliablellm-as-a-judgeframeworkforevaluatingtextgenerationusing\nchecklists. arXivpreprintarXiv:2403.18771,2024b.\nJan Leike, David Krueger, Tom Everitt, Miljan Martic, Vishal Maini, and Shane Legg. Scalable\nagentalignmentviarewardmodeling: aresearchdirection. ArXiv,abs/1811.07871,2018. URL\nhttps://api.semanticscholar.org/CorpusID:53745764.\nJixuanLeng,ChengsongHuang,BanghuaZhu,andJiaxinHuang.TamingoverconfidenceinLLMs:\nRewardcalibrationinRLHF. InTheThirteenthInternationalConferenceonLearningRepresen-\ntations,2025. URLhttps://openreview.net/forum?id=l0tg0jzsdL.\n17\nRewardModelsareMetricsinaTrenchCoat-Preprint\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer\nLevy, Veselin Stoyanov, and Luke Zettlemoyer. BART: Denoising sequence-to-sequence pre-\ntraining for natural language generation, translation, and comprehension. In Dan Jurafsky,\nJoyce Chai, Natalie Schluter, and Joel Tetreault (eds.), Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics, pp. 7871–7880, Online, July 2020. As-\nsociation for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.703. URL https:\n//aclanthology.org/2020.acl-main.703/.\nPijiLi,LidongBing,andWaiLam. Actor-criticbasedtrainingframeworkforabstractivesumma-\nrization. CoRR,abs/1803.11070,2018. URLhttp://arxiv.org/abs/1803.11070.\nHunter Lightman, Vineet Kosaraju, Yuri Burda, Harrison Edwards, Bowen Baker, Teddy Lee, Jan\nLeike,JohnSchulman,IlyaSutskever,andKarlCobbe. Let’sverifystepbystep. InTheTwelfth\nInternationalConferenceonLearningRepresentations,2024. URLhttps://openreview.\nnet/forum?id=v8L0pN6EOi.\nChin-YewLin. ROUGE:Apackageforautomaticevaluationofsummaries. InTextSummarization\nBranchesOut, pp.74–81, Barcelona, Spain, July2004.AssociationforComputationalLinguis-\ntics. URLhttps://aclanthology.org/W04-1013/.\nChrisYuhaoLiu, LiangZeng, JiacaiLiu, RuiYan, JujieHe, ChaojieWang, ShuichengYan, Yang\nLiu,andYahuiZhou. Skywork-reward:Bagoftricksforrewardmodelinginllms. arXivpreprint\narXiv:2410.18451,2024.\nSiqi Liu, Ian Gemp, Luke Marris, Georgios Piliouras, Nicolas Heess, and Marc Lanctot. Re-\nevaluatingopen-endedevaluationoflargelanguagemodels.InTheThirteenthInternationalCon-\nference on Learning Representations, 2025a. URL https://openreview.net/forum?\nid=kbOAIXKWgx.\nTianqiLiu,WeiXiong,JieRen,LichangChen,JunruWu,RishabhJoshi,YangGao,JiamingShen,\nZhenQin,TianheYu,DanielSohn,AnastasiaMakarova,JeremiahZheLiu,YuanLiu,BilalPiot,\nAbeIttycheriah,AviralKumar,andMohammadSaleh. RRM:Robustrewardmodeltrainingmit-\nigatesrewardhacking. InTheThirteenthInternationalConferenceonLearningRepresentations,\n2025b. URLhttps://openreview.net/forum?id=88AS5MQnmC.\nYantao Liu, Zijun Yao, Rui Min, Yixin Cao, Lei Hou, and Juanzi Li. Rm-bench: Benchmarking\nrewardmodelsoflanguagemodelswithsubtletyandstyle. InTheThirteenthInternationalCon-\nferenceonLearningRepresentations,ICLR2025,Singapore,April24-28,2025.OpenReview.net,\n2025c. URLhttps://openreview.net/forum?id=QEHrmQPBdd.\nQingsong Ma, Ondˇrej Bojar, and Yvette Graham. Results of the WMT18 metrics shared task:\nBoth characters and embeddings achieve good performance. In Ondˇrej Bojar, Rajen Chatter-\njee, Christian Federmann, Mark Fishel, Yvette Graham, Barry Haddow, Matthias Huck, An-\ntonio Jimeno Yepes, Philipp Koehn, Christof Monz, Matteo Negri, Aure´lie Ne´ve´ol, Mariana\nNeves, Matt Post, Lucia Specia, Marco Turchi, and Karin Verspoor (eds.), Proceedings of the\nThirdConferenceonMachineTranslation: SharedTaskPapers,pp.671–688,Belgium,Brussels,\nOctober 2018. Association for Computational Linguistics. doi: 10.18653/v1/W18-6450. URL\nhttps://aclanthology.org/W18-6450/.\nQingsong Ma, Johnny Wei, Ondˇrej Bojar, and Yvette Graham. Results of the WMT19 metrics\nsharedtask: Segment-levelandstrongMTsystemsposebigchallenges. InOndˇrejBojar,Rajen\nChatterjee, Christian Federmann, Mark Fishel, Yvette Graham, Barry Haddow, Matthias Huck,\nAntonio Jimeno Yepes, Philipp Koehn, Andre´ Martins, Christof Monz, Matteo Negri, Aure´lie\nNe´ve´ol, Mariana Neves, Matt Post, Marco Turchi, and Karin Verspoor (eds.), Proceedings of\ntheFourthConferenceonMachineTranslation(Volume2: SharedTaskPapers,Day1),pp.62–\n90,Florence,Italy,August2019.AssociationforComputationalLinguistics. doi: 10.18653/v1/\nW19-5302. URLhttps://aclanthology.org/W19-5302/.\nSaumya Malik, Valentina Pyatkin, Sander Land, Jacob Morrison, Noah A. Smith, Hannaneh Ha-\njishirzi, and Nathan Lambert. Rewardbench 2: Advancing reward model evaluation. CoRR,\nabs/2506.01937, 2025. doi: 10.48550/ARXIV.2506.01937. URL https://doi.org/10.\n48550/arXiv.2506.01937.\n18\nRewardModelsareMetricsinaTrenchCoat-Preprint\nDavid Manheim and Scott Garrabrant. Categorizing variants of goodhart’s law. arXiv preprint\narXiv:1803.04585,2018.\nNitika Mathur, Johnny Wei, Markus Freitag, Qingsong Ma, and Ondˇrej Bojar. Results of the\nWMT20metricssharedtask. InLo¨ıcBarrault,OndˇrejBojar,FethiBougares,RajenChatterjee,\nMartaR.Costa-jussa`,ChristianFedermann,MarkFishel,AlexanderFraser,YvetteGraham,Paco\nGuzman,BarryHaddow,MatthiasHuck,AntonioJimenoYepes,PhilippKoehn,Andre´ Martins,\nMakotoMorishita,ChristofMonz,MasaakiNagata,ToshiakiNakazawa,andMatteoNegri(eds.),\nProceedings of the Fifth Conference on Machine Translation, pp. 688–725, Online, November\n2020. Association for Computational Linguistics. URL https://aclanthology.org/\n2020.wmt-1.77/.\nJoshuaMaynez,ShashiNarayan,BerndBohnet,andRyanMcDonald.Onfaithfulnessandfactuality\nin abstractive summarization. In Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel Tetreault\n(eds.),Proceedingsofthe58thAnnualMeetingoftheAssociationforComputationalLinguistics,\npp.1906–1919,Online,July2020.AssociationforComputationalLinguistics. doi:10.18653/v1/\n2020.acl-main.173. URLhttps://aclanthology.org/2020.acl-main.173/.\nR.ThomasMcCoy,ElliePavlick,andTalLinzen.Rightforthewrongreasons:Diagnosingsyntactic\nheuristics in natural language inference. In Anna Korhonen, David Traum, and Llu´ıs Ma`rquez\n(eds.),Proceedingsofthe57thAnnualMeetingoftheAssociationforComputationalLinguistics,\npp. 3428–3448, Florence, Italy, July 2019. Association for Computational Linguistics. doi: 10.\n18653/v1/P19-1334. URLhttps://aclanthology.org/P19-1334/.\nYannick Metz, Andras Geiszl, Raphae¨l Baur, and Mennatallah El-Assady. Reward learning from\nmultiple feedback types. In The Thirteenth International Conference on Learning Representa-\ntions,2025. URLhttps://openreview.net/forum?id=9Ieq8jQNAl.\nSewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen-tau Yih, Pang Koh, Mohit Iyyer,\nLukeZettlemoyer,andHannanehHajishirzi. FActScore: Fine-grainedatomicevaluationoffac-\ntual precision in long form text generation. In Houda Bouamor, Juan Pino, and Kalika Bali\n(eds.), Proceedings of the 2023 Conference on Empirical Methods in Natural Language Pro-\ncessing, pp.12076–12100, Singapore, December2023.AssociationforComputationalLinguis-\ntics.doi:10.18653/v1/2023.emnlp-main.741.URLhttps://aclanthology.org/2023.\nemnlp-main.741/.\nVolodymyrMnih, NicolasHeess, Alex Graves, andKoray Kavukcuoglu. Recurrent modelsof vi-\nsualattention. InZoubinGhahramani,MaxWelling,CorinnaCortes,NeilD.Lawrence,andKil-\nianQ.Weinberger(eds.),AdvancesinNeuralInformationProcessingSystems27: AnnualCon-\nference on Neural Information Processing Systems 2014, December 8-13 2014, Montreal, Que-\nbec,Canada,pp.2204–2212,2014.URLhttps://proceedings.neurips.cc/paper/\n2014/hash/09c6c3783b4a70054da74f2538ed47c6-Abstract.html.\nBhuvanashree Murugadoss, Christian Po¨litz, Ian Drosos, Vu Le, Nick McKenna, Carina Suzana\nNegreanu,ChrisParnin,andAdvaitSarkar. Evaluatingtheevaluator: Measuringllms’adherence\nto task evaluation instructions. In Toby Walsh, Julie Shah, and Zico Kolter (eds.), AAAI-25,\nSponsoredbytheAssociationfortheAdvancementofArtificialIntelligence,February25-March\n4, 2025, Philadelphia, PA, USA, pp. 19589–19597. AAAI Press, 2025. doi: 10.1609/AAAI.\nV39I18.34157. URLhttps://doi.org/10.1609/aaai.v39i18.34157.\nVaishnavh Nagarajan, Anders Andreassen, and Behnam Neyshabur. Understanding the failure\nmodes of out-of-distribution generalization. In International Conference on Learning Repre-\nsentations,2021. URLhttps://openreview.net/forum?id=fSTD6NFIW_b.\nOpenAI. Gpt-5 system card, Aug 2025. URL https://cdn.openai.com/\ngpt-5-system-card.pdf.\nLongOuyang,JeffWu,XuJiang,DiogoAlmeida,CarrollL.Wainwright,PamelaMishkin,Chong\nZhang,SandhiniAgarwal,KatarinaSlama,AlexRay,JohnSchulman,JacobHilton,FraserKel-\nton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike,\nandRyanLowe. Traininglanguagemodelstofollowinstructionswithhumanfeedback. InPro-\nceedingsofthe36thInternationalConferenceonNeuralInformationProcessingSystems,NIPS\n’22,RedHook,NY,USA,2022.CurranAssociatesInc. ISBN9781713871088.\n19\nRewardModelsareMetricsinaTrenchCoat-Preprint\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: a method for automatic\nevaluation of machine translation. In Pierre Isabelle, Eugene Charniak, and Dekang Lin (eds.),\nProceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pp.\n311–318, Philadelphia, Pennsylvania, USA, July 2002. Association for Computational Linguis-\ntics. doi: 10.3115/1073083.1073135. URLhttps://aclanthology.org/P02-1040/.\nRamakanthPasunuruandMohitBansal. Reinforcedvideocaptioningwithentailmentrewards. In\nMarthaPalmer,RebeccaHwa,andSebastianRiedel(eds.),Proceedingsofthe2017Conference\non Empirical Methods in Natural Language Processing, pp. 979–985, Copenhagen, Denmark,\nSeptember2017.AssociationforComputationalLinguistics. doi: 10.18653/v1/D17-1103. URL\nhttps://aclanthology.org/D17-1103/.\nRamakanthPasunuruandMohitBansal. Multi-rewardreinforcedsummarizationwithsaliencyand\nentailment. InMarilynWalker,HengJi,andAmandaStent(eds.),Proceedingsofthe2018Con-\nference of the North American Chapter of the Association for Computational Linguistics: Hu-\nman Language Technologies, Volume 2 (Short Papers), pp. 646–653, New Orleans, Louisiana,\nJune 2018. Association for Computational Linguistics. doi: 10.18653/v1/N18-2102. URL\nhttps://aclanthology.org/N18-2102/.\nRomain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\nsummarization. InInternationalConferenceonLearningRepresentations,2018. URLhttps:\n//openreview.net/forum?id=HkAClQgA-.\nStefano Perrella, Lorenzo Proietti, Alessandro Scire`, Edoardo Barba, and Roberto Navigli.\nGuardiansofthemachinetranslationmeta-evaluation: Sentinelmetricsfallin! InLun-WeiKu,\nAndreMartins,andVivekSrikumar(eds.),Proceedingsofthe62ndAnnualMeetingoftheAssoci-\nationforComputationalLinguistics(Volume1:LongPapers),pp.16216–16244,Bangkok,Thai-\nland,August2024.AssociationforComputationalLinguistics. doi: 10.18653/v1/2024.acl-long.\n856. URLhttps://aclanthology.org/2024.acl-long.856/.\nMatt Post. A call for clarity in reporting BLEU scores. In Ondˇrej Bojar, Rajen Chatterjee,\nChristianFedermann, MarkFishel, YvetteGraham, BarryHaddow, MatthiasHuck, AntonioJi-\nmeno Yepes, Philipp Koehn, Christof Monz, Matteo Negri, Aure´lie Ne´ve´ol, Mariana Neves,\nMatt Post, Lucia Specia, Marco Turchi, and Karin Verspoor (eds.), Proceedings of the Third\nConference on Machine Translation: Research Papers, pp. 186–191, Brussels, Belgium, Oc-\ntober 2018. Association for Computational Linguistics. doi: 10.18653/v1/W18-6319. URL\nhttps://aclanthology.org/W18-6319/.\nZhaopengQiu,XianWu,andWeiFan.Automaticdistractorgenerationformultiplechoicequestions\nin standard tests. In Donia Scott, Nuria Bel, and Chengqing Zong (eds.), Proceedings of the\n28th International Conference on Computational Linguistics, pp. 2096–2106, Barcelona, Spain\n(Online),December2020.InternationalCommitteeonComputationalLinguistics.doi:10.18653/\nv1/2020.coling-main.189. URL https://aclanthology.org/2020.coling-main.\n189/.\nRafael Rafailov, Archit Sharma, Eric Mitchell, Christopher D. Manning, Stefano Ermon, and\nChelseaFinn. Directpreferenceoptimization: Yourlanguagemodelissecretlyarewardmodel.\nInAliceOh,TristanNaumann,AmirGloberson,KateSaenko,MoritzHardt,andSergeyLevine\n(eds.), Advances in Neural Information Processing Systems 36: Annual Conference on Neural\nInformation Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 -\n16,2023,2023. URLhttp://papers.nips.cc/paper_files/paper/2023/hash/\na85b405ed65c6477a4fe8302b5e06ce7-Abstract-Conference.html.\nDeborah Raji, Emily Denton, Emily M. Bender, Alex Hanna, and Amandalynne\nPaullada. Ai and the everything in the whole wide world benchmark. In J. Van-\nschoren and S. Yeung (eds.), Proceedings of the Neural Information Processing\nSystems Track on Datasets and Benchmarks, volume 1, 2021. URL https:\n//datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/\n2021/file/084b6fbb10729ed4da8c3d3f5a3ae7c9-Paper-round2.pdf.\nPeter A. Rankel, John M. Conroy, Hoa Trang Dang, and Ani Nenkova. A decade of automatic\ncontent evaluation of news summaries: Reassessing the state of the art. In Hinrich Schuetze,\n20\nRewardModelsareMetricsinaTrenchCoat-Preprint\nPascaleFung, andMassimoPoesio(eds.), Proceedingsofthe51stAnnualMeetingoftheAsso-\nciation for Computational Linguistics (Volume 2: Short Papers), pp. 131–136, Sofia, Bulgaria,\nAugust 2013. Association for Computational Linguistics. URL https://aclanthology.\norg/P13-2024/.\nMarc’AurelioRanzato,SumitChopra,MichaelAuli,andWojciechZaremba. Sequenceleveltrain-\ningwithrecurrentneuralnetworks. InYoshuaBengioandYannLeCun(eds.),4thInternational\nConference on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May 2-4, 2016,\nConferenceTrackProceedings,2016. URLhttp://arxiv.org/abs/1511.06732.\nHannah Rashkin, Vitaly Nikolaev, Matthew Lamm, Lora Aroyo, Michael Collins, Dipanjan Das,\nSlavPetrov,GauravSinghTomar,IuliaTurc,andDavidReitter. Measuringattributioninnatural\nlanguage generation models. Computational Linguistics, 49(4):777–840, December 2023. doi:\n10.1162/coli a 00486. URLhttps://aclanthology.org/2023.cl-4.2/.\nCharvi Rastogi, Tian Huey Teh, Pushkar Mishra, Roma Patel, Zoe Ashwood, Aida Mostafazadeh\nDavani, Mark Diaz, Michela Paganini, Alicia Parrish, Ding Wang, Vinodkumar Prabhakaran,\nLoraAroyo,andVerenaRieser.Insightsondisagreementpatternsinmultimodalsafetyperception\nacrossdiverseratergroups. InNeuripsSafeGenerativeAIWorkshop2024,2024. URLhttps:\n//openreview.net/forum?id=8TI0lUrJBP.\nCharviRastogi,TianHueyTeh,PushkarMishra,RomaPatel,DingWang,MarkD´ıaz,AliciaParrish,\nAidaMostafazadehDavani,ZoeAshwood,MichelaPaganini,etal.Whoseviewofsafety?adeep\ndivedatasetforpluralisticalignmentoftext-to-imagemodels. arXivpreprintarXiv:2507.13383,\n2025.\nRicardo Rei, Marcos Treviso, Nuno M. Guerreiro, Chrysoula Zerva, Ana C Farinha, Christine\nMaroti, Jose´ G. C. de Souza, Taisiya Glushkova, Duarte Alves, Luisa Coheur, Alon Lavie,\nand Andre´ F. T. Martins. CometKiwi: IST-unbabel 2022 submission for the quality estima-\ntionsharedtask. InPhilippKoehn,Lo¨ıcBarrault,OndˇrejBojar,FethiBougares,RajenChatter-\njee,MartaR.Costa-jussa`,ChristianFedermann,MarkFishel,AlexanderFraser,MarkusFreitag,\nYvette Graham, Roman Grundkiewicz, Paco Guzman, Barry Haddow, Matthias Huck, Antonio\nJimenoYepes,TomKocmi,Andre´ Martins,MakotoMorishita,ChristofMonz,MasaakiNagata,\nToshiakiNakazawa,MatteoNegri,Aure´lieNe´ve´ol,MarianaNeves,MartinPopel,MarcoTurchi,\nand Marcos Zampieri (eds.), Proceedings of the Seventh Conference on Machine Translation\n(WMT),pp.634–645,AbuDhabi,UnitedArabEmirates(Hybrid),December2022.Association\nforComputationalLinguistics. URLhttps://aclanthology.org/2022.wmt-1.60/.\nEhudReiter. AstructuredreviewofthevalidityofBLEU. Comput.Linguistics,44(3),2018. doi:\n10.1162/COLI\\ A\\ 00322. URLhttps://doi.org/10.1162/coli_a_00322.\nStevenJ.Rennie,EtienneMarcheret,YoussefMroueh,JerretRoss,andVaibhavaGoel. Self-critical\nsequencetrainingforimagecaptioning. In2017IEEEConferenceonComputerVisionandPat-\nternRecognition,CVPR2017,Honolulu,HI,USA,July21-26,2017,pp.1179–1195.IEEECom-\nputer Society, 2017. doi: 10.1109/CVPR.2017.131. URL https://doi.org/10.1109/\nCVPR.2017.131.\nMarcoTulioRibeiro,SameerSingh,andCarlosGuestrin. ”whyshoulditrustyou?”explainingthe\npredictionsofanyclassifier. InProceedingsofthe22ndACMSIGKDDinternationalconference\nonknowledgediscoveryanddatamining,pp.1135–1144,2016.\nSte´phane Ross, Geoffrey J. Gordon, and Drew Bagnell. A reduction of imitation learning and\nstructured prediction to no-regret online learning. In Geoffrey J. Gordon, David B. Dunson,\nandMiroslavDud´ık(eds.),ProceedingsoftheFourteenthInternationalConferenceonArtificial\nIntelligenceandStatistics,AISTATS2011,FortLauderdale,USA,April11-13,2011,volume15\nof JMLR Proceedings, pp. 627–635. JMLR.org, 2011. URL http://proceedings.mlr.\npress/v15/ross11a/ross11a.pdf.\nKeita Saito, Akifumi Wachi, Koki Wataoka, and Youhei Akimoto. Verbosity bias in preference\nlabelingbylargelanguagemodels. CoRR,abs/2310.10076, 2023. doi: 10.48550/ARXIV.2310.\n10076. URLhttps://doi.org/10.48550/arXiv.2310.10076.\n21\nRewardModelsareMetricsinaTrenchCoat-Preprint\nJohnSchulman,FilipWolski,PrafullaDhariwal,AlecRadford,andOlegKlimov. Proximalpolicy\noptimization algorithms. CoRR, abs/1707.06347, 2017. URL http://arxiv.org/abs/\n1707.06347.\nThomasScialom,SylvainLamprier,BenjaminPiwowarski,andJacopoStaiano.Answersunite!un-\nsupervisedmetricsforreinforcedsummarizationmodels.InKentaroInui,JingJiang,VincentNg,\nandXiaojun Wan(eds.), Proceedingsof the2019Conferenceon EmpiricalMethodsin Natural\nLanguageProcessingandthe9thInternationalJointConferenceonNaturalLanguageProcess-\ning (EMNLP-IJCNLP), pp. 3246–3256, Hong Kong, China, November 2019. Association for\nComputational Linguistics. doi: 10.18653/v1/D19-1320. URL https://aclanthology.\norg/D19-1320/.\nThomas Scialom, Paul-Alexis Dray, Sylvain Lamprier, Benjamin Piwowarski, and Jacopo Sta-\niano. MLSUM: The multilingual summarization corpus. In Bonnie Webber, Trevor Cohn,\nYulan He, and Yang Liu (eds.), Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), pp. 8051–8067, Online, November 2020. Associ-\nation for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.647. URL https:\n//aclanthology.org/2020.emnlp-main.647/.\nThomasScialom,Paul-AlexisDray,SylvainLamprier,BenjaminPiwowarski,JacopoStaiano,Alex\nWang,andPatrickGallinari.QuestEval:Summarizationasksforfact-basedevaluation.InMarie-\nFrancine Moens, Xuanjing Huang, Lucia Specia, and Scott Wen-tau Yih (eds.), Proceedings of\nthe 2021 Conference on Empirical Methods in Natural Language Processing, pp. 6594–6604,\nOnline and Punta Cana, Dominican Republic, November 2021. Association for Computational\nLinguistics.doi:10.18653/v1/2021.emnlp-main.529.URLhttps://aclanthology.org/\n2021.emnlp-main.529/.\nDonia Scott and Johanna Moore. An nlg evaluation competition? eight reasons to be cautious.\nProceedingsoftheWorkshoponSharedTasksandComparativeEvaluationinNaturalLanguage\nGeneration,2006.\nThibault Sellam, Dipanjan Das, and Ankur Parikh. BLEURT: Learning robust metrics for text\ngeneration. InDanJurafsky,JoyceChai,NatalieSchluter,andJoelTetreault(eds.),Proceedings\nof the 58th Annual Meeting of the Association for Computational Linguistics, pp. 7881–7892,\nOnline,July2020.AssociationforComputationalLinguistics. doi: 10.18653/v1/2020.acl-main.\n704. URLhttps://aclanthology.org/2020.acl-main.704/.\nMrinank Sharma, Meg Tong, Tomasz Korbak, David Duvenaud, Amanda Askell, Samuel R.\nBowman, Esin DURMUS, Zac Hatfield-Dodds, Scott R Johnston, Shauna M Kravec, Timo-\nthy Maxwell, Sam McCandlish, Kamal Ndousse, Oliver Rausch, Nicholas Schiefer, Da Yan,\nMiranda Zhang, and Ethan Perez. Towards understanding sycophancy in language models.\nIn The Twelfth International Conference on Learning Representations, 2024. URL https:\n//openreview.net/forum?id=tvhaxkMKAn.\nShiqiShen,YongCheng,ZhongjunHe,WeiHe,HuaWu,MaosongSun,andYangLiu. Minimum\nrisktrainingforneuralmachinetranslation. InKatrinErkandNoahA.Smith(eds.),Proceedings\nofthe54thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:LongPa-\npers),pp.1683–1692,Berlin,Germany,August2016.AssociationforComputationalLinguistics.\ndoi: 10.18653/v1/P16-1159. URLhttps://aclanthology.org/P16-1159/.\nRaphaelShu,KangMinYoo,andJung-WooHa. Rewardoptimizationforneuralmachinetransla-\ntionwithlearnedmetrics. CoRR,abs/2104.07541,2021. URLhttps://arxiv.org/abs/\n2104.07541.\nShivalika Singh, Yiyang Nan, Alex Wang, Daniel D’Souza, Sayash Kapoor, Ahmet U¨stu¨n, Sanmi\nKoyejo, Yuntian Deng, Shayne Longpre, Noah A Smith, et al. The leaderboard illusion. arXiv\npreprintarXiv:2504.20879,2025.\nJoarMaxViktorSkalse,NikolausH.R.Howe,DmitriiKrasheninnikov,andDavidKrueger. Defin-\ning and characterizing reward gaming. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave,\nand Kyunghyun Cho (eds.), Advances in Neural Information Processing Systems, 2022. URL\nhttps://openreview.net/forum?id=yb3HOXO3lX2.\n22\nRewardModelsareMetricsinaTrenchCoat-Preprint\nNisanStiennon,LongOuyang,JeffWu,DanielM.Ziegler,RyanLowe,ChelseaVoss,AlecRadford,\nDarioAmodei,andPaulChristiano. Learningtosummarizefromhumanfeedback. InProceed-\ningsofthe34thInternationalConferenceonNeuralInformationProcessingSystems,NIPS’20,\nRedHook,NY,USA,2020.CurranAssociatesInc. ISBN9781713829546.\nHao Sun, Yunyi Shen, and Jean-Francois Ton. Rethinking reward modeling in preference-based\nlargelanguagemodelalignment. InTheThirteenthInternationalConferenceonLearningRepre-\nsentations,2025. URLhttps://openreview.net/forum?id=rfdblE10qm.\nJiaoSun,ThibaultSellam,ElizabethClark,TuVu,TimothyDozat,DanGarrette,AdityaSiddhant,\nJacobEisenstein,andSebastianGehrmann. Dialect-robustevaluationofgeneratedtext. InAnna\nRogers,JordanBoyd-Graber,andNaoakiOkazaki(eds.),Proceedingsofthe61stAnnualMeet-\ning of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 6010–6028,\nToronto,Canada,July2023.AssociationforComputationalLinguistics. doi: 10.18653/v1/2023.\nacl-long.331. URLhttps://aclanthology.org/2023.acl-long.331/.\nSimeng Sun, Ori Shapira, Ido Dagan, and Ani Nenkova. How to compare summarizers without\ntarget length? pitfalls, solutions and re-examination of the neural summarization literature. In\nAntoine Bosselut, Asli Celikyilmaz, Marjan Ghazvininejad, Srinivasan Iyer, Urvashi Khandel-\nwal, Hannah Rashkin, and Thomas Wolf (eds.), Proceedings of the Workshop on Methods for\nOptimizing and Evaluating Neural Language Generation, pp. 21–29, Minneapolis, Minnesota,\nJune 2019. Association for Computational Linguistics. doi: 10.18653/v1/W19-2303. URL\nhttps://aclanthology.org/W19-2303/.\nRichardS.SuttonandAndrewG.Barto.Reinforcementlearning-anintroduction,2ndEdition.MIT\nPress, 2018. URL http://www.incompleteideas.net/book/the-book-2nd.\nhtml.\nRachel Thomas and David Uminsky. The problem with metrics is a fundamental problem for ai.\narXivpreprintarXiv:2002.08512,2020.\nBrianThompson,NitikaMathur,DanielDeutsch,andHudaKhayrallah. Improvingstatisticalsig-\nnificance in human evaluation of automatic metrics via soft pairwise accuracy. In Barry Had-\ndow, Tom Kocmi, Philipp Koehn, and Christof Monz (eds.), Proceedings of the Ninth Con-\nference on Machine Translation, pp. 1222–1234, Miami, Florida, USA, November 2024. As-\nsociation for Computational Linguistics. doi: 10.18653/v1/2024.wmt-1.118. URL https:\n//aclanthology.org/2024.wmt-1.118/.\nRamakrishna Vedantam, C. Lawrence Zitnick, and Devi Parikh. Cider: Consensus-based image\ndescriptionevaluation. InIEEEConferenceonComputerVisionandPatternRecognition,CVPR\n2015,Boston,MA,USA,June7-12,2015,pp.4566–4575.IEEEComputerSociety,2015.doi:10.\n1109/CVPR.2015.7299087. URLhttps://doi.org/10.1109/CVPR.2015.7299087.\nAlexWang,KyunghyunCho,andMikeLewis. Askingandansweringquestionstoevaluatethefac-\ntualconsistencyofsummaries. InDanJurafsky,JoyceChai,NatalieSchluter,andJoelTetreault\n(eds.),Proceedingsofthe58thAnnualMeetingoftheAssociationforComputationalLinguistics,\npp.5008–5020,Online,July2020.AssociationforComputationalLinguistics. doi:10.18653/v1/\n2020.acl-main.450. URLhttps://aclanthology.org/2020.acl-main.450/.\nPeiyi Wang, Lei Li, Liang Chen, Zefan Cai, Dawei Zhu, Binghuai Lin, Yunbo Cao, Lingpeng\nKong, Qi Liu, Tianyu Liu, and Zhifang Sui. Large language models are not fair evaluators. In\nLun-WeiKu,AndreMartins,andVivekSrikumar(eds.),Proceedingsofthe62ndAnnualMeet-\ning of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 9440–9450,\nBangkok,Thailand,August2024.AssociationforComputationalLinguistics. doi: 10.18653/v1/\n2024.acl-long.511. URLhttps://aclanthology.org/2024.acl-long.511/.\nJerry Wei, Chengrun Yang, Xinying Song, Yifeng Lu, Nathan Hu, Jie Huang, Dustin Tran,\nDaiyi Peng, Ruibo Liu, Da Huang, Cosmo Du, and Quoc V. Le. Long-form factual-\nity in large language models. In Amir Globersons, Lester Mackey, Danielle Belgrave,\nAngela Fan, Ulrich Paquet, Jakub M. Tomczak, and Cheng Zhang (eds.), Advances in\nNeural Information Processing Systems 38: Annual Conference on Neural Information\nProcessing Systems 2024, NeurIPS 2024, Vancouver, BC, Canada, December 10 - 15,\n23\nRewardModelsareMetricsinaTrenchCoat-Preprint\n2024, 2024. URL http://papers.nips.cc/paper_files/paper/2024/hash/\n937ae0e83eb08d2cb8627fe1def8c751-Abstract-Conference.html.\nJohnnyWeiandRobinJia. ThestatisticaladvantageofautomaticNLGmetricsatthesystemlevel.\nIn Chengqing Zong, Fei Xia, Wenjie Li, and Roberto Navigli (eds.), Proceedings of the 59th\nAnnualMeetingoftheAssociationforComputationalLinguisticsandthe11thInternationalJoint\nConferenceonNaturalLanguageProcessing(Volume1: LongPapers),pp.6840–6854,Online,\nAugust 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.acl-long.533.\nURLhttps://aclanthology.org/2021.acl-long.533/.\nTianjunWei,WeiWen,RuizhiQiao,XingSun,andJianghongMa. Rocketeval:Efficientautomated\nLLMevaluationviagradingchecklist. InTheThirteenthInternationalConferenceonLearning\nRepresentations,2025. URLhttps://openreview.net/forum?id=zJjzNj6QUe.\nJiaxin Wen, Ruiqi Zhong, Akbir Khan, Ethan Perez, Jacob Steinhardt, Minlie Huang, Samuel R.\nBowman, He He, and Shi Feng. Language models learn to mislead humans via RLHF. In\nThe Thirteenth International Conference on Learning Representations, 2025a. URL https:\n//openreview.net/forum?id=xJljiPE6dg.\nXueru Wen, Jie Lou, Zichao Li, Yaojie Lu, XingYu XingYu, Yuqiu Ji, Guohai Xu, Hongyu Lin,\nBen He, Xianpei Han, Le Sun, and Debing Zhang. Cheems: A practical guidance for building\nand evaluating Chinese reward models from scratch. In Wanxiang Che, Joyce Nabende, Eka-\nterina Shutova, and Mohammad Taher Pilehvar (eds.), Proceedings of the 63rd Annual Meeting\nof the Association for Computational Linguistics (Volume 1: Long Papers), pp. 15187–15211,\nVienna, Austria, July 2025b. Association for Computational Linguistics. ISBN 979-8-89176-\n251-0. doi: 10.18653/v1/2025.acl-long.737. URLhttps://aclanthology.org/2025.\nacl-long.737/.\nXueru Wen, Jie Lou, Yaojie Lu, Hongyu Lin, XingYu, Xinyu Lu, Ben He, Xianpei Han, Debing\nZhang, and Le Sun. Rethinking reward model evaluation: Are we barking up the wrong tree?\nInTheThirteenthInternationalConferenceonLearningRepresentations,2025c. URLhttps:\n//openreview.net/forum?id=Cnwz9jONi5.\nRonaldJ.Williams.Simplestatisticalgradient-followingalgorithmsforconnectionistreinforcement\nlearning. Machine Learning, 8:229–256, 1992. doi: 10.1007/BF00992696. URL https://\ndoi.org/10.1007/BF00992696.\nSam Wiseman and Alexander M. Rush. Sequence-to-sequence learning as beam-search optimiza-\ntion. In Jian Su, Kevin Duh, and Xavier Carreras (eds.), Proceedings of the 2016 Confer-\nence on Empirical Methods in Natural Language Processing, pp. 1296–1306, Austin, Texas,\nNovember2016.AssociationforComputationalLinguistics. doi: 10.18653/v1/D16-1137. URL\nhttps://aclanthology.org/D16-1137/.\nLijun Wu, Fei Tian, Tao Qin, Jianhuang Lai, and Tie-Yan Liu. A study of reinforcement learning\nfor neural machine translation. In Ellen Riloff, David Chiang, Julia Hockenmaier, and Jun’ichi\nTsujii (eds.), Proceedings of the 2018 Conference on Empirical Methods in Natural Language\nProcessing,pp.3612–3621,Brussels,Belgium,October-November2018a.AssociationforCom-\nputationalLinguistics. doi: 10.18653/v1/D18-1397. URLhttps://aclanthology.org/\nD18-1397/.\nLijun Wu, Yingce Xia, Fei Tian, Li Zhao, Tao Qin, Jianhuang Lai, and Tie-Yan Liu. Adversarial\nneuralmachinetranslation. InJunZhuandIchiroTakeuchi(eds.),ProceedingsofThe10thAsian\nConferenceonMachineLearning,volume95ofProceedingsofMachineLearningResearch,pp.\n534–549. PMLR, 14–16 Nov 2018b. URL https://proceedings.mlr.press/v95/\nwu18a.html.\nxAI. Grok 4 model card, Aug 2025. URL https://data.x.ai/\n2025-08-20-grok-4-model-card.pdf.\nGoYasui,YoshimasaTsuruoka,andMasaakiNagata. Usingsemanticsimilarityasrewardforrein-\nforcementlearninginsentencegeneration.InFernandoAlva-Manchego,EunsolChoi,andDaniel\nKhashabi (eds.), Proceedings of the 57th Annual Meeting of the Association for Computational\n24\nRewardModelsareMetricsinaTrenchCoat-Preprint\nLinguistics:StudentResearchWorkshop,pp.400–406,Florence,Italy,July2019.Associationfor\nComputational Linguistics. doi: 10.18653/v1/P19-2056. URL https://aclanthology.\norg/P19-2056/.\nLantaoYu,WeinanZhang,JunWang,andYongYu. Seqgan: Sequencegenerativeadversarialnets\nwithpolicygradient. InSatinderSinghandShaulMarkovitch(eds.),ProceedingsoftheThirty-\nFirstAAAIConferenceonArtificialIntelligence,February4-9,2017,SanFrancisco,California,\nUSA, pp. 2852–2858. AAAI Press, 2017. doi: 10.1609/AAAI.V31I1.10804. URL https:\n//doi.org/10.1609/aaai.v31i1.10804.\nWojciech Zaremba and Ilya Sutskever. Reinforcement learning neural turing machines. CoRR,\nabs/1505.00521,2015. URLhttp://arxiv.org/abs/1505.00521.\nLining Zhang, Simon Mille, Yufang Hou, Daniel Deutsch, Elizabeth Clark, Yixin Liu, Saad Ma-\nhamood, Sebastian Gehrmann, Miruna Clinciu, Khyathi Raghavi Chandu, and Joa˜o Sedoc. A\nneedle in a haystack: An analysis of high-agreement workers on MTurk for summarization. In\nAnna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki (eds.), Proceedings of the 61st Annual\nMeetingoftheAssociationforComputationalLinguistics(Volume1: LongPapers),pp.14944–\n14982, Toronto, Canada, July2023.AssociationforComputationalLinguistics. doi: 10.18653/\nv1/2023.acl-long.835. URLhttps://aclanthology.org/2023.acl-long.835/.\nYinan Zhang, Eric Tzeng, Yilun Du, and Dmitry Kislyuk. Large-scale reinforcement learning for\ndiffusion models. In European Conference on Computer Vision, 2024. URL https://api.\nsemanticscholar.org/CorpusID:267095304.\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang,\nZi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. Judging llm-as-a-judge with mt-bench and\nchatbotarena. Advancesinneuralinformationprocessingsystems,36:46595–46623,2023.\nChuntingZhou,PengfeiLiu,PuxinXu,SriniIyer,JiaoSun,YuningMao,XuezheMa,AviaEfrat,\nPingYu,LILIYU,SusanZhang,GargiGhosh,MikeLewis,LukeZettlemoyer,andOmerLevy.\nLIMA:Lessismoreforalignment. InThirty-seventhConferenceonNeuralInformationProcess-\ningSystems,2023. URLhttps://openreview.net/forum?id=KBMOKmX2he.\nEnyu Zhou, Guodong Zheng, Binghai Wang, Zhiheng Xi, Shihan Dou, Rong Bao, Wei Shen, Li-\nmao Xiong, Jessica Fan, Yurong Mou, Rui Zheng, Tao Gui, Qi Zhang, and Xuanjing Huang.\nRMB:comprehensivelybenchmarkingrewardmodelsinLLMalignment. InTheThirteenthIn-\nternationalConferenceonLearningRepresentations,ICLR2025,Singapore,April24-28,2025.\nOpenReview.net,2025. URLhttps://openreview.net/forum?id=kmgrlG9TR0.\nDawei Zhu, Sony Trenous, Xiaoyu Shen, Dietrich Klakow, Bill Byrne, and Eva Hasler. A\npreference-drivenparadigmforenhancedtranslationwithlargelanguagemodels. InKevinDuh,\nHelena Gomez, and Steven Bethard (eds.), Proceedings of the 2024 Conference of the North\nAmerican Chapter of the Association for Computational Linguistics: Human Language Tech-\nnologies (Volume 1: Long Papers), pp. 3385–3403, Mexico City, Mexico, June 2024. Asso-\nciation for Computational Linguistics. doi: 10.18653/v1/2024.naacl-long.186. URL https:\n//aclanthology.org/2024.naacl-long.186/.\nVile´m Zouhar, Shuoyang Ding, Anna Currey, Tatyana Badeka, Jenyuan Wang, and Brian Thomp-\nson. Fine-tunedmachinetranslationmetricsstruggleinunseendomains. InLun-WeiKu,Andre\nMartins,andVivekSrikumar(eds.),Proceedingsofthe62ndAnnualMeetingoftheAssociation\nforComputationalLinguistics(Volume2: ShortPapers), pp.488–500, Bangkok, Thailand, Au-\ngust2024.AssociationforComputationalLinguistics. doi: 10.18653/v1/2024.acl-short.45. URL\nhttps://aclanthology.org/2024.acl-short.45/.\n25\nRewardModelsareMetricsinaTrenchCoat-Preprint\n70\n60\n50\n40\n30\n20\n10\n0\n2016 2017 2018 2019 2020 22002211 22002222 222000222333 222000222444 222000222555\noga\nsraey\n+3\nsrepap\not\nsnoitatiC\n%\nField\nEvaluation Metric\nReward Model\nLLM as a Judge\nFigure3: Weshowthepercentageofcitationstopapersthatwerepublishedmorethanthreeyears\nago. Rewardmodelliteratureexhibitsoutlierbehaviorinwhichthispercentageisdecreasingdras-\nticallyeveryyear.\nA DETAILED METHODS FOR CITATION ANALYSIS\nTheresultsinthemaintextpresentahigh-leveloverviewofthekeyfindingsofourcitationanalysis.\nWechosetopresentresultsforthelast5yearssincerewardmodelsthatresemblethosediscussedin\nthispaperwereonlypopularizedinthistimeframe. WhiletheSemanticScholarAPIyieldsresults\nfor the years prior, they are mostly irrelevant to the discussion at hand. We extended the analysis\nforevaluationmetricsbackto2016butfindnosignificantdifferenceinresults. Therefore,weomit\nthemforreadability.\nSimilarly, we choose to present results of an analysis of up to 300 papers per year as a result of\nqualitativeassessmentofthedata. Aqualitativeassessmentfoundthat,beyondthefirst300papers,\nsearch results became too noisy, with irrelevant papers being retrieved. We repeated the analysis\nwithonlythetop100and200paperswithnosignificantdifferencesinresults.\nThespecifickeywordsfortheanalysisinFigure2awereselectedbasedonrepeatedtrialstomax-\nimize precision at the cost of recall. For example, including “evaluation” as a proxy keyword for\nevaluationmetricswouldhaveyieldedanypaperthatdiscussestheirevaluationresults, notneces-\nsarily discusses how to build evaluation metrics. Similarly, we included generic RL-related terms\nlike“policy”forrewardmodelssincetheterminologywasevolvingandpapersonlyfairlyrecently\nconvergedonthisterm. Tonotmisscitationstorelevantpaperspriorto2020,weincludedthemat\ntheriskofoverestimatingthetruecitationcount.\nAsaresult,thespecificnumericalresultsareasideeffectofthiskeyword-basedidentificationand\nshould be interpreted with caution. While an LLM-based identification process may yield more\naccurateresults,itwouldrequireprocessingasignificantnumberoftokens. Sincewewereonlyin-\nterestedinaggregatetrendinformation,wefoundtheresultsfromkeyword-basedsearchessufficient\nandstableacrossmanyvariants.\nB RECENCY BIAS IN CITATIONS\nWequantifyrecencybiasincitationsacrossthethreefieldsofstudy. Citationsonlytorecentpapers\nwouldprovideanadditionalpieceofevidencethatinsightsfromworkbeforeLLMsbecamepopular\narenotbeingconsidered. Indeed,wefindthatwhiletheaverageageofacitedpaperforevaluation\nmetricspublishedin2025is5.0years,citedpapersbyrewardmodelingandLLM-as-a-judgepapers\nareonly3.6and3.8yearsold. 62.2%ofcitationsinrewardmodelingpapersaretopaperspublished\nless than 2 years ago (68.5% for LLM-as-a-Judge), in contrast to 46.8% for evaluation metrics.\nCritically,Figure3showshowcitationstoolderpapershavebeendecreasing,especiallyinliterature\nonrewardmodels. Thisresultisanindicatorthatrewardmodelingresearchisevolvingquicklyand\nthatbenchmarksarequicklymadeirrelevantbynewresults.\n26\nRewardModelsareMetricsinaTrenchCoat-Preprint\nC ASSIGNMENTS OF CONFERENCE TO SUBFIELD\nFor our analysis of citations to research areas in Section 3, we assign academic venues to an area\nif the venue is clearly affiliated with it. For example, AAAI’s scope is all of AI and we therefore\ndo not include it in this analysis. We include a venue in this analysis if papers published there\nreceivedatleast50citationsamongallthe50,000+papersincludedinouranalysis. Weaccountfor\nvariousmisspellings,capitalizationdifferences,andabbreviations,butonlylisteachvenueoncein\nthefollowinglistofassignments:\nMachineLearning COLT,ICLR,ICML,JMLR,NeurIPS/NIPS,TMLR,TNNLS\nNatural Language Processing ACL (including Findings of ACL), CONLL, EACL, EAMT,\nEMNLP,INLG,LREC,NAACL,SemEval,WMT\nRobotics CoRL,ICRA,IROS,IJRR,RSS\nVision CVPR,ECCV,ICCV,IJCV,MICCAI,TIP,TOG,WACV\n27\n",
    "tables": [],
    "images": []
  },
  {
    "metadata": {
      "id": "2510.03230v1",
      "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
      "authors": [
        "Suyuchen Wang",
        "Tianyu Zhang",
        "Ahmed Masry",
        "Christopher Pal",
        "Spandana Gella",
        "Bang Liu",
        "Perouz Taslakian"
      ],
      "summary": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.",
      "published": "2025-10-03T17:59:34Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03230v1"
    },
    "text": "IMPROVING GUI GROUNDING WITH EXPLICIT\nPOSITION-TO-COORDINATE MAPPING\nSuyuchenWang1,2,3,TianyuZhang1,2,3,AhmedMasry1,4,ChristopherPal1,2,5,7,\nSpandanaGella1,BangLiu2,3,7,PerouzTaslakian1,6\n1ServiceNow 2Mila-QuebecAIInstitute 3Universite´ deMontre´al 4YorkUniversity\n5PolytechniqueMontre´al 6McGillUniversity 7CIFARAIChair\nABSTRACT\nGUIgrounding,thetaskofmappingnatural-languageinstructionstopixelcoordinates,iscrucialfor\nautonomousagents,yetremainsdifficultforcurrentVLMs.Thecorebottleneckisreliablepatch-to-\npixelmapping,whichbreakswhenextrapolatingtohigh-resolutiondisplaysunseenduringtraining.\nCurrent approaches generate coordinates as text tokens directly from visual features, forcing the\nmodel to infer complex position-to-pixel mappings implicitly; as a result, accuracy degrades and\nfailuresproliferateonnewresolutions. Weaddressthiswithtwocomplementaryinnovations. First,\nRULERtokensserveasexplicitcoordinatemarkers,lettingthemodelreferencepositionssimilarto\ngridlinesonamapandadjust ratherthangeneratecoordinatesfromscratch. Second, Interleaved\nMRoPE(I-MROPE)improvesspatialencodingbyensuringthatwidthandheightdimensionsare\nrepresented equally, addressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot,ScreenSpot-V2,andScreenSpot-Proshowconsistentgainsingroundingaccuracy,with\nthelargestimprovementsonhigh-resolutioninterfaces.Byprovidingexplicitspatialguidancerather\nthanrelyingonimplicitlearning,ourapproachenablesmorereliableGUIautomationacrossdiverse\nresolutionsandplatforms.\n1 Introduction\nGUI grounding is the task of mapping natural language instructions to precise pixel coordinates in graphical user\ninterfaces,enablingautonomousagentstointeractwithsoftwareashumansdo(Zhangetal.,2025a;Wangetal.,2024a;\nZheng et al., 2024). This capability is fundamental for computer automation: without accurate grounding, agents\ncannotclickbuttons,fillforms,ornavigateinterfacesreliably.Althoughearlyapproachesreliedonstructuredmetadata\nfrom HTML/DOM trees or accessibility APIs (Li et al., 2020; Deng et al., 2023), these methods face significant\nlimitations: they require access to the underlying UI structure, which is often unavailable in desktop applications,\ninconsistentacrossplatforms, orcompletelyabsentinlegacysystems. Purevision-basedgrounding, whichoperates\ndirectly on screenshots, offers universal applicability across any visual interface without requiring special access or\ninstrumentation (Qin et al., 2025; Wang et al., 2025b; Guo et al., 2025). This approach mirrors human interaction\nwithGUIsandenablesautomationofanysoftwarevisibleonscreen,frommodernwebapplicationstolegacydesktop\ntools.\nCurrent vision-based approaches typically formulate GUI grounding as a coordinate generation task, where mod-\nels output pixel positions as text tokens (e.g., “x=523, y=217”). This paradigm, adopted by models such as\nSeeClick(Chengetal.,2024),CogAgent(Hongetal.,2024),andUI-TARS(Qinetal.,2025),treatscoordinatepre-\ndictionasastandardlanguagemodelingproblem. However,thisapproachfacesafundamentalchallengeillustratedin\nFigure1: modelsmustlearntomapfromhigh-dimensionalvisualpositionalembeddingstoprecisenumericalcoor-\ndinatesastokenoutputswithoutexplicitspatialguidance. Themappingisentirelyimplicit: themodelreceivesvisual\npatches with positional embeddings and must learn to translate these abstract and similar representations into exact\nanddistinctpixelvaluetokensthroughitslanguagemodelinghead.\nThis implicit approach leads to two critical problems. First, unreliable coordinate prediction: Without explicit\nguidancelinkingpositionstocoordinates,modelsstruggletolearnstablemappings,requiringextensivetrainingdata\nandstillproducinginconsistentresults(Gouetal.,2025;Wuetal.,2025a). Second,poorresolutiongeneralization:\nModelstrainedonspecificresolutionsgenerallyfailwhendeployedondifferentscreensizes,astheimplicitmapping\nfunctionlearnedduringtrainingdoesnottransfertonewcoordinateranges(Nayaketal.,2025;Lietal.,2025b).\n5202\ntcO\n3\n]VC.sc[\n1v03230.0152:viXra\nImprovingGUIGroundingwithExplicitPosition-to-CoordinateMapping\n“Record the sound” Image Token\nTraditional Direct Mapping\nDirect PE to “300” 𝑥\nToken Mapping\n“84” 𝑦\nExplicit Coordinate Mapping with RULER\nPEtoRULER 280 +20 “300” 𝑥\nMapping\n(30, 30)\nPosition Embedding 84 +0 “84” 𝑦\n(30, 22) (22, 22)\nFigure 1: A comparison between traditional direct positional embedding-to-pixel coordinate mapping and RULER’s\nexplicitcoordinatemapping.\nWe also identify a technical limitation in the way current VLMs encode spatial information. Standard Multidi-\nmensional Rotary Positional Embedding (MRoPE), used in state-of-the-art models like Qwen2-VL and Qwen2.5-\nVL (Wang et al., 2024b; Bai et al., 2025), assigns different frequency bands to height and width dimensions se-\nquentially. Thiscreatesanimbalancewhereonedimensionreceivesonlyhigh-frequencycomponentswhileanother\nreceives only low-frequency components, leading to uneven spatial modeling capabilities across axes, a previously\noverlookedissuethatimpactsgroundingprecision.\nTo address these challenges, we introduce a framework that provides explicit spatial guidance for GUI grounding\nthroughtwokeyinnovations:\nFirstly,RULER(Rotaryposition-to-pixeLmappER)tokensestablishanexplicitcoordinatereferencesystemwithin\nthe model. As illustrated in Figure 1, these auxiliary tokens encode pixel coordinates directly and share positional\nembeddingswiththecorrespondingimagepatches. Instead ofregressingthecoordinatesfromabstractfeatures, the\nmodelscannowrefertothenearestRULERtokenandperformsimpleboundedarithmetictodetermineexactpositions.\nThis transforms an unstable regression problem into a robust reference-and-adjustment mechanism, similar to how\nhumansmightusegridlinesonamap.\nSecondly, Interleaved MRoPE (I-MROPE) addresses frequency imbalance in standard positional encodings. By\ninterleaving rather than sequentially assigning frequency components across spatial dimensions, it distributes high-\nand low-frequency signals uniformly across width and height. This produces balanced spatial representations and\nimprovesthemodel’sabilitytodistinguishpositionsalongbothaxesequally.\nTraining models from scratch with our framework and finetuning existing VLMs with RULER tokens, we perform\nextensiveevaluationonScreenSpot(Chengetal.,2024),ScreenSpot-V2(Wuetal.,2025b),andScreenSpot-Pro(Li\netal.,2025b). Ourapproachachievessignificantimprovements: onthechallengingScreenSpotProbenchmarkwith\nhigh-resolutiondisplaysexceedingourtrainingresolution,weimproveaccuracyfrom31.1%to37.2%throughfine-\ntuning alone, demonstrating strong generalization capability. These gains are achieved with minimal computational\noverhead,asRULERtokensaddlessthan1%tothetotaltokencountevenfor8Kdisplays.\nOurworkmakesthreekeycontributions: (1)WeidentifyandformalizetheimplicitmappingproblemincurrentGUI\ngrounding approaches, showing how it leads to poor accuracy and resolution brittleness; (2) We introduce RULER\ntokens,anexplicitcoordinatereferencemechanismthattransformsunstableregressionintorobustspatialreferencing;\n(3) We present I-MROPE, a balanced positional embedding scheme that provides equal spatial modeling capacity\nacross dimensions. Together, these innovations establish a more principled approach to GUI grounding that treats\npixel-levelprecisionasanexplicitarchitecturalconcernratherthananemergentproperty.\n2 RelatedWork\nPositional Embeddings in Vision-Languge Models. Rotary Positional Embedding (RoPE) (Su et al., 2024) en-\ncodes positions by rotating embedding dimension pairs with angles proportional to token indices, but suffers from\na long-term decay bias in low-frequency components. HoPE (Li et al., 2025a) zeros out these low-frequency terms\nto prevent long-range bias. For vision-language models, abundant visual tokens exhaust RoPE’s context window;\nV2PE (Ge et al., 2024) rescales step sizes for vision tokens, while CircleRoPE (Wang et al., 2025a) projects image\n2\nImprovingGUIGroundingwithExplicitPosition-to-CoordinateMapping\n(10,42)\n“How do I switch to French?”\nLLM Decoder\nRULER Tokens Interleaved MRoPE\nHeight Width High-frequency Low-frequency\n“How do I switch to French?” Reference Reference RoPE\nH W H W H W H W H W H W H W\n0 28 Vector\n(21, 21) (23, 23)\nHeight Dimension Width Dimension\nAdding (21, 25) (10,42)\n(21, 25)\nMulti-dimensional\nPosition IDs\n… 0 28 56 … …\n(0, 0) (0, 1) (0, 2)(0, 3) (0, 4) (0, 5)\n(0, 0) (1, 1) (20, 20)(21, 21)(23, 23)(25, 25)(21, 21)(21, 22)(21, 23) (23, 25)(26, 26)(27, 27)(28, 28) (38, 38)(39, 39)(40, 40)(41, 41)\n(1, 0) (1, 1) (1, 2)(1, 3) (1, 4) (1, 5)\nSystem Prompt RULER Tokens Vision Tokens User Query Outputs\n(2, 0) (2, 1) (2, 2)(2, 3) (2, 4) (2, 5)\n(3, 0) (3, 1) (3, 2)(3, 3) (3, 4)(3, 5)\nFigure 2: Model architecture. Our framework augments vision-language models with two key innovations: (1)\nRULERtokensthatprovideexplicitposition-to-coordinatemappings,transformingcoordinatepredictionfromregres-\nsion to retrieval, and (2) I-MROPE that rebalances positional embeddings by interleaving frequency components\nacrossspatialdimensions,ensuringequalrepresentationalcapacityforwidthandheight,and\ntokensintocircularspaceorthogonaltotext,ensuringequalcross-modaldistances. Forvideo,M-RoPE(Wangetal.,\n2024b)separatelyencodesspatial-temporaldimensionsbutdisruptscross-modalalignmentbyoffsettingtexttokens.\nVideoRoPE(Liuetal.,2025)addressesthisbyrotatingspatialpositionswhilepreservingtext-videocontinuityand\nrelativespatialinformation. Currently,Qwen2-VLandQwen2.5-VL’sMRoPE(Wangetal.,2024b;Baietal.,2025)\nisoneofthemostprevailingmultidimensionalpositionalembeddingduetothepopularityofthesemodels. However,\nthe implementation of MRoPE results in a biased partition of RoPE features for each spatial-temporal dimensions.\nOurI-MROPEprovidesanelegantimprovementtoMRoPEthatprovidesafullfrequencyspectrumofRoPEfeatures\nforeachspatial-temporaldimension,whichallowsthemodeltoperformbetterpositionperception.\nConcurrenttoourwork, Qwen3-VL(Qwen,2025)independentlydevelopedInterleaved-MRoPE.Wenotethatboth\napproaches arrived at nearly identical designs through independent research paths, as confirmed through correspon-\ndencewiththeteammembersofQwen3-VL.\nGUIGroundingModels. Giventhelimitationsofgeneral-purposemodelsonUIgroundingtasks(Lietal.,2025b;\nNayaketal.,2025),recentworkhasfocusedondevelopingtask-specificmodels.Earlyapproachesformulatedcoordi-\nnateprediction(UIgrounding)asatextgenerationproblem. Forexample,JEDI(Xieetal.,2025)andUI-TARS(Qin\net al., 2025) finetune open-source VLMs on synthetically generated data to enhance grounding capabilities. Build-\ningonthis, GTA1 (Yangetal.,2025)and SE-GUI (Yuanetal.,2025)leveragereinforcementlearning,specifically\nGRPO (Shao et al., 2024), with rule-based rewards to self-improve grounding performance. PHI-GROUND (Zhang\net al., 2025b) introduces a label smoothing strategy that weights coordinate token predictions by their numerical\ndistance from the ground truth, while emphasizing digit positions (e.g., tens, hundreds). In contrast, some recent\napproacheshavemovedawayfromtext-basedcoordinategeneration. Forexample, GUI-ACTOR (Wuetal.,2025a)\nproposes coordinate-free grounding, where the model directly predicts the visual patches corresponding to the tar-\nget locations. However, current methods either generate coordinates as natural language response, which requires\nmapping positional embeddings to number tokens, or requires large changes to the model architecture, which is not\ndirectlycompatiblewithgeneraltasks. Ourintroduced RULER providesbothexplicitguidanceformappingposition\ninformationtotokens,whilekeepingthemodel’soriginalautoregressivegenerationdesigntomaximizecompatibility\nwithothermodelusagescenarios.\n3 Method\nWepresentaframeworkforUIgroundingthataddressesfundamentallimitationsinhowcurrentVLMshandlespatial\nperception. Ourapproachintroducestwocomplementaryinnovations: (i)InterleavedMultidimensionalRotaryPo-\n3\nImprovingGUIGroundingwithExplicitPosition-to-CoordinateMapping\nsitionalEmbedding(I-MROPE)thatprovidesbalancedspatialrepresentations,and(ii)RULERtokensthatestablish\nexplicitposition-to-pixelcoordinatemappings. WeprovideanoverviewofourproposedmethodinFigure2.\n3.1 RULER: ExplicitPosition-to-PixelCoordinateMapping\nCurrentVLMspredictpixelcoordinatesforGUIgroundingbygeneratingcoordinatesastexttokens(e.g.,“x=523,\ny=217”). Since the source of such coordinate-related information is only recorded by image tokens’ positional\nembeddings,generatingcoordinatetokensrequiresimplicitanddirectmappingfromhigh-dimensionalvisualfeatures’\npositionalembeddingstonaturallanguagenumbertokens.Thisapproachsuffersfromunstablelearningdynamicsand\npoorgeneralizationtounseenresolutions,asthelearnedregressionfunctionsareinherentlyresolution-specific (Gou\netal.,2025;Wuetal.,2025a).\nToprovideamoreexplicitguidanceforthemodelingeneratingpixelcoordinates,wepropose RULER,whichintro-\nduces auxiliary tokens that explicitly encode pixel coordinates and share positional embeddings with corresponding\nimagepatches. InspiredbytheinductionheadmechanisminpretrainedTransformers(Olssonetal.,2022), wetake\nadvantageofthemodel’slearnedcapabilitytocomparepositionIDsandtocopytokensaccordingtotheirpositions,\nanduseaseriesoftokenswithcarefullydesignedpositionIDsandtokenvaluesasarulerfortheimage. Withthehelp\nofthesetokens,insteadofregressingpixelvaluesfrompositionalembeddings,themodelfindsaRULERtokenwhose\npositionalencodingbestalignswithanimagepatch,andcopyitsvalueasareferencecoordinatevalue. Basedonthe\nretrievedcoordinatevalue, themodelonlyneedstoaddanumberboundedbyaconstantbinternallytogetthefinal\noutputnumber, wherebisirrelevantoftheimageresolution, reducingthegeneralizationgaponimageswithhigher\nresolutions than the trained ones. An illustrated comparison between RULER and traditional grounding methods is\nshowninFigure1.\nSpecifically,consideranimagepartitioned(tokenized)intoH ×W patcheseachcoveringp×ppixels,andletx\nsys\ndenotesystemtokens,x thevisualpatchembeddings,andx thetextpromptembeddings. Weaugmentthe\nvision prompt\ninputsequencewithasetofauxiliarycoordinatetokensx asfollows:\nRULER\n(cid:2) (cid:3)\nx = x ,x ,x ,x , (1)\ninput sys RULER vision prompt\nWe construct each RULER token r\ni\n∈ x\nRULER\nso that it shares the same spatial position ID as a visual patch and\nhas the face token value of the initial pixel coordinate of the corresponding visual patch. This construction both\nalignsRULER’spositionwithinputvisualpatchesandalignsitsvaluewithoutputcoordinatetokens;thus,bridgesthe\nposition-to-coordinatemapping:\nPE (r )=RMRoPE (2)\nRULER i Θ,t0+i\nwhere RMRoPE is a multidimensional RoPE operator, and t is a fixed temporal index ensuring that the height and\n0\nwidth components match those of the vision token at spatial position i. In practice, t is the initial spatial position\n0\nIDoftheimagepatches. NotethatRULERonlymodelsoneofthemultipledimensionsofspatialpositionIDs,since\nt is the same for both height and width dimensions, and each image patch covers a square part of image. Thus,\n0\nthemappingbetweenheightorwidthtothepixelcoordinatevaluesisidentical. Thissharingof RULER mappingon\nmultiplespatialdimensionshelpsreducethenumberofRULERtokensandimproveefficiency.\nTofurthermanagecomputationalcost, weintroduce RULER tokensatregularintervalssinsteadofhavingthemfor\neachposition:\nR={r :i∈{0,s,2s,...,⌊max(H,W)/s⌋·s}} (3)\ni\nInthiscase,thearithmeticboundisb=s×p. TheRULERtokensaregeneratedduringthepreparationofmultimodal\ninputs. Whentheinputsequencehasmultipleimages,wegenerateaRULERtokensequencebeforeeachimagewith\npositionIDcorrespondingtoeachimage.\n3.2 I-MROPE:InterleavedMultidimensionalRotaryPositionalEmbedding\nPositionalembeddingsencodespatialinformationinvisiontransformers. MultidimensionalRoPE(MRoPE)(Wang\net al., 2024b; Bai et al., 2025) extends standard RoPE to VLMs by decomposing positions into multiple spatial-\ntemporaldimensions. However,acriticallimitationofMRoPEisthatitcreatesafrequencyimbalancebetweenspatial\ndimensions.\nRotary positional embeddings (RoPE) encode relative positions by applying rotation matrices directly to the query\nandkeyvectorsineachattentionhead. Letm ∈ Ndenotethepositionindexofatokenanddthedimensionofthe\nattention head. For each 2×2 block, RoPE rotates a pair of dimensions by a position-dependent angle mθ . The\nj\nrotationmatrixR appliedtothequeryandkeyvectorsisthusexpressedas:\nθj,m\n(cid:18) (cid:19)\ncos(mθ ) −sin(mθ )\nR = j j , θ =b−2j/d, (4)\nθj,m sin(mθ\nj\n) cos(mθ\nj\n) j\n4\nImprovingGUIGroundingwithExplicitPosition-to-CoordinateMapping\nwherebisahyperparametercalledRoPEbase. Thefrequencyθ decreasesexponentiallywiththedimensionindex\nj\nj, producingaspectrumthatrangesfromhigh-frequencytolow-frequencycomponentsasj progressesfrom0tod,\nwhichisillustratedintherightpartofFigure2. InstandardMRoPE,thesefrequenciesarepartitionedandassigned\nconsecutivelytodifferentspatial-temporaldimensions:\nRMRoPE =diag(R ,R ,R ) (5)\nΘ,t,h,w Θt,t Θh,h Θw,w\nwhereΘ ,Θ ,andΘ denotedisjointyetconsecutivesubsetsofthefrequencyspectrumθ . Thissequentialalloca-\nt h w j\ntionleadstoanimbalance: thehigh-,mid-,andlow-frequencypartsoftheRoPEvectorarefullyandonlyoccupied\nbythetemporal,height,andwidthdimensions,respectively. Asaresult,eachdimensionisbiasedtowardsalimited\nanddifferentfrequencyband,constrainingtherepresentationalcapacityanddegradinggroundingperformanceacross\naxes(Liuetal.,2024c;Wangetal.,2024c). Thisimbalancealsopotentiallyresultsindifferentinnerprocessingmech-\nanismsofeachspatial-temporaldimensionduetothedifferentmodelingbehaviorsoftheircorrespondingpositional\nembedding.\nI-MROPE addresses this imbalance by distributing the frequency spectrum uniformly across spatial dimensions\nthroughfrequencyinterleaving. Specifically,insteadofassigningconsecutivefrequencybandstoasingleaxis,each\nfrequencyindexj iscyclicallymapped.\n\nw ifj mod3=0\n\nDimensionassignmentforfrequencyj : p = h ifj mod3=1 (6)\nj\nt ifj mod3=2\nwherep denotesthespatialdimension(width,height,ortemporal)assignedtofrequencyθ .\nj j\nThisinterleavingensuresthateverydimensionreceivesafullrangeoffrequencies,combininghigh-frequencycompo-\nnentsforfine-grainedlocalizationwithlow-frequencycomponentsforlong-rangedependencies.LikevanillaMRoPE,\ntexttokensinthesequencehaveidenticaltemporal,height,andwidthindices(t=h=w =m),andtheformulation\nreducesexactlytostandardRoPE:\nRI-MROPE =RRoPE (7)\nΘ,m,m,m Θ,m\nThispreservesbackwardcompatibilitywithpre-trainedlanguagemodelswhileprovidingmorebalancedspatialrep-\nresentationsforvisiontasks.\n4 ExperimentalSetup\nTrainingSetup. Weconducttwosetsofexperimentstovalidateourapproach: trainingfromscratchandfinetuning\nexisting VLMs. For the from-scratch experiments, we build on the LLaVA-NeXT framework (Liu et al., 2024b)\nusingSigLIP-SO400M-14@384(Zhaietal.,2023)asvisionencoderandQwen2.57BInstruct(Qwenetal.,2024)as\nlanguagedecoder. Wereplacethestandard1DpositionalembeddingsinthelanguagedecoderinLLaVA-NeXTwith\nMRoPEorI-MROPE,andintegrateRULERtokensintotheinputsequenceduringbothtrainingandinference.\nFollowing the LLaVA-NeXT training paradigm, we employ a two-stage training process. First, we perform vision-\nlanguagealignmentpretrainingontheLLaVA-558Kdataset(Liuetal.,2024a),trainingonlytheMLPprojectionlayer.\nSecond, weconductdomain-specificsupervisedfinetuningonUIgroundingtasks, trainingboththeprojectionlayer\nthroughfullfinetuningandthelanguagemodelthroughLoRA(Huetal.,2022)forparameterefficiency.\nFor finetuning experiments, we adapt Qwen2.5-VL 7B Instruct (Bai et al., 2025) by introducing RULER tokens and\nfocusonverifyingthesignificanceofRULERaloneongroundingperformance.Wedonotchangetheoriginalmodel’s\nMRoPEtoavoiddramaticchangestothelearnedmodelbehaviorsregardingpositionalembedding. WeuseQwen2.5-\nVL’sdefaultsystempromptandchattemplateforallthefinetuningexperiments.\nInallexperiments,wesettheRULERtoken’sdefaultintervalass=8inthemainexperiments. ForI-MROPE,since\nGUIgroundingdoesnotrequireatemporaldimension,weuse2DMRoPEandI-MROPEinthefrom-scratchtraining\nexperiments. Specifically,thedimensionassignmentforfrequencyj is:\n(cid:26)\nh ifj mod2=0\nDimensionassignmentforfrequencyj : p = (8)\nj t ifj mod2=1\nThetrainingprocessfollowsstandardVLMobjectiveswithUIgroundingtasks. ThemodellearnstoleverageRULER\ntokensforcoordinatepredictionwhileI-MROPEprovidesbalancedspatialrepresentationsthroughoutthetransformer\nlayers. Thiscombinationenablesprecisepixel-levelgroundingwithoutcompromisinggeneralvision-languagecapa-\nbilities. MorehyperparametersettingscanbefoundinAppendixA.\n5\nImprovingGUIGroundingwithExplicitPosition-to-CoordinateMapping\nTrainingData. Bothexperimentalsettingsare trainedontheUGrounddataset(Gouet al., 2025), whichprovides\ncomprehensiveUIgroundingannotationsonwebsites.Itcontainsapproximately8Melementannotationsacross775K\nscreenshots,providingdiversetrainingsignalsforrobustgroundingcapabilities.\nTocomplywithQwen2.5-VL’spost-trainingsettingsregardingcoordinates(Baietal.,2025), wepre-processallco-\nordinatesinUGroundtouserawpixelvaluesratherthannormalizedones. Thischoiceensuresconsistencywithour\nRULERtokendesign,whichrequireseachpatch’ssizeintermsoftheoutputcoordinatetobeasquare,andavoidsthe\nambiguityintroducedbynormalizationindifferentaspectratios.\nEvaluation Setup. We evaluate our models on three UI grounding benchmarks: ScreenSpot (Cheng et al., 2024),\nScreenSpot-V2(Wuetal.,2025b),andScreenSpotPro(Lietal.,2025b).Eachbenchmarkpresentsscreenshotspaired\nwith natural language instructions that describe the target UI elements. Models must predict the pixel coordinates\ncorrespondingtothedescribedelement.\nScreenSpot and ScreenSpot-V2 contain 1,272 instructions each on mobile, desktop, and web platforms, with V2\ncorrecting the annotation errors from the original. ScreenSpot-Pro presents a more challenging scenario with 1,581\ntasks from 23 professional desktop-only applications featuring higher resolution interfaces and greater domain shift\nfrom typical training data. In particular, ScreenSpot-Pro features higher-resolution images than our training data,\nmakingitastrongtestofresolutiongeneralization.\nWepreprocessallbenchmarkstouserawpixelcoordinatesforevaluation,ensuringfaircomparisonbetweenmethods.1\nWe measure performance using Element Accuracy, which considers a prediction correct if the predicted point falls\nwithintheground-truthboundingboxofthetargetelement. Weusetheevaluationsettingandthecodeprovidedby\nWuetal.(2025a).\nBaselines. We compare against state-of-the-art UI grounding models of comparable scale. Our baseline models\nincludesQwen-2-VL7BInstruct(Wangetal.,2024b),oneofthemostcommonlyusedopen-sourceVLMs;SeeClick-\n9.6B (Cheng et al., 2024), an early specialized UI grounding model; OS-Atlas-7B (Wu et al., 2025b), a model de-\nsigned for operating system interactions; Aguvis-7B (Xu et al., 2025), which uses visual grounding with bounding\nboxsupervision;UGround-V1-7B(Gouetal.,2025)trainedonthesameUGrounddataset;UI-TARS-7B(Qinetal.,\n2025),arecentstrongbaseline;andGUI-Actor-7B(Wuetal.,2025a)whichusesattention-basedgroundinginsteadof\noutputtingcoordinates.Allbaselinenumbersarereportedfromoriginalpapersorreproducedusingofficialimplemen-\ntationswithconsistentevaluationprotocols. NotethatourmodelsuselesstrainingdatathanGUI-Actor. Besides,our\nmodelsareonlytrainedonUGroundandthushavenotseendatafromdomainsotherthanwebsites,unlikeUI-TARS\nandGUI-Actor.\n5 Results\n5.1 GUIGroundingPerformance\nWepresentthecomparisonamongthemodelstrainedfromscratchwith RULER and I-MROPE,thefinetunedmod-\nels equipped with RULER, and the baseline models on ScreenSpot-Pro, ScreenSpot, and ScreenSpot-V2 in Table 1,\nTable2,andTable3,respectively.\nFor the from-scratch training experiments, multidimensional RoPE consistently outperforms the default 1D RoPE\n(LLaVA PE) across all benchmarks. Furthermore, our proposed I-MROPE achieves both lower training loss and\nstrongergroundingperformancethantheoriginalMRoPE,demonstratingtheeffectivenessofbalancingthespectrum\nacross the spatial dimensions. RULER tokens further enhance performance by providing guidance on position-to-\ncoordinatemapping,achievingthebestoverallresultsamongallmodelstrainedfromscratchacrossalldatasets. No-\nticeably,thegainsfromRULERaremostpronouncedonScreenSpot-Pro,reflectinghowitsreference-then-copymech-\nanismandboundedpixelcoordinatearithmeticacrossresolutionshelpgeneralizationtohigherresolutiongrounding\ntasks.\nForfine-tuningexperiments,wealsoobservethataddingRULERconsistentlyimprovesperformance,withthelargest\ngainsonthehigher-resolutionScreenSpot-Probenchmark. AlthoughRULERdoesnotachievestate-of-the-artresults\npartly due to the limited training data and domains, our experiments nevertheless demonstrate that incorporating\nRULERreliablyenhancesgroundingperformanceundercomparabletrainingconditions.\n1Forbaselinestrainedwithnormalizedcoordinates,weapplyappropriatetransformationstotheoutputtoenablecomparison.\n6\nImprovingGUIGroundingwithExplicitPosition-to-CoordinateMapping\nTable1: GroundingelementaccuracyonScreenSpot-Pro. Theresultsofmodelsmarkedwith†areadoptedfromWu\netal.(2025a).Bestresultspercolumnwithineachcomparablemodelgroupareshowninbold.Notethatresultsinthe\nfirsttwogroupsarenotdirectlycomparabletoours,eitherbecausethemodelsareclosed-source(weights/architectures\nunavailable)orbecausetheirtrainingdataandunderlyingbasemodelsareunclearorincomparable. Wenevertheless\nincludethesenumbersforreference.\nModel Dev Creative CAD Scientific Office OS Avg\nGPT-4o† 0.7 0.6 1.5 1.2 0.9 0.0 0.8\nClaudeCompute† 12.6 16.8 11.9 25.8 26.9 8.1 17.1\nQwen2-VL-7B† 1.3 0.9 0.4 3.5 3.0 0.5 1.6\nSeeClick-9.6B† 0.3 0.6 1.9 2.0 0.9 1.5 1.1\nOS-Atlas-7B† 17.7 17.9 10.3 24.4 27.4 16.8 18.9\nAguvis-7B† 16.1 21.4 13.8 34.6 34.3 19.4 22.9\nUGround-V1-7B 28.1 31.7 14.6 39.0 49.6 24.5 31.1\nUI-TARS-7B 36.1 32.8 18.0 50.0 53.5 24.5 35.7\nGUI-Actor-7B+Verifier† 38.8 40.5 37.2 44.5 64.8 43.9 44.2\nTrainedFromScratchwithLLaVA-NeXTFramework\nLLaVA-NeXT+LLaVAPE 23.1 25.5 12.6 35.4 43.8 20.5 26.8\nLLaVA-NeXT+MRoPE 26.8 29.4 13.6 36.5 47.5 21.2 29.2\nLLaVA-NeXT+I-MROPE 27.1 29.8 13.8 36.6 47.8 21.5 29.4\nLLaVA-NeXT+I-MROPE+RULER 28.2 32.1 15.3 40.5 51.6 24.8 32.1\nFinetuning\nQwen2.5-VL 31.4 34.2 17.1 42.8 54.0 28.3 34.6\nQwen2.5-VL+RULER 34.2 36.5 21.1 43.9 55.4 32.0 37.2\n5.2 AnalysisonRULERTokenInterval\nToanalyzetheeffectofchangingtheintervaloftheRULERtoken,weprovideasensitivityanalysisofsinEquation3.\nTheresultsareshowninFigure3.\nInthefigure, wenoticethatallintervalsettingsyieldconsistentimprovementscomparedtomodelswithout RULER\ntokens in all datasets. However, varying the RULER token interval does not yield significant or consistent improve-\nmentsonthebenchmarks.Basedontheresults,weadoptthesettingofs=8asagoodtrade-offbetweenperformance\nand efficiency. However, it should be noted that in extremely low-resolution settings such as mobile phone screen-\nshot grounding, an interval s = 16 may inject only a single RULER token, leading to reduced performance in the\nmobile-relatedsubtasksofScreenSpotandScreenSpot-V2.\n5.3 EfficiencyAnalysis\nTo demonstrate the efficiency of adding RULER tokens, we provide an efficiency analysis in the p = 8 setting in\nFigure4. Inthisfigure,wereporttheratioofRULERtokenstoimagetokensincommonresolutionsofmobilephones\nand computer screens under different interval settings. Even in the extreme 8K screenshot scenarios and using an\nintervalofs = 2,RULERonlyadds68additionaltokens,whichismerely0.2%ofthetotalnumberofvisiontokens.\nForlow-resolutionmobilescreenshots,thehighestratioofRULERtovisiontokensobservedis2.8%,wheretheimpact\nonefficiencyremainsnegligible. TheseresultsconfirmthattheintroductionoftokensRULERcaneffectivelyimprove\ngroundingperformancewhilemaintainingefficiency.\n6 ConclusionsandLimitations\nWepresentedaframeworkforGUIgroundingthatreplacesimplicitposition-to-pixelcoordinatemappingwithexplicit\nspatialguidance. RULERtokensprovidecoordinatereferencesthattransformunstableregressionintorobustreference\nandadjustment,whileI-MROPEcorrectsfrequencyimbalancesinthepositionalembeddings. Ourapproachachieves\nconsistentimprovementsacrossbenchmarks,withparticularlystronggainsonhigh-resolutiondisplaysbeyondtrain-\n7\nImprovingGUIGroundingwithExplicitPosition-to-CoordinateMapping\nTable 2: Grounding element accuracy on ScreenSpot. The results of models marked with † are adopted from Wu\netal.(2025a). Bestresultspercolumnwithineachgroupareshowninbold.\nM-Text M-Icon D-Text D-Icon W-Text W-Icon Avg\nGPT-4† 22.6 24.5 20.2 11.8 9.2 8.8 16.2\nGPT-4o† 20.2 24.9 21.1 23.6 12.2 7.8 18.3\nClaudeComputerUse† - - - - - - 83.0\nGemini2.0† - - - - - - 84.0\nQwen2-VL-7B† 75.5 60.7 76.3 54.3 35.2 25.7 55.3\nSeeClick-9.6B† 78.0 52.0 72.2 30.0 55.7 32.5 53.4\nOS-Atlas-7B† 93.0 72.9 91.8 62.9 90.9 74.3 82.5\nAguvis-7B 95.6† 77.7 93.8 67.1 88.3 75.2 84.4\nUGround-v1-7B 93.0 79.9 93.8 76.4 90.9 84.0 86.3\nUI-TARS-7B 94.5 85.2 95.9 85.7 90.0 83.5 89.5\nGUI-Actor-7B+Verifier† 96.0 83.0 93.8 82.1 92.2 87.4 89.7\nTrainedFromScratchwithLLaVA-NeXTFramework\nLLaVA-NeXT+LLaVAPE 88.9 74.2 88.3 70.2 85.7 75.4 80.5\nLLaVA-NeXT+MRoPE 90.0 76.2 90.2 72.7 88.3 77.5 82.5\nLLaVA-NeXT+I-MROPE 90.5 76.9 90.9 73.4 88.5 77.7 83.0\nLLaVA-NeXT+I-MROPE+RULER 91.4 77.0 91.5 73.2 89.5 77.2 83.3\nFinetuning\nQwen2.5-VL 93.4 80.5 94.6 76.4 91.1 84.6 86.8\nQwen2.5-VL+RULER 94.2 84.1 93.6 76.5 92.4 85.3 87.7\n37\n35\n33\n31\n29\nMRoPE I-MRoPE Finetuned\nTraining Setting\nerocS\necnamrofreP\nScreenSpot-Pro ScreenSpot ScreenSpot-v2\n91 91\n37.237.1\n36.5 89.289.0\n89 89 88.6 88.2\n87.887.7\n34.6 87 86.8 87.1 87\n32.732.932.7 85.585.685.4\n86.186.085.7\n32.332.131.9 85\n83.7 83.383.1 83.0\n84.5\n83.6 84.1\n85\n84.0\n84.5\n83 82.5 83\n29.2 29.4\n81 81\nMRoPE I-MRoPE Finetuned MRoPE I-MRoPE Finetuned\nTraining Setting Training Setting\nNo RULER RULER Interval 4 RULER Interval 8 RULER Interval 16\nFigure3: AblationstudyonRULERtokenintervalssacrossdifferentbenchmarksandtrainingsettings.\ningresolutions,validatingitsgeneralizationcapability. Theminimalcomputationaloverhead(lessthan1%oftoken\nincrease) makes deployment practical. Future work could explore adaptive token placement and extension to video\ninterfaces. ThesuccessofexplicitspatialguidanceoverimplicitlearningsuggestsbroaderapplicationsbeyondGUI\nautomationforanytaskthatrequiresprecisevisuallocalization.\nReferences\nShuaiBai, KeqinChen, XuejingLiu, JialinWang, WenbinGe, SiboSong, KaiDang, PengWang, ShijieWang, Jun\nTang,HumenZhong,YuanzhiZhu,MingkunYang,ZhaohaiLi,JianqiangWan,PengfeiWang,WeiDing,Zheren\nFu, Yiheng Xu, Jiabo Ye, Xi Zhang, Tianbao Xie, Zesen Cheng, Hang Zhang, Zhibo Yang, Haiyang Xu, and\nJunyangLin. Qwen2.5-vltechnicalreport. arXivpreprintarXiv: 2502.13923,2025.\n8\nImprovingGUIGroundingwithExplicitPosition-to-CoordinateMapping\nTable3: GroundingelementaccuracyonScreenSpot-V2. Theresultsofmodelsmarkedwith†areadoptedfromWu\netal.(2025a). Bestresultspercolumnwithineachgroupareshowninbold.\nM-Text M-Icon D-Text D-Icon W-Text W-Icon Avg\nGPT-4o+OmniParser-v2† 95.5 74.6 92.3 60.9 88.0 59.6 80.7\nSeeClick-9.6B† 78.4 50.7 70.1 29.3 55.2 32.5 55.1\nOS-Atlas-7B† 95.2 75.8 90.7 63.6 90.6 77.3 84.1\nAguvis-7B† 95.5 77.3 95.4 77.9 91.0 72.4 86.0\nUGround-V1-7B 95.0 83.3 95.0 77.8 92.1 77.2 87.6\nUI-TARS-7B 96.9 89.1 95.4 85.0 93.6 85.2 91.6\nGUI-Actor-7B+Verifier† 97.2 84.8 94.3 85.0 94.0 85.2 90.9\nTrainedFromScratchwithLLaVA-NeXTFramework\nLLaVA-NeXT+LLaVAPE 92.4 78.8 90.1 75.3 87.9 74.1 83.1\nLLaVA-NeXT+MRoPE 93.2 79.1 90.8 76.6 88.0 76.3 84.0\nLLaVA-NeXT+I-MROPE 93.4 80.0 91.3 77.5 88.1 76.7 84.5\nLLaVA-NeXT+I-MROPE+RULER 95.0 82.7 90.3 79.8 88.6 77.1 85.6\nFinetuning\nQwen2.5-VL 95.6 85.2 95.2 80.8 92.5 79.9 88.2\nQwen2.5-VL+RULER 96.2 87.0 95.3 80.5 93.2 81.6 89.0\n2.5\n2.0\n1.5\n1.0\n0.5\n0.0\n320\n×240\n640\n×480\n800\n×600\n1024\n×768\n1280\n×1024\n1366\n×768\n1600\n×900\n1920\n×1080\n2560\n×1440\n2560\n×1600\n3200\n×1800\n3440\n×1440\n3840\n×2160\n5120\n×2880\n7680\n×4320\nImage Resolution\n)%(\nsnekoT\negamI\n#\n/\nsnekoT\nRELUR\n#\n2.8%\nRULER Interval 4\nRULER Interval 8\nRULER Interval 16\n1.9%\n1.4%\n1.3%\n0.9% 1.0% 0.9%\n0.7% 0.6% 0.7% 0.8% 0.7%\n0.5% 0.3% 0 0 . . 5 3 % % 0 0 . . 4 2 % % 0 0 . . 5 3 % % 0 0 . . 4 2 % % 0 0 . . 3 2 % % 0 0 0 . . . 5 3 1 % % % 0 0 0 . . . 4 2 1 % % % 0 0 0 . . . 4 2 1 % % % 0 0 0 . . . 5 3 1 % % % 0 0 0 . . . 3 2 1 % % % 0 00 . .. 2 11 % %% 0 00 . .. 2 10 % %%\nFigure4: AnalysisoftheratioofthenumberofRULERtokenstothenumberofimagetokensundercommonmobile\nphoneandcomputerscreenresolutionsfordifferentRULERintervals. Allnumbersareinpercentages(%).\nKanzhi Cheng, Qiushi Sun, Yougang Chu, Fangzhi Xu, Li YanTao, Jianbing Zhang, and Zhiyong Wu. SeeClick:\nHarnessing GUI grounding for advanced visual GUI agents. In Proceedings of the 62nd Annual Meeting of\nthe Association for Computational Linguistics (Volume 1: Long Papers), pp. 9313–9332, Bangkok, Thailand,\nAugust 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.505. URL https:\n//aclanthology.org/2024.acl-long.505/.\nXiangDeng, YuGu, BoyuanZheng, ShijieChen, SamuelStevens, BoshiWang, HuanSun, andYuSu. Mind2web:\nTowards a generalist agent for the web. In Thirty-seventh Conference on Neural Information Processing Systems\nDatasetsandBenchmarksTrack,2023. URLhttps://openreview.net/forum?id=kiYqbO3wqw.\nJunqi Ge, Ziyi Chen, Jintao Lin, Jinguo Zhu, Xihui Liu, Jifeng Dai, and Xizhou Zhu. V2pe: Improving multi-\nmodal long-context capability of vision-language models with variable visual position encoding. arXiv preprint\narXiv:2412.09616,2024.\nBoyuGou,RuohanWang,BoyuanZheng,YananXie,ChengChang,YihengShu,HuanSun,andYuSu. Navigating\nthedigitalworldashumansdo: UniversalvisualgroundingforGUIagents. InTheThirteenthInternationalCon-\nferenceonLearningRepresentations,2025. URLhttps://openreview.net/forum?id=kxnoqaisCT.\n9\nImprovingGUIGroundingwithExplicitPosition-to-CoordinateMapping\nDong Guo, Faming Wu, Feida Zhu, Fuxing Leng, Guang Shi, Haobin Chen, Haoqi Fan, Jian Wang, Jianyu Jiang,\nJiaweiWang,JingjiChen,JingjiaHuang,KangLei,LipingYuan,LishuLuo,PengfeiLiu,QinghaoYe,RuiQian,\nShenYan,ShixiongZhao,ShuaiPeng,ShuangyeLi,SihangYuan,SijinWu,TianhengCheng,WeiweiLiu,Wenqian\nWang, Xianhan Zeng, Xiao Liu, Xiaobo Qin, Xiaohan Ding, Xiaojun Xiao, Xiaoying Zhang, Xuanwei Zhang,\nXuehanXiong,YanghuaPeng,YangruiChen,YanweiLi,YanxuHu,YiLin,YiyuanHu,YiyuanZhang,YoubinWu,\nYuLi,YudongLiu,YueLing,YujiaQin,ZanboWang,ZhiwuHe,AoxueZhang,BairenYi,BenchengLiao,Can\nHuang,CanZhang,ChaoruiDeng,ChaoyiDeng,ChengLin,ChengYuan,ChenggangLi,ChenhuiGou,Chenwei\nLou,ChengzhiWei,ChundianLiu,ChunyuanLi,DeyaoZhu,DonghongZhong,FengLi,FengZhang,GangWu,\nGuodongLi,GuohongXiao,HaibinLin,HaihuaYang,HaomingWang,HengJi,HongxiangHao,HuiShen,Huixia\nLi,JiahaoLi,JialongWu,JianhuaZhu,JianpengJiao,JiashiFeng,JiazeChen,JianhuiDuan,JihaoLiu,JinZeng,\nJingqunTang,JingyuSun,JoyaChen,JunLong,JundaFeng,JunfengZhan,JunjieFang,JuntingLu,KaiHua,Kai\nLiu, Kai Shen, Kaiyuan Zhang, Ke Shen, Ke Wang, Keyu Pan, Kun Zhang, Kunchang Li, Lanxin Li, Lei Li, Lei\nShi,LiHan,LiangXiang,LiangqiangChen,LinChen,LinLi,LinYan,LiyingChi,LongxiangLiu,MengfeiDu,\nMingxuanWang, NingxinPan, PeibinChen, PengfeiChen, PengfeiWu, QingqingYuan, QingyaoShuai, Qiuyan\nTao,RenjieZheng,RenruiZhang,RuZhang,RuiWang,RuiYang,RuiZhao,ShaoqiangXu,ShihaoLiang,Shipeng\nYan,ShuZhong,ShuaishuaiCao,ShuangzhiWu,ShufanLiu,ShuhanChang,SonghuaCai,TenglongAo,Tianhao\nYang,TingtingZhang,WanjunZhong,WeiJia,WeiWeng,WeihaoYu,WenhaoHuang,WenjiaZhu,WenliYang,\nWenzhi Wang, Xiang Long, XiangRui Yin, Xiao Li, Xiaolei Zhu, Xiaoying Jia, Xijin Zhang, Xin Liu, Xinchen\nZhang,XinyuYang,XiongcaiLuo,XiuliChen,XuantongZhong,XuefengXiao,XujingLi,YanWu,YaweiWen,\nYifanDu,YihaoZhang,YiningYe,YonghuiWu,YuLiu,YuYue,YufengZhou,YufengYuan,YuhangXu,Yuhong\nYang, Yun Zhang, Yunhao Fang, Yuntao Li, Yurui Ren, Yuwen Xiong, Zehua Hong, Zehua Wang, Zewei Sun,\nZeyu Wang, Zhao Cai, Zhaoyue Zha, Zhecheng An, Zhehui Zhao, Zhengzhuo Xu, Zhipeng Chen, Zhiyong Wu,\nZhuofanZheng,ZihaoWang,ZilongHuang,ZiyuZhu,andZuquanSong. Seed1.5-vltechnicalreport,2025. URL\nhttps://arxiv.org/abs/2505.07062.\nWenyi Hong, Weihan Wang, Qingsong Lv, Jiazheng Xu, Wenmeng Yu, Junhui Ji, Yan Wang, Zihan Wang, Yuxiao\nDong, Ming Ding, and Jie Tang. Cogagent: A visual language model for gui agents. In Proceedings of the\nIEEE/CVFConferenceonComputerVisionandPatternRecognition(CVPR),pp.14281–14290,June2024.\nEdwardJHu,yelongshen,PhillipWallis,ZeyuanAllen-Zhu,YuanzhiLi,SheanWang,LuWang,andWeizhuChen.\nLoRA:Low-rankadaptationoflargelanguagemodels. InInternationalConferenceonLearningRepresentations,\n2022. URLhttps://openreview.net/forum?id=nZeVKeeFYf9.\nHaoran Li, Yingjie Qin, Baoyuan Ou, Lai Xu, and Ruiwen Xu. Hope: Hybrid of position embedding for length\ngeneralizationinvision-languagemodels. arXivpreprintarXiv:2505.20444,2025a.\nKaixin Li, Ziyang Meng, Hongzhan Lin, Ziyang Luo, Yuchen Tian, Jing Ma, Zhiyong Huang, and Tat-Seng Chua.\nScreenspot-pro: Gui grounding for professional high-resolution computer use. arXiv preprint arXiv:2504.07981,\n2025b.\nYangLi,JiacongHe,XinZhou,YuanZhang,andJasonBaldridge. Mappingnaturallanguageinstructionstomobile\nuiactionsequences,2020. URLhttps://arxiv.org/abs/2005.03776.\nHaogeng Liu, Quanzeng You, Xiaotian Han, Yongfei Liu, Huaibo Huang, Ran He, and Hongxia Yang.\nVisual anchors are strong information aggregators for multimodal large language model. In Ad-\nvances in Neural Information Processing Systems, volume 37, pp. 17696–17718. Curran Associates,\nInc., 2024a. URL https://proceedings.neurips.cc/paper_files/paper/2024/file/\n1f84412e84da6440ca355d87184cb1b3-Paper-Conference.pdf.\nHaotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual instruction tuning. In Thirty-seventh Con-\nference on Neural Information Processing Systems, 2023. URL https://openreview.net/forum?id=\nw0H2xGHlkw.\nHaotian Liu, Chunyuan Li, Yuheng Li, Bo Li, Yuanhan Zhang, Sheng Shen, and Yong Jae Lee. Llava-next: Im-\nprovedreasoning,ocr,andworldknowledge,January2024b. URLhttps://llava-vl.github.io/blog/\n2024-01-30-llava-next/.\nXiaoranLiu,HangYan,ChenxinAn,XipengQiu,andDahuaLin. ScalinglawsofRoPE-basedextrapolation. InThe\nTwelfth International Conference on Learning Representations, 2024c. URL https://openreview.net/\nforum?id=JO7k0SJ5V6.\nZikangLiu, LongtengGuo,YepengTang, TongtianYue,JunxianCai, KaiMa,QingbinLiu, XiChen,andJingLiu.\nVrope: Rotarypositionembeddingforvideolargelanguagemodels. arXivpreprintarXiv:2502.11664,2025.\nShravan Nayak, Xiangru Jian, Kevin Qinghong Lin, Juan A. Rodriguez, Montek Kalsi, Rabiul Awal, Nicolas Cha-\npados, M.Tamer O¨zsu, AishwaryaAgrawal, David Vazquez, ChristopherPal, Perouz Taslakian, SpandanaGella,\n10\nImprovingGUIGroundingwithExplicitPosition-to-CoordinateMapping\nandSaiRajeswar. Ui-vision: Adesktop-centricguibenchmarkforvisualperceptionandinteraction, 2025. URL\nhttps://arxiv.org/abs/2503.15661.\nCatherineOlsson,NelsonElhage,NeelNanda,NicholasJoseph,NovaDasSarma,TomHenighan,BenMann,Amanda\nAskell,YuntaoBai,AnnaChen,TomConerly,DawnDrain,DeepGanguli,ZacHatfield-Dodds,DannyHernandez,\nScott Johnston, Andy Jones, Jackson Kernion, Liane Lovitt, Kamal Ndousse, Dario Amodei, Tom Brown, Jack\nClark, Jared Kaplan, Sam McCandlish, and Chris Olah. In-context learning and induction heads. arXiv preprint\narXiv: 2209.11895,2022.\nYujia Qin, Yining Ye, Junjie Fang, Haoming Wang, Shihao Liang, Shizuo Tian, Junda Zhang, Jiahao Li, Yunxin\nLi, Shijue Huang, et al. Ui-tars: Pioneering automated gui interaction with native agents. arXiv preprint\narXiv:2501.12326,2025.\nQwen. Qwen3-VL: Sharper vision, deeper thought, broader action. https://qwen.\nai/blog?id=99f0335c4ad9ff6153e517418d48535ab6d8afef&from=research.\nlatest-advancements-list,2025. [Accessed01-10-2025].\nQwen,:,AnYang,BaosongYang,BeichenZhang,BinyuanHui,BoZheng,BowenYu,ChengyuanLi,DayihengLiu,\nFeiHuang,HaoranWei,HuanLin,JianYang,JianhongTu,JianweiZhang,JianxinYang,JiaxiYang,JingrenZhou,\nJunyangLin,KaiDang,KemingLu,KeqinBao,KexinYang,LeYu,MeiLi,MingfengXue,PeiZhang,QinZhu,\nRuiMen, RunjiLin, TianhaoLi,TianyiTang,TingyuXia, XingzhangRen, XuanchengRen, YangFan,YangSu,\nYichangZhang,YuWan,YuqiongLiu,ZeyuCui,ZhenruZhang,andZihanQiu. Qwen2.5technicalreport. arXiv\npreprintarXiv: 2412.15115,2024.\nSamyamRajbhandari, JeffRasley, OlatunjiRuwase, andYuxiongHe. Zero: Memoryoptimizationstowardtraining\ntrillionparametermodels. arXivpreprintarXiv: 1910.02054,2019.\nJie Ren, Samyam Rajbhandari, Reza Yazdani Aminabadi, Olatunji Ruwase, Shuangyan Yang, Minjia Zhang, Dong\nLi,andYuxiongHe. Zero-offload: Democratizingbillion-scalemodeltraining. arXivpreprintarXiv: 2101.06840,\n2021.\nZhihongShao,PeiyiWang,QihaoZhu,RunxinXu,JunxiaoSong,XiaoBi,HaoweiZhang,MingchuanZhang,Y.K.\nLi,Y.Wu,andDayaGuo. Deepseekmath: Pushingthelimitsofmathematicalreasoninginopenlanguagemodels,\n2024. URLhttps://arxiv.org/abs/2402.03300.\nJianlin Su, Murtadha Ahmed, Yu Lu, Shengfeng Pan, Wen Bo, and Yunfeng Liu. Roformer: Enhanced transformer\nwithrotarypositionembedding. Neurocomput.,568(C),February2024. ISSN0925-2312. doi: 10.1016/j.neucom.\n2023.127063. URLhttps://doi.org/10.1016/j.neucom.2023.127063.\nChengcheng Wang, Jianyuan Guo, Hongguang Li, Yuchuan Tian, Ying Nie, Chang Xu, and Kai Han. Circle-\nrope: Cone-like decoupled rotary positional embedding for large vision-language models. arXiv preprint\narXiv:2505.16416,2025a.\nJunyangWang,HaiyangXu,JiaboYe,MingYan,WeizhouShen,JiZhang,FeiHuang,andJitaoSang. Mobile-agent:\nAutonomousmulti-modalmobiledeviceagentwithvisualperception. arXivpreprintarXiv:2401.16158,2024a.\nPengWang,ShuaiBai,SinanTan,ShijieWang,ZhihaoFan,JinzeBai,KeqinChen,XuejingLiu,JialinWang,Wenbin\nGe,YangFan,KaiDang,MengfeiDu,XuanchengRen,RuiMen,DayihengLiu,ChangZhou,JingrenZhou,and\nJunyang Lin. Qwen2-vl: Enhancing vision-language model’s perception of the world at any resolution. arXiv\npreprintarXiv: 2409.12191,2024b.\nSuyuchen Wang, Ivan Kobyzev, Peng Lu, Mehdi Rezagholizadeh, and Bang Liu. Resonance RoPE: Improving\ncontext length generalization of large language models. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar\n(eds.), Findings of the Association for Computational Linguistics: ACL 2024, pp. 586–598, Bangkok, Thai-\nland, August 2024c. Association for Computational Linguistics. doi: 10.18653/v1/2024.findings-acl.32. URL\nhttps://aclanthology.org/2024.findings-acl.32/.\nXinyuan Wang, Bowen Wang, Dunjie Lu, Junlin Yang, Tianbao Xie, Junli Wang, Jiaqi Deng, Xiaole Guo, Yiheng\nXu,ChenHenryWu,ZhennanShen,ZhuokaiLi,RyanLi,XiaochuanLi,JundaChen,BoyuanZheng,PeihangLi,\nFangyuLei,RuishengCao,YeqiaoFu,DongchanShin,MartinShin,JiaruiHu,YuyanWang,JixuanChen,Yuxiao\nYe,DanyangZhang,DikangDu,HaoHu,HuarongChen,ZaidaZhou,HaotianYao,ZiweiChen,QizhengGu,Yipu\nWang, HengWang, DiyiYang, VictorZhong, FloodSung, Y.Charles, ZhilinYang, andTaoYu. Opencua: Open\nfoundationsforcomputer-useagents,2025b. URLhttps://arxiv.org/abs/2508.09123.\nQianhui Wu, Kanzhi Cheng, Rui Yang, Chaoyun Zhang, Jianwei Yang, Huiqiang Jiang, Jian Mu, Baolin Peng,\nBo Qiao, Reuben Tan, et al. Gui-actor: Coordinate-free visual grounding for gui agents. arXiv preprint\narXiv:2506.03143,2025a.\n11\nImprovingGUIGroundingwithExplicitPosition-to-CoordinateMapping\nZhiyongWu,ZhenyuWu,FangzhiXu,YianWang,QiushiSun,ChengyouJia,KanzhiCheng,ZichenDing,Liheng\nChen, Paul Pu Liang, and Yu Qiao. OS-ATLAS: Foundation action model for generalist GUI agents. In The\nThirteenthInternationalConferenceonLearningRepresentations,2025b. URLhttps://openreview.net/\nforum?id=n9PDaFNi8t.\nTianbaoXie,JiaqiDeng,XiaochuanLi,JunlinYang,HaoyuanWu,JixuanChen,WenjingHu,XinyuanWang,Yuhui\nXu, Zekun Wang, et al. Scaling computer-use grounding via user interface decomposition and synthesis. arXiv\npreprintarXiv:2505.13227,2025.\nYiheng Xu, Zekun Wang, Junli Wang, Dunjie Lu, Tianbao Xie, Amrita Saha, Doyen Sahoo, Tao Yu, and Caiming\nXiong. Aguvis: UnifiedpurevisionagentsforautonomousGUIinteraction. InForty-secondInternationalConfer-\nenceonMachineLearning,2025. URLhttps://openreview.net/forum?id=PlihOwfx4r.\nYanYang,DongxuLi,YutongDai,YuhaoYang,ZiyangLuo,ZiruiZhao,ZhiyuanHu,JunzheHuang,AmritaSaha,\nZeyuanChen,etal. Gta1: Guitest-timescalingagent. arXivpreprintarXiv:2507.05791,2025.\nXinbinYuan,JianZhang,KaixinLi,ZhuoxuanCai,LujianYao,JieChen,EnguangWang,QibinHou,JinweiChen,\nPeng-TaoJiang,etal.Enhancingvisualgroundingforguiagentsviaself-evolutionaryreinforcementlearning.arXiv\npreprintarXiv:2505.12370,2025.\nXiaohuaZhai,BasilMustafa,AlexanderKolesnikov,andLucasBeyer. Sigmoidlossforlanguageimagepre-training.\nIEEEInternationalConferenceonComputerVision,2023. doi: 10.1109/ICCV51070.2023.01100.\nChaoyun Zhang, Liqun Li, Shilin He, Xu Zhang, Bo Qiao, Si Qin, Minghua Ma, Yu Kang, Qingwei Lin, Saravan\nRajmohan,etal. Ufo: Aui-focusedagentforwindowsosinteraction. InProceedingsofthe2025Conferenceofthe\nNationsoftheAmericasChapteroftheAssociationforComputationalLinguistics: HumanLanguageTechnologies\n(Volume1: LongPapers),pp.597–622,2025a.\nMiaosenZhang,ZiqiangXu,JialiangZhu,QiDai,KaiQiu,YifanYang,ChongLuo,TianyiChen,JustinWagle,Tim\nFranklin,etal. Phi-groundtechreport: Advancingperceptioninguigrounding. arXivpreprintarXiv:2507.23779,\n2025b.\nBoyuanZheng,BoyuGou,JihyungKil,HuanSun,andYuSu. Gpt-4v(ision)isageneralistwebagent,ifgrounded.\nInICML,2024. URLhttps://openreview.net/forum?id=piecKJ2DlB.\nA ImplementationDetails\nWeprovidedetailedtrainingconfigurationsforourexperimentsinthefollowing. Allexperimentsareperformedon8\nNVIDIAH100GPUs.\nA.1 TrainingfromScratch\nStage 1: Vision-Language Alignment Pretraining. We follow the LLaVA-NeXT training paradigm. The model\nusesSigLIP-SO400M-14@384(Zhaietal.,2023)asthevisionencoderandQwen2.57BInstruct(Qwenetal.,2024)\nas the language model. During pretraining, we train only the MLP projection layer while keeping both vision and\nlanguage models frozen. Training is performed on the LLaVA-558K dataset (Liu et al., 2023) for 1 epoch with a\nlearning rate of 1×10−3 using cosine scheduling and 3% warmup ratio. We use a per-device batch size of 4 with\ngradient accumulationsteps of2, resultingin an effectivebatch sizeof 64 across8 GPUs. Themaximum sequence\nlengthissetto8,192tokens. ImagesareprocessedusingtheAnyResconfigurationwithamaximumof9patchesand\ngridpinpointsrangingfrom(1×1)to(12×6)toaccommodatehigh-resolutionimagesduringinference. Weemploy\nDeepSpeedZero-2withCPUoffload(Renetal.,2021)andmixedprecisiontraining(bf16)formemoryefficiency.For\nmodelsusingRULER,wesetthetokenintervaltos=8,whilepositionalembeddingconfigurations(defaultLLaVA\nPE,MRoPE,orI-MRoPE)arespecifiedthroughoutthepretrainingandfinetuningprocess.\nStage 2: Domain-Specific Finetuning. Using the pretrained projection layer from Stage 1, we finetune on the\nUGrounddataset(Gouetal.,2025)withcoordinatesconvertedtorawpixelvaluestomatchourRULERtokendesign.\nIn this stage, we train the projection layer with full parameter finetuning and the language model using LoRA (Hu\net al., 2022) with rank 16 for parameter efficiency. The base learning rate is set to 1 × 10−5 for the projection\nlayer and LoRA parameters. We use a per-device batch size of 1 with gradient accumulation steps of 4, yielding\nan effective batch size of 32. The maximum sequence length is extended to 16,384 tokens to accommodate higher-\nresolutionimages. Trainingrunsfor1epochwithcosinelearningrateschedulingand3%warmup. Wecontinueusing\nDeepSpeedZero-2withCPUoffloadandbf16mixedprecision.\n12\nImprovingGUIGroundingwithExplicitPosition-to-CoordinateMapping\nA.2 FinetuningQwen2.5-VL\nFor adapting the pretrained Qwen2.5-VL 7B Instruct model (Bai et al., 2025), we use a conservative finetuning ap-\nproach to preserve the existing capabilities of the model while adding RULER tokens. We maintain the model’s\noriginal MRoPE configuration to avoid disrupting learned position-aware behaviors. The model is finetuned with a\nlow learning rate of 1×10−5 using cosine scheduling with 3% warmup to ensure stable adaptation. We use a per-\ndevicebatchsizeof4withgradientaccumulationstepsof4,resultinginaneffectivebatchsizeof128. Themaximum\nsequence length remains at 16,384 tokens, and we utilize Qwen2.5-VL’s dynamic resolution capability with pixel\ncounts ranging from 784 to 50,176. Training runs for 1 epoch on the UGround dataset with all components (vision\nencoder, MLP projector, and language model) being trainable. We employ DeepSpeed Zero-3 (Rajbhandari et al.,\n2019) for distributed training and bf16 mixed precision. RULER tokens are integrated into the input sequence with\ninterval s = 8 when specified, and we use Qwen2.5-VL’s native chat template and system prompts for consistency\nwiththepretrainedmodel’sbehavior.\nA.3 EvaluationProtocol\nAllmodelsareevaluatedusinggreedydecoding(temperature=0)withthesamemaximumsequencelengthastraining.\nForScreenSpotbenchmarks,wepreprocessallcoordinatestorawpixelvaluesandusetheevaluationcodefromWu\net al. (2025a). Element accuracy is computed by checking if the predicted coordinate falls within the ground-truth\nboundingbox. Weensureconsistentpre-processingacrossallbaselinesforfaircomparison.\n13\n",
    "tables": [],
    "images": []
  },
  {
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "text": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for\nTexture Recognition\nRicardoT.Fares1 LucasC.Ribas1\nAbstract etal.,2023). Thefirstonesarecharacterizedbyapproaches\nmanuallydesignedfromscratch,whichprovidegreaterex-\nRandomizedneuralnetworksforrepresentation\nplainability but generally have limited descriptive power.\nlearning have consistently achieved prominent\nOntheotherhand,thesecondgroupischaracterizedbythe\nresults in texture recognition tasks, effectively\nuseofneuralnetworkstoautomaticallyextracttheessential\ncombiningtheadvantagesofbothtraditionaltech-\nattributes. Although they offer greater descriptive power,\nniquesandlearning-basedapproaches. However,\nthesemethodsaregenerallylessinterpretableanddemand\nexistingapproacheshavesofarfocusedmainlyon\nsubstantialamountsofdataandenergy. improvingcross-informationprediction,without\nintroducingsignificantadvancementstotheover- Inthiscontext,thethirdgroupofapproachesseekstolever-\nallrandomizednetworkarchitecture.Inthispaper, age the advantages of the previous ones while simultane-\nwepropose MIXER,anovelrandomizedneural ouslyaddressingtheirinherentlimitations. Inthisgroup,\nnetworkfortexturerepresentationlearning. Atits approachesarecharacterizedbythosethateithercombine\ncore,themethodleverageshypersphericalrandom traditionaldescriptorswithneuralnetworksasinSuetal.\nembeddingscoupledwithadual-branchlearning (2023)orthoseasinJunior&Backes(2016);Scabinietal.\nmoduletocapturebothintra-andinter-channel (2023)thatuseneuralnetworkswhilemaintaininginherent\nrelationships, further enhanced by a newly for- characteristicsofsomehandcrafteddescriptors,suchasthe\nmulatedoptimizationproblemforbuildingrich absenceofadatasettoworkproperlyasforinstanceinLBP\ntexturerepresentations.Experimentalresultshave (Ojalaetal.,2002b),i.e.,givenanimageaLBPrepresenta-\nshowntheinterestingresultsoftheproposedap- tionispromptlyreturnedwithouttheneedofapre-defined\nproach across several pure texture benchmarks, training and test split. Therefore, thinking in a Venn dia-\neachwithdistinctcharacteristicsandchallenges. gram,hybridapproachescanbeseenastheintersectionof\nThesourcecodewillbeavailableuponpublica- thehandcraftedandlearning-basedapproaches,suchthat\ntion. someofthementionedlearning-basedtechniquesmaybe\nconsideredhybridones.\n1.Introduction Currently,interestinghybridtexturerecognitionapproaches\nare those based on shallow and fast neural networks. In\nTextureisawidelystudiedvisualfeatureinbothresearch particular,tothebestofourknowledge,Junior&Backes\nfields of computer vision (Haralick et al., 1973) and neu- (2016)proposedthefirsttexturerepresentationlearningtech-\nroscience (Julesz, 1981). Its study has not only enabled niqueusingaRandomizedNeuralNetwork(RNN).Thisis\na deeper understanding of human texture perception but ashallow1-hidden-layerneuralnetwork,wherethehidden\nalsoallowedcomputerstoefficientlyrepresentthemintheir layerisrandomlyinitializedandtheoutputlayerweights\nown language for later use in downstream tasks, such as arecomputedusingaclosed-formsolution. Thisleadstoa\nmaterialrecognition(Sharanetal.,2013;Chenetal.,2021), rapidtrainingprocedure,andtheresultingweightsaresub-\nlandclassification(Akivaetal.,2022),andbiologicalimage sequentlyusedtocomposetheimagerepresentation. This\nanalysis(Oiticicaetal.,2025). techniquehasbeensuccessfullyappliedinrepresentation\nlearningtasks,suchasincolor-texture(Ribasetal.,2024),\nTo tackle these tasks, many texture representation ap-\nandshaperepresentation(Junioretal.,2018;Fujiwara&\nproacheshavebeenproposedintheliterature, whichcur-\nHashimoto,2020;Ribas&Bruno,2024).\nrentlycanbebroadlyclassifiedinthreegroups:handcrafted\n(Haralick et al., 1973; Manjunath & Ma, 1996; Leung & However,mostoftheserepresentationlearningtechniques\nMalik,2001;Ojalaetal.,2002b),learning-based(Cimpoi havefocusedprimarilyonconstructingimprovedinputand\netal.,2015;Zhangetal.,2017;Zhaietal.,2020),andhybrid outputfeaturematricestoenhancethelearningofweights\ntechniques(Junior&Backes,2016;Scabinietal.,2023;Su throughbettercross-informationprediction,thatis,guiding\nthe network to learn more effective weights by forcing it\n1InstituteofBiosciences,HumanitiesandExactSciences,Sa˜o\ntopredictmorecomplexrelationshipsbetweeninputand\nPauloStateUniversity,Sa˜oJose´doRioPreto,Brazil.Correspon-\ndenceto:LucasC.Ribas<lucas.ribas@unesp.br>. outputcontent. Incontrast,littletonoresearchintexture\nrepresentationlearninghassimultaneouslyexploredarchi-\n1\n5202\ntcO\n3\n]VC.sc[\n1v82230.0152:viXra\nMIXER:MixedHypersphericalRandomEmbeddingNeuralNetworkforTextureRecognition\ntecturalimprovements,suchasenhancementstotherandom ters a ∈ R be scalars, and the boldface lowercase letters\nprojectorortheunderlyingoptimizationproblem. a ∈ Rn be n-dimensional vectors, where a ∈ R is its\nk\nk-thcomponent. Wedefinetheboldfaceuppercaseletters\nInthiswork, weintroduce MIXER, anoveltexturerepre-\nA∈Rm×n asarealmatrixofsizem×n,wherea ∈R\nsentationlearningrandomneuralnetwork. Itiscomposed ij\nisits(i,j)-entry. Further,letcalligraphicuppercaseletters\noffourcoremodules. Foranygivenimage,thefirstmod-\nAdenoteasetofelements,withthefollowingexceptions\nule, called the local pattern extractor, is responsible for\nthatRn isthesetofalln-dimensionalrealvectors,Rm×n\ndenselyextractingsmallpatchesfromeachimagechannel\nisthesetofallrealmatricesofsizem×n,andNistheset\nindependently,aimingtocapturerawlocaltextureinforma-\nofnaturalnumbers.\ntion. Next, thesecondmodule, calledthehyperspherical\nrandomprojector,encodestheextractedpatchesintoran-\n2.1.TextureRecognition\ndomembeddingsandconstrainsthemtolieonthesurface\nof a hypersphere through embedding normalization. The ClassicalTextureRecognition. Theearlydaysoftexture\nthirdmodule,referredtoasthelearningmodule,consistsof recognitionreliedheavilyonclassicalorhandcraftedfea-\ntwobranchesthatcaptureintra-andinter-channelintensity tureextractors,whichweremanuallydesignedbyspecialists\nrelationships. The first branchemploysa purely random- andtypicallybasedonpredefinedsteps. Tobeginwith,the\nizedautoencoder,whilethesecondaddressesthislearning pioneeringworkbyHaralicketal.(1973)notonlyproposed\nthroughanoveloptimizationproblem. Finally,thelastmod- afeatureextractiontechniquebasedonmeasuressuchas\nule,calledcompressionmodule,compresses(summarizes) angularsecondmoment,contrast,andcorrelationderived\nthe decoders’ learned weights into a useful color-texture fromgray-levelco-occurrencematrices,butalsointroduced\nrepresentationforrecognitiontasks. thenotionoftextureasthespatialdistributionofgray-level\ntones,althoughnoformalanduniversallyaccepteddefini-\nContributionsofthispaper. Ourcontributionsaresum-\ntionexiststothisday.\nmarizedasfollows:\nLater,studiesonthevisualinformationprocessingsystem\n• Weintroducedanovelhypersphericalmulti-headrandom (Daugman,1985;Jones&Palmer,1987)discussedthere-\nprojectorthat: (i)distinctlyencodesthelocalpatchesof ceptivefieldsofsimplecellsinthevisualcortex,showing\ndifferentimagechannels,therebyimplicitlyintroducing thattheycanbeexpressedintermsofGaborfilters. This\nchannel ownership information; and (ii) constrains the inspiredresearchersinproposingtexturefeatureextractors\nrandomembeddingstolieonthesurfaceofahypersphere, usingthesefiltersorwavelets(Boviketal.,1990;Manju-\nretainingonlytheirdirectionalinformation. nath&Ma,1996). Ingeneral,theseapproachesconsistof\ngeneratingafilterbankwithfiltersofdistinctorientations\n• WeproposedanovellearningmodulecomposedoftheDI-\nandfrequencies,andthenconvolvingtheimagewitheach\nRECTandMIXEDlearningbranches. Theformercaptures\nfilter. Subsequently,measuressuchasthemeanandstan-\nintra-channel intensity relationships, whereas the latter\ndarddeviationcanbecomputedfromthefilterresponsesto\nfocusesoninter-channelrelationships,achievedthrough\nserveasfeaturesoftheinputimage.\nanewoptimizationproblemappliedtoanintermediate\nfusedrepresentation. Followingthis,Ojalaetal.(1996)proposedtheLocalBi-\nnaryPattern(LBP).Atitscore,alocalneighborhoodscans\n• Experimentalresultsdemonstratedthatourcolor-texture\ntheentireimagewithoverlap,andthevalueswithineach\nrepresentationconsistentlyoutperformedtheexistingap-\nneighborhoodarethresholdedrelativetothecentralpixel\nproaches,beingtheonlyamongthecomparedapproaches\nvalue. Thenumbersresultingfromthebinarypatternsof\ntosurpassthe97%barrierofOutex,andthe99%barrier\neachneighborhoodareaggregatedintoahistogram,which\noftheaverageaccuracy.\nservesasthetexturerepresentation. Inaddition,manyim-\nprovedandrobusterversionsandsimilartechniquestoLBP\nStructureofthepaper. Section2presentsthenotationand\nwereproposed,suchasOjalaetal.(2002b)thatintroduced\ntherequiredbackground. Section3introducesthemethod\nthewidelyknownrotationinvariantversionoftheformer\nofournoveltexturerepresentation. Section4exhibitsthe\napproach,Ojansivu&Heikkila¨ (2008)proposedtheLocal\nexperimentalsetup.Section5showstheresultsandpresents\nPhaseQuantization(LPQ)technique,atexturedescriptor\nthediscussion. Toconclude,Section6terminatesthework\nrobusttoblurring,andGuoetal.(2010)presentedthecom-\nwiththeconclusionsandfutureworks.\npleteLBP(CLBP).\nAroundtheearly2000s,techniquessuchasBagofTextons\n2.BackgroundandNotation\n(BoT) (Leung & Malik, 2001) and Bag of Visual Words\nNotation. Throughoutthepaper,weadoptthefollowing (BoVW) (Csurka et al., 2004) emerged, representing an\nnotationconventionsforreadability. Letthelowercaselet- image as a histogram over a learned or predefined code-\n2\nMIXER:MixedHypersphericalRandomEmbeddingNeuralNetworkforTextureRecognition\nbook (Liu et al., 2019). Generally, given a training set, ing simultaneously shallow and deep layer features, thus\nthese methods select and describe local patches from the obtainingrichcross-layerfeaturesfortexturerecognition.\nimages and then build a codebook by applying a vector Tothisend,theDTPmoduleperformacross-layerfeature\nquantization algorithm, such as k-means, over the set of aggregation, and inspired by LBP, it denselysamples 3D\nlocalpatchdescriptors. Later,thiscodebookisusedtogen- patchesofthegroupedtensortocapturespatialandcross-\neratethehistogramfromatestimage,whichservesasits layer information. After, a spatial pyramid histogram is\nfeaturevector. Inaddition,withtheriseofthedeep-learning usedtocomprisethefeaturevector.\nmodels,thephaseoflocalpatchdescriptionturnedtouse\ndeep-learnedfeatures,suchasinFV-CNN(Cimpoietal., 2.2.RandomizedNeuralNetwork\n2015),DeepTEN(Zhangetal.,2017)andBoFF(Florindo\nGeneralBackground. Randomizedneuralnetworkspro-\n&Laureano,2023).\nposed in (Huang et al., 2006; Pao & Takefuji, 1992; Pao\nDeep-learning-based Texture Recognition. Since the etal.,1994;Schmidtetal.,1992)arecontinuouslybeing\nrapidemergenceofdeeplearningmethodsinthelastdecade, used by the research community for pattern recognition\ntheresearchcommunityhasseenavarietyofapproaches tasks. Inparticular,canonicalapplicationareasareclassifi-\nadoptingConvolutionalNeuralNetworks(CNNs)and,more cationandregression. However,aspreviouslymentioned,\nrecently,VisionTransformers(ViTs)fortexturerecognition. inthelastdecadenovelapproachesemployingrandomized\nThis is largely attributed to their ability to automatically neuralnetworkshavebeenproposedforrepresentationlearn-\nlearnandextractkeyfeaturesfromimages,incontrastto ing. Thesemethodshavebeenappliedprimarilytotextures,\nthemanuallydesigneddescriptorsdiscussedearlier. dynamictextures,andshaperepresentations,divergingfrom\ntheirmorecommonapplications.\nTheseapproachescanbedividedintotwocategories:feature\nextractionandend-to-endlearning. Theformerischaracter- Ingeneral,thelargeadoptionofthecommunityisdueto\nizedbytheuseoftheextractedfeaturesfromaoff-the-shelf threeessentialaspectsthatattractedinterestinrandomized\npre-trainedbackbonefollowedbytheuseofaclassicclas- neuralnetworks. Inthefirstplace,thesimplicity,sincethe\nsifier,suchasKNNandSVM.Thelatterinvolvestraining mostcommoncasesarearchitecturescomposedbyasin-\nacompletearchitecturefromscratchorfine-tuningapre- glefully-connectedhiddenlayerwithrandomlygenerated\ntrainedmodel. weights,andwhoseresponsibilityistoperformanon-linear\nrandom projection of the input data. Another important\nRemarkableexamplesoffeatureextractionapproachesare:\naspectisitsspeedandlowcomputationalcost,whichresult\nFV-CNN(Cimpoietal.,2015)whichusestheFisherVector\nfromcomputingtheoutputlayerweightsthroughaclosed-\n(FV)topoolthelocalfeaturesfromaconvolutionallayer\nformsolution. Thisenablesfasttrainingwithouttheneed\nofaCNNbackbone,ignoringthespatialinformation,thus\nforbackpropagation.Finally,thesemodelsalsoexhibitgood\ncreatinganorderlessrepresentation;andRADAM(Scabini\ngeneralizationcapabilitiesforcertaintypesofproblems.\netal.,2023)thatrandomlyencodesmulti-depthaggregated\nfeaturesfromCNNbackbonestolatercomposethetexture Commonly,therearetwowidelyutilizedrandomizedneural\nrepresentation. networksintheliterature: RandomizedVectorFunctional\nLink(RVFL),andtheExtremeLearningMachine(ELM).\nConversely, in the end-to-end learning category, notable\nBotharchitecturessharethecommonaspectofnon-linearly\ntechniquesare: DeepTEN(Zhangetal.,2017)wherethe\nrandom project the input data into another dimensional\nauthorsproposedasinglenetworkthatperformsthefeature\nspace, and the characteristic of a fast-training phase con-\nextraction,thecodebook(ordictionary)learning(inasu-\nductedviaaclosed-formsolutionbyusingthe(regularized)\npervisedmanner)andtheencodingoftherepresentation;\nleast-squaressolution.\nDEPNet (Xue et al., 2018) where authors discussed that\nthetexturesinsurfacespreservesomespatialinformation. Nevertheless,theirmaindifferenceliesinhowtheoutput\nThus, guided by this starting point, the authors proposed nodesareconnected. TheRVFLarchitecturehastheoutput\nthetextureencodingbranchandtheglobalaveragepooling nodesconnectedbothwiththehiddennodesandtheinput\nbranch. Theformeraddressestheorderlessrepresentation ones,whileintheELMarchitecture,theoutputnodesare\nof the image, while the latter captures local spatial cues. onlyconnectedwiththehiddenones. Althoughitsstrengths\nLater,DSRNet(Zhaietal.,2020)isatexturerecognition andweaknesseshavebeenextensivelydiscussed,particu-\nnetworkthatlearnsthespatialdependencybetweentexture larlyregardinghowtheoutputlayershouldbeconnected.\nprimitives. This was motivated by the fact that multiple In this work, the output layer is connected only with the\ntextureprimitivesappeardifferentlyintheirspatialcontext; hiddennodes, followingthepreviousliteratureintexture\nhowever,theypresentaninherentspatialdependency. Fol- representationlearningusingrandomizedneuralnetworks.\nlowing,Chenetal.(2024)proposedtheDTP(DeepTracing\nFormalism. Inthispart,wepresentamathematicalback-\nPattern) module. This module is responsible for leverag-\n3\nMIXER:MixedHypersphericalRandomEmbeddingNeuralNetworkforTextureRecognition\ngroundoftherandomizedneuralnetwork. Alternatively,aregularizationtermmaybeintroducedfor\ntwomainreasons.First,theregularizationcontributesinbal-\nLetD ={(x ,y )}N ⊂X×Ybethedatasetconsistingof\ni i i=1 ancingthemodelcomplexitybyadjustingthemodel’sbias-\nN samples,wherex ∈X isap-dimensionalinputfeature\ni variancetrade-off. Second,invertingthematrixZZT may\nvector,andy ∈Y isar-dimensionaloutputfeaturevector.\ni bechallengingwhenitisill-conditioned. Underthesecir-\nFromDitisassembledtheinputandoutputfeaturematrices\ncumstances,onemayutilizetheTikhonov’sregularization\nrepresented by X = hconcat(x ,x ,...,x ) ∈ Rp×N,\n1 2 N (Calvettietal.,2000)withoutlosingtheclosed-formaspect.\nandY = hconcat(y ,y ,...,y ) ∈ Rr×N,respectively,\n1 2 N Tothisend,theregularizationtermissettoΩ(φ)=∥φ∥2.\nwherehconcat(·)isthehorizontalconcatenationoperation. F\nIn this case, the solution of Problem (2) is given by the\nFollowingthis,thenetworknon-linearlyprojectstheseinput regularizedleast-squaressolution:\nfeaturevectorsintoanotherdimensionalspace. Tothisend,\namatrixψ ∈Rω×pisrandomlygeneratedbysomestrategy, φ∗ =YZT(ZZT +γId)−1, (3)\nsuchassamplingeachmatrix’sentryfromsomedistribu-\ntion,e.g.,ψ ∼ N(µ,σ2),orusingsomepseudorandom whereIdistheidentitymatrixofsizeω×ω.\nij\nnumbergeneratorprocedure. Further,definingthismatrix\nis a fundamental step, because the number of neurons in 3.Method\nthehiddenlayer(ω),morespecificallythedimensionofthe\nspacewherethefeaturesareprojectedinto,shallbespeci- Inthissection,weintroduceMIXER,ournovelapproachfor\nfied. Inthiscontext,uponthespecificationoftherandom texturerepresentationlearning. AsillustratedinFigure1,\nweightmatrixψ,thehiddenorprojectedfeaturematrixis MIXERconsistsoffourcoremodules: 1)LocalPatternEx-\ngivenby: tractor(LPE)module;2)HypersphericalRandomProjector\nZ=α(ψX)∈[0,1]ω×N, (1) (HRP)module;3)Learningmodule;and4)Compression\nModule. Thus,theremainderofthissectionisdedicatedto\nwhereα(x):=1/(1+e−x)isthesigmoidfunctionapplied\npresentingtheinternalmechanismsofthesemodules.\nelement-wise.Ingeneral,onecanchooseanothernon-linear\nLocal Pattern Extractor Module. Given an image\nfunction, such as hyperbolic tangent. Accordingly, from\nI∈RC×H×W. Thismodule,depictedinFigure1(b),isre-\nEquation(1),theprojectedmatrixconsistsofallrealvectors\nz = α(ψx ) ∈ Rω, which represent the ω-dimensional sponsibleforextractinglocalintensitypatternsfromtheim-\ni i\ninternalrepresentationoftheinputfeaturevectorx ∈Rp. agebydenselysamplingmultiplesmallpatches. Itspurpose\ni\nis to capture variations and implicit spatial relationships\nSubsequently, the learning phase to obtain the trained amongpixelintensities,therebyinherentlyrepresentingraw\nweights of the output layer shall be conducted. In this textureinformationtobesubsequentlyusedasinputforthe\nsense,themainobjectiveofarandomizedneuralnetwork remainderofthenetwork.\nistoseekforamatrixφ∈Rr×ω ofalineartransformation\nT :Rω →Rr,thattakestheimageofz ,beingz theinter- To this end, the module extracts multiple J ×J patches\ni i\ncenteredateverypixelfromeachimagechannelofI,thus\nnalrepresentationofx ,ascloseaspossibletoy underthe\ni i\nwithoverlapping. However,centeringapixelatornearthe\nsquaredℓ norm. Moreprecisely,thisinvolvessolvingthe\n2\nimageborderisnotfeasiblebecausethepatchsizewould\nfollowingminimizationproblem:\noverflowtheimagebounds. Therefore,theimageispadded\nbeforepatchextraction. AssumingthatJ isanoddnatural\nOptimization 1 (Least-squares). Let X ∈ Rp×N, Y ∈ number,thepaddingsizeappliedinallimagechannelsides\nRr×N andZ∈Rω×N bethepreviouslydefinedinput,out- is J−1, and the utilized padding mode is replication. In\n2\nput,andprojectedfeaturematrices. Weseekforamatrix general,thismoduleisexpressedby:\nφ∗ ∈ Rr×ω that solves the following minimization prob-\nlem: Pad (I)∈RC×(H+J−1)×(W+J−1) (4)\nJ\nmin∥Y−φZ∥2 +γΩ(φ), (2)\nφ F LPE(Pad J (I))∈RC×H×W×J×J. (5)\nwhere∥·∥ istheFrobeniusnorm,Ω(·)istheregularization\nF\nterm,andγ >0istheregularizationparameter. Therefore,theoutputofEquation(5)isa5-dimensionalten-\nsorthat,basically,storeseveryJ×Jimagepatchescentered\nateverypixeloftheimagechannelofdimensionH×W for\nInparticular,whentheregularizationtermissettoΩ(φ)= everyimagechannelamongtheC available. Finally,this\n0, i.e., no regularization is applied. The solution for the modulegeneralizesthewidelyusedpatch-basedextraction\nminimizationprobleminEquation(2)isgivenbytheleast- technique,extendingittoimageswithanarbitrarynumber\nsquaressolution: φ∗ =YZ†,whereZ† =ZT(ZZT)−1is ofchannels,ascommonlyemployedinRNN-basedtexture\ntheMoore-Penrosepseudoinverse(Penrose,1955). representationlearningapproaches(Junior&Backes,2016;\n4\nMIXER:MixedHypersphericalRandomEmbeddingNeuralNetworkforTextureRecognition\nFigure1.OverviewoftheMIXERpipeline.TheinputimageI∈RC×H×W isfedtotheLocalPatternExtractor(LPE)module,which\npadstheimageandsubsequentlyperformstheextractionoftinypatchestorecordtherawtextureinformation.Thereafter,thesepatches\narefedtotheHypersphericalRandomProjector(HRP)modulethatmapsthesepatchesinhypersphericalrandomembeddingscomposing\ntherandomprojectedmatricesZ′\ni\n′ ∈R(ω+1)×HW.TheprojectedmatricesarefedtobothDIRECTandMIXEDbranchesresponsiblefor\nlearningtheintra-andinter-channellocalintensityrelationships,respectively.Thelineardecoder’slearnedweightsfrombothmodulesare\nfedtothecompressionmodule,whichisresponsibleforverticallyconcatenatingthem,resultingintheaggregatedlearnedweightmatrix,\nandisresponsibleforapplyingselectedcompressionfunctionstocompresstheweightmatrixintoausefulcolor-texturerepresentation.\nRibas&Bruno,2024). WereferthereadertoSectionAof Hence, after the reshaping process, we obtain\nthe supplementary materials for further details about this X ,X ,...,X , where each X ∈ RJ2×HW is a\n1 2 C k\nmodule. matrixcontainingtheflattened,denselyextractedpatches\noverthespatialdimensionsofthek-thimagechannel. Sub-\nHypersphericalRandomProjectorModule. Thismod-\nsequently,eachofthesematricesisusedduringtherandom\nule,illustratedinFigure1(c),encodestherawpixelinten-\nprojection phase to obtain the internal representation of\nsitiesoftheextractedpatchesintointernalrepresentations,\neachflattenedpatch. Tothisend,weperform:\nreferredtoashypersphericalrandomembeddings. These\nembeddingsaresubsequentlyusedduringthetrainingphase\nZ =α(ψ X′′)∈[0,1]ω×HW , (7)\noftheproposedlearningmodules. Inthiscontext,toobtain k k k\nthese internal representations, the module performs non- whereψ ∈Rω∈(J2+1)istherandomweightmatrix1used\nlinearrandomprojectionsofthepatchintensities,encoding k\nonlytoprojectthek-thpre-processedinputfeaturematrix:\nthemintoagenerallyhigherω-dimensionalspace. These\nprojectionsarethenconstrainedtolieonthesurfaceofa X′′ =vconcat({−1 ,X′})∈R(J2+1)×HW , (8)\nunithyperspherethroughembeddingnormalization. This k HW k\nnormalizationstephelpscomputationalandtrainingstability where vconcat(·) is the vertical concatenation operation,\n(Zhangetal.,2023;Wang&Isola,2020),andhereitdoes 1 ∈R1×HW isarowmatrixwithallentriessettoone,\nHW\nbyadjustingpotentialcolumn-normdistortionsinthepro- representingthebiasterms,andX′ istheunitnormalscaled\nk\njected(hidden)matrixandbyenhancingtheconditioning\ninputfeaturematrixdefinedby:\nofthematrixduringtheinversionstep.\n[X ] −[X ]\nTo accomplish this, let L = LPE(Pad J (I)) be the 5- [X′] = k ij k i,: , k ∈{1,2,...,C}, (9)\ndimensionaltensoroutputofthepreviouslayer,whichcon- k ij s k,i +ϵ\ntainsthepixelintensitiesoftheextractedpatchesforevery\nchanneloftheimage. Wereshapethistensorbyindepen- where[X k ] i,: = H 1 W (cid:80)H j= W 1 [X k ] ij isthesamplemeanof\ndentlymergingtheimagespatialdimensionsandthepatch the i-th row of the k-th input feature matrix X , s2 =\nk k,i\nsizedimensions. Followingthis,weinterchangetheselast 1 (cid:80)HW([X ] − [X ] )2 is the sample variance,\ntworeshapeddimensions. Weexpressthesestepsby: HW−1 j=1 k ij k i,:\n1WereferthereadertotheSectionBoftheSupplementary\nX=Reshape(L)∈RC×J2×HW\n. (6) Materialfortherandomweightmatrixgenerationprocess.\n5\nMIXER:MixedHypersphericalRandomEmbeddingNeuralNetworkforTextureRecognition\nandϵ=10−10isasmallpositivenumbertopreventdivision TheoptimizationproblempresentedinEquation(12)has\nbyzero. aclosed-formsolutiongivenbythefollowingregularized\nleast-squaressolution:\nIn this context, we have that Z consists of all the ω-\nk\ndimensionalrandomembeddedpatchintensities. Follow- θ∗ =X Z′′T (Z′′Z′′T +γ Id)−1. (13)\ning this, before entering the learning modules, these pro- k k k k k D\njectedfeaturematricesZ ,Z ,...,Z havetheircolumn\n1 2 C Finally,thesubscriptisemphasizedbecausealinearde-\nvectorsprojectedontotheunithypersphereSω−1 ={v ∈\ncoder network is found for each channel of the input\nRω |∥v∥ =1}. Thisprocessisexpressedby:\n2 image. Thus,asetoflineardecodersthatlearnedthespa-\n[Z ] tialtexturerelationshipsofeachchannelindependently\n[Z′] = k ij , k ∈{1,2,...,C}, (10)\nk ij max(∥[Z ] ∥ ,ϵ) is obtained. In this sense, this branch outputs the set\nk :,j 2\nS ={θ∗,θ∗,...,θ∗}thatcharacterizesthelocalinten-\nwhere ∥·∥ is the Euclidean norm, and [Z ] is the j-th D 1 2 C\n2 k :,j sityrelationshipspresentintheinputimagechannels.\ncolumnofZ . Finally,asdonefortheinputfeaturematrix,\nk\nwealsoaddabiasweightbyverticallyconcatenatingarow • MIXED: Unlike the DIRECT branch that uses its own\nmatrixfilledwith−1,suchthattheoutputofthismoduleis: patch internal representation to reconstruct itself. This\nZ′′ =vconcat({−1 ,Z′})∈R(ω+1)×HW . (11) branchaimstoreconstructeachpatchnotonlyfromits\nk HW k\nown random embedding but also from the random em-\nTosimplifythenotation,wedenoteZ′′,theoutputofthis\nbeddings of the corresponding patch across all image\nk\nmoduleforainputfeaturematrixX k ,asf ψ (X k ),where channels.\nk\nf (·) is designated as the k-th random encoder whose\nψ k Inthiscontext,thisbranchfirstconstructsasharedrepre-\nrandomweightmatrixisgivenbyψ ∈Rω×(J2+1).\nk sentationbycombiningtheinternalrepresentations,serv-\nLearning Module. This module represents one of the ingasanintermediatefusionphase. Followingthis,the\nmaincomponentsofournovelapproach,andisshownin resultofthemixingprocessisusedasinputtothedecoder\nFigure1(d). Thisispartitionedintotwolearningbranches network, whosemainroleistoreconstructtheoriginal\ncalledtheDIRECTandMIXEDbranches. Thesearerespon- patch intensities. Therefore, the network is guided to\nsibleforlearningmultiplelineardecodernetworks,where reconstruct the original patch information of a specific\ntheir learned layer weights (scalars) are used later by the image channel by leveraging all available information\ncompression(summarization)moduletoassembleauseful fromthecorrespondingpatchacrossallchannels,thereby\ncolor-texturerepresentation. learninginter-channelrelationships.\nTo achieve this, this branch learns the reconstruction\n• DIRECT: Thisbranchisresponsibleforlearningamap-\nthroughthefollowingoptimizationproblem:\npingthatreconstructsthelocalintensitypatternsofthe\nextractedJ ×J patchesfromthehypersphericalrandom\nembeddings,withtheintenttoinducethenetworktolearn Optimization3(MixedBranch). Letg ϕ (Z) = ϕZbe\ntherelationshipbetweenthehidden(projected)spaceand a linear decoder network with parameters ϕ. We seek\ntheintensities(input)space,fromthepointofviewofthe\ntolearntheparametersϕ∗ ∈RJ2×(ω+1)foreachimage\nk\nrawspatialtexturepresentintheinputmatrixX. channelbysolvingthefollowingminimizationproblem:\nTothisend,thisbranchlearnsthemappingthroughthe\nmin∥X −g (S)∥2 +γ ∥ϕ ∥2 , (14)\nfollowingoptimizationproblem. ϕ k ϕ k F M k F\nk\nwhere γ > 0 is the regularization parameter of the\nOptimization 2 (Direct Branch). Let g (Z) = θZ be M\nθ mixedbranch,andS∈R(ω+1)×N isthemixedrandom\na linear decoder network with parameters θ. We seek\nembeddingbuiltbyaveragingallinternalrandomembed-\ntolearntheparametersθ∗ ∈RJ2×(ω+1)foreachimage\nk dingsobtainedforeachimagechannel. Thatis,\nchannelbysolvingthefollowingminimizationproblem:\nmin∥X −g (f (X ))∥2 +γ ∥θ ∥2 , (12) 1 (cid:88) C\nθk k θk ψ k k F D k F S= C f ψ j (X j ). (15)\nj=1\nwhere γ > 0 is the regularization parameter of the\nD\ndirectbranch. Thisoptimizationproblemactsasapure\nrandomizedautoencoder,whereweforcethenetworkto\nlearnhowtoreconstructtheoriginalpatchesintensities Consequently, from Equation (15), we have that the\nfromanon-linearrandomprojectionofthemselves. sharedinternalrepresentations ofsomepatchk,emerge\nk\nastheaverageoftheinternalrepresentationsofthesame\n6\nMIXER:MixedHypersphericalRandomEmbeddingNeuralNetworkforTextureRecognition\npatchforallimagechannels. Next,similarlytothepre- wheref ∈ R|S|J2 isthek-thcolumnofF,s isthereal\nk h\ncedingoptimizationproblem,theclosed-formsolutionfor vectorrepresentingthecompressedmatrixFunderh∈H,\ntheEquation(14)isgivenbythefollowingregularized andΩ (I)isthetexturerepresentationoftheimageIusing\nω\nleast-squaressolution: ω-dimensionalrandomembeddings.\nϕ∗ =X ST(SST +γ Id)−1. (16) Inthepresentwork,thesetofcompressionfunctionsem-\nk k M ployediscomposedbyfourstatisticalmeasuresh ,h ,h\nµ σ γ\nandh whichcorrespondstothemean,standarddeviation,\nFinally,asinthedirectbranch,theoutputofthisbranchis κ\nasetoflineardecodersS ={ϕ∗,ϕ∗,...,ϕ∗}trained skewness, andexcesskurtosis, respectively. Thus, thedi-\nM 1 2 C\nmensionalityofthetexturerepresentationinEquation(18)\ntoreconstructthelocalintensitypatternsofeachimage\nisgivenby4(ω+1). Formoreinformationabouttheem-\nchannelfromacommonmixedrepresentation.\nployedstatisticalmeasures,suchastheirformulas,werefer\nthereadertoSectionCofthesupplementarymaterial.\nCompressionModule. GivenanimageI∈RC×H×W its\nimagerepresentationshouldbedefinedbyan-dimensional Finally,weassembleanewtexturerepresentationbylatefus-\nreal vector that carries useful information about I to be ingthelearnedrepresentationsfromdistinctω ,ω ,...,ω\n1 2 n\nusedindownstreamtasks. Nevertheless,aswasobserved, randomembeddingssizes. Thisisacommonutilizedap-\nasetS = S ∪S ⊂ RJ2×(ω+1) containingthelearned proachinpreviousRNN-basedtechniques,suchas(Junior\nD M\nlineardecoders’weightsisobtainedasoutputofthelearning & Backes, 2016; Ribas et al., 2020), which shown to im-\nmodule (i.e., previous module). In this context, the role provetheperformanceofthetexturerecognitiontask. Thus,\nof this module, illustrated in Figure 1(e), is to compress wedefinethislatefusedcolor-texturerepresentationas:\n(summarize)thelearnedweightsoftheselineardecoders,\nΥ (I)=hconcat({Ω (I)|ω ∈W})∈Rm, (19)\nrepresented by real matrices, in real vectors to serve as a W ω\nusefulcolor-texturerepresentation. Tothisend,webegin whereW ={ω ,ω ,...,ω }⊂Nisthesetcontainingthe\n1 2 n\nbydefiningacompressionfunction:\nrandomembeddingssizesusedtocomposethelatefused\n(cid:80)\nrepresentation,andm = 4· (ω+1)isthedimen-\nω∈W\nDefinition 3.1 (Compression Function). Every scalar- sionalityoftheproposedcolor-texturerepresentation.\nvalued function h : A ⊂ Rn → R that maps a n-\ndimensionalrealvectorx∈Atoascalarh(x)∈R,where\n4.Experiments\nh(x)embedssomestructuralorsemanticinformationabout\nxiscalledacompression(summarization)function. In this section, we present the server infrastructure used\ntoconducttheexperiments,alongwiththeversionsofthe\nmainlibrariesemployedtodeveloptheproposedapproach.\nBydefiningthecompressionfunction,alsocalledthesum- Wethendescribethebenchmarkdatasetsusedtoevaluate\nmarizationfunction,weexpressthathmustextractsome the technique, highlighting their main characteristics. Fi-\nusefulknowledge(simpleorcomplex)abouttheinputvec- nally,wedetailthecross-validationstrategy,theevaluation\ntor. Inthissense, afunctionthatreceivesanyrealvector metrics,andtheclassifier.\nandsimplyreturnsarandomnumbercannotbeconsidered\nSetup. Theexperimentswereconductedonaserverrun-\nacompressionfunction,sinceitdoesnotembedanyinfor-\nningUbuntu22.04.03LTSoperatingsystemequippedwith\nmation.\naInteli9-14900Kprocessor,128GBofRAM,andasingle\nIn this context, let F = vconcat(S) ∈ R|S|J2×(ω+1) be graphiccardNVIDIARTX4090. Specifically,theapproach\ntherealmatrixresultingfromtheverticalconcatenationof runs on the specified graphic card. Furthermore, the pro-\neverymatrixinS,where|S| = 2C,sinceC decodersare posed technique is implemented using PYTORCH v2.6.0,\nlearnedineachbranch. Asaresult,thematrixFcontains andtheevaluationprocessusedtheSCIKIT-LEARNv1.6.1\nthe weights of the all decoders learned in both proposed package.\nbranches. Since these weights contain valuable content\nBenchmarks. Weevaluatedourapproachusingfourwell-\naboutthetextureinformationoftheinputimage, asetof\nknown texture datasets exhibiting distinct textural chal-\nsummarization functions H are applied to compress the\nlenges,attributes,andcharacteristics. Inthiscontext,this\nmatrix F in a real vector serving as representation of the\nenabledustoanalyzethenovelapproachoverabroadrange\ntexture image I. Therefore, this compression process is\nofscenariosandhowwelltheproposedapproachgeneral-\nrepresentedby:\nizedinthetexturerecognitiontask. Next,webrieflydetail\ns =(h(f ),h(f ),...,h(f ))∈Rω+1 (17) thepeculiaritiesofeachemployedtexturedataset:\nh 1 2 ω+1\nΩ (I)=hconcat({s |h∈H})∈R|H|(ω+1), (18)\nω h • OutexTC13(Ojalaetal.,2002a): Thisisthethirteenth\n7\nMIXER:MixedHypersphericalRandomEmbeddingNeuralNetworkforTextureRecognition\ntextureclassificationsuiteproposedfromtheOutexsur-\n5\nfaces and is widely used in both grayscale and colored\n4\nversions. Thisdatasethasproventobehardtocategorize 3\n2\nduetotheneedforanefficientmicro-texturalcharacteriza- 1\n0\ntion. Thus,asdonein(Backesetal.,2013),theemployed 1\n2\ndatasetconfigurationiscomposedby1360color-texture\n3\nimages obtained by cropping 20 non-overlapping win- 4\n5\ndowsofsize128×128pixelsfrom68color-texturesource 5 4 3 2 10 1 2 3 4 5\nlog10( D)\nimagesofsize538×746pixels.\n• CUReT (Dana et al., 1999): It stands for Columbia-\nUtrecht Reflectance and Texture dataset. This dataset\nwas proposed to study the appearances of the textured\nsurfacesunderdistinctilluminationsandviewingangles,\ntherefore, tackling conditions that most datasets would\nnot. Inthissense,thepresenceofreal-worldsurfacetex-\ntures(e.g.,aluminum,leather,corduroy,paperetc.) under\nmultiplelightconditionsandviewinganglesmakesthe\ntexturerecognitiontaskharder,therebyresultinginasuit-\nable dataset for evaluation. The utilized dataset setup\nconsistsof5612color-textureimagesresultingfrom61\nexisting classes with each 92 samples with dimensions\n200×200 pixels. This is the same setup performed in\n(Scabinietal.,2020).\n• USPtex(Backesetal.,2012): Thisnaturalimagedataset,\nbuiltbytheUniversityofSa˜oPaulofocusedonobtaining\nsamples found day-to-day (e.g., rice, vegetation, walls,\nbricks etc.). The intent was to obtain a dataset with a\nhigher degree of texture samples that exhibit irregular,\nrandom,ornon-periodicpatterns. Theutilizedconfigu-\nrationiscomposedby2292color-textureimagesdivided\nin191classes,eachcontaining12samplesofdimensions\n128×128pixels.\n• MBT(Abdelmounaime&Dong-Chen,2013): TheMulti-\nbandTexture(MBT)datasetwasproposedfortheanalysis\noftexturalapproachesfocusinginsampleswithintra-and\ninter-bandspatialvariations. Thecolorspresentinthese\nsamplesofMBTareduetothedistincttexturalcontent\nthatcompriseseachcolorchannel. Inthiscontext, this\nisaninterestingdatasettoevaluatehowwellournovel\napproachsimultaneouslydescribestheseintra-andinter-\nbandspatialvariations. Asdonein(Scabinietal.,2020),\nwe employed the dataset configuration that comprises\n2464sampleswithdimension160×160pixelsbycrop-\nping16non-overlappingwindowsfromeachofthe154\noriginalimagesofsize640×640pixels.\nCross-validation,MetricsandClassifier. Toevaluatethe\nperformanceofthenovelapproachweutilizedtheLinear\nDiscriminantAnalysis(LDA)classifierwiththeLeave-One-\nOut(LOO)cross-validationstrategyusingtheaccuracyas\nperformance metric. This metric was used since all uti-\nlizedbenchmarkdatasetsarebalanced,andisawell-known\n)M\n(01gol\nOutex\n96.9\n5\n4\n95.9 3\n2\n94.9 1\n0\n93.8 1\n2\n3\n92.8\n4\n5\n91.8 5 4 3 2 10 1 2 3 4 5\nlog10( D)\n)M\n(01gol\nCUReT\n98.0\n97.5\n97.0\n96.6\n96.1\n95.6\n5\n4\n3\n2\n1 0\n1\n2\n3\n4\n5\n5 4 3 2 10 1 2 3 4 5\nlog10( D)\n)M\n(01gol\nUSPtex\n99.5\n5\n4\n99.1 3\n2\n98.7 1 0\n98.4 1\n2\n3\n98.0\n4\n5\n97.6 5 4 3 2 10 1 2 3 4 5\nlog10( D)\n)M\n(01gol\nMBT\n99.5\n98.2\n96.9\n95.7\n94.4\n93.1\nFigure2.Accuracy(%)behaviorofthecolor-texturerepresenta-\ntionΩ (I)forallthebenchmarkdatasetsastheregularizationof 59\ntheDIRECTandMIXEDbranchesvaries.\nperformanceproxyusedforevaluationoftexturerecogni-\ntionmethods. Inaddition,weadoptedthislineardecision\nboundary classifier owing to its simplicity, and we used\nthedefaulthyperparameterconfigurationprovidedbythe\nSCIKIT-LEARN v1.6.1 package, which uses the Singular\nValueDecomposition(SVD)assolver. Formoreinforma-\ntionaboutthesetting,wereferthereadertothesupplemen-\ntarymaterial.\n5.ResultsandDiscussions\nRegularizationAnalysis. Tounderstandtheeffectofthe\nregularizationonthedecoder’slearnedweights,andconse-\nquently, inthecolor-texturerepresentation. Weanalyzed\nthebehavioroftheobtainedaccuraciesofthetexturerep-\nresentation Ω (I) across all benchmark datasets, as the\n59\nregularization hyperparameters γ and γ for the direct\nD M\nand mixed branches, respectively, varies over the region\nR×R,whereR={10k |k ∈Z ∧−5≤k ≤5}.\nFigure 2 exhibits a greater performance of the proposed\ncolor-texture representation in Outex and CUReT as the\nregularizationvaluesforbothbranchesincreased. Thisis\nobservedbywarmercolors,representinggreateraccuracy,\npresentontheupperrightregion,whichisdeterminedby\nhigh regularization on both branches. In that region, ac-\ncuracies of up to 96.9% were achieved in Outex, and up\nto 98.0% in CUReT, thus indicating a good performance\nofthetexturerepresentationinthiscondition. Inaddition,\nanothercommonaspectinthesedatasetswastherelatively\nlowperformanceidentifiedbythepresenceofcoolercolors\nintheremainingregion,correspondingtothecasesinwhich\neitheroneofthebranchesexhibitedlowregularizationor\nbothbranchesdid.\n8\nMIXER:MixedHypersphericalRandomEmbeddingNeuralNetworkforTextureRecognition\n5\n4\n3\n2\n1\n0\n1\n2\n3\n4\n5\n5 4 3 2 10 1 2 3 4 5\nlog10( D)\n)M\n(01gol\nOutex & CUReT\n97.5 97.5\n5\n97.3\n5 4\n96.7 97.1 3\n97.0 2 4\n96.0 96.8 1\n3 4 5 96.7 0\n95.3 1\n2\n3\n94.6\n4\n5\n93.8 5 4 3 2 10 1 2 3 4 5\nlog10( D)\n)M\n(01gol\nUSPtex & MBT\n99.5 99.5\n1 99.3\n98.7 99.2 0\n99.1\n98.0 1 99.0\n1 0 1 98.9\n97.3\n96.6\n95.9\nFigure3.Accuracy(%)behaviorofthecolor-texturerepresentationΩ (I)fortheOutex&CUReTandUSPtex&MBTdatasetpairsas\n59\ntheregularizationoftheDIRECTandMIXEDbranchesvaries.Thebehavioristheaverageoftheaccuraciesobtainedbythedatasetsin\neachconfiguration.Theinsetplotineachfigurereferstotheregionneartothehighestaverageaccuracy.Note:Thecolorbaroftheinset\nplotwasadjustedtohelpthevisualizationofthehighestaverageaccuracy.\nThesefindingssuggestthatOutexandCUReTfavorfrom particularly those characterized by low to moderate lev-\ntheuseofbothbranches,andwhiletheseareoperatingin els. Amongtheseregularizationlevels,therepresentation\nconjunction,theyhadastrongerpreferencetowardshigher achievedthemaximumaccuracyof99.5%.\nregularizationtoobtaingoodperformances. Thismaybe\nInadditiontotheprecedinganalysis,Figure2showstwo\nattributed to the fact that stronger regularization induces\npairsofdatasetsthatexhibitsimilarsuitableregularization\nthe decoders to reduce the fitting of the original patches\nvalues. ThefirstpaircomprisesOutexandCUReT,while\nintensitiesaswellaspossiblenoise,thusforcingthedecoder\nthesecondconsistsofUSPtexandMBT.Thus,toensure\nto focus on the general discriminative information about\nfair hyperparameter selection within each pair, we adopt\nthetextureontheimage,insteadofthesmallpeculiarities\nthesameregularizationvaluesacrossthedatasets. Weana-\npotentiallypresentinit.\nlyzedtheiraverageaccuraciesthroughajointevaluationas\nFollowing,USPtexshownacommonaspectwiththelast theregularizationvaluesvariedwithinthesameparameter\ntwo evaluated benchmarks, wherein all three presented a space.\nlowperformanceintheupperleftregion,correspondingto\nFigure3presentsthejointanalysisforbothpairsofdatasets.\nlowregularizationontheDIRECTbranchandhighonthe\nForOutexandCUReT,theinsetplothighlightingtheregion\nMIXEDone. However,thefactthattheproposedrepresenta-\nwiththehighestaccuracyclearlyshowsthatγ =104and\ntioninUSPtexshownamoderateperformancewhenboth D\nγ =105 yieldthebestaverageconfiguration. Similarly,\nregularizationvalueswerelow,andthisperformanceweak- M\nforUSPtexandMBT,theplotrevealsthatγ =100,and\nened as only the MIXED branch regularization increased\nγ =100aretheoptimalconfigurationsonav\nD\nerageaswell.\nindicatesthatthisbranchplayedakeyroleinthegeneraliz- M\nTherefore,theseconfigurationswillbeusedforeachpair\nabilityoftheUSPtexbenchmark,andmightbeattributedto\nfortheremainderofthepaper.\nthefactthattheincreasedregularizationresultedinunderfit,\nand consequently the decoder did not properly learn the AblationAnalysis. Figure4presentstheresultsfortheab-\ntextural content of the image under the mixing optimiza- lationanalysisoftheproposedtexturerepresentationΩ (I).\nω\ntionproblem,thusweakeningtheoverallrepresentation. In In Outex and CUReT, it can be observed that the repre-\naddition,unlikeOutexandCUReT,USPtexhasachieved sentationobtainedusingbothbranchesincreasedtheper-\nthe highest accuracy of 99.5% with moderate values for formance,beingmorenotableforOutex. Furthermore,al-\nregularizationinbothbranches. thoughtheMIXEDbranchachievedthelowestaccuracies\non these datasets, the final representations were strength-\nSubsequently, the performance behavior for the MBT\nenedwhenbothlearningbrancheswerecombined. Inother\ndatasetwasbasicallytheoppositeofthatobservedinOutex\nwords,accuracyimprovedwhenbothbrancheswereused,\nand CUReT. The higher accuracies occurred outside the\nsuggestingthatthefeatureslearnedineachbranchcomple-\nhigh regularization region, whereas the lower accuracies\nmentedoneanother.\nwereobtainedthere. Thisdenotesthatbothbranchesmay\nbe suffering from underfit when strongly regularized, as InUSPtexandMBT,itwasobservedthatusingonlyasingle\nin the case of USPtex for the MIXED branch. Neverthe- branchwassufficienttoachievethehighestperformance.\nless,unlikethelastthreebenchmarks,theMBTexhibited Thisindicatesthatoneofthelearningbranchesisalready\ngoodperformanceonabroadrangeofregularizationvalues, capableofextractingthemeaningfulfeaturesfromthetex-\n9\nMIXER:MixedHypersphericalRandomEmbeddingNeuralNetworkforTextureRecognition\n100\n98\n96\n94\n92\nOutex CUReT USPtex MBT\nDataset\n)%(\nycaruccA\ndiscriminativeenoughtoalmostsaturatetheCUReT,USP-\nBoth texandMBTsimultaneously,andsurpassthe97%barrier,\nDirect andalmostthe98%one,performanceoftheOutexdataset,\nMixed wheretothebestofourknowledgeistheuniqueRNN-based\napproachtoachievethisasshallbediscussedlater.\nInaddition,followingpreviousstudies(Junior&Backes,\n2016;Ribasetal.,2020),wealsoinvestigatedtheperfor-\nmanceofthenovelapproachΥ (I)whenmorerandom\nW\nembeddingsizesareincorporated. Weperformedthisanal-\nysisbecausepreviousstudieshaveshownthatcombining\nfeatureslearnedfromlower-dimensionalembeddingsgener-\nallyyieldsrepresentationswithhigherperformance,even\nwhenthetotalnumberoffeaturesremainsthesame. Inpar-\nticular,ourstudyconsideredonlytworandomembedding\nsizestoavoidgeneratingexcessivelylargefeaturevectors,\nFigure4.Averageaccuracy(%)behavioroftheproposedtexture\nwiththeselectedpairofembeddingsizessatisfying:\nrepresentationΩ (I)wheneitheroneofthebranchesarebeing\nω\nusedorbothofthemare.\ntureimage. Interestingly,whileUSPtexshowstheMIXED (ω 1 ,ω 2 )∈{(ω 1 ,ω 2 )∈O×O |ω 1 <ω 2 }. (20)\nbranchachievingthehighestaccuracy, MBTexhibitsthe\nbestperformancewiththeDIRECTbranch. Table1showstheperformanceoftheapproachforallbench-\nmark datasets over the combined embeddings. Although\nTherefore, this brief analysis demonstrates the beneficial there were a performance improvement of Υ (I) over\nW\nimpactofemployingbothlearningbranches,particularlyin Ω (I),theincreasewasmodest.Particularly,thegreaterim-\nω\ntheOutexandCUReTdatasets,aswellastheusefulnessof provementoccurredinCUReTwith99.7%(Υ (I))vs.\n99,109\nhavingbothbranchesavailable. Thisdesignhighlightsthe 99.0%(Ω (I)),followedbyOutex97.9%(Υ (I))vs.\n109 39,79\nadaptabilityoftheapproachtoextractfeaturesfromdiverse 97.7%(Ω (I)),andMBT99.8%(Υ (I))vs. 99.6%\n109 69,79\ntextural patterns, as illustrated by the USPtex and MBT (Ω (I)). TherewasnoperformancegaininUSPtex. This\n109\ndatasets,whereasinglebranchwassufficient. However,the suggests that our simpler approach Ω (I) with only one\nω\nremainderofthepaperusesthecolor-texturerepresentation\nembeddingalreadycontainsenoughdiscriminativefeatures\nobtainedwhenbothlearningbranchesareactivated.\nforclassification.\nEmbeddingSizeAnalysis. Weevaluatedhowtheaccuracy\nNevertheless,ourexperimentsareconsistentwithprevious\noftheproposedtexturerepresentationΩ (I)behavesasits\nω findingsindicatingthatcombininglower-dimensionalem-\nuniqueparameterω ∈N,representingtherandomembed-\nbeddingscanyieldbetterperformancewhilemaintaining\ndingsize, varies. Tothisend, theparameterspacewhere\nthe same number of features. For instance, in Outex, the\nω varied over was defined as O = {9,19,...,109}, and representationΥ (I)achieved97.4%with360descrip-\n29,59\nisbroaderthanthosepresentedinpreviousstudies(Junior tors,wheretherepresentationΩ (I)achieved96.7%with\n89\n& Backes, 2016; Ribas et al., 2020). We also presented\nthesameamountofdescriptors.\ntheobtainedaccuraciesforallbenchmarkdatasets,thereby\nprovidingathoroughanalysisoftheparameterimpact. Weendthissectionbyselectingthetexturerepresentation\nthat achieved the highest average accuracy, for a fairness\nFigure5presentstheperformanceforalldatasets. Inpar-\ncomparisonwiththeliteraturemethods. Thisrepresentation\nticular,Outexgenerallyexhibitedanincreaseinaccuracy wasΥ (I)andachievedtheaverageaccuracyof99.2%\n39,109\nastheembeddingsizegrew. However,performancedrops\nwith600descriptors.\nwereobservedintheintervals[29,39]Nand[59,89]N. The\nformershowedamorepronounceddrop,whilethelatterex- LiteratureComparison. Wecomparedournovelapproach\nhibitedonlyasubtledecrease. Conversely,CUReT,USPtex, with twotypes oftexturerecognition methods: thehand-\nandMBT,unlikeOutex,displayedasharpincreaseinper- crafted ones, and those based on randomized neural net-\nformanceattheinitialvalues,followedbyrelativestability works. IncludedamongthehandcraftedaretheOpponent-\nacrosstheremainingparameterspace. Gabor(Jain&Healey,1998),composedbyopponentfea-\ntures from Gabor-filter outputs; the ones based in local\nThissuggeststhattheembeddingsizehadabeneficialim-\npatterns, such as LPQ (Ojansivu & Heikkila¨, 2008) and\npactontheoverallperformanceoftheproposedrepresen-\nCLBP(Guoetal.,2010);andthosethatmodelsthetexture\ntation. Thisislargelymotivatedbytheincreasingnumber\nascomplexnetworks,buildingtherepresentationuponnet-\nof learned features which depends on ω, and which are\nwork’stopologicalmeasures,suchasMCND(Scabinietal.,\n10\nMIXER:MixedHypersphericalRandomEmbeddingNeuralNetworkforTextureRecognition\n98.7\n97.6\n96.6\n95.5\n94.5\n93.4\n)%(\nycaruccA\n100.0\n96.8\n93.6\n90.4\n87.2\nOutex CUReT\n84.0\n100.0\n98.9\n97.8\n96.8\n95.7\n94.6\n9 19 29 39 49 59 69 79 89 99109\nRandom Embedding Size\n)%(\nycaruccA\nFigure5.Accuracy (%)\n100.0 behavior of the pro-\n98.7 posed texture represen-\ntationΩ (I)astheran-\n97.4 ω\ndom embedding size ω\n96.1\nvariesinthedefinedpa-\nUSPtex 94.8 MBT rameterspace. Thisbe-\n93.5 havior analysis is pre-\n9 19 29 39 49 59 69 79 89 99109 sentedforallbenchmark\nRandom Embedding Size datasets.\n2019),andSSN(Scabinietal.,2020). racyof99.2%amongthecomparedmethods,representing\nanincreaseof0.7%overthesecond-bestaccuracyof98.5%\nFollowingthis,amongtheRNN-basedapproaches,themain\nachievedbySSN,andbeingtheonlytechniquetosurpass\nones to be compared, include: SSR (Ribas et al., 2024),\nthe99%. Therefore,thisemphasizesitsgreaterdiscrimina-\nwhichcombinescomplexnetworktheorywiththerandom-\ntivepoweranditsadaptabilitytodiversetexturalpatterns\nized neural network, the SST (Fares & Ribas, 2024) that\nandconditionspresentinthetackledbenchmarks.\nperformsaspatio-spectraltexturelearningbycross-channel\npredicting,andtheVCTex(Fares&Ribas,2025)thatuses\nvolumetric(3D)colorcubesforsimultaneouscolor-texture 6.ConclusionsandFutureWorks\nencoding, thereby requiring only a single neural network\nInthiswork,weintroducedMIXER,atexturerepresentation\nforlearningtherawtexturerepresentation,differingfrom\nlearningapproachthatlearnsbydecodingtheencodedtex-\nthelasttwoapproachesthatrequiremore.\ntureinformationfromhypersphericalrandomembeddings.\nTable2presentstheaccuracycomparisonamongtheliter- Byleveragingtwolearningbranches,called DIRECT and\naturemethods. InOutex,ournovelapproachattainedthe MIXED branches, trained by distinct optimization objec-\nhighestaccuracyof97.8%,being1.0%greaterthanSSN, tives,andusingasrepresentationtheweightsofthelearned\nthesecond-besttechnique,andbeingtheuniqueapproach lineardecodernetworks,ourapproachwasabletolearna\ntosurpassthe97%barrier,andalmostthe98%. Similarly robustandefficienttexturedescriptor,achievingthehighest\ntoOutex,inCUReT,ourapproachalsoachievedthehighest averageaccuracyinthetexturebenchmarks.\naccuracyof99.5%,being0.9%greaterthanthetworunner-\nToachievethis,wefirstdenselyextractlocalpatchesfrom\nupapproaches,whichwereSSNandSSR,achieving98.6%.\ntheimagetocapturetherawtextureinformation. Follow-\nThus, inbothdiscusseddatasets, thebetterperformances\ning,thesepatchesarerandomlyencodedandrestrictedto\nindicateincreasesofapproximately13,and50imagescor-\nlie on the surface of a unit hypersphere, emphasizing the\nrectlyclassified,respectively,withallthisachievedusinga\ndirectionalinformation. Next,theDIRECTmodulelearnsto\nsmallernumberofdescriptors.\nreconstructtheoriginalpatchinformationjustbylooking\nInUSPtexandMBT,ourproposedtechniqueachievedthe atitsownrepresentation. Conversely,theMIXEDmodule\nhighestaccuracyontheformerandthesecond-bestperfor- learnstoreconstructtheoriginalpatchofaspecificchannel\nmanceonthelatter.Theincreaseandtherespectivedecrease bymixingtheinternalrepresentationofthesamepatchin\nwereminimal,adifferenceofonly0.1%inbothdatasets. allimagechannels,thusperformingasimultaneouscross-\nThus, taking into account implementation and hardware channelreconstructionbymeansofanintermediatefused\nvariability, it is reasonable to state that no significant im- representation.\nprovementsordeclineswereobserved. However,itshould\nFutureWorks. Therearetwointerestingpointsforfuture\nbenotedthatourapproachachievedthebestaccuracyinthe\nworks. First,webelievethattheremightbebetterwaysto\nlastbenchmarkswithasmallernumberoffeatures,indicat-\ncreatetheinputandoutputmatricesbyleveragingdistinct\ningthatitprovidesamoreefficientdescriptor.\ntexturemodelingtechniques,suchasthoseusingcomplex\nFinally,ourapproachpresentedthehighestaverageaccu- networks. Further,modelingthesematricesdifferentlyim-\n11\nMIXER:MixedHypersphericalRandomEmbeddingNeuralNetworkforTextureRecognition\nAccuracy(↑) Accuracy(↑)\n(ω ,ω ) Outex13 CUReT USPtex MBT Avg. (ω ,ω ) Outex13 CUReT USPtex MBT Avg.\n1 2 1 2\nLineleftforadjustment (39,49) 97.1 98.8 99.6 99.5 98.8\n(9,19) 95.4 95.4 98.8 98.8 97.1 (39,59) 97.6 99.1 99.6 99.7 99.0\n(9,29) 96.2 96.2 99.2 98.9 97.6 (39,69) 97.6 99.1 99.6 99.7 99.0\n(9,39) 95.5 97.4 99.2 99.4 97.9 (39,79) 97.9 99.2 99.5 99.6 99.1\n(9,49) 96.5 98.0 99.3 99.2 98.3 (39,89) 97.1 99.3 99.7 99.5 98.9\n(9,59) 96.8 98.4 99.5 99.5 98.6 (39,99) 97.4 99.4 99.5 99.6 99.0\n(9,69) 96.5 98.6 99.5 99.6 98.6 (39,109) 97.8 99.5 99.7 99.7 99.2\n(9,79) 96.8 98.7 99.4 99.5 98.6 (49,59) 97.4 99.1 99.7 99.5 98.9\n(9,89) 96.9 99.1 99.6 99.4 98.8 (49,69) 97.1 99.1 99.6 99.6 98.9\n(9,99) 97.4 99.1 99.5 99.4 98.9 (49,79) 97.5 99.2 99.5 99.6 99.0\n(9,109) 97.5 99.3 99.7 99.6 99.0 (49,89) 97.1 99.3 99.5 99.4 98.8\n(19,29) 96.4 97.6 99.3 99.2 98.1 (49,99) 97.6 99.4 99.7 99.6 99.1\n(19,39) 96.4 98.2 99.2 99.4 98.3 (49,109) 97.6 99.4 99.5 99.6 99.0\n(19,49) 96.5 98.3 99.3 99.3 98.4 (59,69) 97.6 99.2 99.7 99.6 99.0\n(19,59) 97.1 98.6 99.6 99.5 98.7 (59,79) 97.6 99.5 99.6 99.6 99.1\n(19,69) 97.2 98.8 99.5 99.4 98.7 (59,89) 97.4 99.5 99.6 99.6 99.0\n(19,79) 97.3 99.0 99.6 99.5 98.9 (59,99) 97.6 99.5 99.5 99.6 99.1\n(19,89) 97.1 99.2 99.6 99.5 98.9 (59,109) 97.4 99.6 99.6 99.7 99.1\n(19,99) 97.4 99.3 99.5 99.6 99.0 (69,79) 97.8 99.3 99.5 99.8 99.1\n(19,109) 97.5 99.2 99.7 99.7 99.0 (69,89) 97.4 99.4 99.7 99.6 99.0\n(29,39) 96.6 98.4 99.6 99.4 98.5 (69,99) 97.2 99.5 99.6 99.5 99.0\n(29,49) 96.8 98.5 99.5 99.3 98.5 (69,109) 97.7 99.6 99.6 99.7 99.2\n(29,59) 97.4 98.9 99.6 99.3 98.8 (79,89) 97.7 99.5 99.7 99.6 99.1\n(29,69) 97.3 98.9 99.6 99.6 98.9 (79,99) 97.3 99.6 99.6 99.5 99.0\n(29,79) 97.6 99.1 99.5 99.5 98.9 (79,109) 97.5 99.6 99.7 99.6 99.1\n(29,89) 97.3 99.3 99.7 99.4 98.9 (89,99) 97.3 99.6 99.6 99.6 99.0\n(29,99) 97.1 99.3 99.7 99.4 98.9 (89,109) 97.4 99.6 99.7 99.7 99.1\n(29,109) 97.8 99.4 99.6 99.5 99.1 (99,109) 97.4 99.7 99.7 99.7 99.1\nTable1.Accuracy(%)oftheproposedtexturerepresentationΥ (I)forallthebenchmarkdatasets. Thelefttablepresentsthe\nω1,ω2\naccuraciesfortherandomembeddingsizescombinationswhereω ∈{9,19,29}.Therighttableexhibitstheaccuraciesfortheremaining\n1\nofthecombinationsofthepreviouslydefinedspacefor(ω ,ω ).\n1 2\nposesthenetworktocrossthisinformation,whichmight (1):876386,2013.\nproduce better representations. Second, we suggest that\nAkiva,P.,Purri,M.,andLeotta,M. Self-supervisedmate-\ndirectlyadjustingtheoptimizationproblemaccountingfor\nrialandtexturerepresentationlearningforremotesens-\namulti-objectiveleastsquares,maintainingtheclosed-form\ningtasks. InProceedingsoftheIEEE/CVFConference\nexpressiveness,mightproduceinterestingrepresentations\nonComputerVisionandPatternRecognition,pp.8203–\ndependingonhoweachobjectiveisspecified.\n8215,2022.\nAcknowledgements Backes, A. R., Casanova, D., and Bruno, O. M. Color\ntexture analysis based on fractal descriptors. Pattern\nR. T. Fares acknowledges support from FAPESP (grant\nRecognition,45(5):1984–1992,2012.\n#2024/01744-8),L.C.Ribasacknowledgessupportfrom\nFAPESP(grants#2023/04583-2and2018/22214-6). Backes, A. R., Casanova, D., and Bruno, O. M. Texture\nanalysis and classification: A complex network-based\napproach. InformationSciences,219:168–180,2013.\nReferences\nAbdelmounaime,S.andDong-Chen,H.Newbrodatz-based Bovik,A.,Clark,M.,andGeisler,W. Multichanneltexture\nimagedatabasesforgrayscalecolorandmultibandtexture analysisusinglocalizedspatialfilters. IEEETransactions\nanalysis. InternationalScholarlyResearchNotices,2013 onPatternAnalysisandMachineIntelligence,12(1):55–\n73,1990.\n12\nMIXER:MixedHypersphericalRandomEmbeddingNeuralNetworkforTextureRecognition\nMethod Outex13 CUReT USPtex MBT Acc #\nTable2.Accuracy comparison with literature\nOpponent-Gabor† 93.5 95.8 99.1 97.6 96.5 − methods. Approaches with a † symbol were\nLPQ†,i 80.1 91.7 90.4 95.7 89.5 − sourcedfrom(Scabinietal.,2020),andthose\nCLBP†,i 89.6 91.8 97.4 98.2 94.3 − withsymboliindicateanintegrativeapproach.\nCNTD†,i 92.3 91.9 97.9 98.5 95.2 − Theresultswiththesymbol∗werecalculated.\nMCND† 95.4 97.0 99.0 97.1 97.1 − Theremainingapproaches’resultswereobtained\nSSN 96.8 98.6 99.5 99.0 98.5 648 fromtheiroriginalpapers.Accreferstotheav-\nerageaccuracyamongthebenchmarkdatasets.\nSSR 96.7 98.6 99.3 98.2 98.2 630\nSST 96.8 95.6∗ 99.1 99.8 97.8 756\nVCTex 96.0 96.0∗ 99.6 99.1 97.7 648\nMixer(Ours) 97.8 99.5 99.7 99.7 99.2 600\nCalvetti, D., Morigi, S., Reichel, L., and Sgallari, F. Florindo,J.B.andLaureano,E.E. Boff: Abagoffuzzy\nTikhonov regularization and the l-curve for large dis- deepfeaturesfortexturerecognition.ExpertSystemswith\ncreteill-posedproblems. JournalofComputationaland Applications,219:119627,2023.\nAppliedMathematics,123(1-2):423–446,2000.\nFujiwara,K.andHashimoto,T. Neuralimplicitembedding\nChen, Z., Li, F., Quan, Y., Xu, Y., and Ji, H. Deep tex-\nforpointcloudanalysis. InProceedingsoftheIEEE/CVF\nturerecognitionviaexploitingcross-layerstatisticalself-\nConferenceonComputerVisionandPatternRecognition,\nsimilarity. InProceedingsoftheIEEE/CVFConference\npp.11734–11743,2020.\nonComputerVisionandPatternRecognition,pp.5231–\n5240,2021. Guo,Z.,Zhang,L.,andZhang,D. Acompletedmodeling\noflocalbinarypatternoperatorfortextureclassification.\nChen,Z.,Quan,Y.,Xu,R.,Jin,L.,andXu,Y. Enhancing\nIEEE Transactions on Image Processing, 19(6):1657–\ntexturerepresentationwithdeeptracingpatternencoding.\n1663,2010.\nPatternRecognition,146:109959,2024.\nCimpoi,M.,Maji,S.,andVedaldi,A. Deepfilterbanksfor Haralick,R.M.,Shanmugam,K.,andDinstein,I. Textu-\ntexturerecognitionandsegmentation. InProceedingsof ralfeaturesforimageclassification. IEEETransactions\nthe IEEE Conference on Computer Vision and Pattern onSystems,Man,andCybernetics,SMC-3(6):610–621,\nRecognition,pp.3828–3836,2015. 1973.\nCsurka,G.,Dance,C.,Fan,L.,Willamowski,J.,andBray, Huang,G.-B.,Zhu,Q.-Y.,andSiew,C.-K.Extremelearning\nC. Visual categorization with bags of keypoints. In machine: theoryandapplications. Neurocomputing,70\nWorkshop on Statistical Learning in Computer Vision, (1-3):489–501,2006.\nECCV,volume1,pp.1–2.Prague,2004.\nJain,A.andHealey,G. Amultiscalerepresentationinclud-\nDana, K. J., Van Ginneken, B., Nayar, S. K., and Koen-\ningopponentcolorfeaturesfortexturerecognition. IEEE\nderink, J. J. Reflectance and texture of real-world sur-\nTransactionsonImageProcessing,7(1):124–128,1998.\nfaces. ACM Transactions On Graphics (TOG), 18(1):\n1–34,1999. Joanes,D.N.andGill,C.A. Comparingmeasuresofsam-\npleskewnessandkurtosis. JournaloftheRoyalStatisti-\nDaugman, J. G. Uncertainty relation for resolution in\ncalSociety: SeriesD(TheStatistician),47(1):183–189,\nspace, spatial frequency, and orientation optimized by\n1998.\ntwo-dimensional visual cortical filters. Journal of the\nOpticalSocietyofAmericaA,2(7):1160–1169,1985.\nJones, J. P. and Palmer, L. A. An evaluation of the two-\nFares,R.T.andRibas,L.C.Anewapproachtolearnspatio- dimensionalgaborfiltermodelofsimplereceptivefields\nspectraltexturerepresentationwithrandomizednetworks: incatstriatecortex. JournalofNeurophysiology,58(6):\nApplicationtobrazilianplantspeciesidentification. In 1233–1258,1987.\nInternationalConferenceonEngineeringApplicationsof\nJulesz,B. Textons,theelementsoftextureperception,and\nNeuralNetworks,pp.435–449.Springer,2024.\ntheirinteractions. Nature,290(5802):91–97,1981.\nFares,R.T.andRibas,L.C. Volumetriccolor-texturerepre-\nsentationforcolorectalpolypclassificationinhistopathol- Junior,J.J.d.M.S.andBackes,A.R. Elmbasedsignature\nogyimages. In20thInternationalConferenceonCom- fortextureclassification. PatternRecognition,51:395–\nputerVisionTheoryandApplications,pp.210–221,2025. 401,2016.\n13\nMIXER:MixedHypersphericalRandomEmbeddingNeuralNetworkforTextureRecognition\nJunior, J. J. d. M. S., Backes, A. R., and Bruno, O. M. Ribas,L.C.andBruno,O.M. Learningacomplexnetwork\nRandomizedneuralnetworkbaseddescriptorsforshape representationforshapeclassification. PatternRecogni-\nclassification. Neurocomputing,312:201–209,2018. tion,154:110566,2024.\nLeung,T.andMalik,J. Representingandrecognizingthe Ribas,L.C.,Junior,J.J.d.M.S.,Scabini,L.F.,andBruno,\nvisualappearanceofmaterialsusingthree-dimensional O. M. Fusion of complex networks and randomized\ntextons. InternationalJournalofComputerVision,43(1): neuralnetworksfortextureanalysis. PatternRecognition,\n29–44,2001. 103:107189,2020.\nLiu,L.,Chen,J.,Fieguth,P.,Zhao,G.,Chellappa,R.,and Ribas,L.C.,Scabini,L.F.,Condori,R.H.,andBruno,O.M.\nPietika¨inen,M.Frombowtocnn:Twodecadesoftexture Color-textureclassificationbasedonspatio-spectralcom-\nrepresentation for texture classification. International plexnetworkrepresentations. PhysicaA:StatisticalMe-\nJournalofComputerVision,127(1):74–109,2019. chanicsanditsApplications,635:129518,2024.\nManjunath,B.andMa,W. Texturefeaturesforbrowsing Scabini,L.,Zielinski,K.M.,Ribas,L.C.,Gonc¸alves,W.N.,\nandretrievalofimagedata.IEEETransactionsonPattern DeBaets,B.,andBruno,O.M. Radam: Texturerecog-\nAnalysisandMachineIntelligence,18(8):837–842,1996. nitionthroughrandomizedaggregatedencodingofdeep\nactivationmaps. PatternRecognition,143:109802,2023.\nOiticica,P.R.,Angelim,M.K.,Soares,J.C.,Soares,A.C.,\nProenc¸a-Mo´dena, J. L., Bruno, O. M., and Oliveira Jr, Scabini,L.F.,Condori,R.H.,Gonc¸alves,W.N.,andBruno,\nO.N. Usingmachinelearningandopticalmicroscopy O.M. Multilayercomplexnetworkdescriptorsforcolor–\nimage analysis of immunosensors made on plasmonic texturecharacterization. InformationSciences,491:30–\nsubstrates: Application to detect the sars-cov-2 virus. 47,2019.\nACSSensors,10(2):1407–1418,2025.\nScabini, L. F., Ribas, L. C., and Bruno, O. M. Spatio-\nOjala,T.,Pietika¨inen,M.,andHarwood,D. Acomparative spectralnetworksforcolor-textureanalysis. Information\nstudy of texture measures with classification based on Sciences,515:64–79,2020.\nfeatureddistributions. PatternRecognition,29(1):51–59,\nSchmidt,W.F.,Kraaijveld,M.A.,Duin,R.P.,etal. Feed\n1996.\nforward neural networks with random weights. In In-\nOjala, T., Maenpaa, T., Pietikainen, M., Viertola, J., Kyl- ternationalConferenceonPatternRecognition,pp.1–4.\nlonen, J., and Huovinen, S. Outex-new framework for IEEEComputerSocietyPress,1992.\nempiricalevaluationoftextureanalysisalgorithms. InIn-\nSharan, L., Liu, C., Rosenholtz, R., and Adelson, E. H.\nternationalConferenceonPatternRecognition,volume1,\nRecognizing materials using perceptually inspired fea-\npp.701–706.IEEE,2002a.\ntures. InternationalJournalofComputerVision,103(3):\nOjala,T.,Pietikainen,M.,andMaenpaa,T. Multiresolution 348–371,2013.\ngray-scale and rotation invariant texture classification\nSu,Z.,Zhang,J.,Wang,L.,Zhang,H.,Liu,Z.,Pietika¨inen,\nwith local binary patterns. IEEE Transactions on Pat-\nM.,andLiu,L. Lightweightpixeldifferencenetworks\nternAnalysisandMachineIntelligence,24(7):971–987,\nforefficientvisualrepresentationlearning. IEEETrans-\n2002b.\nactionsonPatternAnalysisandMachineIntelligence,45\nOjansivu,V.andHeikkila¨,J. Blurinsensitivetextureclassi- (12):14956–14974,2023.\nficationusinglocalphasequantization. InInternational\nWang,T.andIsola,P. Understandingcontrastiverepresen-\nConferenceonImageandSignalProcessing,pp.236–243.\ntationlearningthroughalignmentanduniformityonthe\nSpringer,2008.\nhypersphere. In International Conference on Machine\nPao,Y.-H.andTakefuji,Y. Functional-linknetcomputing: Learning,pp.9929–9939.PMLR,2020.\ntheory, system architecture, and functionalities. Com-\nXue,J.,Zhang,H.,andDana,K. Deeptexturemanifoldfor\nputer,25(5):76–79,1992. doi: 10.1109/2.144401.\ngroundterrainrecognition. InProceedingsoftheIEEE\nPao,Y.-H.,Park,G.-H.,andSobajic,D.J.Learningandgen- ConferenceonComputerVisionandPatternRecognition,\neralizationcharacteristicsoftherandomvectorfunctional- pp.558–567,2018.\nlinknet. Neurocomputing,6(2):163–180,1994.\nZhai, W., Cao, Y., Zha, Z.-J., Xie, H., and Wu, F. Deep\nPenrose,R. Ageneralizedinverseformatrices. Mathemati- structure-revealed network for texture recognition. In\ncalProceedingsoftheCambridgePhilosophicalSociety, ProceedingsoftheIEEE/CVFConferenceonComputer\n51(3):406–413,1955. VisionandPatternRecognition,pp.11010–11019,2020.\n14\nMIXER:MixedHypersphericalRandomEmbeddingNeuralNetworkforTextureRecognition\nZhang,H.,Xue,J.,andDana,K. Deepten: Textureencod-\ningnetwork. InProceedingsoftheIEEEConferenceon\nComputerVisionandPatternRecognition,pp.708–717,\n2017.\nZhang,J.,Zhang,H.,Vasudevan,R.,andJohnson-Roberson,\nM.Hypersphericalembeddingforpointcloudcompletion.\nIn Proceedings of the IEEE/CVF Conference on Com-\nputer Vision and Pattern Recognition, pp. 5323–5332,\n2023.\n15\nSupplementaryMaterialforMIXER:MixedHypersphericalRandomEmbeddingNeuralNetworkforTextureRecognition\nA.LocalPatternExtractorModule\n3 3 5 8 8\nInthissection,weexploreingreaterdepthsomenuancesof\n3 5 8 3 3 5 8 8\ntheproposedLocalPatternExtractor(LPE)module,whose\nReplication \nresponsibilityistoextractthelocalintensitypatternspresent Padding\n7 1 9 7 7 1 9 9\nineachinputimagechannel,andsubsequentlyusethisvalu-\nableinformationasinputtotheremainingofthenetwork.\n2 6 4 2 2 6 4 4\nPadding. Tobeginwith,asexpressedinthemaintext,this\nprocessstartsbycentralizingJ ×J patchesateverypixel 2 2 6 4 4\npositionforagivenchannelofdimensionsH ×W ofthe\ninputimage. Nevertheless,ascanbeobservedifnoaction\nFigureA.2.Concreteexampleofthepaddingprocessusingthe\nweretakeninrelationtothechannel’soriginaldimensions,\nreplicationmodeofa3×3image,andassumingapatchsidesize\nitwouldnotbepossibletocenterthepatchesnexttoorat\nofJ =3.Afterthepaddingthedimensionis5×5.\ntheimagemargin.\nPad (I) ∈ R1×5×5. Thus, it should be noted that in the\nJ\nInthisregard,toenableustocentralizethepatchesatevery\nexemplifiedprocesstheimageconsistsofonlyonechannel.\npixelpositionoftheimagechannel, apaddingprocessis\nHowever, for an arbitrary channel-sized image, this pro-\nperformed. Thus, if the patch side is J, being J an odd\ncessisperformedforeachchannelindependently. Finally,\nnumber, then a padding size of J−1 is applied at every\n2 formoreinformationonthereplicationmodewereferthe\nchannelside. ThisprocessisdepictedinFigureA.1. Asa readertothePyTorchv2.6.0officialdocumentation2.\nresult,afterthepaddingprocesstheoriginalimagechannel\ndimensionsH×W changeto(H+J−1)×(W +J−1). Patch-basedExtraction. Aftertheimagepadding,multi-\npleJ ×J patchesarecenteredateverypixelofthepadded\nimagePad (I),whichcorrespondstoallpixelsoftheorigi-\nJ\nnalimageI. Thisismathematicallyexpressedby:\nLPE(Pad (I))∈RC×H×W×J×J. (A.2)\nJ\nPadding\nAs expressed in the main text, this 5-dimensional output\ntensorstoresalloftheseJ ×J patchescenteredatevery\npositionforeachimagechannel.\nInthissense,withtheintenttoprovideaconcreteexample\nof this process. Let I be the same image as the concrete\nexamplerepresentedinFigureA.2,andletJ =3. Hence,\ntheFigureA.3showstheallninepossiblepatchesofsize\nFigureA.1.Illustrationofthepaddingprocessofanarbitraryma-\ntrix. Inthispresentstudy, thisarbitrarymatrixstoresthepixel 3×3.Eachofthesepatchesrepresentsthecontentofthelast\nintensityvaluesofanimagechannel. twodimensionsofthe5-dimensionaltensor. Nevertheless,\nonemayvisualizetheoverallfigureasamatrixofmatrices,\nParticularly,thepaddingisperformedemployingtherepli- whichrepresentsthelastfourdimensionsofthattensor.\ncation mode, where the channel’s edge values are repli-\nTherefore,itcanbeclearlyvisualizedhowtheLPEmodule\ncated. This process of replication is depicted in Figure\ncapturestheessentialinformationoftherawpixelsintensi-\nA.2. Furthermore, as expected, since in the concrete im-\ntiesinformationpresentintheinputimage.\nage example H = W = 3, and the patch side size\nis J = 3, the dimension after the padding process is\n(H +J −1) = (3+3−1) = 5 (which is equal for the B.HypersphericalRandomProjectorModule\nwidthdimension),matchingthedimensionsofthematrixof\nReshaping. Weshowwithaconcreteexampletheresultof\ntherightsideofFigureA.2.\nthereshapingprocessoftheoutputofthepreviousmodule.\nTherefore,mathematically,theexhibitedprocessinFigure LetthecontentinFigureA.3bethe5-dimensionaltensor\nA.2clearlyrepresentstheinputandoutputofthefunction L∈R1×3×3×3×3containingtheextracted3×3patchescen-\nteredineverypixeloftheimage’sspatialdimension. Note\nPad J :RC×H×W →RC×(H+J−1)×(W+J−1). (A.1) thattheunitarydimensionreferstothenumberofchannels.\nForthesakeofclarity,althoughourconcreteexampledeals\nIn the presented case, the input image dimension is\nI ∈ R1×3×3, and the output padded image dimension is 2https://docs.pytorch.org/docs/2.6/generated/torch.nn.functional.pad.html\n16\nSupplementaryMaterialforMIXER:MixedHypersphericalRandomEmbeddingNeuralNetworkforTextureRecognition\n(0, 0) (0, 1) (0, 2)\n3 3 5 3 5 8 5 8 8 3 3 5 3 3 5 7 7 1\n3 3 5 3 5 8 5 8 8\n3 5 8 3 5 8 7 1 9\n7 7 1 7 1 9 1 9 9\n5 8 8 5 8 8 1 9 9\n(1, 0) (1, 1) (1, 2)\n3 3 5 777 7 1 2 2 6\n3 3 5 3 5 8 5 8 8\n3 5 8 7 1 9 2 6 4\n7 7 1 7 1 9 1 9 9\n5 8 8 1 9 9 6 4 4\n2 2 6 2 6 4 6 4 4\n7 7 1 2 2 6 2 2 6\n(2, 0) (2, 1) (2, 2)\n7 1 9 2 6 4 2 6 4\n7 7 1 7 1 9 1 9 9\n1 9 9 6 4 4 6 4 4\n2 2 6 2 6 4 6 4 4\nFigureB.4.ConcreteexampleofthematrixX=Reshape(L)∈\n2 2 6 2 6 4 6 4 4\nR1×9×9obtainedafterthereshapingprocessofthe5-dimensional\nLegend tensorL∈R1×3×3×3×3representedinFigureA.3.\nImage Pixel Padding Pixel Center Pixel randomN-dimensionaltensorT∈Rn1×n2×···×nN.\nLetv ∈ RL, whereL = (cid:81)N n , withn beingthesize\ni=1 i i\nFigureA.3.Concreteexampleoftheinformationcapturedbythe\nofthei-thdimensionofT. Thisvectorwillbefilledusing\noutputoftheLPEmodulerepresentedbyLPE(Pad(I)).Eachof\nthesameprocedureandconfigurationasinJunior&Backes\nthematrixrepresentsa3×3patchobtainedbycenteringitatthe\n(2016). Inparticular,theauthorsusedaLinearCongruential\nbluecoloredpixel,whilealsorepresentsthecontentofthelasttwo\nGenerator (LCG) for generating pseudorandom numbers.\ndimensionsofthetensor.Inaddition,theoverallfigurecanbeseen\nSpecifically, utilizing this approach, the elements of the\nasamatrixofmatrices,representingthelastfourdimensions.\nvectorvsatisfiesthefollowingrecurrencerelation:\nwithonlyonechannel,thisisdoneforeachchannelindepen-\ndently. Thus,thematrixX=Reshape(L)∈RC×J2×HW v :=(av +b)modc, k ∈{0,1,...,L−2} (B.3)\nk+1 k\nresultingfromthereshapingprocessofthe5-dimensional\ntensorLisillustratedinFigureB.4. where the parameters are initialized as v 0 = L+1,a =\nL+2,b=L+3,andc=L2 followingJunior&Backes\nFromthismatrix,itcanbeobservedthattheintensitiesof\n(2016). After filling the entire vector, a standardization\neachpatcharealongthecolumnofthematrixX,whilethe\nprocessisapplieduponv,i.e.,\nrows refers to the intensities of a specific position inside\neachpatch. Itshallbenotedthatalthoughmostofthepixels v = v k −v , k ∈{0,1,...,L−1} (B.4)\narepaddingpixels, thosecoloredinred, thisisattributed k s\nv\ntothefactthatourinitialimagehasaspatialdimensionof\n3×3. Ingeneral,forlargertextureimagessuch128×128 where v = L 1 (cid:80)L k= − 0 1v k , is the sample mean of v, and\nmostofthecolumnswouldbesimilartothefifthcolumn, s2 = 1 (cid:80)L−1(v −v)2isthesamplevarianceofv.\nv L−1 k=0 k\ni.e.,withoutanypaddingpixels. Toconclude,thismatrixis\nIn this context, to obtain the tensor T, the vector v is re-\nusedintheremainingoftherandomprojectormodule.\nshapedtopresentN dimensions,wherethei-thdimension\nRandomWeightMatrixGeneration. Inthispart,itis hasn elements. Following,wepresentinAlgorithm1a\ni\npresentedhowtherandomweightmatrixusedintheprocess PyTorch-likepseudocodefortheprevioustakensteps.\nofprojectingtheinputdataintoanotherdimensionalspace\nIn this context, if we let LCG(n ,n ,...,n ) be the N-\nisbuilt. Althoughinourproposedapproachweneedaset 1 2 N\ndimensional tensor representing the output of the pseu-\noftheserandomweightmatrices,i.e.,oneforeachimage\ndocode, then for any input texture image I ∈ RC×H×W,\nchannel,whichwouldcorrespondtoa3-dimensionaltensor,\ntherandomweightmatricesusedintherandomprojector\nwewillpresentthestepsandanalgorithmforgeneratinga\nmoduleisgivenbyLCG(C,ω,J2+1)∈RC×ω×(J2+1).\n17\nSupplementaryMaterialforMIXER:MixedHypersphericalRandomEmbeddingNeuralNetworkforTextureRecognition\nAlgorithm1RandomWeightMatrixGenerator morerobusttexturerepresentation. Next,theirformulasare\nInput: Eachdimensionsizen ,n ,...,n presented.\n1 2 N\nOutput: RandomtensorT∈Rn1×n2×···×nN Letm (x)bethen-thsamplecentralmoment,whichfol-\nv←torch.zeros(\n(cid:81)N\ni=1\nn\ni\n)\nlowing\nr\n(Joanes&Gill,1998),isdefinedby:\nv ←L+1\n0\na←L+2 N\nb←L+3 m r (x):= N 1 (cid:88) (x k −x)r , (C.5)\nc←L2 k=1\nfork ←0toL−2do\nwhere x = 1 (cid:80)N x is the sample mean of the N-\nv k+1 ←(av k +b)modc N k=1 k\ndimensional real vector x. Thus, the utilized statistical\nendfor\nmeasures’formulasaregivenby:\nv←(v−torch.mean(v))/torch.std(v)\nreturntorch.reshape(v,(n ,n ,...,n ))\n1 2 N h (x):=x (C.6)\nµ\nC.CompressionModule h (x):=(m (x))1/2 (C.7)\nσ 2\nm (x)\nInthissection,wepresentthesetHofcompressionfunc- h (x):= 3 (C.8)\ntions used to summarize the weights of the learned de- γ (m 2 (x))3/2\ncoderstoassemblethetexturerepresentation. Specifically, m (x)\nh (x):= 4 −3 (C.9)\nthis set consists mostly of statistical measure functions κ (m (x))2\n2\nh ,h ,...,h used to compress the column vectors of\n1 2 |H|\ntheresultingmatrixF∈R|S|J2×HW fromtheverticalcon- Itcanbenotedthattheutilizedstatisticalmeasuresformulas\nof standard deviation and kurtosis are not unbiased esti-\ncatenationofthelearneddecoders’weightspresentinthe\nmators. Nevertheless,itisnotnecessarytohavethemost\nsetS =S ∪S ,whereS andS arethesetscontain-\nD M D M\naccurateestimator,theobjectivehereissolelyamechanism\ningthelearneddecoders’sweightsfromthe DIRECT and\ntocompress(summarize)aninformationpresentinareal\nMIXEDbranches,respectively.\nvectortoarealnumber.\nFigureC.5.Illustrationofacompressionfunctionh:A⊂Rn →\nR.Thecompressionfunctionisresponsibleforcompressing(or\nsummarizing)an-dimensionalrealvectorx∈Ainarealnumber\nh(x).Thecompletedefinitionispresentedinthemaintext.\nInthiscontext,aspresentedinthemaintext,fourstatistical\nmeasures are employed: mean, standard deviation, skew-\nness,andexcesskurtosis.Themeangivesacentraltendency\nofthesample,whilethestandarddeviationisadispersion\nmeasure. Followingthis,theskewnessandkurtosisaremea-\nsuresabouttheshapeofthedistribution. Inthissense,these\nmeasurescomplementeachother,andareusedtocreatea\n18\n",
    "tables": [],
    "images": []
  },
  {
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "text": "A fast non-reversible sampler for Bayesian\nfinite mixture models\n∗ † Filippo Ascolani and Giacomo Zanella\nOctober 6, 2025\nAbstract\nFinite mixtures are a cornerstone of Bayesian modelling, and it is well-known that\nsampling from the resulting posterior distribution can be a hard task. In particular,\npopular reversible Markov chain Monte Carlo schemes are often slow to converge when\nthe number of observations n is large. In this paper we introduce a novel and simple\nnon-reversible sampling scheme for Bayesian finite mixture models, which is shown to\ndrasticallyoutperformclassicalsamplersinmanyscenariosofinterest,especiallyduring\nconvergence phase and when components in the mixture have non-negligible overlap.\nAt the theoretical level, we show that the performance of the proposed non-reversible\nscheme cannot be worse than the standard one, in terms of asymptotic variance, by\nmore than a factor of four; and we provide a scaling limit analysis suggesting that the\nnon-reversible sampler can reduce the convergence time from O(n2) to O(n). We also\ndiscuss why the statistical features of mixture models make them an ideal case for the\nuse of non-reversible discrete samplers.\n∗Duke University, Department of Statistical Science, Durham, NC, United States (fil-\nippo.ascolani@duke.edu)\n†Bocconi University, Department of Decision Sciences and BIDSA, Milan, Italy (gia-\ncomo.zanella@unibocconi.it)\nGZ acknowledges support from the European Research Council (ERC), through StG “PrSc-HDBayLe”\ngrant ID 101076564.\n5202\ntcO\n3\n]OC.tats[\n1v62230.0152:viXra\n1 Introduction\n1.1 Bayesian finite mixture models\nLet K ∈ N and consider a finite mixture model (Marin et al., 2005; Fru¨hwirth-\nSchnatter, 2006; McLachlan et al., 2019) defined as\nK\ni.i.d. (cid:88)\nY | θ,w ∼ w f (·) i = 1,...,n\ni k θ\nk\n(1) k=1\ni.i.d.\nθ ∼ p k = 1,...,K\nk 0\nw ∼ Dir(α),\nwhere θ = (θ ,...,θ ), w = (w ,...,w ), α = (α ,...,α ) and Dir(α) denotes the\n1 K 1 K 1 K\nDirichletdistributiononthe(K−1)-dimensionalsimplex∆ ⊂ RK withparameters\nK−1\nα. Heref isaprobabilitydensityonaspaceY dependingonaparameterθ ∈ Θ ⊂ Rd,\nθ\nto which a prior distribution with density p is assigned. For example, one could have\n0\nY = Θ = Rd and f (y) = N(y | θ,Σ) for some fixed Σ, where N(y | θ,Σ) denotes the\nθ\ndensity of the multivariate normal with mean vector θ and covariance matrix Σ at a\npoint y.\nA popular strategy to perform posterior computations with model (1) (also for\nmaximum likelihood estimation, as originally noted in Dempster et al. (1977)) consists\nin augmenting the model as follows\ni.i.d. i.i.d. i.i.d.\n(2) Y | c,θ,w ∼ f (y), c | θ,w ∼ Cat(w), w ∼ Dir(α), θ ∼ p ,\ni θci i k 0\nwhere c = (c ,...,c ) ∈ [K]n, with [K] = {1,...,K}, is the set of allocation variables\n1 n\nand Cat(w) denotes the Categorical distribution with probability weights w. Given a\nsample Y = (Y ,...,Y ), the joint posterior distribution of (c,θ,w) then reads\n1 n\n(cid:34) n (cid:35) K\n(cid:89) (cid:89)\nπ(c,θ,w) ∝ w f (Y ) Dir(w | α) p (θ )\nci θci i 0 k\ni=1 k=1\n(3)\n(cid:34) K (cid:35) K\n(cid:89) n (c)+α −1 (cid:89) (cid:89)\n∝ w k k f (Y )p (θ ),\nk θ k i 0 k\nk=1 k=1i:ci=k\nwhere n (c) = (cid:80)n 1(c = k) and 1 denotes the indicator function. In particular, it is\nk i=1 i\npossible to integrate out (θ,w) from (3) to obtain the marginal posterior distribution\nof c given by\n(cid:34) K (cid:35) K (cid:90)\n(cid:89) (cid:89) (cid:89)\n(4) π(c) ∝ Γ(α +n (c)) f (Y )p (θ )dθ ,\nk k θ i 0 k k\nk\nΘ\nk=1 k=1 i:ci=k\n2\nfrom which we deduce the so-called full-conditional distribution of c\ni\n(5) π(c = k | c ) ∝ [α +n (c )]p(Y | Y ,c ,c = k) k ∈ [K]\ni −i k k −i i −i −i i\nwhere c = (c ,...,c ,c ,...,c ), Y = (Y ,...,Y ,Y ,...,Y ) and\n−i 1 i−1 i+1 n −i 1 i−1 i+1 n\n(cid:81)\n(cid:90) f (Y )p (θ)\np(Y | Y ,c ,c = k) = f (Y )\nj̸=i:cj=k θ j 0\ndθ\ni −i −i i θ i (cid:82) (cid:81) f (Y )p (θ′)dθ′\nΘ Θ j̸=i:cj=k θ′ j 0\nis the predictive distribution of observation Y given Y and the allocation variables.\ni −i\nIf p is conjugate with respect to the density f , then p(Y | Y ,c ,c = k) and thus\n0 θ i −i −i i\nπ(c = k | c ) are available in closed form. For example, if f (y) = N(y | θ,Σ) and\ni −i θ\np (θ) = N(θ | θ ,Σ ) it holds that p(Y | Y ,c ,c = k) = N(Y | µ¯,Σ¯), where\n0 0 0 i −i −i i i\nΣ¯ = Σ+ (cid:0) Σ−1+n (c )Σ−1(cid:1)−1 , µ¯ = (cid:0) Σ−1+n (c )Σ−1(cid:1)−1(cid:0) Σ−1θ +n (c )Σ−1Y¯ (cid:1)\n0 k −i 0 k −i 0 0 k −i k,−i\nand Y¯ = n−1(c ) (cid:80) Y . Analogous expressions are available for likelihoods\nk,−i k −i j̸=i:cj=k j\nin the exponential family, see e.g. Robert (2007, Sec.3.3) for details.\n1.2 The Marginal Gibbs (MG) sampler\nMost popular algorithms for finite mixture models are based on the augmentation\nin (2), see e.g. Diebolt and Robert (1994). Here we consider the random-scan1 Gibbs\nsamplerwhichiteratesupdatesfromπ(c | c )forrandomlychoseni ∈ [n]. ItsMarkov\ni −i\nkernel P is defined as\nMG\nn\n1 (cid:88)\nP (c,c′) = P (c,c′), c,c′ ∈ [Kn]\nMG MG,i\nn\ni=1\nwith P (c,c′) = δ (c′ )π(c | c ). The associated pseudocode is given in Algo-\nMG,i c−i −i i −i\nrithm 1. We refer to P as marginal sampler, since it targets the marginal posterior\nMG\ndistribution of c defined in (4). Once a sample from π(c) is available, draws from\nπ(c,θ,w) can be obtained by sampling from π(θ,w | c), so that Algorithm 1 can be\nused to perform full posterior inference on π(c,θ,w).\nBeinganirreducibleandaperiodicMarkovkernelonafinitespace,P isuniformly\nMG\nergodic for every fixed n, see e.g. Levin and Peres (2017, Theorem 4.9) and Roberts\nand Rosenthal (2004, Sec.3.3) for discussion about uniform ergodicity. However, as we\nwill see later on, its rate of convergence tends to deteriorate quickly as n increases.\n1Hereweconsidertherandom-scanstrategysinceitsimplifiessomeoftheproofsandcomparisonsbelow.\nWe expect the behaviour of Pn , where Pk = P ...P denotes the k-th power of a Markov kernel P, to be\nMG\nroughlycomparabletotheoneofthedeterministic-scanversion(whichupdatesc fori=1,...,nsequentially\ni\nat each iteration) in most cases of interest, and thus stick to the random-scan for simplicity.\n3\nAlgorithm 1 (Marginal sampler P )\nMG\nInitialize c(0) ∈ [K]n.\nfor t ≥ 1 do\nSample i ∼ Unif({1,...,n}), where Unif denotes the uniform distribution.\nSample c(t) ∼ π(c | c(t−1)), with π(c = k | c ) as in (5), and set c(t) = c(t−1).\ni i −i i −i −i −i\nend for\nA popular alternative to the marginal sampler is the so-called conditional sampler\nintroduced in Diebolt and Robert (1994), which directly targets π(c,θ,w) defined in\n(3) alternating updates of (θ,w) | c and c | (θ,w). We postpone the discussion of\nthis algorithm to Section 3.2, since the latter is always dominated by P in terms of\nMG\nmixing speed (see e.g. Proposition 3.3).\n1.3 Illustrative example\nIt is well-known that P can be slow to converge when n is large (Celeux et al.,\nMG\n2000; Lee et al., 2009). As a first illustrative example, we take model (1) with K = 2,\nf (y) = N(y | θ,1), p (θ) = N(θ | 0,1), α = (0.5,0.5), and we consider the posterior\nθ 0\ndistribution given (Y ,...,Y ) generated as\n1 n\ni.i.d.\n(6) Y ∼ 0.9N(0.9,1)+0.1N(−0.9,1), i = 1,...,n\ni\nwith n = 2000. This is a relatively simple one-dimensional problem, with data gener-\nated from two components with a reasonable degree of separation between them (the\ntwo means are almost two standard deviations away from each other).\nWe use P to sample from the resulting posterior π(c), leading to a Markov chain\nMG\n{c(t)} on[K]n. TheleftpanelofFigure1displays100independenttraceplotsof\nt=0,1,2,...\nthesizeofthelargestclusterin{c(t)} ,withallchainsindependentlyinitializedbysam-\nt\npling c(0) uniformly from [K]n. Most runs are still far from 0.9 (value around which we\nexpecttheposteriortoconcentrate)after150×niterations. Indeedtrajectoriesexhibit\na typical random-walk behaviour, with slow convergence to stationarity. The center\npanelinsteadshowsthetraceplotsgeneratedbythesamenumberofrunsanditerations\nof P , the non-reversible scheme we propose in Section 2.2 (see Algorithm 6 therein\nNR\nfor pseudocode and full details). The chain appears to reach the high-probability re-\ngion and forget the starting configuration much faster. This is also clear from the right\npanel, which displays empirical estimates of the marginal distributions of the Markov\nchains induced by P and P over time.\nMG NR\n4\n0 50 100 150\n0.1\n9.0\n8.0\n7.0\n6.0\n5.0\nMarginal\n0 50 100 150\n0.1\n9.0\n8.0\n7.0\n6.0\n5.0\nNon reversible\n0.1\n9.0\n8.0\n7.0\n6.0\n5.0\nMarginal distribution of the chains\n1 20 40 60 80 100 120 140\nFigure 1: Left and center: traceplots of 100 independent runs of the size of the largest cluster for\n150 iterations (after a thinning of size n, i.e. after 150×n total updates) of P (left)\nMG\nandP (center)inAlgorithm6. Right: empiricalestimatesofthemarginaldistribution\nNR\nat every 10×n iterations for P (gray) and P (black). The model is the one in (1)\nMG NR\nwith K = 2, f (y) = N(y | θ,1), p (θ) = N(θ | 0,1) and α = (0.5,0.5), while the data\nθ 0\nare generated as in (6). Initial configurations c(0) are sampled uniformly from [K]n.\n1.4 Lifted samplers for discrete spaces\nOur proposed sampler is inspired by classical non-reversible MCMC constructions (Di-\naconis et al., 2000; Fearnhead et al., 2018), which loosely speaking force the algorithm\nto persistently move in one direction as much as possible. To illustrate the idea, con-\nsider an arbitrary probability distribution π on a countable space C and an augmented\ndistribution\nπ(c)\nπ˜(c,v) = , c ∈ C,v ∈ {−1,+1},\n2\non the space X = C ×{−1,+1}, so that π is the marginal distribution of π˜ over C.\nGiven two Markov kernels {q (c,·)} and {q (c,·)} on C, let P be the non-\n+1 c∈C −1 c∈C lift\nreversible π˜-invariant Markov kernel defined in Algorithm 2. The kernels are usually\nAlgorithm 2 Generating a sample (c′,v′) ∼ P ((c,v),·)\nlift\nGenerate c˜∼ q (c,·).\nv\nSet (c′,v′) = (c˜,v) with probability\n(cid:26) (cid:27)\nπ(c˜)q (c˜,c)\n−v\nmin 1, .\nπ(c)q (c,c˜)\nv\nOtherwise set (c′,v′) = (c,−v).\nchosen so that q (c,·) and q (c,·) have disjoint support and the variable v ∈ {−1,+1}\nv −v\nencodes a direction (or velocity) along which the chain is exploring the space: such\ndirection is reversed only when a proposal is rejected (see Algorithm 2). As a simple\n5\nexample, take C = N and q (c,·) = δ (·), so that v = +1 implies that the chain is\nv c+v\nmoving towards increasing values and viceversa with v = −1. Within this perspective\nv can be seen as a “memory bank” which keeps track of the past history of the chain\nand introduces momentum. The kernel P is often referred to as a lifted version of\nlift\nthe (reversible) Metropolis-Hastings kernel with proposal distribution q = 0.5q +\n+1\n0.5q and target distribution π. Lifted kernels can mix significantly faster than their\n−1\nreversible counterparts (Diaconis et al., 2000) and are in general at least as efficient as\ntheoriginalmethodundermildassumptions(Bierkens,2016;AndrieuandLivingstone,\n2021; Gagnon and Maire, 2024b). However, whether or not lifting techniques achieve\na notable speed-up depends on the features of π and the choice of q . For example, if\nv\nproposed moves are often rejected, then the direction v will be reversed frequently and\nthe chain will exhibit an almost reversible behaviour; while if the sampler manages to\nmake long ‘excursions’ (i.e. consecutive moves without flipping direction) one expects\nto observe significant gains obtained by lifting.\nNon-reversible samplers for mixture models General techniques to con-\nstruct non-reversible samplers for discrete spaces have been proposed in the literature,\nseee.g.GagnonandMaire(2024a,Sec.3)forconstructionsonpartially-ordereddiscrete\nspaces and Power and Goldman (2019) for discrete spaces with algebraic structures.\nWe are, however, not aware of successful applications of these methodologies to mix-\nture models. Part of the reason could be that, in order to build a lifted counter-part of\nP for mixture models, one would need to define some notion of direction or partial\nMG\nordering on [K]n, or more generally on the space of partitions and it is not obvious\nhow to do so in a way that is computationally efficient and results in long excursions\nwith persistence in direction (thus leading to substantial speed-ups). For example, one\ncould directly rely on the cartesian product structure of [K]n and attach a velocity\ncomponent to each coordinate, applying for example the discrete Hamiltonian Monte\nCarlo algorithm of Nishimura et al. (2020): this however would not pair well with the\ngeometry of posterior distributions π(c) arising in mixture models and likely result in\nshort excursions and little speed-up.\nTotacklethisissue, wetakeadifferentperspectiveon[K]n, movingfromthekernel\nP , which is a mixture over data-points (i.e. over i ∈ [n]), to a kernel P which is a\nMG R\nmixture over pairs of clusters (see Section 2.1 for definition). This allows us to derive\nan effective non-reversible sampler P targeting π(c), built as a mixture of lifted\nNR\nsamplers associated to pairs of clusters (see Section 2.2 for definition). Note that,\nwhile we designed our sampler to be effective for posterior distributions of mixture\nmodels, the proposed scheme can in principle be used with any distribution π on [K]n.\n1.5 Related literature\nBayesian mixture models Bayesian finite mixture models are a classical topic\nwhich has received a lot of attention in the last decades, see Marin et al. (2005);\n6\nFru¨hwirth-Schnatter (2006) for some reviews. The challenges related to sampling from\nthe resulting posterior distribution have been also discussed extensively, see e.g. early\nexamples in (Diebolt and Robert, 1994; Celeux et al., 2000; Stephens, 2000; Lee et al.,\n2009; Hobert et al., 2011), and the marginal and conditional samplers we compare\nwith are arguably the most popular schemes that are routinely used to accomplish\nsuch tasks (Marin et al., 2005, Section 1.4).\nLifted MCMC for statistical models with discrete parameters Non-\nreversible MCMC samplers have been previously designed for and applied to Bayesian\nstatistical models with discrete parameters, such as variable selection, permutation-\nbased and graphical models; see e.g. Power and Goldman (2019); Gagnon and Maire\n(2024a); Schauer and Wien¨obst (2024) and references therein. However, posterior\ndistributions arising from such models are usually strongly concentrated and highly\nnon-smooth,limitingthelengthofexcursionsandspeed-upsobtainedwithliftedchains.\nAs a result, one often ends up observing large gains (e.g. hundred-fold) when targeting\nuniform or prior distributions (which are usually quite flat) and more modest gains\n(e.g. two-fold) when targeting actual posterior distributions used in practice; see e.g.\nSchauer and Wien¨obst (2024, Figures 1 and 3), Power and Goldman (2019, Table 1) or\nGagnon and Maire (2024a, Figure 1)2. Instead, a key feature of our proposed sampler\nis that, in many cases of interest, the speed-up relative to its reversible counter-part\nremains large even in the presence of observed data (i.e. for the actual posterior). We\nargue that this is due to statistical features of mixture models that make them well-\nsuited to appropriately designed non-reversible samplers (such as P ); see Section\nNR\n2.2.1 for more details.\n1.6 Structure of the paper\nIn Section 2 we introduce our proposed non-reversible Markov kernel P , which tar-\nNR\ngets π(c) in (4). In Section 3 we first show that, after accounting for computational\ncost, P cannot perform worse than P , in terms of asymptotic variance, by more\nNR MG\nthan a factor of four. This is done by combining some variations of classical results on\nasymptoticvariancesofliftedsamplerswithaPeskuncomparisonbetweenP andan\nMG\nauxiliary reversible kernel P . We then provide analogous results for the conditional\nR\nsampler by showing that it is dominated by the marginal one (Section 3.2). In Section\n4 we continue the comparison between P and P , showing that in the prior case\nMG NR\nthe latter improves on the former by an order of magnitude, i.e. reducing the conver-\ngence time from O(n2) to O(n). This is done through a scaling limit analysis, which\n2ThisisincontrastwithapplicationsofliftingtechniquestodiscretemodelsarisinginStatisticalPhysics\n(see e.g. Vucelja, 2016), which often feature a higher degree of symmetry and smoothness, thus making\nnon-reversible MCMC methods more effective; see e.g. Power and Goldman (2019, Table 1) for numerical\nexamples and Faulkner and Livingstone (2024) for a recent review.\n7\nproves that, after rescaling time by a factor of n2, the evolution of the frequencies\nn (c) evolving according to P converges to a Wright-Fisher process (Ethier, 1976),\nk MG\nwhich is a diffusion on the probability simplex. In contrast, when the chain evolves\naccording to P , we obtain convergence to a non-singular piecewise deterministic\nNR\nMarkov process (Davis, 1984) after rescaling time by only a factor of n. Section 5 dis-\ncusses a variant of P and, finally, Section 6 provides various numerical simulations,\nNR\nwhere P is shown to significantly outperform P in sampling from mixture models\nNR MG\nposterior distributions, both in low and high-dimensional cases. The Supplementary\nMaterial contains additional simulation studies, together with the proofs of all the\ntheoretical results. R code to replicate all the numerical experiments can be found at\nhttps://github.com/gzanella/NonReversible_FiniteMixtures.\n2 A non-reversible marginal sampler\n2.1 A reversible sampler that operates over pairs of clus-\nters\nLet π(c) be an arbitrary probability distribution on [K]n, such as (4) in the context of\nfinitemixtures,anddenotethesetoforderedpairsin[K],withcardinalityK(K−1)/2,\nas\n(7) K = (cid:8) (k,k′) ∈ [K]2 : k < k′(cid:9) .\nAs an intermediate step towards defining P , we first consider a π-reversible Markov\nNR\nkernel on [K]n defined as\n(cid:88)\n(8) P (c,c′) = p (k,k′)P (c,c′) c,c′ ∈ [K]n,\nR c k,k′\n(k,k′)∈K\nwhere\nn (c)+n (c)\n(9) p (k,k′) = k k′ , (k,k′) ∈ K\nc\n(K −1)n\nis a probability distribution on K for each c ∈ [K]n, i.e. (cid:80) p (k,k′) = 1, and\n(k,k′)∈K c\nP is the π-reversible Metropolis-Hastings (MH) kernel that proposes to move a\nk,k′\nuniformly drawn point from cluster k to cluster k′ or viceversa with probability 1/2.\nThe resulting kernel P is defined in Algorithm 3 where, for ease of notation, for every\nR\nc ∈ [K]n, i ∈ [n] and k ∈ [K] we write (c ,k) ∈ [K]n for the vector c with the i-th\n−i\nentry c replaced by k.\ni\nDespite the fact that P is a mixture with weights p depending on the current\nR c\nstate c, invariance with respect to π is preserved, as proven in the next lemma. The\n8\nAlgorithm 3 Generating a sample c′ ∼ P (c,·)\nR\nSample (k,k′) ∼ p as in Algorithm 4.\nc\nSet (k ,k ) = (k,k′) with probability 1/2 and (k ,k ) = (k′,k) otherwise\n− + − +\nIf n (c) = 0 set c′ = c.\nk−\nIf n (c) > 0 sample i ∼ Unif({i′ ∈ [n] : c = k }) and set c′ = (c ,k ) with probability\nk− i′ − −i +\nmin{1,r(c,i,k ,k )} and c′ = c otherwise, where\n− +\n(cid:18) (cid:19)\nn (c) π(c = k | c )\n(10) r(c,i,k ,k ) =\nk− i + −i\n,\n− +\nn (c)+1 π(c = k | c )\nk+ i − −i\nkey point is that p (k,k′) only depends on n (c)+n (c) and P leaves the latter\nc k k′ k,k′\nquantity unchanged.\nLemma 2.1. The Markov kernel P defined in Algorithm 3 is π-reversible. Moreover,\nR\nif π(c) > 0 for every c ∈ [K]n it is also irreducible, aperiodic and uniformly ergodic.\nSampling from p can be performed efficiently using Algorithm 4, where one cluster\nc\nis selected with probability proportional to its size and the other uniformly at random\nfrom the remaining ones. Validity is proved in the next lemma.\nLemma 2.2. For each c ∈ [K]n, Algorithm 4 produces a sample (k,k′) from the\nprobability distribution p defined in (9).\nc\nAlgorithm 4 Sampling (k,k′) ∼ p defined in (9)\nc\nSample k from {1,...,K} with probabilities (n (c)/n,...,n (c)/n)\n1 1 K\nSample k uniformly at random from {1,...,K}\\{k }\n2 1\nSet k = min{k ,k } and k′ = max{k ,k }\n1 2 1 2\nComparison between P and P Both P and P can be interpreted as\nMG R MG R\nreversible Metropolis-Hastings schemes that propose single-point moves. Specifically,\nP and P propose moving datapoint i to cluster k with, respectively, probabilities\nMG R\nπ(c = k | c ) n (c)+n (c) 1(c ̸= k)\na (i,k) =\ni −i\nand a (i,k) =\nci k i\n,\nMG R\nn n (c) 2(K −1)n\nci\nfor(i,k) ∈ [n]×[K]. ForP theMetropolis-Hastingsacceptanceprobabilityisalways\nMG\none, while for P it is not. It is interesting to note that\nR\n1 1\na (i,k) ≥ ≥ a (i,k),\nR MG\n2(K −1)n 2(K −1)\n9\nmeaning that the proposal probabilities of P can be at most 2(K −1) times smaller\nR\nthan the ones of P . This connection will help providing formal comparison results\nMG\nbetween P and P in Section 3 (see Theorem 3.1 and Remark 3.2 for more details).\nR MG\nWepostponedetailsonthesecomparisonstoSection3andnowfocusonhowtoleverage\nthe mixture representation of P in (8) to build effective non-reversible algorithms\nR\ntargeting π(c).\nCost per iteration of P and P For both P and P the cost per iteration\nMG R MG R\nis usually dominated by the computation of the conditional distribution π(c = k | c )\ni −i\nin (5), which will depend on the specific combination of kernel f and prior p . Indeed,\nθ 0\nAlgorithm 1 requires in addition only to sample from a uniform distribution on a\ndiscrete set (which has a fixed cost). Similar considerations hold for Algorithm 3,\nsince sampling from p with Algorithm 4 entails again only sampling from two uniform\nc\ndistributions. Thus, we measure cost per iteration of these samplers in terms of the\nnumber of conditional distribution evaluations, which is K for P and 2 for P :\nMG R\ntherefore the ratio of costs of P versus P is K/2. The same will hold for P in\nMG R NR\nAlgorithm 6 below, which requires essentially the same computations of Algorithm 3.\n2.2 The proposed non-reversible sampler\nConsider the extended target distribution\n(cid:18)\n1\n(cid:19)K(K−1)/2\n(11) π˜(c,v) := π(c) c ∈ [K]n, v = (v ) ∈ {−1,+1}K(K−1)/2\n2\nk,k′ (k,k′)∈K\nand the π˜-invariant Markov kernel P defined as\nNR\n(cid:88)\n(12) P ((c,v),(c′,v′)) = p (k,k′)P˜ ((c,v),(c′,v′)),\nNR c k,k′\n(k,k′)∈K\nwith p defined as in (9) and P˜ being the π˜-invariant kernel defined in Algorithm 5.\nc k,k′\nThe kernel P˜ operates on the k-th and k′-th clusters, and it is a lifted counter-part\nk,k′\nof P , with associated velocity component v . In this construction, the velocity\nk,k′ k,k′\nvector v is K(K −1)/2 dimensional and only one of its component is actively used to\nmove c at each iteration. The pseudo-code associated to P is given in Algorithm 6.\nNR\nThe algorithm depends on a parameter ξ ≥ 0, which can be interpreted as the\nrefresh rate at which directions are flipped. While useful to take ξ > 0 for technical\nreasons (i.e. to ensure aperiodicity), we do not expect the value of ξ to have significant\nimpacts in practice provided it is set to a small value, and in the simulations we always\nset ξ = 1/2.\nThe next lemma shows that P is a valid π˜-invariant kernel.\nNR\n10\nAlgorithm 5 Generating a sample (c′,v′) ∼ P ˜ ((c,v),·)\nk,k′\nWith probability ξ/n flip v to −v\nk,k′ k,k′\nSet (k ,k ) = (k,k′) if v = +1, and (k ,k ) = (k′,k) if v = −1\n− + k,k′ − + k,k′\nIf n (c) = 0, set (c′,v′) = (c,v(flip)), with v(flip) = (v ,−v )\nk− −(k,k′) k,k′\nIf n (c) > 0, sample i ∼ Unif({i′ ∈ [n] | c = k }) and set (c′,v′) = ((c ,k ),v) with\nk− i′ − −i +\nprobability min{1,r(c,i,k ,k )} and otherwise (c′,v′) = (c,v(flip)), with r(c,i,k ,k )}\n− + − +\ndefined in (10)\nWith probability ξ/n flip v′ to −v′\nk,k′ k,k′\nAlgorithm 6 One step of the non-reversible kernel (c′,v′) ∼ P ((c,v),·)\nNR\nSample (k,k′) ∼ p as in Algorithm 4.\nc\nSample (c′,v′) ∼ P ˜ ((c,v),·) as in Algorithm 5.\nk,k′\nLemma2.3. Foranyprobabilitydistributionπ on[K]n, theMarkovkernelP defined\nNR\nin Algorithm 6 is π˜-invariant, with π˜ as in (11). Moreover, if ξ > 0 and π(c) > 0 for\nevery c ∈ [K]n, then P is irreducible, aperiodic and uniformly ergodic.\nNR\n2.2.1 Specificities of mixture models that make P work well\nNR\nWenowdiscussataninformallevelsomeofthespecificitiesoftheposteriordistribution\nπ(c) arising from mixture models that make P work well.\nNR\nLack of identifiability and concentration An important statistical feature of\nmixture models is that cluster labels are in general not identifiable as n → ∞, meaning\nthatevenwhennislargethereisnon-vanishinguncertaintyonthevalueofc . Inother\ni\nwords, while the posterior distribution of w and θ concentrates as n → ∞, the one of c\ndoes not (not even at the level of marginals, meaning that, for every fixed i, π(c ) does\ni\nnot converge to a point mass as n → ∞); see e.g. Nguyen (2013); Guha et al. (2021)\nand references therein for asymptotic results for mixture model posteriors. Intuitively,\nlack of concentration occurs because the information about each individual c does not\ni\ngrow with n (since each c is associated to a single datapoint). This also tends to\ni\nmake posteriors flatter, i.e. moving one observation from one cluster to another usually\nleads to a small change in the target distribution. By contrast, many models with\ndiscrete parameters lead to posteriors that become increasingly more concentrated and\nrough as n → ∞, which has a major impacts on the convergence properties of MCMC\nalgorithms targeting them, including making standard MCMC converge faster (see e.g.\nYang et al., 2016; Zhou et al., 2022; Zhou and Chang, 2023) and lifting techniques less\neffective (as already discussed in Section 1.5).\n11\nCancellationsintheacceptanceratio Forπ(c)asin(4),theMHratior(c,i,k ,k )\n− +\nreads\n(cid:18) (cid:19)(cid:18) (cid:19)\nα +n (c) n (c) p(Y | Y ,c ,c = k )\n(13) r(c,i,k ,k ) =\nk+ k+ k− i −i −i i +\n.\n− +\nn (c)+1 α +n (c)−1 p(Y | Y ,c ,c = k )\nk+ k− k− i −i −i i −\nInterestingly, the proposal probability almost matches the term α +n (c) arising from\nk k\nthe prior. In particular, by writing\n(cid:18)\nα +n (c)\n(cid:19)(cid:18)\nn (c)\n(cid:19) (cid:18)\nα −1\n(cid:19)(cid:18)\nα −1\n(cid:19)−1\nk+ k+ k−\n= 1+\nk+\n1+\nk−\n,\nn (c)+1 α +n (c)−1 n (c)+1 n (c)\nk+ k− k− k+ k−\nwe see that the first part of (13) goes to 1 as n (c) and n (c) increase, for every\nk+ k−\nfixed value of α. Notice that with α = 1 for every k this ratio is always equal to 1.\nk\nThis cancellation contributes to make (13) closer to 1 and thus to make excursions of\nP longer.\nNR\nFlatness in the tails and behavior out of stationarity Interestingly,alsothe\nratio of predictive distributions in (13) tends to get close to 1 for partitions that do not\ncorrespond to well-identified and separate clusters, meaning that mixture model poste-\nriors π(c) become increasingly flatter in the tails. To illustrate this, consider the com-\n(0) i.i.d.\nmon situation when labels are initialized uniformly at random, i.e. c ∼ Unif([K]).\ni\nIn this situations, by construction, clusters are similar to each other under c(0), re-\nsulting in ratios of predictive distributions that are close to 1 (and converge to 1 as\nn → ∞). As a consequence, the non-reversible chain will proceed almost deterministi-\ncallywithoutflippingdirectionsuntilclustersstarttodifferentiatesignificantly. Thisis\nindeed the behavior observed in the middle panel of Figure 1, as well as in Section 6.2\nand B of the Supplementary Material with different values of K and likelihood kernels.\nMoregenerally, inmixturemodelcontexts, non-reversibilityisparticularlyhelpfuldur-\ning the transient phase, where the algorithm has not yet reached the high-probability\nregion under π and has to explore large flat regions of the state space3.\nOverlapping components and the overfitted case Another situation that\nmakesratiosofpredictivedistributionscloseto1iswhentheactualclustersinthedata\nhave a considerable overlap. An extreme case of this situation is when the true number\nof components K∗ (assuming data were actually generated by a well-specified mixture\nmodel) is strictly smaller than K, which amounts to assuming that a plausible upper\nbound on K∗ is known and K is set to such value (instead of the less plausible scenario\nwhere K∗ itself is known). This is often called the overfitted case, see e.g. Rousseau\n3This is, again, in contrast with typical Bayesian discrete models that lead to posteriors with large\n“discrete gradients” in the tails providing strong enough signal for reversible schemes to converge fast in the\nfirst part of the transient phase (Yang et al., 2016; Zhou et al., 2022; Zhou and Chang, 2023).\n12\nand Mengersen (2011) for a theoretical exploration of its asymptotic properties, and it\nis a common situation since in many context (e.g. density estimation) it is preferable\nto overshoot rather than undershoot the value of K and thus practitioners often set K\nto some conservative, moderately large value. See Section 6.4 for more discussion on\nthe overfitted case and empirical evidence that in this setting the improvement of P\nNR\nover the latter is particularly apparent.\n3 Asymptotic variance comparison results\nIn this section we compare the various kernels discussed above in terms of asymptotic\nvariances. Among other results we show that, after accounting for computational cost,\nP cannotbeworsethanP bymorethanafactorof4. GivenaMarkovchain{X }\nNR MG t t\nwith a π-invariant Markov kernel P started in stationarity, the asymptotic variance of\nthe associated MCMC estimator is given by\n(cid:32) T (cid:33) ∞\n1 (cid:88) (cid:88)\nVar(g,P) = lim TVar g(X ) = Var (g)+2 Cov(g(X ),g(X )),\nt π 0 t\nT→∞ T\nt=1 t=1\nfor every function g such that Var (g) is well-defined.\nπ\n3.1 Ordering of reversible and non-reversible schemes\nThe next theorem provides ordering results for the asymptotic variances of P , P\nMG R\nand P . Technically speaking these kernels are not directly comparable, since P\nNR MG\nandP aredefinedon[K]n whileP isdefinedon[K]n×{−1,+1}K(K−1)/2. Nonethe-\nR NR\nless, we are only interested in estimating expectations of test functions that depend\non c alone, so that we can restrict attention to those, as usually done in non-reversible\nMCMCliterature(AndrieuandLivingstone,2021;GagnonandMaire,2024b). Givena\ntestfunctiong : [K]n → R,withaslightabuseofnotation,wealsouseginVar(g,P )\nNR\ntodenotethefunctiondefinedasg(c,v) = g(c)forall(c,v) ∈ [K]n×{−1,+1}K(K−1)/2.\nTheorem 3.1. Let π be a probability distribution on [K]n and g : [K]n → R. Then\n(14) Var(g,P ) ≤ Var(g,P ) ≤ c(K)Var(g,P )+[c(K)−1]Var (g),\nNR R MG π\nwhere c(K) = 2(K −1) and Var (g) denotes Var(g(X )) for X ∼ π.\nπ 0 0\nSince in most realistic applications Var(g,P ) is much larger than Var (g), the\nMG π\ninequality in (14) implies that P can be worse than P , in terms of variance of\nNR MG\nthe associated estimators, only by a factor of 2(K −1). Moreover, since the cost per\niteration of P is K/2 times the one of P (see Section 2.1) the overall worsening\nMG NR\nis at most by a factor of 4.\n13\nRemark 3.2. The proof of the second inequality in (14) relies on showing that\nP (c,c′) ≥ c−1(K)P (c,c′) for every c ̸= c′, which means that the probability of\nR MG\nchanging state according to P is not too low compared to the one of P . Interest-\nR MG\ningly, the converse is not true, in the sense that there is no d > 0 independent from n\nsuch that P (c,c′) ≥ dP (c,c′). Indeed, let π be as in (4) with K = 3, α = (1,1,1)\nMG R\nand f = f. Then if c = (1,...,1,2,3) and c′ = (1,...,1,2,2) it is easy to see that\nθ\n2 1\nP (c,c′) = and P (c,c′) = .\nMG R\nn(3+n−1) 6n\nThe first inequality in (14) instead relies on extending classical asymptotic variance\ncomparison results for lifted kernels to the case of state-dependent mixtures such as in\nP , as shown in Section C.1.1 of the supplement.\nNR\n□\nWe stress that the results of Theorem 3.1 hold uniformly, in the sense that no as-\nsumptions on π are needed. Thus using P is guaranteed to provide performances\nNR\nwhich never get significantly worse than the ones of P in terms of asymptotic vari-\nMG\nances. In the next sections, we will see that on the contrary P can lead to significant\nNR\nimprovements (e.g. by a factor of n) relative to P .\nMG\n3.2 Comparison with conditional sampler\nWe now define the conditional sampler targeting π(c,θ,w) mentioned in Section 1.2.\nThepseudocodeisgiveninAlgorithm7andwedenotewithP theassociatedMarkov\nCD\nkernel on [K]n × ΘK × ∆ . Also here we consider the random-scan case, which\nK−1\nallows for an easier comparison with P and P . We expect the main take-away\nMG NR\nmessages to remain valid for the arguably more popular deterministic-scan scheme,\neven if theoretical results there are less neat (see e.g. Roberts and Rosenthal (2015);\nHe et al. (2016); Gaitonde and Mossel (2024); Ascolani et al. (2024) and references\ntherein).\nThe next proposition, whose proof is inspired by the one of (Liu, 1994, Thm.1),\nshows that P always yields a smaller asymptotic variance than P . Again with an\nMG CD\nabuseofnotationweusegtodenotebothg : [K]n → Randg : [K]n×ΘK×∆ → R\nK−1\nfunction of the first argument alone.\nProposition 3.3. Let π be as in (3) and g : [K]n → R. Then for every f , n, Y we\nθ\nhave that Var(g,P ) ≤ Var(g,P ).\nMG CD\nCombinedwithTheorem3.1,theaboveresultimpliesthatVar(g,P ) ≤ c(K)Var(g,P )+\nNR CD\n[c(K)−1]Var (g), so that if P outperforms P then it should also be preferred to\nπ NR MG\nP . Thus in the following we restrict to the comparison between P and P .\nCD MG NR\n14\nAlgorithm 7 (Conditional sampler P )\nCD\nInitialize (c(0),θ(0),w(0)) ∈ [K]n ×ΘK ×∆\nK−1\nfor t ≥ 1 do\nSample i ∼ Unif({1,...,n+1}).\nif i ≤ n then\nSample c(t) ∼ π(c | θ(t−1),w(t−1)) with\ni i\nw f (Y )\nk θ I\nπ(c = k | θ,w) = k , k = 1,...,K.\ni (cid:80)K\nw f (Y )\nk′=1 k′ θ k′ i\nend if\nif i = n+1 then\n(cid:0) (cid:1)\nSample w(t) ∼ Dir α +n (c(t−1)),...,α +n (c(t−1)) .\n1 1 K K\nSample θ(t) ∼ π(θ | c(t−1)) ∝ (cid:81) f (Y )p (θ ) for k = 1,...,K.\nk k j:c(t−1)=k θ k j 0 k\nj\nend if\nend for\n4 Scaling limit analysis\nIn this section we derive scaling limit results for P and P as n → ∞. In gen-\nMG NR\n(n)\neral, given a sequence of discrete-time Markov chains {X\nt\n} t∈N, scaling limit results\n(Gelman et al., 1997; Roberts and Rosenthal, 2001b) consist in showing that a time-\n(n) (n) (n)\nchangedprocess{Z t } t∈R definedasZ t = X ⌈h(n)t⌉ , withh(n) → ∞and⌈·⌉denoting\ntheceilingfunction, convergesinasuitablesensetoanon-degenerateprocess{Z t } t∈R +\nas n → ∞. Provided the limiting process is non-singular and ergodic, this is usually\ninterpreted assuggesting thatO(h(n))iterations ofthe discrete-timeMarkovchainare\nneeded to mix. In other words, the time rescaling required to obtain a non-trivial limit\nis a measure of how the process speed scales as n grows.\nIn order to derive such results we restrict to the prior case, where the likelihood\nis uninformative and the posterior distribution of c coincides with the prior (2). This\ncan be formally described by setting f (y) = f(y), with f probability density on Y, so\nθ\nthat the data do not provide any information on the labels. The joint distribution and\nfull conditionals become\n(cid:81)K\nΓ(α +n (c)) α +n (c )\n(15) π(c) = k=1 k k , π(c = k | c ) = k k −i ,\ni −i\nΓ(|α|+n) |α|+n−1\nwith|α| =\n(cid:80)K\nα . Thisisclearlyasimplifiedsetting, whichallowsanexplicitmath-\nk=1 k\nematical treatment and it can be considered as an extreme case of un-identifiability\nand overlapping components (which are indeed all the same). Extending the analysis\n15\nto the more realistic case of informative likelihood is an interesting direction for future\nresearch, see Section 7 for more details.\n4.1 Marginal sampler\nConsider a Markov chain {c(t)} t∈N with kernel P MG and invariant distribution (15),\nwhere we suppress the dependence on n for simplicity. Let\nn\nX (c) = n k (c) = 1 (cid:88) 1(c = k), c ∈ [K]n,\nk i\nn n\ni=1\nbe the multiplicity of component k and\n(cid:16) (cid:16) (cid:17) (cid:16) (cid:17)(cid:17)\n(16) X = (X ,...,X ) = X c(t) ,...,X c(t) .\nt t,1 t,K 1 K\nCrucially, since π(c = k | c ) defined in (15) only depends on the multiplicities, i.e.\ni i\n(c ,...,c ) are exchangeable a priori, it follows that (X ) is itself a Markov\n1 n t t=0,1,2,...\nchain. Moreover, {X t } t∈N is de-initializing for {c(t)} t∈N in the sense of Roberts and\nRosenthal (2001a), so that the convergence properties of the former are equivalent to\nthe one of the latter (by e.g. Corollary 2 therein). With an abuse of notation, we\ndenote the kernel of {X t } t∈N also as P MG .\nIn the proof of Theorem 4.1 we show that\n2 (cid:104)α x (cid:105)\nE[X −x | X = x] = k −|α| k +o(1)\nt+1,k k t n2 2 2\nand\n(cid:104) (cid:105) 2\nE (X −x )2 | X = x = [x (1−x )+o(1)],\nt+1,k k t n2 k k\nas n → ∞. The above suggests that a rescaling of order O(n2) is needed to have a\nnon-trivial limit, as we will formally show below. In particular, let {Z t } t∈R + be the\ncontinuous-time process with generator\n1 (cid:88) K ∂ 1 (cid:88) K ∂2\n(17) Ag(x) = (α −|α|x ) g(x)+ x (δ −x ) g(x),\nk k k kk′ k′\n2 ∂x 2 ∂x ∂x\nk k k′\nk=1 k,k′=1\nforeveryg : ∆ → Rtwicedifferentiableandwherex = (x ,...,x ). Suchprocess\nK−1 1 K\nexists (Ethier, 1976) and is called Wright-Fisher with mutation rates given by α. In\nparticular, {Z t } t∈R + is a diffusion taking values in ∆ K−1 whose stationary density is\nexactly π(x) = Dir(x | α). The next theorem shows that, choosing h(n) = n2/2, the\ncontinuous-time rescaling of {X t } t∈N converges to {Z t } t∈R + .\n16\n(n) (n)\nTheorem 4.1. Let {Z t } t∈R + such that Z t = X ⌈n2 t⌉ , where {X t } t∈N is the Markov\n2\nchain in (16) with kernel P MG and invariant distribution π as in (15). Let {Z t } t∈R +\n(n)\nbe a diffusion with generator as in (17). Then if Z → Z weakly as n → ∞, we have\n0 0\n(n)\nthat {Z t } t∈R + → {Z t } t∈R + weakly as n → ∞, according to the Skorokhod topology.\nRemark 4.2. The proof relies on convergence of generators, which is a standard tech-\nnique when dealing with sequences of stochastic processes: we refer to (Ethier and\nKurtz, 1986, Chapter 4) for details. While this approach is common in the MCMC\nliterature (see e.g. Gelman et al. (1997); Roberts and Rosenthal (2001b) and related\nworks), we are not aware of applications of it to mixture model contexts. On the\ncontrary, the Wright-Fisher process often arises as the scaling limit of models for pop-\nulations subjected to genetic drift and mutation (Ethier and Kurtz, 1986; Etheridge,\n2011). Connections between sampling schemes and diffusions in population genetics\nhave been also explored in other context, especially for sequential Monte Carlo tech-\nniques (Koskela et al., 2020; Brown et al., 2021). □\nRemark 4.3. Theorem 4.1 suggests that O(n2) iterations are needed for P to\nMG\nconverge. This is coherent with Khare and Zhou (2009, Prop.14.10.1) where, albeit\nmotivated by a different problem, the authors show that, when targeting the prior\ndistribution π(c) in (15), the second largest eigenvalue of P is\nMG\n|α|\n1− .\nn(n+|α|−1)\nThis implies that the so-called relaxation time of P scales as O(n2) as n → ∞,\nMG\nwhich means that O(n2) iterations are required to mix; see e.g. Levin and Peres (2017,\nThm.12.5) for more details on relaxation times. □\nIn order to see why an O(n2) convergence is slower than desired, consider for\nexample the case K = 2. Then {X t,1 } t∈N is a Markov chain on {0,1/n,...,1} and\nthus P requires n2 iterations to sample from a distribution on a state space with\nMG\ncardinality n. Moreover, {X t,1 } t∈N can be seen as a random walk with transition\nprobabilities\n(cid:18) (cid:19)\n1 α +nx\nP X = x + | X = x = (1−x ) 1 1 ≈ x (1−x )\nt+1,1 1 t,1 1 1 1 1\nn α +α +n−1\n1 2\nand\n(cid:18) (cid:19)\n1 α +n(1−x )\nP X = x − | X = x = x 2 1 ≈ x (1−x ),\nt+1,1 1 t,1 1 1 1 1\nn α +α +n−1\n1 2\nwhennislarge. Thustheprobabilityofgoingupanddownisalmostthesame, leading\nto the observed random-walk behaviour. This is reminiscent of classical examples\nstudied in the non-reversible MCMC literature (Diaconis et al., 2000), where a faster\nalgorithm is devised by considering a lifted version of the standard random walk.\n17\n4.2 Non-reversible sampler P\nNR\nConsider now a Markov chain {c(t),v(t)} t∈N with kernel P NR and invariant distribution\n(cid:8) (cid:9)\n(15). Define X as in (16) and V = V as\nt t t,k,k′ (k,k′)∈[K]2\n\n0 if k = k′\n\n\nV = v (t) if k < k′\nt,k,k′ k,k′\n −v (t) if k > k′.\nk′,k\nThis means that V = +1 implies that we are proposing from cluster k′ to k, for\nt,k′,k\nevery pair (k,k′). This allows for a simpler statement in the theorem to follow.\nBy exchangeability arguments as above, it is simple to see that {(X t ,V t )} t∈N is\nde-initializing for {c(t),v(t)} t∈N and thus it has the same convergence properties. In\nthe proof of Theorem 4.4 we show that\n \nE[X t+1,k −x k | X t = x,V t = v] = 1  (cid:88) x k +x k′ − (cid:88) x k +x k′ +o(1),\nn K −1 K −1\nk′:v k′,k =+1 k′:v k′,k =−1\nwhich suggest that rescaling time by n is sufficient for a non-trivial limit. A technical\nissueisthat,whenX = 0forsomekthenoneofthevelocitiesjumpsdeterministically\nt,k\nto V = +1 with k′ ̸= k. To avoid complications related to such boundary effects,\nt,k′,k\nwe study the scaling of the process in the set\n(cid:26) (cid:27)\n1\nE ×V = x ∈ ∆ | x > for every k\n×{−1,0,+1}[K]2\n,\nM K−1 k\nM\nwith M > 0 arbitrarily large but fixed.\n(cid:110) (cid:111) (cid:110) (cid:111)\n(M) (M) (M)\nLet Z = Z ,Z beapiecewisedeterministicMarkovprocess\nt t∈R\n+\n1,t 2,t t∈R\n+\n(Davis,1984)onE ×V definedasfollows. ConsiderainhomogeneousPoissonprocess\nM\nΛ with rate\nt\n(cid:16) (M) (cid:17) 1 (cid:88) (cid:16) (M) (M) (cid:17) (cid:16) (M) (M) (M) (cid:17)\n(18) λ Z = Z +Z β Z ,Z ,Z +2ξ,\nt 2(K −1) 1,t,k 1,t,k′ 1,t,k 1,t,k′ 2,t,k,k′\nk̸=k′\nwhere\n(cid:26) (cid:27)\nα −1 1−α\nβ(x ,x ,v ) = max 0,\nk−\n+\nk+\nk k′ k′,k\nx x\nk− k+\nwith k = k′ and k = k if v = +1 and viceversa if v = −1. In between events,\n− + k′,k k′,k\n18\n(M)\n{Z t } t∈R + evolves deterministically as\n(19)\n(M)\ndZ (cid:16) (cid:17)\n1,t,k (M)\n= Φ Z\ndt k t\n \n= 1  (cid:88) (cid:16) Z (M) +Z (M) (cid:17) − (cid:88) (cid:16) Z (M) +Z (M) (cid:17) \nK −1  1,t,k 1,t,k′ 1,t,k 1,t,k′ \nk′:Z(M) =+1 k′:Z(M) =−1\n2,t,k′,k 2,t,k′,k\nand\n(M)\ndZ\n2,t,k′,k\n= 0,\ndt\nwith (k′,k) ∈ [K]2. The system of differential equations in (19) admits a unique\nsolution by linearity in its arguments. Instead, at each event of Λ , say at τ > 0, a pair\nt\n(k,k′) ∈ [K]2 is selected with probability\n(M) (M)\nZ +Z (cid:104) (cid:16) (cid:17) (cid:105)\nq(k,k′) ∝ 1,t,k 1,t,k′ β Z (M) ,Z (M) ,Z (M) +2ξ 1(k ̸= k′)\n2(K −1) 1,τ−,k 1,τ−,k′ 2,τ−,k′,k\nand then the process jumps as follows:\n(M) (M) (M) (M)\n(20) Z = −Z and Z = −Z ,\n2,τ,k′,k 2,τ−,k′,k 2,τ,k,k′ 2,τ−,k,k′\n(cid:110) (cid:111)\n(M)\nwhere τ denotes the the left-limit at τ. It follows that Z is a continuous-\n− t\nt∈R\n+\ntime process with generator\n(21)\n \nK\nB(M)g(z) = 1(z ∈ E ) (cid:88) Φ (z) ∂ g(z)+λ(z) (cid:88) q(k,k′) (cid:2) g(z )−g(z) (cid:3)  ,\n1 M k\n∂z\n(k,k′)\n 1,k \nk=1 k̸=k′\nfor every g : E ×V → R twice continuously differentiable in the first argument,\nM\nwhere z(k,k′) ∈ E ×V is equal to z except for\nM\n(k,k′) (k,k′)\nz = −z = −z .\n2,k,k′ 2,k′,k 2,k,k′\nSuch a process exists for every M > 0 since the rates λ(z) are bounded (Davis, 1984).\n(cid:110) (cid:111)\n(M)\nWe can think of Z as a process with an absorbing boundary, which remains\nt\nt∈R\n+\n(M)\nconstant as soon as Z ≤ 1/M for some k.\n1,t,k\n(cid:110) (cid:111)\n(M) (M)\nAnalogously, define X\nt\n,V\nt\nas a modification of {X\nt\n,V\nt\n} t∈N, which re-\nt∈N\n(M)\nmains constant as soon as X ≤ 1/M for some k. The next theorem shows that,\nt,k\n(cid:110) (cid:111)\n(M) (M)\nchoosing h(n) = n, the continuous-time rescaling of X ,V converges to\nt t\nt∈N\n(cid:110) (cid:111)\n(M)\nZ .\nt\nt∈R\n+\n19\n(cid:110) (cid:111) (cid:16) (cid:17)\n(M,n) (M,n) (M) (M)\nTheorem 4.4. Fix M > 0 and let Z such that Z = X ,V ,\nt t∈R\n+\nt ⌈nt⌉ ⌈nt⌉\nwhere {X t ,V t } t∈N is a Markov chain with operator P NR and invariant distribution\n(cid:110) (cid:111)\n(M)\nas in (11), with π in (15). Let Z be a piecewise deterministic Markov\nt\nt∈R\n+\n(M,n) (M)\nprocess with generator (21). Then if Z → Z weakly as n → ∞, we have that\n0 0\n(cid:110) (cid:111) (cid:110) (cid:111)\n(M,n) (M)\nZ → Z weakly as n → ∞, according to the Skorokhod topology.\nt t\nt∈R\n+\nt∈R\n+\nRemark 4.5. Looking at the process only in the interior of the simplex is inspired by\nother works on diffusion approximations, see e.g. Barton et al. (2004) where they use\na similar technique to deal with explosive behaviour in the boundary. If α > 1 for\nk\nevery K, we could proceed as in Theorem 4.2 therein to show that the boundary is\nnever reached and thus the limit can be extended to the whole space. □\nTheorem 4.4 suggests that the overall computational cost of Algorithm 6 is O(n)\nand, combined with Theorem 4.1, this suggest an O(n) speed-up relative to P in\nMG\nthe prior case. In Section 6 we will show empirically that large improvements are also\npresent in more realistic and interesting settings where the likelihood is informative.\n5 A variant of P\nNR\nThe kernels P and P sample a new pair (k,k′) at every iteration. While this is\nR NR\nnatural and allows for direct theoretical comparisons with P (see Theorem 3.1), an\nMG\nalternative in the non-reversible case is to keep the same value of (k,k′) for multiple\niterations. We thus define the following, non-reversible and π˜-invariant kernel\n∞\n(cid:88) 2 (cid:88)\n(22) Q = q (t)P˜t ,\nNR K(K −1) mc(k,k′) k,k′\n(k,k′)∈K t=1\nwith m (k,k′) = (n (c) + n (c))/s for some fixed s ∈ (0,1) and q (t) being the\nc k k′ m\nprobability mass function of a geometric random variable with parameter 1/m. The\nalgorithm picks a couple (k,k′) uniformly at random and then takes a random number\nof steps of the lifted kernel P˜ , with average number of steps proportional to the total\nkk′\nnumber of points in the two clusters, i.e. n (c)+n (c). The associated pseudo-code\nk k′\nis presented in Algorithm 8. Reasoning as in Lemma 2.3 it is easy to see that Q is\nNR\nAlgorithm 8 Modified non-reversible sampler (c′,v′) ∼ Q ((c,v),·)\nNR\nSample (k,k′) ∼ Unif(K)\nSample t ∼ Geom(s/(n (c)+n (c))) for some fixed s ∈ (0,1)\nk k′\nSample (c′,v′) ∼ P ˜t ((c,v),·)\nk,k′\nπ˜-invariant and uniformly ergodic, as stated in the next lemma.\n20\nLemma 5.1. For any probability distribution π on [K]n, the Markov kernel Q de-\nNR\nfined in Algorithm 8 is π˜-invariant, with π˜ as in (11). Moreover, if π(c) > 0 for every\nc ∈ [K]n, then Q is irreducible, aperiodic and uniformly ergodic.\nNR\nThe distinction with the main algorithm is that P resamples the pair (k,k′) at\nNR\neachiterationwithprobabilityproportionalton (c)+n (c),whileQ keepsthesame\nk k′ NR\n(k,k′)forO(n (c)+n (c))iterationsandthenresamplesthepair(k,k′)uniformlyfrom\nk k′\nK. Indeed we expect P and Q to perform similarly for fixed values of K, but we\nNR NR\nempirically observe that Q tends to yield slower mixing as K increases: see Section\nNR\nA in the Supplementary Material for a simulative comparison in the prior case. This\nmotivated us to focus on P as the main scheme of interest in this paper.\nNR\nRemark 5.2. In the prior case of Section 4, where the invariant distribution is given\nby (15), it is possible to find a corresponding scaling limit for Q . The proof is\nNR\nanalogous to the case of P and we omit it for brevity, just limiting ourselves to\nNR\nidentifying the candidate limit and discussing its implications. Consider a Markov\nchain {(X t ,V t )} t∈N with kernel Q NR . With similar calculations as in Theorem 4.4, the\n(cid:110) (cid:111) (cid:16) (cid:17)\n(M,n) (M,n) (M) (M)\nprocess Z defined as Z = X ,V can be shown to converge\nt t∈R\n+\nt ⌈nt⌉ ⌈nt⌉\nto {Z t } t∈R + with generator\n(cid:26)\n∂ ∂\nC(M)g(z) = 1(z ∈ E ) g(z)− g(z)\n1 M\n∂z ∂z\n1,k+ 1,k−\n(cid:26) (cid:27)\nα −1 1−α\n+max 0,\nk−\n+\nk+\n[g(z ,−z )−g(z)]\n1 2\nz z\n1,k− 1,k+\n(cid:27)\ns (cid:88) z 1,k +z 1,k′ (cid:104) (cid:16) (k,k′) (cid:17) (cid:105)\n+ g z ,z −g(z) ,\nz +z 2(K −1) 1 2\n1,k− 2,k+\nk̸=k′\nwith k = k′ and k = k if z = +1 and viceversa if z = −1. Moreover\n− + 2,k,k′ 2,k,k′\nz (k,k′) is the vector with z = −z = +1 and zero otherwise. Interestingly, C(M)\n2 2,k,k′ 2,k′,k\ncoincides with the generator of the so-called Coordinate Sampler, introduced in Wu\nand Robert (2020), with target distribution Dir(α). □\n5.1 The random projection sampler being approximated\nThe main feature of Q is that, after sampling a pair (k,k′) ∈ K, the operator P˜ is\nNR k,k′\napplied for a random number of iterations. If s → 0 the latter diverges almost surely,\nmeaning that after selecting the pair the sampler will behave as P˜t with t → ∞. By\nk,k′\ndefinition of P˜t and ergodicity, this converges to the kernel Π that updates the\nk,k′ k,k′\nsub-partition of points in clusters k and k′ conditional on the rest, i.e.\n \n(23) lim P k t ,k′ (c,c′) = Π˜ k,k′ (c,c′) ∝  (cid:89) 1(cid:0) c i = c′ i (cid:1) π(c′) c,c′ ∈ [K]n.\nt→∞\ni:ci∈/{k,k′}\n21\nNote that Π is a projection kernel, i.e. Π2 = Π . Analogously, again as s → 0,\nk,k′ k,k′ k,k′\nQ converges to the random projection kernel defined as\nNR\n2 (cid:88)\n(24) P (c,c′) = Π (c,c′) c,c′ ∈ [K]n,\nRP k,k′\nK(K −1)\n(k,k′)∈K\nwhose structure resembles the one of a random-scan Gibbs Sampler that updates the\nsub-partition of two randomly chosen pairs of clusters given the configuration of the\nother clusters. In this perspective, Q can be interpreted as a Metropolis-within-\nNR\nGibbs sampler approximating P .\nRP\nRemark 5.3. In the prior case, as n → ∞, we expect P in turn to approximate a\nRP\nGibbs sampler on the (K −1)-dimensional simplex, which at every iteration updates\ntwo coordinates chosen at random. In the special case of α = (1,...,1), the latter has\nbeen studied in Smith (2014) and shown to require O(Klog(K)) iterations for mixing.\n□\n6 Simulations\n6.1 Prior case\nFirst of all we consider the prior case, where f = f and the target distribution is given\nθ\nby (15). We let K = 3, n = 1000 and we run Algorithms 1 and 6 for 300 independent\nruns, first with α = (1,1,1) and then with α = (0.1,0.1,0.1). Initial configurations are\n(0) i.i.d.\nindependentlygenerated, sothatc ∼ Unif([K]). Foreachrunwestorethevalueof\ni\nthe chains after T = 100×n iterations and plot the corresponding proportion of labels\nof the first two components, i.e. (n (c(T))/n,n (c(T))/n) in Figure 2. If the chains had\n1 2\nreached convergence by then, these should be 300 independent samples approximately\nfollowing a Dirichlet-Multinomial distribution with parameters α (since n is large, this\nis visually close to drawing samples directly from a Dir(α) distribution).\nFrom the results in Figure 2, it is clear that the non-reversible scheme (second\ncolumn) leads to faster convergence: this is particularly manifest in the second row\n(corresponding to α = (0.1,0.1,0.1)), where the mass should be concentrated around\nthe borders of the simplex. Indeed, both chains associated to P remain stuck close\nMG\nto the initial configuration, where the proportion within each group is close to 1/3.\nThis is also clear from the last column of Figure 2, which shows that the marginal\ndistribution of P (in black) converges to the stationary one after fewer iterations.\nNR\n22\n0.0 0.2 0.4 0.6 0.8 1.0\n0.1\n8.0\n6.0\n4.0\n2.0\n0.0\nMarginal\n0.0 0.2 0.4 0.6 0.8 1.0\n0.1\n8.0\n6.0\n4.0\n2.0\n0.0\nNon reversible\n0.1\n8.0\n6.0\n4.0\n2.0\n0.0\nMarginal distribution of the chains\n1 10 30 50 70 90\n0.0 0.2 0.4 0.6 0.8 1.0\n0.1\n8.0\n6.0\n4.0\n2.0\n0.0\nMarginal\n0.0 0.2 0.4 0.6 0.8 1.0\n0.1\n8.0\n6.0\n4.0\n2.0\n0.0\nNon reversible\n0.1\n8.0\n6.0\n4.0\n2.0\n0.0\nMarginal distribution of the chains\n1 10 30 50 70 90\nFigure 2: Left and center column: plot of the proportions of the first two components in the last\nof100iterations(afterathinningofsizen)over300independentrunsforP (left)and\nMG\nP (center). Right column: plot of the marginal distribution of the proportion of the\nNR\nfirst component at every 10 iterations (after thinning) for P (gray) and P (black).\nMG NR\nThe first and second rows refer to α = (1,1,1) and α = (0.1,0.1,0.1), respectively. The\ntarget distribution is given in (15).\n6.2 Posterior case\nWe now consider model (1) with Y = Θ = R, K = 3,\n(25) f (y) = N(y | θ,σ2), p (θ) = N(θ | µ ,σ2).\nθ 0 0 0\nand hyperparameters set to µ = 0 and σ2 = σ2 = 1. We then generate 300 indepen-\n0 0\ndent data sets of size n = 1000, each generated from the model as follows:\ni.i.d.\n1. Sample w ∼ Dirichlet(α) and θ ∼ p for k = 1,...,K.\nk 0\n2. Sample Y\ni.\n∼\ni.d. (cid:80)K\nw f (y) for i = 1,...,n.\ni k=1 k θ k\nFor each dataset we target the associated posterior using P and P . As before\nMG NR\n(0) i.i.d.\nwe initialize each chain uniformly, i.e. c ∼ Unif([K]), and store its value after\ni\nT = 100 × n iterations. Since the data are generated from the (Bayesian) model,\nthe resulting distribution of the proportions within each component should be close\nto the prior one, i.e. again a Dirichlet-multinomial with parameter α. This test for\nconvergence, discussed for example in Geweke (2004), relies on the fact that sampling\nfrom the prior distribution is equivalent to sampling from the posterior, given data\ngenerated according to the marginal distribution induced by the model.\n23\nThe resulting samples are displayed in Figure 3, with the same structure as in\nFigure 2. Again the non-reversible scheme is much closer to the correct distribution,\nwhileP remainsclosetotheinitialconfiguration. Indeed,theresultsareremarkably\nMG\nclose to the ones presented in Section 6.1: this suggests that the behaviour observed in\nthepriorcaseisinformativealsooftheactualbehaviourobservedintheposteriorcase,\nat least in this setting. In Section B of the Supplementary Material similar results are\nshown for the Poisson kernel.\n0.0 0.2 0.4 0.6 0.8 1.0\n0.1\n8.0\n6.0\n4.0\n2.0\n0.0\nMarginal\n0.0 0.2 0.4 0.6 0.8 1.0\n0.1\n8.0\n6.0\n4.0\n2.0\n0.0\nNon reversible\n0.1\n8.0\n6.0\n4.0\n2.0\n0.0\nMarginal distribution of the chains\n1 10 30 50 70 90\n0.0 0.2 0.4 0.6 0.8 1.0\n0.1\n8.0\n6.0\n4.0\n2.0\n0.0\nMarginal\n0.0 0.2 0.4 0.6 0.8 1.0\n0.1\n8.0\n6.0\n4.0\n2.0\n0.0\nNon reversible\n0.1\n8.0\n6.0\n4.0\n2.0\n0.0\nMarginal distribution of the chains\n1 10 30 50 70 90\nFigure 3: Left and center column: plot of the proportions of the first two components in the last\nof 100 iterations (after a thinning of size n) over 300 independent runs for P (left)\nMG\nand P (center). Right column: plot of the marginal distribution of the proportion\nNR\nof the first component at every 10 iterations (after thinning) for P (gray) and P\nMG NR\n(black). The rows refer to α = 1 and α = 0.1 and the target distribution is given by the\nposterior of model (1), with f (y) as in (25), µ = 0 and σ2 = σ2 = 1.\nθ 0 0\n6.3 A high dimensional example\nWe now consider a higher dimensional version of the previous setting, where\n(26) f (y) = N(y | θ,σ2I ), p (θ) = N(θ | µ ,σ2I ),\nθ p p 0 0 0 p\nwherenowy ∈ Rp andθ ∈ Rp withp ≥ 1. Werescalethelikelihoodvarianceasσ2 = cp\np\nwhich guarantees that\np\n1 (cid:88)\n(θ −θ )2 = O(1).\nσ2 1j 2j\np j=1\n24\nIn other words, we ask that the distance across components, rescaled by the variance,\ndoes not diverge as p grows: this implies that some overlap between components is\nretained and that the problem is statistically non-trivial (see e.g. Chandra et al. (2023)\nfor more discussion of Bayesian mixture models with high-dimensional data).\nWe generate 500 independent samples of size n = 1000 from model (26) with\np = 18, K = 5, µ = 0, σ2 = 0.5, c = 2 and α = (4,1,...,1). The data are generated\n0 0\nas explained in the previous section and we run both P and P , retaining only the\nMG NR\nlast iteration for every chain: the initialization is again uniform at random.\nInFigure4weplotthehistogramsofthelastiterationfortheproportionassociated\nto the first component of P and P for 500 independent runs. Comparing the\nMG NR\nlatter with the prior density, given by a Dirichlet-Multinomial with parameters (4,4)\n(approximatelyBeta(4,4)), itisevidentthatthenon-reversibleschemeisabletoforget\nthe initialization while the reversible is not. Indeed, as also clear from the right plot\nof Figure 4, the marginal distribution of P significantly underestimates the size of\nMG\nthe first cluster after T = 100×n iterations.\nMarginal\n0.0 0.2 0.4 0.6 0.8 1.0\n5.2\n0.2\n5.1\n0.1\n5.0\n0.0\nNon reversible\n0.0 0.2 0.4 0.6 0.8 1.0\n0.2\n5.1\n0.1\n5.0\n0.0\n0.1\n8.0\n6.0\n4.0\n2.0\n0.0\nMarginal distribution of the chains\n1 10 30 50 70 90\nFigure 4: Left and center column: histogram of the proportion of the first component in the last\nof100iterations(afterathinningofsizen)over500independentrunsforP (left)and\nMG\nP (center). The gray line corresponds to the density of a Beta(4,4). Right column:\nNR\nplot of the marginal distribution of the chains at every 10 iterations (after thinning) for\nP (gray) and P (black). The target distribution is given by the posterior of model\nMG NR\n(1), with f (y) as in (26), p = 18, K = 5, µ = 0, σ2 = 0.5, c = 2 and α = (4,1,...,1).\nθ 0 0\n6.4 Overfitted setting\nFinally, we consider an overfitted case, previously discussed in Section 2.2.1. We take\na one-dimensional Gaussian kernel as in (25) and take α = α for all k ∈ {1,...,K}.\nk\nIn this setting, using the notation of Section 2.2.1, Rousseau and Mengersen (2011,\nThm.1) implies that\n1. if α > 1/2, then more than K∗ atoms have non-negligible mass, i.e. multiple\natoms are associated to the same “true” component,\n25\n2. if α ≤ 1/2, then the posterior concentrates on configurations with exactly K∗\ncomponents, up to n−1/2 posterior mass.\nWe take K = 2 and K∗ = 1, with Y i. ∼ i.d. N(y | 2,1) and n = 1000. The first two\ni\ncolumns of Figure 5 plot the histogram of the proportion of the first component after\nT = 100×niterations(andthinningofsizen)forα = 1(toprow)andα = 0.1(bottom\nrow). The two algorithms are initialized according to the “incorrect” scenario, i.e. all\nthe observations in the first component in the first row and uniformly at random\nin the bottom row. The figure illustrates that only P is able to reach the high\nNR\nprobability region: this means that, despite its locality, the persistence of P allows\nNR\nfor significantly faster traveling across the space. On the contrary, P remain stuck\nMG\nin the initial configuration (which yields a similar likelihood) for both the scenarios.\nThis is also confirmed by the right column, which depicts the marginal distribution of\nthe chains: after few iterations, the distribution associated to P stabilizes and yields\nNR\nthe correct behaviour.\nMarginal\n0.0 0.2 0.4 0.6 0.8 1.0\n8\n6\n4\n2\n0\nNon reversible\n0.0 0.2 0.4 0.6 0.8 1.0\n2.1\n0.1\n8.0\n6.0\n4.0\n2.0\n0.0\n0.1\n8.0\n6.0\n4.0\n2.0\n0.0\nMarginal distribution of the chains\n1 10 30 50 70 90\nMarginal\n0.0 0.2 0.4 0.6 0.8 1.0\n5.1\n0.1\n5.0\n0.0\nNon reversible\n0.0 0.2 0.4 0.6 0.8 1.0\n5\n4\n3\n2\n1\n0\n0.1\n8.0\n6.0\n4.0\n2.0\n0.0\nMarginal distribution of the chains\n1 10 30 50 70 90\nFigure 5: Left and center column: histogram of the proportion of the first component in the last\nof100iterations(afterathinningofsizen)over300independentrunsforP (left)and\nMG\nP (center). Right column: plot of the marginal distribution of the proportion of the\nNR\nfirst component at every 10 iterations (after thinning) for P (gray) and P (black).\nMG NR\nFirst row: α = 3/2 and initialization uniformly at random. Second row: α = 0.1 and\n(0)\nc = 1 for every i. The target distribution is given by the posterior of model (1), with\ni\nY i. ∼ i.d. N(y | 2,1) and f (y) as in (25), µ = 0 and σ2 = σ2 = 1.\ni θ 0 0\n26\n7 Discussion\nIn this work we introduced a novel, simple and effective non-reversible MCMC sampler\nfor mixture models, which enjoys three favourable features: (i) it is a simple modifi-\ncation of the original marginal scheme of Algorithm 1, (ii) its performance cannot be\nworse than the reversible chain by more than a factor of four (Theorem 3.1), (iii) it is\nshown to drastically speed-up convergence in various scenarios of interest.\nBoththetheoryandmethodologypresentedinthisworkcouldbeextendedinmany\ninteresting directions, and we now discuss some of those, starting from algorithmic and\nmethodological ones. First, in the current formulation of Algorithm 6, the pair of\nclusters to update and the observation to move are selected with probabilities that\ndo not depend on the actual observations within the clusters (except for their sizes).\nA natural extension would be to consider informed proposal distributions, as in e.g.\nZanella(2020);PowerandGoldman(2019);GagnonandMaire(2024b): weexpectthis\ntoleadtoapotentiallylargedecreaseofthenumberofiterationsneededformixing,but\nwith an additional cost per iteration. We leave the discussion and exploration of this\ntradeofftofuturework. Second,onecouldalsoconsiderschemesthatadaptivelymodify\nthe probabilities p (k,k′) in (9) in order to propose more often clusters with higher\nc\noverlap (or higher acceptance rates of proposed swaps), thus reducing computational\nwaste associated to frequently proposing swaps across clusters with little overlap.\nFrom the theoretical point of view, it would be highly valuable to extend the scal-\ning limit analysis to the posterior case. While interesting, we expect this to require\nworking with measure-valued processes and, more crucially, to require significant work\nin combining the MCMC analysis part with currently available results about posterior\nasymptotic behaviour of mixture models (Nguyen, 2013; Guha et al., 2021).\nIn this paper we stick to the case of a fixed number of components. A natural\ngeneralizationregardsthecaseofK randomorinfinite(e.g.Dirichletprocessmixtures,\nsee Ferguson (1973); Lo (1984)). This presents additional technical difficulties that we\nleave to future work: for example, since no upper bound is available on the number\nof components, it would be more natural to define a Markov chain over the full space\nof partitions of [n]. Finally, mixture models are an instance of the broader framework\nof latent class models (Goodman, 1974) and it would be interesting to explore the\neffectiveness of the methodology developed here in such broader settings.\nReferences\nAndrieu, C. and S. Livingstone (2021). Peskun–Tierney ordering for Markovian Monte\nCarlo: beyond the reversible scenario. The Annals of Statistics 49(4), 1958–1981.\nAscolani, F., H. Lavenant, and G. Zanella (2024). Entropy contraction of the Gibbs\nsampler under log-concavity. arXiv preprint arXiv:2410.00858.\n27\nBarton, N. H., A. M. Etheridge, and A. K. Sturm (2004). Coalescence in a random\nbackground. Annals of Applied Probability 14(3), 754 – 785.\nBierkens, J. (2016). Non-reversible Metropolis-Hastings. Statistics and Comput-\ning 26(6), 1213–1228.\nBrown, S., P. A. Jenkins, A. M. Johansen, and J. Koskela (2021). Simple conditions\nfor convergence of sequential Monte Carlo genealogies with applications. Electronic\nJournla of Probability 26, 1 – 22.\nCeleux, G., M. Hurn, and C. P. Robert (2000). Computational and inferential dif-\nficulties with mixture posterior distributions. Journal of the American Statistical\nAssociation 95(451), 957–970.\nChandra, N. K., A. Canale, and D. B. Dunson (2023). Escaping the curse of di-\nmensionality in Bayesian model-based clustering. Journal of Machine Learning Re-\nsearch 24(144), 1–42.\nChen, T.-L. and C.-R. Hwang (2013). Accelerating reversible Markov chains. Statistics\n& Probability Letters 83(9), 1956–1962.\nDavis, M. H. (1984). Piecewise-deterministic Markov processes: A general class of\nnon-diffusion stochastic models. Journal of the Royal Statistical Society: Series B\n(Methodological) 46(3), 353–376.\nDempster, A. P., N. M. Laird, and D. B. Rubin (1977). Maximum likelihood from\nincompletedataviatheEMalgorithm. Journal of the royal statistical society: series\nB (methodological) 39(1), 1–22.\nDiaconis, P., S. Holmes, and R. M. Neal (2000). Analysis of a nonreversible Markov\nchain sampler. Annals of Applied Probability, 726–752.\nDiebolt, J. and C. P. Robert (1994). Estimation of finite mixture distributions through\nBayesian sampling. Journal of the Royal Statistical Society: Series B (Methodologi-\ncal) 56(2), 363–375.\nEtheridge, A. (2011). Some Mathematical Models from Population Genetics: E´cole\nD’E´t´e de Probabilit´es de Saint-Flour XXXIX-2009. Springer.\nEthier, S. N. (1976). A class of degenerate diffusion processes occurring in population\ngenetics. Communications on Pure and Applied Mathematics 29(5), 483–493.\nEthier, S. N. and T. G. Kurtz (1986). Markov processes: characterization and conver-\ngence. John Wiley & Sons.\nFaulkner, M. F. and S. Livingstone (2024). Sampling algorithms in statistical physics:\na guide for statistics and machine learning. Statistical Science 39(1), 137–164.\nFearnhead, P., J. Bierkens, M. Pollock, and G. O. Roberts (2018). Piecewise determin-\nistic Markov processes for continuous-time Monte Carlo. Statistical Science 33(3),\n386–412.\nFerguson, T. S. (1973). A Bayesian analysis of some nonparametric problems. Ann.\nStat. 1(2), 209–230.\nFru¨hwirth-Schnatter, S. (2006). Finite mixture and Markov switching models, Volume\n425. Springer.\n28\nGagnon, P. and F. Maire (2024a). An asymptotic Peskun ordering and its application\nto lifted samplers. Bernoulli 30(3), 2301–2325.\nGagnon, P. and F. Maire (2024b). Theoretical guarantees for lifted samplers. arXiv\npreprint arXiv:2405.15952.\nGaitonde, J. and E. Mossel (2024). Comparison Theorems for the Mixing Times of\nSystematic and Random Scan Dynamics. arXiv preprint arXiv:2410.11136.\nGelman, A., W. R. Gilks, and G. O. Roberts (1997). Weak convergence and opti-\nmal scaling of random walk Metropolis algorithms. The Annals of applied probabil-\nity 7(1), 110–120.\nGeweke, J. (2004). Getting it right: Joint distribution tests of posterior simulators.\nJournal of the American Statistical Association 99(467), 799–804.\nGoodman, L. A. (1974). Exploratory latent structure analysis using both identifiable\nand unidentifiable models. Biometrika 61(2), 215–231.\nGuha, A., N. Ho, and X. Nguyen (2021). On posterior contraction of parameters and\ninterpretability in Bayesian mixture modeling. Bernoulli 27(4), 2159–2188.\nHe, B. D., C. M. De Sa, I. Mitliagkas, and C. R´e (2016). Scan order in Gibbs sampling:\nModelsinwhichitmattersandboundsonhowmuch.Advancesinneuralinformation\nprocessing systems 29.\nHobert, J. P., V. Roy, and C. P. Robert (2011). Improving the Convergence Proper-\nties of the Data Augmentation Algorithm with an Application to Bayesian Mixture\nModeling. Statistical Science 26(3), 332–351.\nKhare, K. and H. Zhou (2009). Rates of convergence of some multivariate Markov\nchains with polynomial eigenfunctions. Ann. App. Probab. 19, 737–777.\nKoskela, J., P. A. Jenkins, A. M. Johansen, and D. Span´o (2020). Asymptotic genealo-\ngies of interacting particle systems with an application to sequential Monte Carlo.\nThe Annals of Statistics 1, 560 – 583.\nLee,K.,J.-M.Marin,K.Mengersen,andC.Robert(2009). Bayesianinferenceonfinite\nmixturesofdistributions. InPerspectives in mathematical sciences I: Probability and\nstatistics, pp. 165–202. World Scientific.\nLevin, D. A. and Y. Peres (2017). Markov chains and mixing times, Volume 107.\nAmerican Mathematical Soc.\nLiu, J. S. (1994). The collapsed gibbs sampler in bayesian computations with appli-\ncations to a gene regulation problem. Journal of the American Statistical Associa-\ntion 89(427), 958–966.\nLo, A.Y.(1984). OnaclassofBayesiannonparametricestimates: I.densityestimates.\nAnn. Stat. 12(1), 351–357.\nMarin,J.-M.,K.Mengersen,andC.P.Robert(2005).Bayesianmodellingandinference\non mixtures of distributions. Handbook of statistics 25, 459–507.\nMcLachlan, G. J., S. X. Lee, and S. I. Rathnayake (2019). Finite mixture models.\nAnnual review of statistics and its application 6(1), 355–378.\nNguyen,X.(2013). Convergenceoflatentmixingmeasuresinfiniteandinfinitemixture\n29\nmodels. Annals of Statistics 41(1), 370–400.\nNishimura, A., D. B. Dunson, and J. Lu (2020). Discontinuous Hamiltonian Monte\nCarlo for discrete parameters and discontinuous likelihoods. Biometrika 107(2),\n365–380.\nPower, S. and J. V. Goldman (2019). Accelerated sampling on discrete spaces with\nnon-reversible Markov processes. arXiv preprint arXiv:1912.04681.\nRobert, C. P. (2007). The Bayesian choice: from decision-theoretic foundations to\ncomputational implementation, Volume 2. Springer.\nRoberts, G. O. and J. S. Rosenthal (2001a). Markov chains and de-initializing pro-\ncesses. Scandinavian Journal of Statistics 28(3), 489–504.\nRoberts, G. O. and J. S. Rosenthal (2001b). Optimal scaling for various Metropolis-\nHastings algorithms. Statistical Science 16(4), 351–367.\nRoberts, G. O. and J. S. Rosenthal (2004). General state space Markov chains and\nMCMC algorithms. Probability Surveys 1, 20–71.\nRoberts, G. O. and J. S. Rosenthal (2015). Surprising convergence properties of some\nsimple Gibbs samplers under various scans. International Journal of Statistics and\nProbability 5(1), 51–60.\nRousseau, J. and K. Mengersen (2011). Asymptotic behaviour of the posterior distri-\nbution in overfitted mixture models. Journal of the Royal Statistical Society Series\nB: Statistical Methodology 73(5), 689–710.\nSchauer, M. and M. Wien¨obst (2024). Causal structure learning with momentum:\nSampling distributions over Markov Equivalence Classes. Proceedings of Machine\nLearning Research 246, 382–400.\nSmith, A. (2014). A Gibbs sampler on the n-simplex. Annals of Applied Probabil-\nity 24(1), 114–130.\nStephens, M. (2000). Dealing with label switching in mixture models. Journal of the\nRoyal Statistical Society: Series B (Statistical Methodology) 62(4), 795–809.\nTierney, L. (1998). A note on Metropolis-Hastings kernels for general state spaces.\nAnnals of Applied probability, 1–9.\nVucelja, M. (2016). Lifting—a nonreversible Markov chain Monte Carlo algorithm.\nAmerican Journal of Physics 84(12), 958–968.\nWu, C. and C. P. Robert (2020). Coordinate sampler: a non-reversible Gibbs-like\nMCMC sampler. Statistics and Computing 30(3), 721–730.\nYang,Y.,M.J.Wainwright,andM.I.Jordan(2016). Onthecomputationalcomplexity\nof high-dimensional Bayesian variable selection. The Annals of Statistics 44(6),\n2497–2532.\nZanella, G. (2020). Informed proposals for local MCMC in discrete spaces. Journal of\nthe American Statistical Association 115(530), 852–865.\nZhou, Q. and H. Chang (2023). Complexity analysis of Bayesian learning of high-\ndimensional DAG models and their equivalence classes. The Annals of Statis-\ntics 51(3), 1058–1085.\n30\nZhou, Q., J. Yang, D. Vats, G. O. Roberts, and J. S. Rosenthal (2022). Dimension-\nfree mixing for high-dimensional Bayesian variable selection. Journal of the Royal\nStatistical Society: Series B (Statistical Methodology) 84(5), 1751–1784.\nA Comparison between P and Q\nNR NR\nInthissectionweconsiderthesamesettingofSection6.1,wherethetargetdistribution\nis given in (15). We run both P and Q (with s = 1) for 300 independent trials\nNR NR\nwith initialization uniformly at random. We consider n = 1000, K = 3,10,20,50 and\nα = (1,1/(K −1),...,1/(K −1), so that the marginal distribution on the proportion\nof the first component is a Dirichlet-Multinomial with parameters (1,1) and thus close\nto a uniform distribution on (0,1).\nFigure 6 plots the corresponding empirical marginal distribution obtained by the\nchains (black corresponds to P and gray to Q ). Even if both schemes correctly\nNR NR\nreachstationarity,itseemsthatQ yieldsslowermixingasK increases: thisispartic-\nNR\nularlyevidentinthecaseK = 50, whereQ remainsclosetotheinitialconfiguration.\nNR\nB Simulations for the Poisson kernel\nHere we consider model (1) with K = 3 and\n(27) f (y) = Po(y | θ), p (θ) = Gamma(θ | β ,β ).\nθ 0 1 2\nIt is easy to show that the predictive distribution reads\np(Y = y | Y) = Γ(β 1 + (cid:80)n i=1 Y i +y) (n+β 2 )β1+(cid:80)n i=1 Yi .\nn+1 Γ(β\n1\n+ (cid:80)n\ni=1\nY\ni\n)Γ(y+1)(n+β\n2\n+1)β1+(cid:80)n\ni=1\nYi+y\nWe consider β = β = 1 and we draw 300 independent samples from the model above\n1 2\nwithn = 1000,followingthesameprocedureillustratedinSection6.2. Foreachdataset\nwe run Algorithms 1 and 6, initialized uniformly at random, and we retain only the\nlast iteration.\nThe results of the simulations are similar to the ones of Section 6.2, as shown in\nFigure7: againthenon-reversibleschemeismuchclosertothepriordistribution,while\nP remains close to the initial configuration.\nMG\n31\n0.1\n8.0\n6.0\n4.0\n2.0\n0.0\nMarginal distribution of the chains\n1 10 15 20 25 30 35 40 45 50\n0.1\n8.0\n6.0\n4.0\n2.0\n0.0\nMarginal distribution of the chains\n1 10 15 20 25 30 35 40 45 50\n0.1\n8.0\n6.0\n4.0\n2.0\n0.0\nMarginal distribution of the chains\n1 10 15 20 25 30 35 40 45 50\n0.1\n8.0\n6.0\n4.0\n2.0\n0.0\nMarginal distribution of the chains\n1 10 15 20 25 30 35 40 45 50\nFigure 6: Plots of the marginal distribution of the proportion of the first component for the\nchains associated to P (black) and Q (gray) at every. From top left to bottom\nNR NR\nright, the plots refer to K = 3,10,20,50, where the target distribution is as in (15) with\nα = (1,1/(K −1),...,1/(K −1) and n = 1000.\nC Proofs\nC.1 General results about lifting and mixtures\nIn order to prove results below, especially Theorem 3.1, we first need to generalize\nsome classical results about lifting of Markov chains (see e.g. Chen and Hwang, 2013;\nBierkens, 2016; Andrieu and Livingstone, 2021) to our mixture case, which can be\nseen as a way to construct ‘multi-dimensional’ lifted chains. We will make use of the\nfollowing classical lemma, which for example follows by results in Chen and Hwang\n(2013) as detailed below.\nLemma C.1. Let µ be a probability distribution on a finite space X, P a µ-invariant\nand irreducible Markov transition matrix, P∗ the µ-adjoint of P and K = (P +P∗)/2.\n32\n0.0 0.2 0.4 0.6 0.8 1.0\n0.1\n8.0\n6.0\n4.0\n2.0\n0.0\nMarginal\n0.0 0.2 0.4 0.6 0.8 1.0\n0.1\n8.0\n6.0\n4.0\n2.0\n0.0\nNon reversible\n8.0\n6.0\n4.0\n2.0\n0.0\nMarginal distribution of the chains\n1 10 30 50 70 90\n0.0 0.2 0.4 0.6 0.8 1.0\n0.1\n8.0\n6.0\n4.0\n2.0\n0.0\nMarginal\n0.0 0.2 0.4 0.6 0.8 1.0\n0.1\n8.0\n6.0\n4.0\n2.0\n0.0\nNon reversible\n0.1\n8.0\n6.0\n4.0\n2.0\n0.0\nMarginal distribution of the chains\n1 10 30 50 70 90\nFigure 7: Left and center column: plot of the proportions of the first two components in the last\nof 100 iterations (after a thinning of size n) over 300 independent runs for P (left)\nMG\nand P (center). Right column: plot of the marginal distribution of the proportion\nNR\nof the first component at every 10 iterations (after thinning) for P (gray) and P\nMG NR\n(black). The rows refer to α = 1 and α = 0.1 and the target distribution is given by the\nposterior of model (1), with f (y) as in (27) and β = β = 1.\nθ 1 2\nThen Var(g,P) ≤ Var(g,K) for all g : X → R.\nProof. Consider the decomposition P = K +Q, Q = 1P − 1P∗. By construction, K\n2 2\nis a µ-reversible transition matrix. Moreover, by definition of adjoint we have that Q\nis antisymmetric with respect to µ, which means that µ(x)Q(x,y) = −µ(y)Q(y,x) for\nall x,y ∈ X. Finally, for every x ∈ X we have that\n(cid:88) 1 (cid:88) 1 (cid:88)\nQ(x,y) = P(x,y)− P∗(x,y) = 0\n2 2\ny∈X y∈X y∈X\nand thus each row of Q sums up to zero. Therefore by Lemma 2 in Chen and Hwang\n(2013) we have that Var(g,P) = Var(g,K +Q) ≤ Var(g,K) for all g : X → R.\nC.1.1 Result with general notation\nLetπ beaprobabilitydistributiononafinitespaceC. LetD ∈ N,and(K )\nd,+1 d∈{1,...,D}\nand (K ) be Markov transition kernels on C such that\nd,−1 d∈{1,...,D}\n(28) π(c)K (c,c′) = π(c′)K (c′,c) for all c ̸= c′ and all d = 1,...,D.\nd,+ d,−\n33\nDefine the Markov transition kernel on C\nD\n(29) K (c,c′) = (cid:88) p (d)K (cid:0) c,c′(cid:1) ,\nR c d\nd=1\nwhere K = (K +K )/2 and p are weights such that\n(cid:80)D\np (d) = 1 for all c ∈ C\nd d,+ d,− c d=1 c\nand\n(30) p (d) = p (d) if K (c,c′) > 0.\nc c′ d\nDefine the Markov transition kernel on C ×{−1,1}D\nD\n(cid:88)\n(31) K ((c,v),(c′,v′)) = p (d)(F K F )((c,v),(c′,v′)),\nNR c d lift,d d\nd=1\nwhere F is the flipping operator defined as\nd\n(cid:20) (cid:21)\nF ((c,v),(c′,v′)) = 1(c = c′) (1−α)1(v = v′)+α1(v = v′ ,v′ = −v )\nd −d −d d d\nfor some fixed α ∈ [0,1] and\n(32) K ((c,v),(c′,v′)) = K (cid:0) c,c′(cid:1) Q (v,v′)\nlift,d d,v\nd\nd,c,c′\nwith\n(cid:20) (cid:21)\n(33) Q (v,v′) = 1(v = v′ ) 1(c ̸= c′)1(v = v′)+1(c = c′)1(v = −v′) .\nd,c,c′ −d −d d d d d\nHere α plays the role of a refresh rate. One could also think at the case α = 0 for\nsimplicity, where F becomes the identity operator and can thus be ignored.\nd\nLemma C.2. Under (28)-(33), we have that\n(a) K is π-reversible.\nR\n(b) K is π˜-invariant, with π˜(c,v) = π(c)2−D.\nNR\n(c) Var(g˜,K ) ≤ Var(g,K ) for all g : C ×{−1,+1}D → R and g˜ : C → R such\nNR R\nthat g(c,v) = g˜(c) for all (c,v) ∈ C ×{−1,+1}D.\nProof. Consider first part (a). By (28), for every c ̸= c′ we have\n2π(c)K (c,c′) = π(c)K (c,c′)+π(c)K (c,c′)\nd d,+ d,−\n= π(c′)K (c′,c)+π(c′)K (c′,c) = 2π(c′)K (c′,c).\nd,− d,+ d\n34\nand thus by (29) and (30) we have\nD\n(cid:88)\nπ(c)K (c,c′) = p (d)π(c)K (c,c′)\nR c d\nd=1\nD\n(cid:88)\n= p (d)π(c′)K (c′,c) = π(c′)K (c′,c),\nc′ d d\nd=1\nmeaning that K is π-reversible.\nR\nConsider now point (b). Let (c′,v′) ∈ C × {−1,+1}D. If v = v′, by (32),\nQ (v,v′) = 1(c ̸= c′) and (28) we have\nd,c,c′\n(cid:88) (cid:88)\nπ˜(c,v)K ((c,v),(c′,v′)) = π(c)K (c,c′)Q (v,v′)2−D\nlift,d d,v\nd\nd,c,c′\nc∈C c∈C\n(cid:88)\n= π(c)K (c,c′)2−D\nd,v′\nd\nc̸=c′\n(cid:88) (cid:104) (cid:105)\n= π(c′)K (c′,c)2−D = π˜(c′,v′) 1−K (c′,c′) .\nd,−v′ d,−v′\nd d\nc̸=c′\nSimilarly, if v = v′ and v = −v′, by Q (v,v′) = 1(c = c′) we have that\n−d −d d d d,c,c′\n(cid:88) (cid:88)\nπ˜(c,v)K ((c,v),(c′,v′)) = π(c)K (c,c′)Q (v,v′)2−D\nlift,d d,v\nd\nd,c,c′\nc∈C c∈C\n= π˜(c′)K (c′,c′)2−D = π˜(c′,v′)K (c′,c′).\nd,−v′ d,−v′\nd d\nSumming the two expressions above, and using the fact that K ((c,v),(c′,v′)) = 0\nlift,d\nif v ̸= v′ , we have\n−d −d\n(cid:88)\nπ˜(c,v)K ((c,v),(c′,v′)) = π˜(c′,v′),\nlift,d\nc,v\nwhich implies that K is π˜-invariant. Since F is also trivially π˜-invariant and com-\nlift,d d\nposition of invariant kernels remains invariant, then F K F is π˜-invariant. Finally,\nd lift,d d\nusing (30), we have\nD\n(cid:88) (cid:88)(cid:88)\nπ˜(c,v)K ((c,v),(c′,v′)) = p (d)π˜(c,v)(F K F )((c,v),(c′,v′))\nNR c d lift,d d\nc,v d=1 c,v\nD\n(cid:88) (cid:88)\n= p (d) π˜(c,v)(F K F )((c,v),(c′,v′))\nc′ d lift,d d\nd=1 c,v\nD 35\n(cid:88)\n= p (d)π˜(c′,v′) = π˜(c′,v′),\nc′\nd=1\nand therefore K is π˜-invariant.\nNR\nConsider now point (c). Let K¯ = (K +K∗ )/2, where K∗ is the π˜-adjoint\nR NR NR NR\nof K . Since F∗ = F , which is easy check by definition of F , we have that\nNR d d d\n(F K F )∗ = F∗K∗ F∗ = F K∗ F , which implies\nd lift,d d d lift,d d d lift,d d\nD\nK∗ ((c,v),(c′,v′)) = (cid:88) p (d) (cid:0) F K∗ F (cid:1) ((c,v),(c′,v′))\nNR c d lift,d d\nd=1\nand thus\nD D\nK¯ ((c,v),(c′,v′)) = 1 (cid:88) p (d)(F K F )((c,v),(c′,v′))+ 1 (cid:88) p (d) (cid:0) F K∗ F (cid:1) ((c,v),(c′,v′))\nR 2 c d lift,d d 2 c d lift,d d\nd=1 d=1\nD\n= (cid:88) p (d) (cid:0) F K¯ F (cid:1) ((c,v),(c′,v′))\nc d NR,d d\nd=1\nwith K¯ := 1K + 1K∗ . By (28) we have that for c′ ̸= c\nNR,d 2 lift,d 2 lift,d\nπ˜(c′,v′)\nK∗ ((c,v),(c′,v′)) = K ((c′,v′),(c,v))\nlift,d π˜(c,v) lift,d\n=\nπ(c′)\nK (cid:0) c′,c (cid:1) Q (v′,v)\nπ(c) d,v d ′ d,c′,c\n= K (cid:0) c,c′(cid:1) Q (v′,v) = K (cid:0) c,c′(cid:1) Q (v,v′),\nd,−v d ′ d,c′,c d,−v d d,c,c′\nwhere we used the definition of Q (v′,v). For c′ = c we have that\nd,c′,c\nK∗ ((c,v),(c,v′)) = K ((c,v′),(c,v))\nlift,d lift,d\n= K (c,c)Q (v′,v) = K (c,c)Q (v,v′)\nd,v d ′ d,c,c d,−v d d,c,c′\nwhere we used that Q (v′,v) > 0 implies v′ = −v . Thus\nd,c,c d d\nK¯ ((c,v),(c′,v′)) = 1 K (cid:0) c,c′(cid:1) Q (v,v′)+ 1 K (cid:0) c,c′(cid:1) Q (v,v′)\nNR,d\n2\nd,v\nd\nd,c,c′\n2\nd,−v\nd\nd,c,c′\n(cid:20) (cid:21)\n= 1 K (cid:0) c,c′(cid:1) + 1 K (cid:0) c,c′(cid:1) Q (v,v′)\nd,+ d,− d,c,c′\n2 2\n= K (c,c′)Q (v,v′).\nd d,c,c′\nLet now g : C ×{−1,+1}D → R and g˜ : C → R such that g(c,v) = g˜(c). Then, since\nF leaves the first coordinate invariate and K does not depend on v, we have that\nd d\n(cid:0) F K¯ F g (cid:1) (c,v) = (cid:88)(cid:0) F K¯ F (cid:1) ((c,v),(c′,v′))g˜(c′)\nd NR,d d d NR,d d\nc′,v′\n(cid:88)\n= K (c,c′)g˜(c′) = K g˜(c),\nd d\nc′ 36\nwhich implies\n(cid:88)\nK¯ g(c,v) = K¯ ((c,v),(c′,v′))g(c′,v′) = K g˜(c).\nNR NR R\nc′,v′\nBy simple induction then K¯t g(c,v) = Kt g˜(c) for every t. It thus follows that\nNR R\nVar(g,K¯ ) = Var(g˜,K ). Point (c) then follows from Var(g,K ) ≤ Var(g,K¯ ),\nR R NR R\nwhich is a consequence of Lemma C.1.\nC.2 Proof of Lemma 2.1\nProof. Reversibility follows by Lemma C.2 (point (a)), with K = P and (k,k′) ∈ K\nR R\nin place of d ∈ [D]. The only delicate condition to verify is given by (30), which\nfollows since P (c,c′) > 0 implies that n (c)+n (c) = n (c′)+n (c′) and therefore\nk,k′ k k′ k k′\np (k,k′) = p (k,k′).\nc c′\nSince π(c) > 0 for every c ∈ [K]n, we have π(c = k | c ) > 0 for every c ∈\ni −i −i\n[K]n−1. Combining this with the fact that p (k,k′) > 0 for every (k,k′) ∈ K such\nc\nthat n (c)+n (c) > 0, we get that for every pair c ̸= c′ ∈ [K]n there exists a T ∈ N\nk k′\nand a sequence c = c(0),c(1),...,c(T) = c′ such that P (cid:0) c(t−1),c(t)(cid:1) > 0 for every\nR\nt = 1,...,T −1. Thus, P is irreducible. It is also easy to see that P is aperiodic.\nNR R\nUniform ergodicity then follows from Levin and Peres (2017, Theorem 4.9).\nC.3 Proof of Lemma 2.2\nProof. Fix (k,k′) ∈ K and let (k ,k ) be the pair sampled in the first two lines of\n1 2\nAlgorithm 4. Then a draw from the latter will have (k,k′) as realization if and only if\n(k ,k ) = (k,k′) or (k ,k ) = (k′,k). By construction\n1 2 1 2\nn (c) n (c)\nP(k = k,k = k′) = k , P(k = k′,k = k) = k′ ,\n1 2 1 2\n(K −1)n (K −1)n\nand thus p (k,k′) = P(k = k,k = k′)+P(k = k′,k = k), as desired.\nc 1 2 1 2\nC.4 Proof of Lemma 2.3\nProof. Invariance follows by Lemma C.2 (point (b)), with K = P and (k,k′) ∈ K\nNR NR\nin place of d ∈ [D]. The condition (30) is satisfied as shown in the proof of Lemma 2.1.\nConsider then irreducibility. For ease of notation, we use the notation X = [K]n ×K\nand x = (c,v) ∈ X. If π(c) > 0, this implies that π(c = k | c ) > 0 for every\ni −i\nc ∈ [K]n−1. Combining this with the fact that p (k,k′) > 0 for every (k,k′) ∈ K\n−i c\nsuch that n (c) + n (c) > 0, we get that for every pair x ̸= x′ ∈ X there exists a\nk k′\nT ∈ N and a sequence x = x(0),x(1),...,x(T) = x′ such that P (cid:0) x(t−1),x(t)(cid:1) > 0 for\nNR\nevery t = 1,...,T −1. Thus, P is irreducible. Moreover, if ξ > 0 it is immediate to\nNR\n37\ndeduce that P is aperiodic. Uniform ergodicity then follows from Levin and Peres\nNR\n(2017, Theorem 4.9).\nC.5 Proof of Theorem 3.1\nProof of Theorem 3.1. The first inequality Var(g,P ) ≤ Var(g,P ) follows by point\nNR R\n(c) of Lemma C.2, with K = P and K = P .\nNR NR R R\nIn order to prove the other inequality in (14) it suffices to show that\n1\n(34) P (c,c′) ≥ P (c,c′), c ̸= c′ ∈ [K]n,\nR MG\nc(K)\nby, e.g., Theorem 2 in Zanella (2020).\nIn order to prove (34), fix c and c′ such that c = (c ,k) and c′ = (c ,k′) with\n−i −i\ni ∈ [n] and (k,k′) ∈ K. Indeed for every other pair (c,c′) such that c ̸= c′ we have that\nP (c,c′) = P (c,c′) = 0. By definition of P and P we have\nR MG MG R\n1\nP (c,c′) = π(c = k′ | c ).\nMG i −i\nn\nand\n1 n +n (cid:26) n π(c = k′ | c ) (cid:27)\nP (c,c′) = k k′ min 1, k i −i ,\nR\n2n (K −1)n n +1 π(c = k | c )\nk k′ i −i\nwhere n = n (c) for every j ∈ [K] and n ≥ 1 by definition of c. Thus\nj j k\n1 (cid:26) n +n n +n π(c = k′ | c ) (cid:27)\nP (c,c′) = min k k′ , k k′ i −i\nR\n2(K −1)n n n +1 π(c = k | c )\nk k′ i −i\n1 (cid:26) π(c = k′ | c ) (cid:27)\ni −i\n≥ min 1,\n2(K −1)n π(c = k | c )\ni −i\nπ(c = k′ | c ) (cid:26) 1 1 (cid:27)\ni −i\n= min ,\n2(K −1)n π(c = k′ | c ) π(c = k | c )\ni −i i −i\n1 π(c = k′ | c ) 1\n≥ i −i = P (c,c′),\nMG\n2(K −1) n 2(K −1)\nwhich is exactly (34).\nC.6 Proof of Proposition 3.3\nProof. Let P˜ be the π(c,w,θ)-reversible Markov kernel on [K]n×ΘK×∆ that,\nMG K−1\ngiven (c(t),w(t),θ(t)) generates (c(t+1),w(t+1),θ(t+1)) by\n(cid:16) (cid:17) (cid:16) (cid:17)\nc(t+1) ∼ P c(t),· , (w(t+1),θ(t+1)) ∼ π w,θ | c = c(t) .\nMG\n38\nBy construction, Var(g,P ) = Var(g,P˜ ) for any g that is a function of c alone,\nMG MG\nbecause the marginal process on [K]n induced by P˜ is a Markov chain with kernel\nMG\nP .\nMG\nWe now compare P˜ and P . Let\nMG CD\n(cid:90)\n⟨f,g⟩ = f(x)g(x)π(dx), X = [K]n×ΘK ×∆ ,\nπ K−1\nX\nbe the L2(π) inner product. Then for any g ∈ L2(π) and (c,w,θ) ∼ π we have\n⟨(I −P )g,g⟩\nCD π\nn\n1 (cid:88) 1\n= E[Var(g(c,w,θ) | c ,w,θ)]+ E[Var(g(c,w,θ) | c)]\n−i\nn+1 n+1\ni=1\n(35) ≤ 1 (cid:88) n E[Var(g(c,w,θ) | c )]+ 1 (cid:88) n E[Var(g(c,w,θ) | c −i )]\n−i\nn+1 n+1 n\ni=1 i=1\nn\n1 (cid:88)\n= E[Var(g(c,w,θ) | c )] = ⟨(I −P˜ )g,g⟩ ,\n−i MG π\nn\ni=1\nwhere the middle inequality follows from the fact that\nE[Var(g(c,w,θ) | c)] = E[E[Var(g(c,w,θ) | c) | c ]] ≤ E[Var(g(c,w,θ) | c )],\n−i −i\nfor every i = 1,...,n by the law of total variance. We thus have ⟨(I −P )g,g⟩ ≤\nCD π\n⟨(I − P˜ )g,g⟩ for every g ∈ L2(π), which implies Var(g,P˜ ) ≤ Var(g,P ) for\nMG π MG CD\nall g (see e.g. the proof of Tierney, 1998, Theorem 4). We thus have Var(g,P ) =\nMG\nVar(g,P˜ ) ≤ Var(g,P ) for all g for functions g that depend only on c.\nMG CD\nC.7 Proof of Theorem 4.1\nProof. By (15) for every x ∈ ∆ we have that, as n → ∞,\nK−1\n1−x α +nx x |α|−α +n(1−x )\nE[X −x | X = x] = k k k − k k k\nt+1,k k t\nn |α|+n−1 n |α|+n−1\nα −|α|x 2 (cid:104)α x (cid:105)\nk k k k\n= = −|α| +o(1)\nn(|α|+n−1) n2 2 2\nand\n(cid:104) (cid:105) 1−x α +nx x |α|−α +n(1−x )\nE (X −x )2 | X = x = k k k + k k k\nt+1,k k t n2 |α|+n−1 n2 |α|+n−1\n2\n= [x (1−x )+o(1)]\nn2 k k\n39\nand\nE(cid:2)\n(X −x )\n(cid:0)\nX −x\n(cid:1)\n| X = x\n(cid:3)\n=\n−x k α k′ +nx k′\n+\nx k′ α k +nx k\nt+1,k k t+1,k′ k′ t n2 |α|+n−1 n2 |α|+n−1\n2\n= [−x x +o(1)],\nn2 k k′\n(cid:104) (cid:105)\nand n2E (X −x )3 | X = x = o(1) for k ̸= k′ ∈ [K]. By a second-order Taylor\nt+1,k k t\nexpansion, this means that\nsup |E[g(X ) | X = x]−g(x)−Ag(x)| → 0,\nt−1 t\nx∈∆K+1\nas n → ∞ for every g twice differentiable real-valued function. The result then follows\nby Corollary 8.9 in (Ethier and Kurtz, 1986, Chapter 4).\nC.8 Proof of Theorem 4.4\nProof. Fix z = (x,v) ∈ E ×V. Notice that\nM\n(cid:20) (cid:21)\nE X (M) −x | X (M) = x,V (M) = v\nt+1,k k t t\n \n(cid:18) (cid:19)\n= 1− ξ 1  (cid:88) x k +x k′ α(x,k,k′)− (cid:88) x k +x k′ α(x,k′,k)\nn n K −1 K −1\nk′:v k′,k =+1 k′:v k′,k =−1\n \n− ξ 1  (cid:88) x k +x k′ α(x,k′,k)− (cid:88) x k +x k′ α(x,k,k′),\nnn K −1 K −1\nk′:v k′,k =+1 k′:v k′,k =−1\nwhere\n(cid:26) (cid:18) (cid:19)(cid:18) (cid:19)(cid:27)\nα +nx nx\nα(x,k,k′) = min 1, k k k′\nnx +1 α +nx −1\nk k′ k′\n(cid:18) (cid:19)\nβ(x ,x ,v ) 1\nk k′ k′,k\n= 1− +o ,\nn n\nfrom which we deduce that\n(cid:20) (cid:21) (cid:18) (cid:19)\nΦ (z) 1\n(36) E X (M) −x | X (M) = x,V (M) = v = k +o .\nt+1,k k t t n n\nSimilarly we get that\n(cid:20) (cid:21) (cid:18) (cid:19)\n(cid:16) (cid:17)(cid:16) (cid:17) 1\n(37) E X (M) −x X (M) −x | X (M) = x,V (M) = v = o ,\nt+1,k k t+1,k′ k′ t t n\n40\nfor every (k,k′) ∈ [K]2. Moreover\n(38)\n(cid:20) (cid:21)\n(cid:16) (cid:17)\nE g x,V (M) −g(x,v) | X (M) = x,V (M) = v\nt+1 t t\n= (cid:88) (cid:2) g(z )−g(z) (cid:3) x k +x k′\n(cid:20)\n(cid:0) 1−α(x,k,k′) (cid:1)\n(cid:18)\n1− ξ\n(cid:19)2\n+α(x,k,k′)\n(cid:18)\n1− ξ\n(cid:19)\nξ\n(k,k′)\n2(K −1) n n n\nk̸=k′\n+ (cid:0) 1−α(x,k′,k) (cid:1)\n(cid:18)\nξ\n(cid:19)2\n+α(x,k′,k) ξ\n(cid:18)\n1− ξ\n(cid:19)(cid:21)\nn n n\n(cid:88) g(z (k,k′) )−g(z) x k +x k′ (cid:2) (cid:3) (cid:18) 1 (cid:19)\n= β(x ,x ,v )+2ξ +o\nk k′ k,k′\nn 2(K −1) n\nk̸=k′\n(cid:18) (cid:19)\n= λ(z) (cid:88) q(k,k′) (cid:2) g(z )−g(z) (cid:3) +o 1 .\nn\n(k,k′)\nn\nk̸=k′\nBy a Taylor expansion we have that\n(cid:104) (cid:105) (cid:104) (cid:105)\nE g(Z (M ) | Z (M) = z −g(z) = E g(x,V (M) ) | Z (M) = z −g(z)\nt+1 t t+1 t\nK (cid:18) (cid:19)\n+ (cid:88) E (cid:104)(cid:16) X (M) −x (cid:17) | Z (M) = z (cid:105) ∂ g(z)+o 1 ,\nt+1,k k t ∂z n\n1,k\nk=1\nthat, combined with (36), (37) and (38), implies\n(cid:12) (cid:104) (cid:105) (cid:12)\nsup (cid:12)E g(Z (M) ) | Z = z −g(z)−Bg(z)(cid:12) → 0,\n(cid:12) t+1 t (cid:12)\nz∈EM×[K]2\nas n → ∞ for every g : ∆ ×[K]2 → R twice continuously differentiable in the\nK−1\nfirst argument. The result then follows by Corollary 8.9 in Ethier and Kurtz (1986,\nChapter 4).\n41\n",
    "tables": [],
    "images": []
  },
  {
    "metadata": {
      "id": "2510.03224v1",
      "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance\n  of Latent Ensembles",
      "authors": [
        "Dong Lao",
        "Yuxiang Zhang",
        "Haniyeh Ehsani Oskouie",
        "Yangchao Wu",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "summary": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.",
      "published": "2025-10-03T17:57:25Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03224v1"
    },
    "text": "Preprintversion. Underreview.\nTEST-TIME DEFENSE AGAINST ADVERSARIAL AT-\nTACKS VIA STOCHASTIC RESONANCE OF LATENT EN-\nSEMBLES\nDongLao1,2 YuxiangZhang2 HaniyehEhsaniOskouie2 YangchaoWu2\nAlexWong3 StefanoSoatto2\n1LSUVisionLab 2UCLAVisionLab 3YaleVisionLab\n1dong.lao@lsu.edu\n2{zhangbrandon102,haniyehehsani,wuyangchao1997,soatto}@ucla.edu\n3alex.wong@yale.edu\nABSTRACT\nWeproposeatest-timedefensemechanismagainstadversarialattacks: impercep-\ntible image perturbations that significantly alter the predictions of a model. Un-\nlikeexistingmethodsthatrelyonfeaturefilteringorsmoothing,whichcanleadto\ninformationloss,weproposeto“combatnoisewithnoise”byleveragingstochas-\nticresonancetoenhancerobustnesswhileminimizinginformationloss. Ourap-\nproachintroducessmalltranslationalperturbationstotheinputimage,alignsthe\ntransformedfeatureembeddings,andaggregatesthembeforemappingbacktothe\noriginalreferenceimage. Thiscanbeexpressedinaclosed-formformula,which\ncanbedeployedondiverseexistingnetworkarchitectureswithoutintroducingad-\nditional network modules or fine-tuning for specific attack types. The resulting\nmethod is entirely training-free, architecture-agnostic, and attack-agnostic. Em-\npiricalresultsshowstate-of-the-artrobustnessonimageclassificationand,forthe\nfirsttime,establishagenerictest-timedefensefordensepredictiontasks,includ-\ning stereo matching and optical flow, highlighting the method’s versatility and\npracticality. Specifically,relativetoclean(unperturbed)performance,ourmethod\nrecoversupto68.1%oftheaccuracylossonimageclassification,71.9%onstereo\nmatching,and29.2%onopticalflowundervarioustypesofadversarialattacks.\n1 INTRODUCTION\nMost deep neural networks in use today are deterministic maps from a fixed-size input to a fixed-\nsize feature vector. In auto-regressive Transformer models, that vector encodes the next element\n(token)intheinputsequence. Similarly,inconvolutionalarchitectures,thatvectormayencodethe\ninput data. In either case, the output vector is often highly sensitive to perturbations of the input,\nandonecanintentionallychoosetheseimperceptibleperturbationsadversariallysoastomaximize\nthe change in the output Goodfellow et al. (2014). In some cases, the same perturbation can even\nbe disruptive for a large number of possible inputs Moosavi-Dezfooli et al. (2017), exploiting the\nconvolutedgeometryofthedecisionboundaryimposedbysuchtrainedmodelsTrame`retal.(2017).\nThisspurioussensitivitycouldbeexploitedadversariallytodisrupttheoperationofamodel.\nFrom a classical perspective of signal processing, adversarial perturbations of images appear as\nsmall high-frequency “noise” resembling aliasing artifacts. These are imperceptible since the hu-\nmanvisualsystemeasilydiscountsthemonaccountoftheirpoorfittothe‘ecologicalstatistics’of\nnatural images Gibson (2014). Classical sampling theory prescribes anti-aliasing by low-pass fil-\nteringthedata,removinginformationalongwiththeartifacts. Low-passfilteringconsistsofspatial\naveragingoftheperturbeddatawithrespecttoachosenkernel, typicallyaGaussianoraconstant\n(“pillbox”). Alternatively, one could “denoise” the embeddings by averaging output vectors, also\na lossy operation. The choice of the kernel should match the statistics of the perturbations, which\nsetsupacat-and-mousegamewheretheadversarycaneasilymodifytheperturbationstobypassthe\nanti-aliasingfilter,namelyadaptiveattacksTrameretal.(2020),andthemodelneedstoconstantly\nbe fine-tuned to “anti-alias” new forms of adversarial perturbations. In the context of deep neural\n1\n5202\ntcO\n3\n]VC.sc[\n1v42230.0152:viXra\nPreprintversion. Underreview.\nnetworks, existing defense methods that manipulate feature representations Xie et al. (2019); Bai\netal.(2021);Yanetal.(2021);Kimetal.(2023)fundamentallyadheretothisparadigminprinci-\nple. Despitesubstantialengineeringefforts,thesemethodsremaininherentlyvulnerabletoadaptive\nattacksbecausetheyrelyonpre-definedfilteringstrategiesthatarefixedatinferencetime.\nDesiderata: Tobreakthiscycle,weadvocateamethodtomitigatetheeffectofadversarialpertur-\nbationthat(i)operatesattesttime,withouttheneedtoupdatethemodelweights,and(ii)doesnot\nentail information loss associated with direct or indirect spatial filtering. In addition, it would be\nideal if this method could (iii) be applied to existing network architectures without modifications,\nand(iv)beagnostictothespecifictypeofadversarialperturbation.\nStochastic resonance is a technique that resolves a quantized signal below the quantization level,\nbyquantizingandensemblingperturbedversionsofthesignalBenzietal.(1981). Ithasbeenused\nextensivelyincochlearimplants,wherepowerconstraintslimittheresolutionofthedigitalcircuitry\nStocksetal.(2002). Ithasalsobeenusedto‘super-resolve’VisionTransformerembeddings,where\nentirepatchesareencodedintoavector,whichiscomputedatacoarselysubsampledgridLaoetal.\n(2024). Inthispaper,instead,weuseStochasticResonancefortheoppositepurpose,nottosuper-\nresolvethequantizedsignal, buttoperformlatentensemblingtoremovetheeffectsofadversarial\nperturbationsintheembedding.\nRatherthanaveragingthedata,oraveragingtheirembeddingasinclassicaldenoising,weaverage\ntransformed embeddings in latent space. This averaging is performed over small transformations\nsampled at random or deterministically from the group of planar translations, by computing the\nencodingofthetransformedimage,andthenmappingtheencodingbackthroughthepush-forward\noftheinversetransformation.Thisprocesscanbeexpressedasasingleformulainequation1.Since\nthe embedding is typically computed on a coarse grid, but the transformations are sampled on the\nnative lattice of the image, the resulting embedding is free of spatial averaging artifacts. As with\nother uses of Stochastic Resonance, the effect is seemingly paradoxical as we combat noise with\nnoise: Weapplypurposefulperturbationstoeliminatetheeffectofadversarialperturbations.\nOurmethodcanbethoughtofasmarginalizingthetranslationgroupinlatentspacewithrespectto\nachosenprior,whichistheonlydesignchoiceinourmethod. Wechoosethesimplest,whichisthe\nconstantprior. Thepurposefulperturbationsalterthespatialsampling,andtheimplicitensembling\ninlatentspaceaveragesouttheeffectofsamplingartifacts,thwartingtheeffectofadversarialper-\nturbations. Itisasifweweregivenmultipleimageswithdifferent‘noise’,exceptthatthenoisein\nquestionisnottheadversarialperturbation,butthesplintersofadversarialperturbationsobtainedby\ndifferentspatiallyquantizedversionsoftheperturbedimage,duetothetranslationalperturbations,\nwhicharethenaveragedoutbythelatentensembling.\nOutcomes: Ourmethodfulfillsthedesiderata(i)-(iv)laidoutearlier: (i)Itdoesnotrequiretraining\norfine-tuning;(ii)itminimizesinformationlossbylatentensemblingofperturbedembeddings;(iii)\nitcanbeappliedtodifferentnetworkarchitecturesandtasks,includingnetworksalreadyequipped\nwithdifferentdefensetechniqueslikeadversarialtraining,and(iv)isagnostictothespecificpertur-\nbation. Tomeasuretheeffectivenessofourmethodinmitigatingtheeffectsofadversarialperturba-\ntions, wetestitonthreevastlydifferenttasks, includingimageclassification, andtwootherdense\npredictiontasks: stereomatchingandopticalflow. wherewearethefirsttoshowasignificantand\nconsistentimprovementinrobustnesstovariousadversarialattacks.\nOne could argue that there is still a cat-and-mouse game in our setting, if the adversary knows\nourtechniqueandtailorstheadversarialperturbationstobypassit. Toassessthisrisk,weconduct\n“worst-case”adaptiveteststomeasuretheperformanceofourmethodunderadaptiveattackswhen\ntheattackerknowstheexactdefensestrategy,thustheadversarialperturbationisdesignedtomax-\nimally disrupt the result end-to-end, including our stochastic resonance. Our results show that the\nmethodisresistanttobreakingevenwhentheadversaryoptimizesadaptivelythroughitend-to-end.\n2 RELATED WORK\nTheliteratureonadversarialattackanddefenseisextensive. Wehighlightsomeoftheadvances.\nAdversarial Training as Defense. Adversarial training increases the robustness of the model by\ntrainingitwithadversariallyaugmentedimages. ThepopularattackmethodsusedareFastGradient\n2\nPreprintversion. Underreview.\nNoisy Features\nAttacked Encode𝛷\nImage “Boxer”\n…\n…\nTransformations\n{𝑔}𝑛 … High Fidelity Features\n𝑖 𝑖=1\n+\nStochastic 𝛷 {𝑔 𝑖 − ∗ 1} 𝑖 𝑛 =1 “Panda”\nResonance Encode Upsample\n& Inverse Pooling\nTransformations\nFigure1: Defenseagainstadversarialattacksviastochasticresonance. Neuralnetworksarehighlysensi-\ntivetosmallperturbationsintheinputspace,whichadversarialattacksexploittomanipulatenetworkoutputs.\nConventionaldefensestrategiesprimarilyfocusonfilteringoutunreliablefeaturesordenoisingeitherthein-\nputorthefeatures. Insteadofremovingnoise, weproposeanoveldefensebyintroducingnoise. Basedon\nstochasticresonance,controlledtransformationsareintroducedtotheinput.Featuresarethenaggregatedafter\ninvertingthesetransformations.Theresultingmethodcanbeappliedexclusivelyatinferencetime,requiresno\ntraining,andiscompatiblewithdiversenetworkarchitectures.Notably,itnotonlyimprovesrobustnessagainst\nadversarialattacksbutalsoincreasesthedifficultyofcraftingsuccessfuladversarialexamples,evenwhenthe\nattackerisfullyawareofwhetherandhowstochasticresonanceisbeingused(i.e.adaptiveattacks).\nSignMethod(FGSM)Goodfellowetal.(2014),andProjectedGradientDescent(PGD)Madryetal.\n(2017). ALPKannanetal.(2018)Minimizesthedifferencebetweenthelogitsofpairsofcleanand\nadversariallyaugmentedimages. TRADESZhangetal.(2019)decomposespredictionerrorforad-\nversarialexamplesintonaturalerrorandboundaryerrortoimproveadversarialrobustnessatthecost\nofaccuracy.MARTWangetal.(2019)improvesadversarialrobustnessbyconsideringmisclassified\nnaturalexamplesduringtraining. SubsequentworkCaietal.(2018);Zhangetal.(2020);Wang&\nWang(2022);Jinetal.(2022);Ghiasvandetal.(2024)improvesadversarialrobustnesswithcurricu-\nlumlearningBengioetal.(2009),modelensembling,secondorderstatistics,andgradienttracking.\nOntheotherhand,somemethodslearnrobustfeaturerepresentationthroughamodifiedarchitecture\norfeaturemanipulation. Gallowayetal.(2019);Benzetal.(2021);Wangetal.(2022)investigate\nthe effect of batch normalization on adversarial robustness. Dhillon et al. (2018); Madaan et al.\n(2020) prunes certain activations in the network that are susceptible to adversarial attacks. Xiao\netal.(2019)keepk-featureswiththelargestmagnitudeanddeactivateeverythingelse. Zoranetal.\n(2020)usesanattentionmasktohighlightrobustregionsonthefeature.FeatureDenoising(FD)Xie\netal.(2019)usesclassicaldenoisingtechniquestodeactivateabnormalactivations.Baietal.(2021);\nYan et al. (2021) proposed Channel Activation Suppression (CAS) and Channel-wise Importance-\nbased Feature Selection (CIFS) to deactivate feature channels that are vulnerable to attacks. Kim\netal.(2023)improvestherobustnesswithFeatureSeparationandRecalibration(FSR).Ourmethod\nalsooperatesinfeaturespace,butpurelyduringtesttime. Whilewechoosesomeoftheseworksas\nbaselines,ourmethodworksinconjunctionwithanyaforementionedmethods.\nAdversarialPurificationasDefenseAnotherlineofworkfocusesonpurifyingoraugmentingthe\nimages before they are used as input. Tang & Zhang (2024); Yeh et al. (2024); Tsai et al. (2023)\ntrainanFGSMrobustclassifier, adiffusionmodel, oramaskauto-encoder, respectively, topurify\nadversarial examples. Wang et al. (2021) optimizes both the model and the input to minimize the\nentropyofmodelpredictionstoadapttochangingattacks. Cohen&Giryes(2024)trainsarandom\nforestpredictortoensembleoutputsfromtest-timeaugmentedimages.Theseworksinvolvetraining\na new model or updating the original model, while our method is purely test-time and does not\nrequire any training. Pe´rez et al. (2021) ensembles model output from different augmentations,\nwhichisaspecialcaseofourmethod,astheensembleisperformedsolelyontheoutput,whilewe\ncanensembleatanylayer,whichbothsavescomputationalcostandachieveshigherperformance\nNotably, we recognize that above methods focus solely on classification as a task for adversarial\nattacks. Throughextensiveexperiments,wedemonstratethatourmethodcannotonlyperformwell\nonclassification,butalsoondensepredictiontaskslikeopticalflow,andstereomatching.\nStochastic Resonance (SR) was proposed by Benzi et al. (1981) and first applied in climate dy-\nnamics (Benzi et al., 1982) and later in signal processing (Wellens et al., 2003; Kosko & Mitaim,\n2001;Chenetal.,2007)andacoustics(Shu-Yaoetal.,2016;Wangetal.,2014). Recently,Stochas-\n3\nPreprintversion. Underreview.\nticResonanceTransformer(SRT)Laoetal.(2024)usesSRto“super-resolve”VisionTransformer\n(ViT)embeddings. Inthiswork,weinsteaduseSRtomitigateadversarialperturbations. SinceSR\nhas been developed specifically to address quantization artifacts, it has never before been used to\nmitigateclassesofperturbationsbeyondaliasing. Ournoveluseofthetechniqueleveragesthefact\nthatgrouptransformationsandspatialquantizationpreservethestatisticsofnaturalimages,which\nareheavy-tailed,butdonotpreservethestatisticsofadversarialperturbations.\n3 METHOD\nNotation. Adigital image x ∈ [0, L−1]W×H can bedescribed asa map froma discreteplanar\nlatticeΛ ⊂ R2 withH rowsandW columnstoLdiscretelevels,x : Λ → [0, L−1]; a‘feature’\nor‘embedding’ofanimagexistheoutputofanencoderϕthatmapsittoavectorspacewithK\nchannels,typicallythroughaparametrictrainedmodel:\nϕ:x(cid:55)→ϕ(x)∈RK.\nWerepresentagrouptransformationoftheimagethroughanoperatorg : R2 → R2,whichcanbe\nrestrictedtothelatticeΛthroughpadding,samplingandquantizationattheexpenseofinvertibility:\ng :x(cid:55)→g(x)∈Λ⊂R2.\nFor example, a translation by an integer pixel can be represented by an upper diagonal matrix G,\ng(x)=Gxwithonesabovethediagonal. Thegroupgoperatingonxinducesanoperationonϕvia\n.\ng ϕ(x)=ϕ(g(x)).\n∗\nWecallthecompositionofϕandgtheencodingofthetransformedimage\n.\nψ(x)=ϕ(g(x))=ϕ◦g(x).\nThemainobjectofinterestinourmethodis:\ng−1ψ(x)=g−1◦ϕ◦g(x).\n∗ ∗\nThis is obtained, reading right-to-left, by first transforming the image, then passing it through an\nencoder,andthentransformingbackthefeaturemapthroughthepush-forwardactiong−1.\n∗\nPerturbations. Weconsidertwotypesofperturbations,extraneousandpurposeful. Theextraneous\nonecouldbeanadditiveperturbationtoanimage, x˜ = x+n, designedtomaximallychangethe\nvalueoftheembedding(adversarialperturbation)ϕ(x˜):\nx˜=x+n(x) | n(x)=argmaxd(ϕ(x),ϕ(x˜)), |n|<ϵ\nforsomesmallϵdesignedsotheperturbationis,ideally,imperceptiblebyhumans.\nThe purposeful perturbations are small group actions g , i = 1,...,N, which could be sampled\ni\ndeterministicallyoratrandomaccordingtosomechosendistributiong ∼ P ,eitherwayyielding\ni g\naset{g (x),...,g (x)}. Ourgoalistousethesepurposefulperturbationstocombattheeffectsof\n1 N\nextraneousadversarialperturbations.\nAveraging, smoothing, and stochastic resonance. The resemblance between adversarial pertur-\nbations and aliasing artifacts has motivated the use of anti-aliasing, or smoothing, techniques to\nmitigatethem. Theseconsistofspatialaveragingofthedatapriortocomputingthemapϕ. Ifwe\ncallBσ aneighborhoodofsizeσ >0around(i,j)∈Λ,\nij\nBσ ={(i′,j′)∈Λ|d((i,j),(i′,j′))≤σ}\nij\nthenthesimplestformofsmoothingissimplyaveraginginaneighborhood,\n1 (cid:88)\nx¯ = x\ni,j σ2 i′j′\n(i′,j′)∈Bσ\ni,j\nwhichwewriteintermsoftranslationsg(x )=x withinthesameneighborhoodBσ,\ni,j i+u,j+v\nN\n1 (cid:88)\nx¯= g (x).\nN i\ni=1\n4\nPreprintversion. Underreview.\nFigure 2: Results on CIFAR-10 under varying levels of stochastic resonance. Increasing the stochastic\nresonance level consistently enhances robustness across all settings, yielding clear gains over the baseline\nmethod(FSR).Notably,ourapproachachievessuperiorperformanceevenunderadaptiveadversarialattacks\n(Ours-WorstCase),despitethebaselinebeingevaluatedonlyinthenon-adaptivecase.\nOnecanthenobtainanencodingbysmoothingtheembedding\nN\nϕ¯(x)= 1 (cid:88) ϕ(g (x)).\nN i\ni=1\nThis can be interpreted as marginalizing the translation group with a prior P when computing ϕ.\ng\nNotice that the average can be computed on a coarser lattice Λ˜, but its value still depends on data\ninthefinergridΛ. ClassicalSamplingTheoryteachesthatsmoothingmitigatestheeffectofhigh-\nfrequencyaliasingnatthecostofinformationlossonx.\nStochasticresonancealsomarginalizesthetranslationgroup,butbyaveragingtransformeddatain\nlatentspace:\nN\nϕˆ(x)= 1 (cid:88) g −1◦ϕ◦g (x). (1)\nN i∗ i\ni=1\nMoregeneralgroups,andmoregeneralaveragingkernels,canbeconsideredalthoughwefindthat\nthesimplestcasedescribedherealreadysuffices.\nStochastic resonance is not smoothing, as it averages transformed versions of the image without\nblurringit,thankstotheinversepush-forward. Itisalsonotsuper-resolution,wherefine-granularity\ndetails are hallucinated based on side information or priors, although it does allow resolving fea-\ntures computed on a coarse grid Λ˜ within a finer grid Λ. Stochastic resonance uses the averaging\nof perturbations in latent space to ensemble populations of embeddings, rather than averaging or\ninterpolationofthesameembedding.\nPurposeful Perturbation. The only design choice in the method is the set of purposeful pertur-\nbations. While that can be optimized for performance, we optimize for simplicity, restricting our\nattentiontotranslationbyintegerpixels. Weknowthat,foradversarialperturbations,d(ϕ(x˜),ϕ(x))\nislarge,whered(·)definesthedistancebetweenfeatures. Ideally,forstochasticresonance,wewant\nd(ϕˆ(x˜),ϕˆ(x)) = 0whilekeepingϕˆasinformation-preservingaspossible. ThetheoryofStochas-\nticResonanceshowsthat,ifwesub-sampleasignalfromitsnativegranularityΛtoacoarsergrid\nΛ˜ ⊂ Λ,andchoosethepurposefulperturbationstoactonthefinergridΛ,undercertainconditions\nonecanrecovertheoriginalsignalatthefinergranularityBenzietal.(1981).Inthispaper,wefocus\nontestingwhetherϕˆisinsensitivetoadversarialperturbations. WedosoempiricallyinSect. 4.\n4 EXPERIMENTS\nWhile g can be sampled from any invertible group transformation (e.g., rotation, scaling), we\nimplement stochastic resonance using integer-pixel translations, denoted as {g } = {(x,y)|x ∈\ni\n[−d ,d ],j ∈ [−d ,d ]},followingtheapproachinSRTLaoetal.(2024),whichavoidsinterpo-\nx x y y\nlation artifacts. While the networks’ inherent sensitivity to pixel-level shifts is typically regarded\nas detrimental due to the “flickering problem” Azulay & Weiss (2019); Sundaramoorthi & Wang\n(2019),ourapproach,onthecontrary,leveragesittodefendagainstadversarialperturbations.Given\ntheseperturbations{g },ensemblingcanbeperformedatanychosenlayerofthenetwork. Features\ni\nareaggregatedasdescribedinEq. 1andthenpassedtodownstreamnetworkcomponents.\nWe first validate this approach on image classification (Sect. 4.1) following standard benchmarks,\nandalsoprovideablationstudiesonlevels/layersoflatentensembleandrotationasaugmentation.\n5\nPreprintversion. Underreview.\nMethod Architecture Natural FGSM PGD-20 PGD-100 C&W Ensemble\nAT 85.02 56.21 48.22 46.37 47.38 45.90\n+FD 85.14 56.81 48.54 46.70 47.72 45.82\n+CAS 85.78 55.57 50.42 49.91 53.47 46.46\n+CIFS 79.87 56.53 49.80 48.17 49.89 47.26\nResNet-18\n+FSR 81.46 58.07 52.47 51.02 49.44 48.34\n+TTE 85.25 59.20 53.00 51.65 52.45 50.60\n+Ours 84.93 61.02 56.08 55.17 55.53 53.68\n+Ours-WorstCase 84.93 58.81 53.58 52.39 52.73 50.95\nTRADES 84.92 60.87 56.13 55.16 54.02 53.38\nWideResNet-34\n+Ours 85.03 62.43 58.64 57.87 57.18 56.28\nMART 83.07 60.21 54.14 52.90 49.62 48.95\nResNet-18\n+Ours 82.70 62.62 59.03 58.13 55.51 54.61\nTable 1: Defenseagainstadversarialattacksonclassificationtask(CIFAR-10). Comparedtobaselines\nthatfilterormanipulatefeatures,oursdoesnotmodifynetworkarchitectureorweights.Instead,oursperforms\nanensembleinthefeaturespace.OnCIFAR-10,oursachievesstate-of-the-artrobustnesswithoutrequiringany\nadditionaltraining.Moreover,eveninaworst-caseadaptiveadversarysettingwheretheattackerisfullyaware\nofthedefenseandhowstochasticresonanceisapplied,theeffectivenessofadversarialattacksisstillnotably\nreduced,whilethecomputationalcostforexecutingsuchattacksissignificantlyincreased.\nAtt.Strength(ϵ) 8/255 4/255 2/255 1/255 Att.Strength(ϵ) 8/255 4/255 2/255 1/255\nMetric Top-1Top-5Top-1Top-5Top-1Top-5Top-1Top-5 Metric Top-1Top-5Top-1Top-5Top-1Top-5Top-1Top-5\nNoDefense 4.51 19.5512.2542.1529.7965.0948.0978.13 NoDefense 8.51 26.19 9.45 27.9211.1030.6315.2136.76\nOurs(d=1) 11.6646.2727.8565.8045.9477.6357.4883.43 InitialConv. 16.9134.6617.3635.2818.1236.3019.5938.25\nOurs(d=2) 18.7858.5836.4272.8651.5880.8560.4184.77 Res.Block1 22.4444.9523.3946.0324.8447.6427.5750.80\nOurs(d=3) 25.7765.8842.5276.7554.9482.6462.0885.50 Res.Block2 24.8848.5425.9049.6627.2351.1930.1154.15\nRes.Block3 21.7644.2822.7345.4724.1447.1427.1850.20\nTable 2: ImageNetwithViT-Small. Increasingthe\nlevel of stochastic resonance consistently improves Table 3: Layer-wise ablation on ResNet-50. Ad-\nboth Top-1 and Top-5 accuracy under adversarial at- versarialperturbationsresemblehigh-frequencynoise.\ntacks.Relativetothecleanbaseline(72.9Top-1,92.91 Applyingstochasticresonancethroughshallowlayers\nTop-5),ourmethodrecoversupto55.8%oftheTop-1 issufficienttodefendagainstadversarialattacks,sub-\naccuracylossand68.1%oftheTop-5accuracyloss. stantiallyreducingtheoverallcomputationalcost.\nSubsequently, we defend against adversarial attacks on dense prediction tasks, including stereo\nmatching(Sec.4.2)andopticalflow(Sec.4.3). Thisisachievedgiventhatourmethodisagnostic\ntoattackmechanisms,networkpre-training,andlargelyindependentofarchitecture,requiringonly\nlatentensembling,resultinginapurelytest-time,training-freeapproachwithnoauxiliarymodules.\n4.1 IMAGECLASSIFICATION\nCIFAR-10. WeevaluateourmethodonCIFAR-10Krizhevskyetal.(2009),buildinguponthestan-\ndardandpubliclyavailablecodebaseofFSRKimetal.(2023)andaccompanyingevaluationproto-\ncol. Weapplystochasticresonancetonetworkspre-trainedwithATMadryetal.(2017),TRADES\nZhang et al. (2019), and MART Wang et al. (2019), using publicly released weights without any\nmodification. Ourmethodoperateswiththesemethodspurelyattesttimewithoutanytraining. We\nconductexperimentsonResNet-18Heetal.(2016)andWideResNet-34Zagoruyko&Komodakis\n(2016), depending on the availability of author-released pre-trained weights. In all cases, feature\nensemblingisperformedbeforethefinallinearlayer. Furthermore,weconsideraworst-caseadap-\ntiveadversarysetting,wheretheattackerhasfullknowledgeofthemodelweights,andknowsevery\nstochasticresonancetransformationbyaccessingeverysingleforwardpassanditsgradients.\nFig. 2 shows the results varying different levels of stochastic resonance. Increasing the resonance\nlevel consistently enhances robustness in all attack settings, leading to substantial improvements\noverthebaselinemethod(FSR).Importantly,ourapproachsurpassesthebaselineevenunderadap-\ntiveadversarialattacks. Additionally,wecompareourmethodagainstmultiplebaselines,including\nfeature-level manipulation methods (FD Xie et al. (2019), CAS Bai et al. (2021), CIFS Yan et al.\n(2021))andensemble-basedapproachTTEPe´rezetal.(2021). Theresults,summarizedinTab.1,\ndemonstratethatstochasticresonanceconsistentlyoutperformsallbaselinesacrossdifferentattacks.\nEvenintheworst-caseadaptiveattackscenario,wheretheadversaryaccountsforallstochasticres-\nonanceforwardpasses,themodelremainssignificantlymorerobustthanthebaselinemethods. In\n6\nPreprintversion. Underreview.\nAttackStrength(ϵ) 0.02 0.01 0.005 0.002\nMetric MAE RMSED1-err MAE RMSED1-err MAE RMSED1-err MAE RMSED1-err\nMSGF\nNoDefense 14.83 24.10 97.33 8.49 14.53 90.49 5.05 7.70 74.71 3.01 3.49 38.12\nLatentSmoothing 13.42 22.09 96.61 8.12 13.69 89.25 4.89 7.05 73.01 2.89 3.32 36.25\nOurs(d=1) 10.12 15.81 95.80 6.46 9.92 86.30 4.39 5.93 68.55 2.78 3.18 31.99\nErrorReduced(%) 31.76 34.40 1.57 23.91 31.73 4.63 13.07 22.99 7.58 7.64 8.88 16.08\nOurs(d=2) 9.22 13.88 94.61 6.13 8.87 84.49 4.19 5.43 66.74 2.73 3.12 31.18\nErrorReduced(%) 37.82 42.40 2.79 27.78 38.95 6.63 16.92 29.41 10.66 9.21 10.65 18.21\nDGP\nNoDefense 161.70162.61 99.99 131.66140.55 98.64 63.97 88.55 85.31 6.83 17.03 39.24\nLatentSmoothing 161.79162.69 99.99 131.46140.41 98.57 63.86 88.21 85.39 7.28 17.44 39.81\nOurs(d=1) 107.86125.14 98.29 69.97 84.72 91.79 20.66 42.29 73.21 4.17 8.32 29.09\nErrorReduced(%) 33.30 23.04 1.70 46.86 39.72 6.94 67.70 52.24 14.18 38.95 51.15 25.87\nOurs(d=2) 77.59 100.14 96.14 44.77 66.23 89.24 17.98 32.80 71.09 3.76 6.73 28.44\nErrorReduced(%) 52.01 38.41 3.85 66.02 52.87 9.53 71.89 62.94 16.66 44.99 60.52 27.53\nTable5: StochasticResonanceEnhancesStereoMatchingRobustness.Incorporatingstochasticresonance\nsignificantly reduces prediction errors induced by adversarial attacks across all evaluation metrics, reducing\nerror by up to 71.89% (MAE, when attacked by PGD with ϵ = 0.005). Notably, this defense mechanism\noperatesentirelyattesttimewithoutrequiringanymodelre-training,whichsetsitapartfromexistingmethods.\naddition, stochasticresonanceincreasesattackcomplexityundertheadaptivesettings, makingad-\nversarialnoisegenerationmorechallengingfortheattacker. Asaresult,thecomputationalcostfor\ngenerating adaptive adversarial perturbations increases substantially. For example, with stochastic\nresonance,8xmorewall-clocktimeisrequiredtocreateadversarialexampleswithPGD-100.\nImageNet. We further evaluate our approach on the ImageNet Deng et al. (2009) classification\ndataset using standard segmentation backbones, including ResNet-50 He et al. (2016) and Vision\nTransformerDosovitskiyetal.(2020),withoutadversarialtraining. AsintheCIFARexperiments,\nwevarythelevelofstochasticresonanceandconductablationstudiesbytestingagainstPGDattacks\nofdifferentstrengths. Tab.2reportstheresultsforViT-Small. ConsistentwiththeCIFAR-10find-\nings,increasingtheresonancelevelleadstoconsistentimprovementsinrobustness,asmeasuredby\nbothTop-1andTop-5accuracy. Notably,thevanillaViT-Smallmodelwithoutattackachieves72.9\n(Top-1)and92.91(Top-5), whichmeansourmethodrecoverstheaccuracydropunderadversarial\nattacksbyuptoarelative55.8%(Top-1, whenϵ = 4/255)and68.1%(Top-5, whenϵ = 2/255).\nWefurtherevaluateourmethodonResNet-50andobserveaconsistenttrend,asshowninTab.4.\nWe also explored group transformations other Att.Strength(ϵ) 8/255 4/255 2/255 1/255\nthan translation, e.g. rotations in Tab. 4. For Metric Top-1Top-5Top-1Top-5Top-1Top-5Top-1Top-5\na fair comparison, we use the same number NoDefense 8.51 26.19 9.45 27.9211.1030.6315.2136.76\nOurs(d=1) 18.4040.3619.5442.6521.0243.8624.6647.81\nof augmentations as in the translation experi- w/Rotation 20.0141.3220.8442.3922.1043.8924.7246.89\nments. Rotations behave similarly to transla- Ours(d=2) 20.0142.2221.0243.4522.4445.3225.8048.97\nw/Rotation 18.8638.6719.55 39.5 20.3640.4822.0142.50\ntions at low levels of stochastic resonance, but\nOurs(d=3) 21.1743.5822.0444.7823.4446.5326.5849.73\nperformancedegradesastheresonancelevelin- w/Rotation 15.1532.8915.6133.4616.1734.1917.3335.59\ncreases. We hypothesize that since convolu-\ntionalfiltersareinherentlytranslation-invariant Table4: Stochasticresonanceusingtranslationv.s.\nrotationonResNet-50. Whilerotationsprovidesimi-\nbutnotrotation-invariant,aligningfeaturesun-\nlargainsatlowresonancelevels,performancedegrades\nder different rotations reduces feature qual-\nastheresonancelevelincreases,likelyduetothelack\nity.Moreover,rotationsareapproximately30%\nofrotationalinvarianceinconvolutionalfilters.\nslowerduetointerpolationoverhead.\nSince adversarial perturbations often manifest as high-frequency noise, having a low-pass filter in\nearlylayersmayformaneffectivedefense. Asourmethodappliestoarbitrarilychosenlayers,we\nvarytheterminationlayerofstochasticresonance. AsshowninTab.3,applyingitonlythroughthe\nfirstresidualblockalreadyachievesstrongadversarialrobustness,whileextendingittothesecond\nblock yields the strongest result. This finding is significant: running stochastic resonance through\nshallowlayerscanbesufficientasadefensestrategy,whichreducesoverallcomputationalcost.\n4.2 STEREOMATCHING\nStereopagnosia Wong et al. (2021) first introduced adversarial attacks to stereo matching , yet no\ntest-timemethodhasdemonstratedaneffectivedefense. Theprimarychallengearisesfromthein-\n7\nPreprintversion. Underreview.\ntupnI\ntuptuO\ndekcattA\nsruO+\nPGD, ε=0.003 PGD, ε=0.005 FGSM, ε=0.01 FGSM, ε=0.02\nFigure3:Stereomatchingrobustnessviastochasticresonance.Wepresentvisualresultsonstereomatching\nundervariousadversarialattackscenarios,includingPGDandFGSMatdifferentperturbationlevels.Theseat-\ntackssignificantlydegradethenetwork’spredictions,leadingtosubstantialerrors.Byincorporatingstochastic\nresonance, we demonstrate a significant reduction in prediction errors. This technique holds significant po-\ntentialforimprovingrobustnessinsafety-criticalreal-worldapplications,suchasautonomousdriving,where\nstereovisionmustremainreliableunderdiverseenvironmentalconditionsandadversarialthreats.\nfeasibilityofdataaugmentations,astheyriskalteringthephysicsoftheinput,leadingtoincorrect\nestimation. Incontrast,ourfeature-levelensembleissuitableforthistask,astransformationsintro-\nducedbystochasticresonanceare“undone”inthelatentspace,ensuringthatfeaturesremainaligned\npreciselywiththeoriginalinput. ThisprocessmirrorsAugUndoWuetal.(2024)conceptually.\nWe evaluate our method on the standard benchmark used in Stereopagnosia, derived from\nKITTI Geiger et al. (2012). Experiments are conducted using FGSM and PGD attacks against a\npre-trained PSMNet Chang & Chen (2018). Since no existing test-time defense is available, we\nadoptlatent-spacesmoothingasabaseline. AsshowninTab.5,bothattackscorruptnetworkpre-\ndictions, with PGD proving substantially more effective due to its iterative nature. Nevertheless,\nstochastic resonance consistently improves robustness across attack strengths. In particular, under\nPGDwithϵ=0.005,ourmethodreduceserrorsbyupto71.89%intermsofMAE.Crucially,these\ngainsareachievedentirelyattesttime,withoutadditionaltrainingorpriorknowledgeoftheattack.\nFig.3providesqualitativeresults,featuringdifferentattackstrengthsandmethods. Theadversarial\nperturbationsintroducesignificantdistortions, asindicatedbybrightregionsinthevisualizedpre-\ndictions.Stochasticresonanceeffectivelymitigatesthesedistortions,drasticallyreducingprediction\nerrors. Thisexperimentisparticularlyrelevantforsafety-criticalapplicationssuchasautonomous\ndriving,whereadversarialdisturbancescanarisenotonlyfrommaliciousattacksbutalsofromen-\nvironmentalfactorssuchasadverseweatherconditions,varyingillumination,orsensordegradation.\nWhilesomedefensesZhangetal.(2023);Chengetal.(2021;2022);Bergeretal.(2022)havebeen\nproposedtotrainamorerobustnetworkunderadverseconditions,test-timedefensesremainlargely\nunexplored. Ourmethodisthefirsttoprovideaviablesolutioninthissetting.\n4.3 OPTICALFLOW\nWe further evaluate our method on optical flow, which computes the dense motion field between\ntwo images. The accuracy of optical flow is measured using the End-Point Error (EPE). We note\nthat multiple adversarial attacks exist for optical flow Schrodi et al. (2022); Ranjan et al. (2019);\nSchmalfussetal.(2022). Amongtheseattacks,PGDisstrongerthanpatch-basedattacksasadver-\nsarialpatcheshavelocalizedeffects. Therefore,inourexperiments,weemploytheRAFTTeed&\nDeng (2020) optical flow model and focus on global adversarial perturbations generated by PGD\nandFGSM.WetestourmethodontheDAVISPont-Tusetetal.(2017)datasetunderbothattacks.\nTo defend against adversarial attacks, we apply stochastic resonance to the convolutional feature\nextractor of RAFT. Since the perturbation is applied only at the feature extraction stage, no addi-\ntionaloverheadisintroducedinthecomputationallyintensivematchingmodule.Quantitativeresults\n(Fig.4)showthatincreasingStochasticResonancereducesEPE,whichalignswithourfindingsin\nclassification. AsinFig.5,ourapproacheffectivelyremoveserrorscausedbyadversarialnoise.\n8\nPreprintversion. Underreview.\nPGD FGSM\negamI\nlanigirO\ndekcattA\nsruO\nFigure 5: Optical flow robustness via stochastic resonance. Qualitative results (visualized with a color\nwheel)showthatourmethodsubstantiallymitigatesthedegradationcausedbybothPGDandFGSMattacks.\nThisrobustnessisparticularlyrelevantforvisualperceptionsystemsthatrelyonaccuratemotionestimation.\nWe further compare our method to an alterna-\ntive ensembling approach that aggregates pre-\ndictionsintheoutputspace, conceptuallysim-\nilar to TTE Pe´rez et al. (2021). In this vari-\nant, we apply the same stochastic transforma-\ntions but instead ensemble at the output level\nrather than in the feature space. While this\nmethodprovidesmarginalimprovements,itre-\nmains less effective than our approach. This\nFigure 4: Enhanced optical flow robustness with\nfinding highlights the advantage of having the\nstochastic resonance. Under PGD and FGSM,\nfreedomtochoosefromanystageofthemodel\nstochasticresonancesignificantlyreducesendpointer-\nto perform ensemble. In this particular exper-\nrorinopticalflowestimation.Notably,ourmethodper-\niment, we demonstrate that ensembling solely\nformsensemblinginthelatentfeaturespaceratherthan\nattheimageencodingsub-module,whileleav- the output space, providing greater flexibility. While\ning the rest of the RAFT network unchanged, ensembling in the output space offers minor perfor-\nyields substantial improvements in robustness, mancegains,ourapproachconsistentlyachievessupe-\nthankstotheflexibilityofourmethod. riorrobustnessacrossalllevelsofstochasticresonance.\n5 DISCUSSION AND CONCLUSION\nSpeed. Stochasticresonanceincurslowcomputationaloverheadwhenexecutedinparallel: raising\nthestochasticresonancelevelto3withResNet-50addsonly0.06secondstotheinferencetimeon\nanNVIDIA1080TiGPU.Mostoftheoverheadarisesfromcreatingperturbationsimplementedvia\nPythonloopswithtorchvision;weexpectfurtherspeedupswithefficientCUDAimplementa-\ntions. Even when executed sequentially, the computational overhead is 0.095 seconds. Moreover,\nstrongrobustnesscanbeattainedbyapplyingstochasticresonanceonlytoshallowlayers,offering\nsubstantiallygreaterefficiencythanexistingensemble-baseddefenses(e.g. Pe´rezetal.(2021))that\nrequire multiple passes through the entire network. Moreover, our method is fully plug-and-play.\nIncontrast,attack-specificadversarialtrainingisover6xslowerthanavanillatrainingpipeline. As\nsuch,thecomputationofourmethodiswelljustifiedbyitsrobustnessgainsandtraining-freenature.\nOn-demandscaling. Oneofthekeystrengthsofourapproachisitsflexibility: providingatrade-\noffbetweenrobustnessandcomputationalcost. Weofferatunable“knob”thatallowspractitioners\ntoadjustthelevelofresiliencebasedonavailableresourcesonthefly: whenthesystemhasmore\ncomputational capacity, add a higher level of stochastic resonance, vice versa. Note that, such a\ndesigndoesnotrelyonadditionalcomputation,yetmorecomputationcanbringextraperformance.\nMoreover,ourexperimentsshowthatthemethodgeneralizesacrossawiderangeoftasksandarchi-\ntecturesthatincludeanencoder. Thison-demandscalingmirrorsinference-timescalinginlanguage\nmodels,whereperformancecanbeimprovedwithoutmodifyingtheunderlyingpre-trainedmodel.\n9\nPreprintversion. Underreview.\nLimitations. Despiteitsstrengths,ourmethodhassomelimitations. First,whileweofferparallel\ncomputationasaremedy,thecomputationaloverheadintroducedbystochasticresonancemaynot\nbe negligible for scenarios with memory and power constraints. Also, our current study focuses\non integer-pixel translations. While this choice avoids interpolation artifacts and preserves spatial\nconsistency,moregenerictransformations,includinglearnedtransformations,couldbeexplored.\nConclusion. Inthiswork,wepresentasignal-processingperspectivefordefendingagainstadver-\nsarialattacks,motivatedbytheconnectionbetweenadversarialperturbationsandaliasingartifacts.\nAccordingly,weproposea“combatnoisewithnoise”approachbyintroducingstochasticresonance\nasadefensemechanism.Weformalizetheproblemandimplementstochasticresonanceusingpixel-\nleveltranslationspairedwiththeirinversetransformationinthefeaturespace. Theresultingmethod\nistraining-free,agnostictobothtasksandattacktypes,andindependentofnetworkarchitectures.\nWeevaluateourmethodacrossvarioustasks. Empiricalresultsonimageclassificationdemonstrate\nthat our stochastic resonance approach achieves state-of-the-art robustness against diverse attack\ntypes,offeringaclearadvantageoverfeature-leveldenoisingandfiltering. Evenintheadaptivead-\nversaryscenario,whereanattackerisawareoftheuseofstochasticresonance,ourmethodmaintains\nstrong robustness. Furthermore, we are the first to introduce test-time defense to dense prediction\ntasks. Specifically,weapplythismethodtostereomatchingandopticalflow,achievinguptoa71%\nreduction in prediction error. More importantly, these findings highlight the practical potential of\nstochasticresonanceasauniversaldefenseinreal-worldadversarialscenarios.\n10\nPreprintversion. Underreview.\nREPRODUCIBILITY STATEMENT\nWe provide sufficient technical details in the paper to ensure reproducibility. Specifically, we\ndescribe the augmentations used for stochastic resonance, including augmentations (e.g. transla-\ntion, rotation) and their corresponding inverse transformations, as well as the model architectures,\ndatasets,andthenetworklayerswhereourmethodisapplied. Attacksettingsandevaluationproto-\ncolsaredrawndirectlyfromstandardbenchmarkdatasetsandpubliclyavailablecodebase,ensuring\ncomparabilitywithpriorwork. Allimplementationdetailsnecessarytoreproduceourexperiments,\nincludingparametersandablationsettings,areprovidedinthemainpaperandfurtherexpandedin\ntheAppendix. Ourexperimentscanbereproducedonasingledesktop-levelGPUwithoutrequiring\nlarge-scale computational resources. We will release the complete source code and pre-computed\nadversarialdatauponpublication.\nLLM STATEMENT\nAlltechnicalcontentofthiswork,includingliteraturereview,methodology,experiments,andanal-\nyses,wasdevelopedentirelybytheauthors. LargeLanguageModels(LLMs)wereemployedasa\ntoolforproofreading,withoutcontributingtothescientificortechnicalsubstanceofthemanuscript.\nREFERENCES\nAharonAzulayandYairWeiss. Whydodeepconvolutionalnetworksgeneralizesopoorlytosmall\nimagetransformations? JournalofMachineLearningResearch,20(184):1–25,2019.\nYang Bai, Yuyuan Zeng, Yong Jiang, Shu-Tao Xia, Xingjun Ma, and Yisen Wang. Improving\nadversarialrobustnessviachannel-wiseactivationsuppressing.arXivpreprintarXiv:2103.08307,\n2021.\nYoshua Bengio, Je´roˆme Louradour, Ronan Collobert, and Jason Weston. Curriculum learning. In\nProceedingsofthe26thannualinternationalconferenceonmachinelearning,pp.41–48,2009.\nPhilippBenz,ChaoningZhang,andInSoKweon.Batchnormalizationincreasesadversarialvulner-\nabilityanddecreasesadversarialtransferability:Anon-robustfeatureperspective.InProceedings\noftheIEEE/CVFInternationalConferenceonComputerVision,pp.7818–7827,2021.\nRoberto Benzi, Alfonso Sutera, and Angelo Vulpiani. The mechanism of stochastic resonance.\nJournalofPhysicsA:mathematicalandgeneral,14(11):L453,1981.\nRoberto Benzi, Giorgio Parisi, Alfonso Sutera, and Angelo Vulpiani. Stochastic resonance in cli-\nmaticchange. Tellus,34(1):10–16,1982.\nZachary Berger, Parth Agrawal, Tian Yu Liu, Stefano Soatto, and Alex Wong. Stereoscopic uni-\nversalperturbationsacrossdifferentarchitecturesanddatasets. InProceedingsoftheIEEE/CVF\nConferenceonComputerVisionandPatternRecognition,pp.15180–15190,2022.\nQi-ZhiCai,MinDu,ChangLiu,andDawnSong. Curriculumadversarialtraining. arXivpreprint\narXiv:1805.04807,2018.\nNicholasCarliniandDavidWagner. Towardsevaluatingtherobustnessofneuralnetworks. In2017\nieeesymposiumonsecurityandprivacy(sp),pp.39–57.Ieee,2017.\nJia-Ren Chang and Yong-Sheng Chen. Pyramid stereo matching network. In Proceedings of the\nIEEEconferenceoncomputervisionandpatternrecognition,pp.5410–5418,2018.\nHaoChen,PramodKVarshney,StevenMKay,andJamesHMichels.Theoryofthestochasticreso-\nnanceeffectinsignaldetection: Parti—fixeddetectors. IEEEtransactionsonSignalProcessing,\n55(7):3172–3184,2007.\nKelvinCheng,ChristopherHealey,andTianfuWu.Towardsadversariallyrobustanddomaingener-\nalizablestereomatchingbyrethinkingdnnfeaturebackbones. arXivpreprintarXiv:2108.00335,\n2021.\n11\nPreprintversion. Underreview.\nKelvin Cheng, Tianfu Wu, and Christopher Healey. Revisiting non-parametric matching cost vol-\numesforrobustandgeneralizablestereomatching. AdvancesinNeuralInformationProcessing\nSystems,35:16305–16318,2022.\nGilad Cohen and Raja Giryes. Simple post-training robustness using test time augmentations and\nrandomforest. InProceedingsoftheIEEE/CVFWinterConferenceonApplicationsofComputer\nVision,pp.3996–4006,2024.\nJiaDeng,WeiDong,RichardSocher,Li-JiaLi,KaiLi,andLiFei-Fei. Imagenet: Alarge-scalehi-\nerarchicalimagedatabase. In2009IEEEconferenceoncomputervisionandpatternrecognition,\npp.248–255.Ieee,2009.\nGuneet S Dhillon, Kamyar Azizzadenesheli, Zachary C Lipton, Jeremy Bernstein, Jean Kossaifi,\nAranKhanna,andAnimaAnandkumar. Stochasticactivationpruningforrobustadversarialde-\nfense. arXivpreprintarXiv:1803.01442,2018.\nAlexeyDosovitskiy,LucasBeyer,AlexanderKolesnikov,DirkWeissenborn,XiaohuaZhai,Thomas\nUnterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. An\nimage is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint\narXiv:2010.11929,2020.\nAngusGalloway, AnnaGolubeva, ThomasTanay, MedhatMoussa, andGrahamWTaylor. Batch\nnormalizationisacauseofadversarialvulnerability. arXivpreprintarXiv:1905.02161,2019.\nAndreasGeiger,PhilipLenz,andRaquelUrtasun. Arewereadyforautonomousdriving? thekitti\nvision benchmark suite. In 2012 IEEE conference on computer vision and pattern recognition,\npp.3354–3361.IEEE,2012.\nSajjad Ghiasvand, Amirhossein Reisizadeh, Mahnoosh Alizadeh, and Ramtin Pedarsani. Robust\ndecentralizedlearningwithlocalupdatesandgradienttracking.arXivpreprintarXiv:2405.00965,\n2024.\nJamesJGibson. Theecologicalapproachtovisualperception: classicedition. Psychologypress,\n2014.\nIanJGoodfellow, JonathonShlens, andChristianSzegedy. Explainingandharnessingadversarial\nexamples. arXivpreprintarXiv:1412.6572,2014.\nKaimingHe,XiangyuZhang,ShaoqingRen,andJianSun. Deepresiduallearningforimagerecog-\nnition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp.\n770–778,2016.\nGaojie Jin, Xinping Yi, Wei Huang, Sven Schewe, and Xiaowei Huang. Enhancing adversarial\ntrainingwithsecond-orderstatisticsofweights. InProceedingsoftheIEEE/CVFconferenceon\ncomputervisionandpatternrecognition,pp.15273–15283,2022.\nHarini Kannan, Alexey Kurakin, and Ian Goodfellow. Adversarial logit pairing. arXiv preprint\narXiv:1803.06373,2018.\nWooJaeKim,YoonkiCho,JunsikJung,andSung-EuiYoon. Featureseparationandrecalibration\nforadversarialrobustness. InProceedingsoftheIEEE/CVFconferenceoncomputervisionand\npatternrecognition,pp.8183–8192,2023.\nBart Kosko and Sanya Mitaim. Robust stochastic resonance: Signal detection and adaptation in\nimpulsivenoise. PhysicalreviewE,64(5):051110,2001.\nAlex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images.\n2009.\nAlexeyKurakin,IanJGoodfellow,andSamyBengio. Adversarialexamplesinthephysicalworld.\nInArtificialintelligencesafetyandsecurity,pp.99–112.ChapmanandHall/CRC,2018.\nDongLao,YangchaoWu,TianYuLiu,AlexWong,andStefanoSoatto. Sub-tokenvitembedding\nvia stochastic resonance transformers. In International Conference on Machine Learning, pp.\n25995–26006.PMLR,2024.\n12\nPreprintversion. Underreview.\nBoLuo, YannanLiu, LingxiaoWei, andQiangXu. Towardsimperceptibleandrobustadversarial\nexample attacks against neural networks. In Proceedings of the AAAI conference on artificial\nintelligence,volume32,2018.\nDivyam Madaan, Jinwoo Shin, and Sung Ju Hwang. Adversarial neural pruning with latent vul-\nnerabilitysuppression. InInternationalconferenceonmachinelearning,pp.6575–6585.PMLR,\n2020.\nAleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.\nTowardsdeeplearningmodelsresistanttoadversarialattacks. arXivpreprintarXiv:1706.06083,\n2017.\nSeyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Omar Fawzi, and Pascal Frossard. Universal\nadversarialperturbations. InProceedingsoftheIEEEconferenceoncomputervisionandpattern\nrecognition,pp.1765–1773,2017.\nHaniyehEhsaniOskouie, Mohammad-ShahramMoin, andShohrehKasaei. Attackonsceneflow\nusingpointclouds. In2024IEEE34thInternationalWorkshoponMachineLearningforSignal\nProcessing(MLSP),pp.1–6.IEEE,2024.\nJuanCPe´rez,MotasemAlfarra,GuillaumeJeanneret,LauraRueda,AliThabet,BernardGhanem,\nandPabloArbela´ez. Enhancingadversarialrobustnessviatest-timetransformationensembling.\nInProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision,pp.81–91,2021.\nJordi Pont-Tuset, Federico Perazzi, Sergi Caelles, Pablo Arbela´ez, Alex Sorkine-Hornung, and\nLuc Van Gool. The 2017 davis challenge on video object segmentation. arXiv preprint\narXiv:1704.00675,2017.\nAnurag Ranjan, Joel Janai, Andreas Geiger, and Michael J. Black. Attacking optical flow. In\nProceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), October\n2019.\nJennySchmalfuss, PhilippScholze, andAndre´sBruhn. Aperturbation-constrainedadversarialat-\ntackforevaluatingtherobustnessofopticalflow. InEuropeanConferenceonComputerVision,\npp.183–200.Springer,2022.\nSimonSchrodi, TonmoySaikia, andThomasBrox. Towardsunderstandingadversarialrobustness\nofopticalflownetworks. InProceedingsoftheIEEE/CVFConferenceonComputerVisionand\nPatternRecognition,pp.8916–8924,2022.\nJiShu-Yao,YuanFei,ChenKe-Yu,andChengEn. Applicationofstochasticresonancetechnology\ninunderwateracousticweaksignaldetection. InOCEANS2016-Shanghai,pp.1–5.IEEE,2016.\nNigel G Stocks, D Allingham, and Robert P Morse. The application of suprathreshold stochastic\nresonancetocochlearimplantcoding. Fluctuationandnoiseletters,2(03):L169–L181,2002.\nGanesh Sundaramoorthi and Timothy E Wang. Translation insensitive cnns. arXiv preprint\narXiv:1911.11238,2019.\nLinyuTangandLeiZhang. Robustoverfittingdoesmatter: Test-timeadversarialpurificationwith\nfgsm. InProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition,\npp.24347–24356,2024.\nZacharyTeedandJiaDeng. Raft: Recurrentall-pairsfieldtransformsforopticalflow. InComputer\nVision–ECCV2020:16thEuropeanConference,Glasgow,UK,August23–28,2020,Proceedings,\nPartII16,pp.402–419.Springer,2020.\nFlorianTrame`r, NicolasPapernot, IanGoodfellow, DanBoneh, andPatrickMcDaniel. Thespace\noftransferableadversarialexamples. arXivpreprintarXiv:1704.03453,2017.\nFlorian Tramer, Nicholas Carlini, Wieland Brendel, and Aleksander Madry. On adaptive attacks\ntoadversarialexampledefenses. Advancesinneuralinformationprocessingsystems, 33:1633–\n1645,2020.\n13\nPreprintversion. Underreview.\nYun-YunTsai,Ju-ChinChao,AlbertWen,ZhaoyuanYang,ChengzhiMao,TapanShah,andJunfeng\nYang. Test-time detection and repair of adversarial samples via masked autoencoder. arXiv\npreprintarXiv:2303.12848,2023.\nDequanWang,AnJu,EvanShelhamer,DavidWagner,andTrevorDarrell. Fightinggradientswith\ngradients:Dynamicdefensesagainstadversarialattacks. arXivpreprintarXiv:2105.08714,2021.\nHaotaoWang,AstonZhang,ShuaiZheng,XingjianShi,MuLi,andZhangyangWang. Removing\nbatchnormalizationboostsadversarialtraining. InInternationalConferenceonMachineLearn-\ning,pp.23433–23445.PMLR,2022.\nHongjunWangandYisenWang. Self-ensembleadversarialtrainingforimprovedrobustness. arXiv\npreprintarXiv:2203.09678,2022.\nJun Wang, Qingbo He, and Fanrang Kong. Adaptive multiscale noise tuning stochastic resonance\nforhealthdiagnosisofrollingelementbearings. IEEETransactionsoninstrumentationandmea-\nsurement,64(2):564–577,2014.\nYisen Wang, Difan Zou, Jinfeng Yi, James Bailey, Xingjun Ma, and Quanquan Gu. Improving\nadversarialrobustnessrequiresrevisitingmisclassifiedexamples. InInternationalconferenceon\nlearningrepresentations,2019.\nThomasWellens,VyacheslavShatokhin,andAndreasBuchleitner. Stochasticresonance. Reports\nonprogressinphysics,67(1):45,2003.\nAlexWong,MukundMundhra,andStefanoSoatto. Stereopagnosia: Foolingstereonetworkswith\nadversarialperturbations. InProceedingsoftheAAAIConferenceonArtificialIntelligence,vol-\nume35,pp.2879–2888,2021.\nYangchao Wu, Tian Yu Liu, Hyoungseob Park, Stefano Soatto, Dong Lao, and Alex Wong. Au-\ngundo: Scalingupaugmentationsformonoculardepthcompletionandestimation. InEuropean\nConferenceonComputerVision,pp.274–293.Springer,2024.\nChangXiao,PeilinZhong,andChangxiZheng. Enhancingadversarialdefensebyk-winners-take-\nall. arXivpreprintarXiv:1905.10510,2019.\nCihangXie,YuxinWu,LaurensvanderMaaten,AlanLYuille,andKaimingHe. Featuredenoising\nforimprovingadversarialrobustness. InProceedingsoftheIEEE/CVFconferenceoncomputer\nvisionandpatternrecognition,pp.501–509,2019.\nHanshu Yan, Jingfeng Zhang, Gang Niu, Jiashi Feng, Vincent Tan, and Masashi Sugiyama. Cifs:\nImprovingadversarialrobustnessofcnnsviachannel-wiseimportance-basedfeatureselection.In\nInternationalConferenceonMachineLearning,pp.11693–11703.PMLR,2021.\nCheng-Han Yeh, Kuanchun Yu, and Chun-Shien Lu. Test-time adversarial defense with opposite\nadversarialpathandhighattacktimecost. arXivpreprintarXiv:2410.16805,2024.\nSergey Zagoruyko and Nikos Komodakis. Wide residual networks. arXiv preprint\narXiv:1605.07146,2016.\nHongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El Ghaoui, and Michael Jordan.\nTheoreticallyprincipledtrade-offbetweenrobustnessandaccuracy. InInternationalconference\nonmachinelearning,pp.7472–7482.PMLR,2019.\nHowardZhang,YunhaoBa,EthanYang,VaranMehra,BlakeGella,AkiraSuzuki,ArnoldPfahnl,\nChethan Chinder Chandrappa, Alex Wong, and Achuta Kadambi. Weatherstream: Light trans-\nportautomationofsingleimagedeweathering. InProceedingsoftheIEEE/CVFConferenceon\nComputerVisionandPatternRecognition,pp.13499–13509,2023.\nJingfengZhang,XilieXu,BoHan,GangNiu,LizhenCui,MasashiSugiyama,andMohanKankan-\nhalli. Attacks which do not kill training make adversarial learning stronger. In International\nconferenceonmachinelearning,pp.11278–11287.PMLR,2020.\nDaniel Zoran, Mike Chrzanowski, Po-Sen Huang, Sven Gowal, Alex Mott, and Pushmeet Kohli.\nTowards robust image classification using sequential attention models. In Proceedings of the\nIEEE/CVFconferenceoncomputervisionandpatternrecognition,pp.9483–9492,2020.\n14\nPreprintversion. Underreview.\nA IMPLEMENTATION FOR CLASSIFICATION\nFor our classification experiments, we built our implementation on top of standard network archi-\ntectures, implementing SR on two main architectures derived from the FSR codebase Kim et al.\n(2023):\n• ResNet-18Heetal.(2016): Astandardresidualnetworkwith18layersorganizedinfour\nmainblockswithincreasingchanneldimensions(64,128,256,512).\n• WideResNet-34 Zagoruyko & Komodakis (2016): A wider variant of ResNet with depth\n34andwidthfactor10,resultinginhigherrepresentationalcapacitywiththreemainblocks\nwithchanneldimensionsscaledbythewidthfactor(160,320,640).\nForbotharchitectures,weapplySRatthebottlenecklayer(afterthefinalconvolutionalblock).\nGivenaninputimagebatchx∈Rb×3×h×w(wherebisthebatchsize),ourSRapproachoperatesas\nfollows. First,wecreateasetof(2d +1)×(2d +1)perturbedversionsoftheinputbyapplying\nx y\npixel-leveltranslationswithintherange[−d ,d ]×[−d ,d ]pixels:\nx x y y\nX ={g (X)|i∈[−d ,d ],j ∈[−d ,d ]} (2)\nperturbed i,j y y x x\nwhereg translatestheimageby(i,j)pixels. ThesetransformationsareappliedusingPyTorch’s\ni,j\n“transforms.functional.affine”functionwithtranslationparameterswhilepreservingtheoriginalim-\nageproperties.\nAllimagesareconcatenatedintoonebatchandprocessedthroughthenetworkinparalleluptothe\nbottlenecklayer:\nF =ϕ(X ) (3)\nperturbed\nwhereϕrepresentsthenetworkuptothebottlenecklayer. Thisbatchprocessingapproachsignifi-\ncantlyimprovescomputationalefficiencycomparedtoindividualforwardpasses.\nAfterobtainingfeaturemapsforallperturbedinputs,weaggregatethemtocreateasingleenhanced\nfeaturemap:\n1 (cid:88)\nF = T (F ) (4)\nensembled n −i,−j i,j\ni,j\nwhere T represents the inverse spatial shift operation that realigns the feature map and n the\n−i,−j\nnumberofaugmentations.\nOurimplementationrequires(2d +1)×(2d +1)forwardpassesthroughthenetworkuptothe\nx y\nbottlenecklayer.\nFor evaluation, we tested our approach against standard adversarial attacks (FGSM Goodfellow\net al. (2014), PGD-20 and PGD-100 Madry et al. (2017), and C&W Carlini & Wagner (2017)),\nall bounded within ϵ = 8/255 under ℓ -norm. We also report an Ensemble metric that measures\n∞\nthe worst-case performance across all attacks for each test example, providing a comprehensive\nrobustnessassessment.\nB IMPLEMENTATION FOR STEREO MATCHING\nForourstereomatchingexperiments,webuiltourimplementationontopofstandardstereonetwork\narchitecturestoensureourapproachremainsmodel-agnosticandrequiresnotrainingorfine-tuning.\nWeintegratedSRwithPSMNetChang&Chen(2018),apyramidstereomatchingnetworkwitha\nstackedhourglassarchitecturethatuses3Dconvolutionsonacostvolumeconstructedbyconcate-\nnatingfeatures. WeapplySRatthefeatureextractionstage,beforecostvolumeconstruction,where\nstereocorrespondencesarefirstestablished.\nGivenapairofinputstereoimagesx ,x ∈Rb×3×h×w(wherebisthebatchsize),ourSRapproach\nL R\noperatesasfollows. First,wecreateasetof(2d +1)×(2d +1)perturbedversionsofeachinput\nx y\nimagebyapplyingtranslationswithintherange[−d ,d ]×[−d ,d ]pixels:\nx x y y\nX ={g (x )|i∈[−d ,d ],j ∈[−d ,d ]} (5)\nL,perturbed i,j L y y x x\n15\nPreprintversion. Underreview.\nX ={g (x )|i∈[−d ,d ],j ∈[−d ,d ]}. (6)\nR,perturbed i,j R y y x x\nAll images are concatenated into batches and processed through the feature extraction component\nofthenetwork:\nF =ϕ(X ) (7)\nL L,perturbed\nF =ϕ(X ) (8)\nR R,perturbed\nwhereϕrepresentsthefeatureextractioncomponentofthestereonetwork. Thisbatchprocessing\napproachsignificantlyimprovescomputationalefficiencycomparedtoindividualforwardpasses.\nAfterobtainingfeaturemapsforallperturbedinputs,weaggregatethemtocreateasingleenhanced\nfeaturemap.\nOurimplementationrequires(2d +1)×(2d +1)forwardpassesthroughthefeatureextraction\nx y\ncomponentofthenetworkforeachstereoimage.\nForevaluation,wetestedourapproachagainstadversarialattacksgeneratedusingFGSMGoodfel-\nlowetal.(2014)andI-FGSMKurakinetal.(2018)(aspecialcaseofPGD),boundedwithinvarious\nϵvalues({0.002,0.005,0.01,0.02})underℓ -norm. Wemeasuredperformanceusingthreestan-\n∞\ndardstereomatchingmetrics: MeanAbsoluteError(MAE),RootMeanSquareError(RMSE),and\nD1-error(percentageofpixelswithdisparityerrorgreaterthan3pixelsor5%ofthegroundtruth)\nLuoetal.(2018).\nC DETAILS ABOUT ATTACK ON OPTICAL FLOW\nTo find an adversarial attack for optical flow estimated by a given neural network f, we utilize\na similar approach to Oskouie et al. (2024) that aims to find a perturbation δ for given frames\nF and F , maximizing the discrepancy between predicted and ground-truth optical flow OF. If\n1 2\ntheground-truthopticalflowisunavailable, weusethepredictedopticalflowfromtheunattacked\nframeasoursurrogateground-truth. Ourmethodappliesδtothefirstinputframe,thenusesadeep\nneural network to estimate optical flow from the perturbed frames. The objective is to maximize\nthe average end-point error (EPE) between the predicted and ground-truth optical flow, calculated\nasthemeanEuclideandistancebetweencorresponding2Dflowvectors. Inotherwords,theϵ-norm\nboundedadversaryδforoptical-flowiscalculatedbyoptimizingthefollowing\n(cid:0) (cid:1)\nmax EPE OF,f(F +δ,F ) . (9)\n1 2\nδ:∥δ∥≤ϵ\nOne l -bounded adversary A for the aforementioned optimization problem is Fast Gradient Sign\n∞\nMethod(FGSM)Goodfellowetal.(2014)whichcanbeobtainedby\nL=EPE(OF,f(F ,F )),\n1 2\n(cid:0) (cid:1)\nA=F +ϵ·sign ∇ L . (10)\n1 F1\nProjected gradient descent (PGD) Madry et al. (2017) represents an enhanced and more complex\nversion of FGSM. This attack method generates adversarial examples through an iterative process\nandtheformulationforthisattackisasfollowing\nF(t+1) =Π (cid:0) F(t)+α·sign(∇ L) (cid:1) . (11)\n1 F1+S 1 F1\nNotethatinPGD,sincetheperturbationsareconsideredtobetoominimaltosignificantlyalterthe\nflowdynamics,theground-truthopticalflowisnotupdatedbyintermediateperturbationsappliedto\ntheinputdata.\nForourexperimentalsetup,wechosetosetthenormvalueϵat 10 . Furthermore,weconfiguredthe\n256\nPGDalgorithmtorunfor10iterations. Thestepsizeαwasdeterminedbydividing2.5·ϵbythe\ntotalnumberofiterations,ensuringabalancedprogressionthroughouttheoptimizationprocess.\nD ADDITIONAL VISUALIZATIONS\nHere we provide additional visualizations from our experiments comparing SR under both FGSM\nand PGD attack. We also provide a visual showing the results of FGSM and PGD pertubation on\nvariousimages.\n16\nPreprintversion. Underreview.\ntupnI\ntuptuO\ndekcattA\nsruO+\nFigure6: VisualresultsonstereomatchingagainstFGSMattack,withoutandwithSR,ϵ=0.02\ntupnI\ntuptuO\ndekcattA\nsruO+\nFigure7: VisualresultsonstereomatchingagainstFGSMattack,withoutandwithSR,ϵ=0.01\ntupnI\ntuptuO\ndekcattA\nsruO+\nFigure8: VisualresultsonstereomatchingagainstFGSMattack,withoutandwithSR,ϵ=0.005\ntupnI\ntuptuO\ndekcattA\nsruO+\nFigure9: VisualresultsonstereomatchingagainstPGDattack,withoutandwithSR,ϵ=0.01\n17\nPreprintversion. Underreview.\ntupnI\ntuptuO\ndekcattA\nsruO+\nFigure10: VisualresultsonstereomatchingagainstPGDattack,withoutandwithSR,ϵ=0.005\ntupnI\ntuptuO\ndekcattA\nsruO+\nFigure11: VisualresultsonstereomatchingagainstPGDattack,withoutandwithSR,ϵ=0.002\nImage FGSMAttacked FGSMNoise PGDAttacked PGDNoise\nFigure12: OriginalimagesandtheircorrespondingattackedimagesandperturbationsusingFGSM\nandPGDmethodsonopticalflow. Theattacksmostlytargetthemainobjectobservedintheimage.\n18\n",
    "tables": [],
    "images": []
  },
  {
    "metadata": {
      "id": "2510.03223v1",
      "title": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention\n  Alignment",
      "authors": [
        "Hongxiang Zhang",
        "Yuan Tian",
        "Tianyi Zhang"
      ],
      "summary": "To solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and\nreinforcement learning. However, as reasoning chains extend, critical\nintermediate steps and the original prompt will be buried in the context,\nreceiving insufficient attention and leading to errors. In this paper, we\npropose Self-Anchor, a novel pipeline that leverages the inherent structure of\nreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories\ninto structured plans and automatically aligns the model's attention to the\nmost relevant inference steps, allowing the model to maintain focus throughout\ngeneration. Our experiment shows that Self-Anchor outperforms SOTA prompting\nmethods across six benchmarks. Notably, Self-Anchor significantly reduces the\nperformance gap between ``non-reasoning'' models and specialized reasoning\nmodels, with the potential to enable most LLMs to tackle complex reasoning\ntasks without retraining.",
      "published": "2025-10-03T17:56:33Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03223v1"
    },
    "text": "Preprint\nSELF-ANCHOR: LARGE LANGUAGE MODEL REASON-\nING VIA STEP-BY-STEP ATTENTION ALIGNMENT\nHongxiangZhang&YuanTian&TianyiZhang\nDepartmentofComputerScience\nPurdueUniversity\nLafayette,IN47907,USA\n{hxxzhang,tian211,tianyi}@purdue.edu\nABSTRACT\nTo solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and re-\ninforcementlearning. However,asreasoningchainsextend,criticalintermediate\nstepsandtheoriginalpromptwillbeburiedinthecontext,receivinginsufficient\nattentionandleadingtoerrors. Inthispaper,weproposeSELF-ANCHOR,anovel\npipelinethatleveragestheinherentstructureofreasoningtosteerLLMattention.\nSELF-ANCHORdecomposesreasoningtrajectoriesintostructuredplansandauto-\nmaticallyalignsthemodel’sattentiontothemostrelevantinferencesteps,allow-\ning the model to maintain focus throughout generation. Our experiment shows\nthat SELF-ANCHOR outperforms SOTA prompting methods across six bench-\nmarks. Notably, SELF-ANCHOR significantly reduces the performance gap be-\ntween“non-reasoning”modelsandspecializedreasoningmodels,withthepoten-\ntialtoenablemostLLMstotacklecomplexreasoningtaskswithoutretraining.\n1 INTRODUCTION\nReasoningabilitiesinLargelanguagemodels(LLMs)arekeytosolvecomplextasks, frommath-\nematicalproblemsolvingtologicalinferenceandmulti-stepreasoning(Ahnetal.,2024;Huang&\nChang,2023;Chengetal.,2025).RecentLLMs,suchasOpenAIo1(OpenAI,2024)andDeepSeek-\nR1(DeepSeek-AI,2025),havefurtheradvancedtheirreasoningcapabilitiesthroughfine-tuningand\nreinforcement learning (Luo et al., 2024; et al., 2025). Howevere, despite their impressive perfor-\nmance,theyrequiresubstantialcomputationandaconsiderableamountoftrainingdata.\nAsanalternative,prompting-basedmethodsemergedtoinduceLLMs’inherentreasoningcapabil-\nitiesattesttimewithoutupdatingmodelparameters. MethodssuchasSelf-Refine(Madaanetal.,\n2023) and ReAct (Yao et al., 2023) facilitate reasoning by iteratively expanding and refining the\ngeneration process. Methods like Self-planning (Jiang et al., 2024), Plan-and-Solve (Wang et al.,\n2023), and Re-Reading (Xu et al., 2024) explicitly decompose complex problems before solving\nthem. However,atradeoffofbeingtraining-freeisthattheseprompting-basedmethodsnecessitate\nlongreasoningchainsbecausetheydependoniterativegenerationorexplicitplanning. Whilethis\ncan be seen as the cost of training-free methods, recent studies have revealed another issue: long-\ncontextreasoningcancausesevereattentionmisalignmenttissue(Guetal.,2024;Chietal.,2023;\nLiuetal.,2024;Sunetal.,2024;Yaoetal.,2021;Tian&Zhang,2024;Lietal.,2024;Hongetal.,\n2025).\nAs a key component in LLMs, the attention mechanism (Vaswani et al., 2023) enables LLMs to\nselectively integrate relevant information from preceding context. However, LLM attention is an\ninherentlylimitedresource. Asthegenerationproceeds,thenumberofprecedingtokensincreases,\nmaking it increasingly difficult for the model to pay attention to the relevant context, especially\nwhenthecontextislongandcomplex(Tian&Zhang,2024;Lietal.,2024;Hongetal.,2025). In\nsuchcases,evenwiththeabilitytocorrectlypredictnexttokenbasedonthecorrespondingcontext,\nLLMs may attend to irrelevant context, thereby generating off-topic or wrong results. As shown\ninFigure1, theintermediatereasoningstepsandmostoftheoriginalpromptwillbeburiedinthe\nmiddle,receiveinsufficientattention,andconsequently,introduceerrors(Liuetal.,2024).\n1\n5202\ntcO\n3\n]LC.sc[\n1v32230.0152:viXra\nPreprint\nTo mitigate such attention misalignment issues, recent works explicitly steer LLM attention to in-\nfluence generation behavior. For example, PASTA (Zhang et al., 2023) adjusts the self-attention\ndistributionwithinasubsetofattentionheads,whileSPA(Tian&Zhang,2024)simulatesattention\nsteeringthroughlogitarithmetic. However,thesemethodsmainlyfocusondevelopingrobustatten-\ntion steering mechanisms, while requiring humans to specify which tokens the model should pay\nmoreattentionto. Sincesuchtokenscanvarysignificantlyatdifferentgenerationstepsandacross\ndifferenttasks,itisunrealisticforhumanstomanuallydecideforeverygenerationstep.\nFigure 1: Comparison between existing reasoning methods and SELF-ANCHOR. Due to inherent\nattentionpatterns,existingreasoningmethodsmayeasilyoverlookintermediatereasoningandmake\nmistakes. SELF-ANCHORaddressesthisbydecomposesthetaskintoplans,andtakeseachplanas\nacomponentforattentionalignment.\nTo reduce human efforts, we introduce SELF-ANCHOR, a novel generative pipeline that explicitly\naligns LLM attention by leveraging the inherent structure of a reasoning chain. SELF-ANCHOR\nbuilds on two key insights: (1) complex reasoning problems can be decomposed into structured\nplans, and (2) each decomposed plan can naturally serve as a component for attention alignment.\nAs illustrated in Figure 1, SELF-ANCHOR decomposes the original prompt into plan steps with\ncorresponding reasoning steps. During generation, it automatically selects and steers the model\nattentiontothepromptandthecorrespondingplan. ThisenablestheLLMtokeepattendingtoboth\ntheproblemstatementandimmediatereasoninggoals,therebypreventingattentionmistakesamong\ncontinuouslyexpandingreasoningsteps.\nWeevaluateSELF-ANCHORonsixbenchmarksandsixbaseLLMswithvaryingsizes,andcompare\nitwithSOTApromptingmethods.Theevaluationbenchmarksincludethreemathematicalreasoning\nbenchmarks(GSM8K,AQuA,MATH),twocommonsensebenchmarks(StrategyQA&Thingsfor\nDoing),andanmulti-taskevaluationbenchmark(BIG-BenchHard,BBH).SELF-ANCHORconsis-\ntentlyimprovesaccuracyonallthesettings,outperformingalltheprompting-basedbaselinesbyat\nleast5.44%onaverage. Inaddition,wedemonstratethatSELF-ANCHORachievesperformanceon\nparwithfivereasoningmodelsbutwithsubstantiallylowercostandcomplexity,suggestingaprac-\nticalalternativetoapplyingreinforcementlearningtoenhancethereasoningcapabilityofLLMs.\n2 METHOD\n2.1 SELF-ANCHOR\nReasoningastheScaffoldforAttentionAlignment. Weareinspiredbytheobservationthatplan-\nning offers a natural scaffold for attention alignment. Specifically, planning helps the model to\nunderstand and break down complex problems into subproblems (Jiang et al., 2024; Wang et al.,\n2023). Eachdecomposedplanstepprovidesacorrespondencetosubsequentreasoning,whichcan\nnaturally serve to guide attention alignment. Building on this idea, we design SELF-ANCHOR to\nleverage the inherent structure in the reasoning chain to conduct the attention alignment. SELF-\n2\nPreprint\nANCHOR prompts the model to decompose the prompt into plans, and then generates and corre-\nspondingreasonedsolutionswithexplicitattentionsteering.\nAttention Steering Mechanism. Several studies have explored methods for attention steer-\ning (Zhang et al., 2023; Shi et al., 2023; Tian & Zhang, 2024). These methods primarily address\nhow to steer the model attention. By contrast, our work focuses on an orthogonal problem—how\ntoautomaticallyselectrelevantcontext andusesthesemethodsasaplug-and-playcomponent. In\nthis work, we choose Selective Prompt Anchoring (SPA) (Tian & Zhang, 2024) as the underlying\nattention steering mechanism, since it is low-cost and efficient. We briefly summarize how SPA\nworkshereandreferinterestedreaderstotheoriginalpaperformoretechnicaldetails.\nGiven a set of tokens that an LLM should pay more attention to, SPA simulates attention steering\nthroughlogitarithmetic. Specifically,itestimatestheinfluenceofselectedtokensbycontrastingthe\noriginallogitswiththelogitswhenthesetokensaremasked,andthenaddthisinfluencebacktothe\noriginallogits. Thesteeredlogitisrepresentedbythelinearcombinationoftheoriginallogitsand\nthelogitswithselectedtokensmasked,whereω isacoefficientdeterminingtheattentionsteering\ni\nstrength. Formally,itcanberepresentedas\nlogitssteered =ω ·logitsoriginal+(1−ω )·logitsmask. (1)\ni i i i i\nSelection of Attention Alignment. Building on this attention steering mechanism, we propose a\nnovelstrategythatdynamicallyalignsmodelattentiontochangingcontexttokensduringgeneration.\nAccordingtotheattentionsinkphenomenon(Xiaoetal.,2023),themodelalreadyattendsstrongly\nto initial tokens and the recent generated tokens. Our method complementarily steer the model\nattentiontotheplanningstepswhenconductingthecorrespondingreasoning. Furthermore, SELF-\nANCHORadditionallysteersthemodelattentiontothequestionintheprompt,whichservesasthe\ncoregenerationpurpose,ensuringthemodelkeepsfocusingontheproblemstatement. 1\nFormally,weusef(x,S)torepresentthegenerationfunctionwithattentionsteering,wherexrep-\nresentstheentireprecedingtokensandSrepresentstheselectedtokenswherethemodel’sattention\nshouldbesteeredto. Letsysdenotethesystemprompttogetherwithhigh-levelbackgroundinstruc-\ntions(e.g., “Youareahelpfulassistant”), andletQdenotethecorequestionunderconsideration.\nThus,theoriginalpromptcanberepresentedasconcat(sys, Q). ThegenerationofSELF-ANCHOR\nconsistsoftwoparts: theplanningandthecorrespondingreasoning.\nAtstepi,theplanningisgeneratedby\n(cid:16) (cid:0) (cid:1) (cid:17)\nplan =f concat sys, Q, plan , plan , ..., plan , Q . (2)\ni 1 2 i−1\nTheplanningisgeneratedby\n(cid:16) (cid:0) (cid:1) (cid:17)\nreason =f concat sys, Q, plan , plan , ..., plan , concat(Q, plan) . (3)\ni 1 2 i−1 i\nThegenerationproceedsbyalternatingbetweenplan andreason ,untiltheprocessterminateswith\ni i\nthefinalresult.\nDynamic Tuning of Attention Alignment Strength. As reasoning trajectories progress, the re-\nquired degree of attention alignment may vary at different steps. According to prior work (Geng\netal.,2024;Fuetal.,2025),LLMs’predictedprobabilitydistributioncanbeviewedasaconfidence\nsignaltodeterminetheirpredictionquality.High-confidencepredictionsuggestsreliablegeneration,\nimplyingacorrectattention,whereaslowconfidencemayindicateunreliablegenerationandatten-\ntion drift. Therefore, we introduce a step-level anchoring strength ω that is dynamically adjusted\ni\nbasedonmodelconfidence.2 LetP = {p ,p ,...,p }representthepredictedprobabilityatstep\ni 1 2 m\ni. WecalculatetheconfidencescoreusingtheharmonicmeanofP\ni\nn\np = . (4)\navg (cid:80)n 1\ni=1 pi\nThis confidence score serves as an additional factor to scale the attention steering strength w in\ni\nEquation1. WediscussdetaileddesignchoicesandexperimentsinAppendixB.\n1AlternativeanchoringstrategiesarediscussedinAppendixD\n2Ourstrengthadjustmentstrategybuildsupontheconfidence-modulatedstrengthstrategyinSPA(Tian&\nZhang,2024). WhileSPAadjuststhestrengthbasedonconfidenceforeachlogitatthevocabularylevel,we\nintroduceanadditionalfactortoadjustthestrengthforeachstep.\n3\nPreprint\n3 EXPERIMENTS\n3.1 BENCHMARKS\nWe evaluated SELF-ANCHOR on six benchmarks. The first three benchmarks incorporate\nGSM8K(Cobbeetal.,2021),AQuA(Lingetal.,2017),andMATH(Hendrycksetal.,2021)repre-\nsentarithmeticreasoning. ThesecondtwobenchmarksincludeStrategyQA(Gevaetal.,2021),and\nThinkingforDoing(T4D)(Zhouetal.,2023)representcommonsensereasoning. Lastly,weevalu-\natedonasubsetofBIG-BenchHard(BBH)(Suzgunetal.,2022),whichcoversadiverserangeof\nreasoningproblemsspanningthemulti-stepalgorithmicreasoning,naturallanguageunderstanding,\ntheapplicationofworldknowledge,andMultilingualKnowledge. Wereportfinalansweraccuracy\nacrossallbenchmarks3.\n3.2 MODELSANDBASELINES\nBase Models. We conduct our experiments on six non-reasoning LLMs spanning various scales.\nFornon-reasoningmodels,weselectLlama-3.1-8B-Instruct(Grattafiorietal.,2024),Llama-3.2-3B-\nInstruct(Grattafiorietal.,2024),Phi-4-mini-instruct(Aboueleninetal.,2025),Qwen3-4B-Instruct-\n2507(Team,2025),Phi-4(Abdinetal.,2024),andQwen3-30B-A3B-Instruct-2507(Team,2025).\nComparison Baselines. We compare our method against three representative prompting meth-\nods for LLM reasoning. First, we include CoT (Wei et al., 2022; Kojima et al., 2022), a widely\nusedbaselinethatmodelsarepromptedtogenerateareasoningprocessleadingtothefinalanswer.\nSecond, weincludePlan-and-Solve+(PS+)(Wangetal.,2023), apromptingmethodthatmodels\nare prompted to first generate a plan and then solve the problem. Third, we include Re-Reading\n(RE2)(Xuetal.,2024),whichasksthemodeltoreadthequestionagainandthensolvetheproblem.\nFurthermore,weconsiderfivestate-of-the-artreasoningLLMsasbaselinestoseeifnon-reasoning\nLLMs combined with SELF-ANCHOR achieve competitive performance against reasoning mod-\nels. The reasoning models include Phi-4-mini-reasoning (Abouelenin et al., 2025), Qwen3-\n4B-Thinking-2507 (Team, 2025), DeepSeek-R1-Distill-Llama-8B (DeepSeek-AI, 2025), Phi-4-\nreasoning(Abdinetal.,2024),andQwen3-30B-A3B-Thinking-2507(Team,2025).\n3.3 MAINRESULTS\nMathematicalReasoning. Arithmeticreasoningrepresentsoneofthemostchallengingaspectsof\nLLMreasoningcapabilities. AsshowninTable1, SELF-ANCHORconsistentlyimprovesaccuracy\nacross three arithmetic benchmarks. These gains reach over 10% improvements on GSM8K, over\n5%onAQuA,andupto8%onMATHacrossmostmodels,outperformingallcompetingmethods.\nWhilePS+andRE2alsodemonstratepotentialforenhancingmathematicalreasoningperformance,\nourexperimentsshowperformancedegradationoncertainLLMs,suggestinglimitedgeneralization\ncapabilities.\nInterestingly, the three benchmarks span increasing difficulty levels, from grade-school prob-\nlems(Cobbeetal.,2021)toGMET/GRE(Lingetal.,2017)levelandcompetition-levelproblems\n(Hendrycksetal.,2021). SELF-ANCHOR demonstratesperformancegaininallthreebenchmarks,\nsuggesting superior generalization capabilities across diverse model architectures and reasoning\ncomplexitylevels.\nCommonsence Reasoning. StrategyQA requires multi-hop reasoning over commonsense knowl-\nedge. As detailed in Table 1, SELF-ANCHOR persistently improves accuracy across six evaluated\nLLMs. Incontrast,PS+andRE2occasionallyoutperformthebaselineCoTmethod.\nForT4D,agroundedsocialagentreasoningtaskrequiresmentalstatereasoningtodetermineappro-\npriateactions. SELF-ANCHORdemonstratessignificantperformancegainsover9%infourLLMs.\nIn comparison, both PS+ and RE2 exhibit mixed performance; they tend to be more effective in\nlarger models. These findings highlight the challenge of applying generic prompting strategies to\nspecializedreasoningdomains.\n3PrompttemplatesandevaluationdetailsareprovidedinAppendixE.\n4\nPreprint\nTable1:Evaluationresultsonsixbenchmarks.Bestresultsareshowningreen,andthoseindicating\naperformancedropcomparedtostandardgreedydecodingareshowningrey.\nMath CommonSense\nModel Method BBH\nGSM8K AQuA MATH StrQA T4D\nCoT 63.84 46.06 42.5 66.64 32.98 35.09\nPS+ 70.62(+6.78) 38.58(-7.48) 44.50(+2.00) 62.79(-3.85) 31.81(-1.17) 40.51(+5.42)\nLlama3.2-3B\nRE2 57.38(-6.46) 47.28(+1.22) 45.00(+2.50) 65.03(-1.61) 30.32(-2.66) 38.02(+2.93)\nSELF-ANCHOR 77.86(+14.02) 48.43(+2.37) 45.00(+2.50) 67.55(+0.91) 43.79(+10.81) 50.48(+15.39)\nCoT 75.36 61.81 51.00 67.03 39.54 60.51\nPS+ 87.17(+11.81) 62.02(+0.21) 54.50(+3.50) 58.86(-8.17) 41.16(+1.62) 59.63(-0.88)\nPhi-4-mini-4B\nRE2 85.75(+10.39) 59.06(-2.75) 51.50(+0.50) 61.83(-5.20) 44.50(+4.96) 61.39(+0.88)\nSELF-ANCHOR 88.02(+12.66) 68.50(+6.69) 59.00(+8.00) 68.69(+1.66) 49.47(+9.93) 62.42(+1.91)\nCoT 86.66 73.62 82.00 68.03 70.21 73.33\nPS+ 82.79(-3.87) 71.65(-1.97) 83.50(+1.50) 68.56(+0.53) 59.82(-10.39) 70.99(-2.34)\nQwen3-4B\nRE2 79.98(-6.68) 75.98(+2.36) 82.50(+0.50) 69.83(+1.80) 67.02(-3.19) 75.75(+2.42)\nSELF-ANCHOR 87.26(+0.60) 79.92(+6.30) 86.50(+4.50) 70.13(+2.10) 71.56(+1.35) 75.31(+1.98)\nCoT 61.85 50.79 44.50 70.24 26.77 49.45\nPS+ 62.24(+0.39) 48.65(-2.14) 47.00(+2.50) 65.85(-4.39) 28.79(+2.02) 51.72(+2.27)\nLlama3.1-8B\nRE2 57.68(-4.17) 51.97(+1.18) 44.50(+0.00) 69.74(-0.50) 28.55(+1.78) 54.58(+5.13)\nSELF-ANCHOR 76.72(+14.87) 55.51(+4.72) 52.50(+8.00) 73.54(+3.30) 40.01(+13.24) 58.53(+9.08)\nCoT 73.16 68.11 74.50 77.51 73.94 72.08\nPS+ 79.07(+5.91) 72.75(+4.64) 72.50(-2.00) 75.59(-1.92) 76.24(+2.30) 68.42(-3.66)\nPhi-4-15B\nRE2 74.87(+1.17) 69.29(+1.18) 73.50(-1.00) 76.90(-0.61) 75.79(+1.85) 74.94(+2.86)\nSELF-ANCHOR 82.41(+9.25) 79.13(+11.02) 81.00(+6.50) 77.82(+0.31) 85.99(+12.05) 75.31(+3.23)\nCoT 84.46 81.10 78.00 78.60 84.92 67.69\nPS+ 85.11(+0.65) 80.83(-0.27) 73.50(-4.50) 78.70(+0.10) 82.62(-2.30) 66.67(-1.02)\nQwen3-30B\nRE2 87.21(+2.75) 82.28(+1.18) 76.00(-2.00) 78.91(+0.31) 89.36(+4.44) 70.55(+2.86)\nSELF-ANCHOR 87.41(+2.95) 83.46(+2.36) 87.00(+9.00) 79.65(+1.05) 85.56(+0.64) 69.30(+1.61)\nBBH.BBHaggregateschallengingalgorithmicandsymbolictasks. SELF-ANCHOR demonstrates\naverage performance gains ranging from 1.61% to 15.39%4. Among all sub-benchmarks, we find\nthat tasks requiring tracking of intermediate reasoning benefit the most, for example date under-\nstanding, and logical deduction. We attribute this to SELF-ANCHOR’s attention steering that aug-\nmentscriticalreasoningstepsandtheoriginalquestionthroughoutgeneration. Incontrast,PS+and\nRE2showinconsistentimprovements.\nIn summary, these results highlight two takeaways. First, while prompting strategies are effective\ninsometasks,theylackrobustnessacrossbenchmarksandmodelarchitectures,tendingtobemore\neffectiveonlargerLLMsandsimplerreasoningtasks. Thismaybebecauselargermodelsaremore\ncapable of following instructions and external guidance to align reasoning trajectories. Second,\nby integrating planning, structured reasoning, and automatic anchoring, SELF-ANCHOR achieves\nconsistentimprovementsacrosstasks,modelsizes,andarchitectures,demonstratingbothrobustness\nandeffectiveness.\n3.4 CANSELF-ANCHORRIVALRL-ENHANCEDTHINKINGMODEL?\nRecentadvancesinreasoningcapabilitieshavebeendominatedbyreinforcementlearning-enhanced\n“thinking”modelsthatemployextensiveinternalreasoningchainsduringinference.However,these\nmodelsarecostlytofine-tuneandrequirelarge-scaletrainingdata. Thisraisesaquestion: Cannon-\nreasoningLLMscombinedwithSELF-ANCHORachievecompetitiveperformanceagainstreasoning\nmodels? To investigate this question, we compare our method applied to non-reasoning LLMs\nagainst corresponding thinking models. Since thinking models typically require longer generated\ncontextstosupporttheirinternalreasoning,weset1.5xlargermaximumtokenlengththanthenon-\nreasoningmodelsinourexperiments.\nTable2presentsourfindingsacrossmathematicalreasoning,commonsensereasoning,andsymbolic\nreasoning tasks. Remarkably, our method applied to non-thinking models achieves competitive or\nsuperiorperformancecomparedtoRL-enhancedthinkingmodels. Specifically,ourapproachcloses\ntheperformancegapsignificantlywiththreearithmeticbenchmarksinvaryingdifficulties,achieving\n4WedetailthesubtaskperformanceinAppendixG\n5\nPreprint\nTable2: Evaluationcomparisonwiththinkingmodels\nMath CommonSense\nModel Method BBH\nGSM8K AQuA MATH StrQA T4D\nCoT 75.36 61.81 51.00 67.03 39.54 60.51\nPhi-4-mini-4B SELF-ANCHOR 88.02 68.50 59.00 68.69 49.47 62.42\nReasoning 81.27 60.62 75.00 66.38 45.04 59.85\nCoT 86.66 73.62 82.00 68.03 70.21 73.33\nQwen3-4B SELF-ANCHOR 87.26 79.92 86.50 70.13 71.56 75.31\nReasoning 83.24 67.32 87.00 68.31 73.40 75.34\nCoT 61.85 50.79 44.50 70.24 26.77 49.45\nLlama3.1-8B SELF-ANCHOR 76.72 55.51 52.50 73.54 40.01 58.53\nReasoning 73.62 62.99 72.50 65.41 48.58 64.98\nCoT 73.16 68.11 74.50 77.51 73.94 72.08\nPhi-4-15B SELF-ANCHOR 82.41 79.13 81.00 77.82 85.99 75.31\nReasoning 81.12 83.20 95.5 75.43 74.11 74.98\nCoT 84.46 81.10 78.00 78.60 84.92 67.69\nQwen3-30B SELF-ANCHOR 87.41 83.46 87.00 79.65 85.56 69.30\nReasoning 94.5 80.31 85.00 77.26 80.96 76.54\nwithin5%differenceofmostthinkingmodels;OncommonsensereasoningtasksandBBH,SELF-\nANCHORexceedsthinkingmodelperformanceonmostbenchmarksandLLMs.\nNoteably, we observe that thinking models demonstrate superior performance on tasks where cor-\nresponding non-reasoning models show poor baseline performance. For example, Llama3.1 and\nPhi-4-minishowlargegapsonMATH,andLlama3.1underperformsonAQuAandBBH.Inthese\nsettings,post-trainingwithreinforcementlearningsignificantlyboostsperformanceinareaswhere\nmodels previously performed poorly. In contrast, for tasks where non-reasoning models already\ndemonstrate strong performance, reinforcement learning provides limited improvement. This pat-\ntern is also observed in Kirk et al. (2023). Nevertheless, SELF-ANCHOR shows consistent perfor-\nmanceimprovementsacrossalltasksanddifficultylevels.\nIn summary, rather than learning implicit reasoning patterns through training, our approach lever-\nagestheinherentstructureinthereasoningchainforattentionalignmenttoimprovethereasoning\ncapabilities,yieldingstableimprovementacrossvaryingdifficultylevelswithoutadditionaltraining\ncost. Thesefindingssuggestthat SELF-ANCHOR canserveasaneffectivealternativetocomputa-\ntionallyexpensiveRL-enhancedreasoning.\n3.5 WHICHTYPESOFTASKSDOSELF-ANCHORHELPTHEMOST?\nTo understand which types of tasks SELF-ANCHOR help the most, we analyze performance gains\nacrosstaskcomplexity.WeadaptthemethodforquantifyingtaskcomplexityfromWuetal.(2025);\nJinetal.(2024),whereeachtaskisrepresentedbyanindividualquestioninabenchmark. Foreach\nbenchmark, 200 questions are randomly sampled to compute the average accuracy per task across\nallexperimentedmodels. Taskcomplexityisthendefinedas1−accuracy5,whereloweraccuracy\nindicateshighercomplexity.\nReasoning Task Complexity. First, we examine the relationship between task complexity and\nSELF-ANCHOR’sperformancegainstounderstandhowourmethodscaleswithtaskdifficulty. We\ncompareSELF-ANCHOR’sperformancegainsagainstRE2,astrongbaselineidentifiedinourmain\nresults(subsection3.3). Foreachtask,wecomputeperformancegainasthedifferenceinaccuracy\nbetweenthetwomethods.\nAs shown in Figure 2a, the box plot summarizes the distribution of performance gains for tasks\nacrosscomplexityranges.Whiletasksinthe0.67–0.83complexityrangeshowafewnegativecases,\nthe average improvement remains positive across all task complexities. Overall, SELF-ANCHOR\npresents performance gains spanning all complexity levels, achieving approximately 7% perfor-\n5SegmentingreasoningstepsandtaskcomplexitydetailsareprovidedinAppendixE.\n6\nPreprint\n60\n40\n20\n0\n20\n40\n60\n(0.17-0.33) (0.33-0.50) (0.50-0.67) (0.67-0.83) (0.83-1.00)\nTask Complexity Range\n)%(\nniaG\necnamrofreP\n30\n25\n20\n15\n10\n5\n(0.00-0.13) (0.13-0.27) (0.40-0.53) (0.53-0.67) (0.67-0.80)\nTask Complexity Range\n(a) Reasoning Tasks Complexity and performance\ngainscomparison\nhtgneL\nniahC\ngninosaeR\n(b)ReasoningTasksComplexityandreasoningchain\nlength comparison. The lower value represents the\neasiertask.\nFigure2: Analysisoftaskcomplexityandreasoningchainlength\nmanceimprovement. TheseresultsdemonstratethatSELF-ANCHORachievesconsistentgainsand\ngeneralizeseffectivelyacrossvaryingtaskcomplexities.\nReasoning Chain Length vs. Task Complexity. Next, we analyze how reasoning chain length\nscales with task difficulty. Figure 2b shows the distribution of successful reasoning chain lengths\nacrosstasksofvaryingdifficultyonLlama3.2-3B.Theresultsshowacleartrendthatascomplexity\nincreases,SELF-ANCHORtendstogeneratelongerreasoningchains. Thisalignswiththeobserva-\ntioninWuetal.(2025)thatharderproblemsrequirelongerreasoningchainstosolve. Weattribute\nthiscapabilitytotheattentionsteeringmechanism,whichenablesthemodeltofocusonbothprob-\nlemcontextandimmediatereasoningobjectthroughoutthereasoning,preventingattentiondriftas\nthereasoningchainextends.\nIn summary, our analysis highlights two takeaways: (1) SELF-ANCHOR demonstrates consistent\nimprovementsacrossallcomplexitylevels,confirmingitsabilitytogeneralizebeyondnarrowtask\ncategories.(2)SELF-ANCHORencouragethemodeltogeneratelongerreasoningchainsfordifficult\nproblems,supportingitseffectivenessinscalingtocomplextasks.\n3.6 EFFICIENCY\nTable3: Efficiencycomparison\nToken/Second\nModel\nSELF-ANCHOR CoT PS+ RE2\nLlama3.2-3B 9.97 10.87 10.84 12.01\nPhi-4-mini-4B 11.02 12.25 12.24 12.21\nQwen3-4B 5.41 6.22 6.22 6.23\nLlama3.1-8B 7.54 8.38 8.26 8.19\nPhi-4-15B 7.92 9.00 8.94 8.88\nQwen3-30B 1.07 1.39 1.39 1.37\nSELF-ANCHORachievedsuperiorperformancecomparedtostate-of-the-artmethods;wearecom-\nmitted to evaluating its efficiency. Table 3 reports inference throughput (tokens/sec) for SELF-\nANCHOR compared to baseline methods. On average, SELF-ANCHOR introduces minimal com-\nputational overhead, with throughput reductions typically below 1–2 tokens/sec relative to base-\nlines. Theresultshighlightafavorabletrade-off; SELF-ANCHOR consistentlyimprovesreasoning\nwhile maintaining comparable runtime cost. Importantly, the cost-performance balance remains\nstable across both smaller (3B–4B) and larger (15B–30B) models, suggesting scalability without\nprohibitivelatency.\n7\nPreprint\nTable4: PerformancecomparingSELF-ANCHORwithandwithoutattentionsteering\nMath CommonSense\nModel Method BBH\nGSM8K AQuA MATH StrQA T4D\nSELF-ANCHOR(w/oattentionsteering) 73.01 53.15 40.90 71.17 35.28 52.77\nLlama3.1-8B\nSELF-ANCHOR 76.72 55.51 52.50 73.54 40.01 58.53\nSELF-ANCHOR(w/oattentionsteering) 78.77 58.66 55.50 68.60 38.83 57.44\nPhi-4-mini-4B\nSELF-ANCHOR 88.02 68.50 59.00 68.69 49.47 62.42\nTable 5: An example of BBH. Incorrect inferences are highlighted in red. Correct ones are high-\nlightedingreen.\nSentence:Thesecretarycametotheanalyst’sofficeandhelpedhertobookaflight.\nPrompt\nOptions:(A)Helpedthesecretarybookaflight(B)Helpedtheanalystbookaflight(C)Ambiguous\nSELF-ANCHOR {”Step1:Identifythepronoun”:”Thepronounis’her’.”,\n(w/oattentionsteering) ”Step2:Determinetheantecedentofthepronoun”:”Theantecedentof’her’isthesubjectofthesentence,whichis’Thesecretary’”,\n”Step3:Analyzethesentencestructure”:Thesubjectofthesentenceis’Thesecretary’,andtheverbis’came’.Theobjectofthe\nverb’came’is’totheanalyst’soffice’.Theverb’helped’hasthepronoun’her’asitsobject.”,\n”Step4:Determinetheantecedentofthepronounbasedonthesentencestructure”:”Basedonthesentencestructure,theantecedent\nofthepronoun’her’isthesubjectofthesentence,whichis’Thesecretary’.”,\n”Step5:Choosethecorrectoption”:”Thecorrectoptionis(A)Helpedthesecretarybookaflight.”}\nSELF-ANCHOR {”Step1:Identifythepronoun”:”Thepronouninthesentenceis’her’.”,\n”Step2:Determinetheantecedentofthepronoun”:”Tofindtheantecedent,weneedtolookforthenounthat’her’refersto.Inthis\ncase,’her’isapossessivepronounthatreferstotheanalyst.”,\n”Step3:Analyzethesentencestructure”:”Thesubjectofthesentenceis’Thesecretary’,andtheobjectoftheverb’helped’is’her’”,\n”Step4:Identifytheantecedentbasedonthesentencestructure”:”’her’referstotheanalyst,notthesecretary.”,\n”Step5:Choosethecorrectoption”:”Since’her’referstotheanalyst,thecorrectoptionis(B)Helpedtheanalystbookaflight.”}\nIn summary, SELF-ANCHOR achieves strong effectiveness and efficiency, offering improved rea-\nsoningperformancewithonlyminorlatencyoverheadcomparedtostate-of-the-artbaselines.\n3.7 ABLATIONSTUDY: THEEFFECTIVENESSOFATTENTIONSTEERING\nToisolatethecontributionofattentionsteering, weconductedanablationstudycomparing SELF-\nANCHORwithandwithoutattentionsteeringontworepresentativeLLMsacrossallsixbenchmarks.\nAs illustrated in Table 4, SELF-ANCHOR consistently outperformed its variant without attention\nsteering,acrossallbenchmarks,demonstratingtheeffectivenessofattentionsteering.\nTable 5further illustrates a representativeexample where attention steering prevents reasoning er-\nrors. InSteps2and4,theSELF-ANCHORwithoutattentionsteeringapproachincorrectlyidentifies\n“her” as referring to “the secretary”; this may be because models over-focus on sentence subjects\nrather than maintaining focus on the syntactic relationships that determine pronoun reference. In\ncontrast,SELF-ANCHORcorrectlyidentifiesthat“her”refersto“theanalyst”bymaintainingatten-\ntiononboththeoriginalquestioncontextandthecurrentreasoningstep6.\nThisablationconfirmsthat,whilestructuredreasoningprovidesafoundationforimprovedperfor-\nmance, it is often insufficient to prevent attention drift on its own. The attention anchoring com-\nponentiscrucialtoensurethemodelmaintainsfocusthroughoutthereasoningprocess,leadingto\nmorerobustandaccurateresults.\n3.8 FAILURECASEANALYSIS\nTo understand the failure modes in SELF-ANCHOR. We conducted a manual failure case analysis\non 200 randomly sampled cases from casual judgement and AQuA. Our analysis identified three\nprimaryfailuremodes:\nReasoningErrors(42%). ThemostfrequentfailuremodeinvolvesLLMmakingmistakesduring\nthereasoning. Theseincludethemisapplicationofcausalprinciples,flaweddeductions,andincor-\nrect conditional reasoning. For example, in one casual judgement instance, the model incorrectly\ntreatedanecessarybutinsufficientconditionasthesolecausalfactor,leadingtoaninvalidconclu-\n6WeprovideadditionalcasestudiesinAppendixFforfurtherillustration.\n8\nPreprint\nsion. Sucherrorssuggestthat, whileattentionanchoringhelpsmaintainfocusonrelevantsteps, it\ncannotfullycompensateforweaklogicalpriorsorgapsinworldknowledge.\nMisunderstandingtheproblem(36.5%). Asubstantialportionoffailuresstemsfromincompre-\nhensionofcomplexquestions,leadingtoerrorssuchasmisidentifyingallvariables,misinterpreting\ntheproblem’srequirements,orincorrectlyparsingtherelationshipsbetweenentities. Forinstance,\ninmulti-variableproblems,themodelsometimesassignsnumericalvaluestothewrongentity.\nComputationalErrors(21.5%). Theremainingfailuresinvolvearithmeticmistakes,unitconver-\nsion errors, or algebraic slips. Even when the reasoning chain is correct, a single miscalculation\noftenpropagatestothefinalanswer.\nTakentogether, thesefindingssuggestthat SELF-ANCHOR primarilymitigatesattentionmisalign-\nment,butdoesnotfullyresolvedeeperissuesoflogicalvalidity,semanticunderstanding,orcompu-\ntationalprecision.\n4 RELATED WORK\nPromptengineeringforreasoning. Promptengineeringhasbeenwidelyadoptedasafundamen-\ntal approach for enhancing LLM reasoning capabilities (Liu et al., 2023; Brown et al., 2020). A\nfoundational line of work, initiated by Chain-of-Thought (CoT) prompting (Wei et al., 2022), en-\ncouragesexplicitintermediatesteps,whichsignificantlyimproveperformanceonmulti-stepreason-\ningtasks.Thishasinspirednumerousderivatives,includingproblemdecompositionmethods(Wang\netal.,2023;Zhouetal.,2022;Khotetal.,2022;Drozdovetal.,2022),aswellastechniquesfocused\nonenhancingquerycomprehension(Xuetal.,2024;Zhengetal.,2023;Mekalaetal.,2023;Deng\netal.,2023;Mishra&Nouri,2022).\nWhilethesepromptingmethodsdemonstrateeffectivenessinspecificdomains,theyrelyonprede-\ntermined, static prompt formats for different tasks. On the other hand, LLMs remain sensitive to\nprompt variations and suffer from attention dilution during long generations (Liu et al., 2024; Li\net al., 2024; Hong et al., 2025; Lu et al., 2021; Gu et al., 2024). SELF-ANCHOR addresses these\nlimitationsbyintegratingstructuredreasoningwithdynamicattentionsteering.Itgoesbeyondstatic\npromptingbyenablingthemodeltorecalibrateitsfocusonthemostsalientcontextateachstepof\nthereasoningtrajectory.\nAttention steering. In contrast to the aforementioned prompt engineering, which devises better\nprompt strategies, attention steering methods directly guide LLMs during inference to emphasize\ntheuser-specifiedpartofcontext. Specifically,SelectivePromptAnchoring(SPA)(Tian&Zhang,\n2024) adjusts the logit probability distribution to emphasize the specified context. PASTA(Zhang\net al., 2023) identifies and reweights a subset of attention heads to redirect the model’s attention\nto user-specified parts. Selective Self-Attention (SSA) (Zhang et al., 2024) augments the softmax\nnonlinearitywithaprincipledtemperaturescalingstrategy. TOAST(Shietal.,2023)learnsfeature\nselection modules that guide attention toward task-relevant information. However, these methods\nrequiremanualspecificationofanchorcontent,limitingtheiradaptabilitytodiversereasoningcon-\ntexts. Real-worldapplicationsdemandautomaticidentificationofrelevantcontextelementsacross\nvaryingtaskrequirementandreasoningpatterns. SELF-ANCHORaddressesthislimitationbylever-\nagingstructuredintermediaterepresentationstoenablecontext-awareanchorselectionwithouthu-\nmanintervention.\n5 CONCLUSION\nWepresentedSELF-ANCHOR,alightweightpipelinethatleveragestheinherentstructureofreason-\ningforattentionalignment. Acrosssixdiversereasoningbenchmarks,SELF-ANCHORconsistently\noutperformsexistingbaselines.Notably,SELF-ANCHORenhanced“non-reasoning”modelsachieve\ncompetitive performance with specialized reasoning models while maintaining significantly lower\ncost. Moreover,ouranalysisrevealsthatSELF-ANCHOR’sadvantagesaregeneralizabletovarying\ntaskcomplexities. WehopeSELF-ANCHORservesasasteptowardmorereliableLLMsreasoning\nthatrequiresneitherparameterupdatesnoradditionalsampling.\n9\nPreprint\n6 REPRODUCIBILITY STATEMENT\nWehavemadeextensiveeffortstoensurethereproducibilityofourwork. Additionalimplementa-\ntion details, hyperparameters, and ablation studies are provided in the appendix. We also include\ncompletedescriptionsofbenchmarkdatasets,samplingprocedures,andtaskcomplexitymeasures.\nLastly, to foster reproducibility and further research, source code will be made publicly available\nuponacceptanceofthispaper.\n7 ETHICS STATEMENT\nThispaperdoesnotinvolveanyethicalconcerns. Theproposedmethodsfocusonimprovingrea-\nsoningabilityandrobustnessinLLMsanddonotraiseissuesrelatedtothecodeofethics.\nREFERENCES\nMarah Abdin, Jyoti Aneja, Harkirat Behl, Se´bastien Bubeck, Ronen Eldan, Suriya Gunasekar,\nMichael Harrison, Russell J Hewett, Mojan Javaheripi, Piero Kauffmann, et al. Phi-4 techni-\ncalreport. arXivpreprintarXiv:2412.08905,2024.\nAbdelrahmanAbouelenin,AtabakAshfaq,AdamAtkinson,HanyAwadalla,NguyenBach,Jianmin\nBao,AlonBenhaim,MartinCai,VishravChaudhary,CongcongChen,etal. Phi-4-minitechnical\nreport: Compactyetpowerfulmultimodallanguagemodelsviamixture-of-loras. arXivpreprint\narXiv:2503.01743,2025.\nJaniceAhn,RishuVerma,RenzeLou,DiLiu,RuiZhang,andWenpengYin.Largelanguagemodels\nfor mathematical reasoning: Progresses and challenges. In Neele Falk, Sara Papi, and Mike\nZhang (eds.), Proceedings of the 18th Conference of the European Chapter of the Association\nfor Computational Linguistics: Student Research Workshop, pp. 225–237, St. Julian’s, Malta,\nMarch 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.eacl-srw.17.\nURLhttps://aclanthology.org/2024.eacl-srw.17/.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\nArvindNeelakantan,PranavShyam,GirishSastry,AmandaAskell,etal. Languagemodelsare\nfew-shotlearners. Advancesinneuralinformationprocessingsystems,33:1877–1901,2020.\nFengxiangCheng,HaoxuanLi,FenrongLiu,RobertvanRooij,KunZhang,andZhouchenLin.Em-\npoweringllmswithlogicalreasoning:Acomprehensivesurvey.arXivpreprintarXiv:2502.15652,\n2025.\nTa-ChungChi,Ting-HanFan,andAlexanderIRudnicky.Attentionalignmentandflexiblepositional\nembeddingsimprovetransformerlengthextrapolation. arXivpreprintarXiv:2311.00684,2023.\nYung-SungChuang,YujiaXie,HongyinLuo,YoonKim,JamesR.Glass,andPengchengHe. Dola:\nDecoding by contrasting layers improves factuality in large language models. In The Twelfth\nInternationalConferenceonLearningRepresentations,2024. URLhttps://openreview.\nnet/forum?id=Th6NyL07na.\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,\nMatthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to\nsolvemathwordproblems. arXivpreprintarXiv:2110.14168,2021.\nDeepSeek-AI. Deepseek-r1: Incentivizingreasoningcapabilityinllmsviareinforcementlearning,\n2025. URLhttps://arxiv.org/abs/2501.12948.\nYihe Deng, Weitong Zhang, Zixiang Chen, and Quanquan Gu. Rephrase and respond: Let large\nlanguagemodelsaskbetterquestionsforthemselves. arXivpreprintarXiv:2311.04205,2023.\nAndrew Drozdov, Nathanael Scha¨rli, Ekin Akyu¨rek, Nathan Scales, Xinying Song, Xinyun Chen,\nOlivierBousquet,andDennyZhou. Compositionalsemanticparsingwithlargelanguagemodels.\narXivpreprintarXiv:2209.15003,2022.\n10\nPreprint\nGuiyao Tie et al. A survey on post-training of large language models, 2025. URL https://\narxiv.org/abs/2503.06072.\nYichao Fu, Xuewei Wang, Yuandong Tian, and Jiawei Zhao. Deep think with confidence, 2025.\nURLhttps://arxiv.org/abs/2508.15260.\nJiahuiGeng,FengyuCai,YuxiaWang,HeinzKoeppl,PreslavNakov,andIrynaGurevych.Asurvey\nofconfidenceestimationandcalibrationinlargelanguagemodels. InKevinDuh,HelenaGomez,\nandSteven Bethard(eds.), Proceedings ofthe2024 Conferenceof theNorthAmerican Chapter\nof the Association for Computational Linguistics: Human Language Technologies (Volume 1:\nLongPapers),pp.6577–6595,MexicoCity,Mexico,June2024.AssociationforComputational\nLinguistics. doi: 10.18653/v1/2024.naacl-long.366. URLhttps://aclanthology.org/\n2024.naacl-long.366/.\nMorGeva,DanielKhashabi,EladSegal,TusharKhot,DanRoth,andJonathanBerant. Didaristotle\nusealaptop? aquestionansweringbenchmarkwithimplicitreasoningstrategies. Transactionsof\ntheAssociationforComputationalLinguistics,9:346–361,2021.\nAaronGrattafiori,AbhimanyuDubey,AbhinavJauhri,AbhinavPandey,AbhishekKadian,Ahmad\nAl-Dahle,AieshaLetman,AkhilMathur,AlanSchelten,AlexVaughan,etal. Thellama3herd\nofmodels. arXivpreprintarXiv:2407.21783,2024.\nXiangming Gu, Tianyu Pang, Chao Du, Qian Liu, Fengzhuo Zhang, Cunxiao Du, Ye Wang, and\nMinLin. Whenattentionsinkemergesinlanguagemodels: Anempiricalview. arXivpreprint\narXiv:2410.10781,2024.\nDanHendrycks,CollinBurns,SauravKadavath,AkulArora,StevenBasart,EricTang,DawnSong,\nandJacobSteinhardt. Measuringmathematicalproblemsolvingwiththemathdataset. NeurIPS,\n2021.\nKelly Hong, Anton Troynikov, and Jeff Huber. Context rot: How increasing input tokens im-\npacts llm performance. Technical report, Chroma, July 2025. URL https://research.\ntrychroma.com/context-rot.\nJie Huang and Kevin Chen-Chuan Chang. Towards reasoning in large language models: A sur-\nvey. In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki (eds.), Findings of the As-\nsociation for Computational Linguistics: ACL 2023, pp. 1049–1065, Toronto, Canada, July\n2023.AssociationforComputationalLinguistics. doi: 10.18653/v1/2023.findings-acl.67. URL\nhttps://aclanthology.org/2023.findings-acl.67/.\nXue Jiang, Yihong Dong, Lecheng Wang, Zheng Fang, Qiwei Shang, Ge Li, Zhi Jin, and Wenpin\nJiao. Self-planningcodegenerationwithlargelanguagemodels. ACMTransactionsonSoftware\nEngineeringandMethodology,33(7):1–30,2024.\nMingyuJin,QinkaiYu,DongShu,HaiyanZhao,WenyueHua,YandaMeng,YongfengZhang,and\nMengnan Du. The impact of reasoning step length on large language models. arXiv preprint\narXiv:2401.04925,2024.\nTusharKhot,HarshTrivedi,MatthewFinlayson,YaoFu,KyleRichardson,PeterClark,andAshish\nSabharwal. Decomposed prompting: A modular approach for solving complex tasks. arXiv\npreprintarXiv:2210.02406,2022.\nRobert Kirk, Ishita Mediratta, Christoforos Nalmpantis, Jelena Luketina, Eric Hambro, Edward\nGrefenstette, andRobertaRaileanu. Understandingtheeffectsofrlhfonllmgeneralisationand\ndiversity. arXivpreprintarXiv:2310.06452,2023.\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large\nlanguage models are zero-shot reasoners. Advances in neural information processing systems,\n35:22199–22213,2022.\nKenneth Li, Tianle Liu, Naomi Bashkansky, David Bau, Fernanda Vie´gas, Hanspeter Pfister, and\nMartinWattenberg.Measuringandcontrollinginstruction(in)stabilityinlanguagemodeldialogs,\n2024. URLhttps://arxiv.org/abs/2402.10962.\n11\nPreprint\nWangLing,DaniYogatama,ChrisDyer,andPhilBlunsom. Programinductionbyrationalegener-\nation: Learningtosolveandexplainalgebraicwordproblems. InReginaBarzilayandMin-Yen\nKan (eds.), Proceedings of the 55th Annual Meeting of the Association for Computational Lin-\nguistics(Volume1: LongPapers), pp.158–167, Vancouver, Canada, July2017.Associationfor\nComputational Linguistics. doi: 10.18653/v1/P17-1015. URL https://aclanthology.\norg/P17-1015/.\nNelsonF.Liu,KevinLin,JohnHewitt,AshwinParanjape,MicheleBevilacqua,FabioPetroni,and\nPercy Liang. Lost in the middle: How language models use long contexts. Transactions of the\nAssociationforComputationalLinguistics,12:157–173,2024. doi: 10.1162/tacl a 00638. URL\nhttps://aclanthology.org/2024.tacl-1.9/.\nPengfeiLiu,WeizheYuan,JinlanFu,ZhengbaoJiang,HiroakiHayashi,andGrahamNeubig. Pre-\ntrain, prompt, and predict: A systematic survey of prompting methods in natural language pro-\ncessing. ACMcomputingsurveys,55(9):1–35,2023.\nYaoLu,MaxBartolo,AlastairMoore,SebastianRiedel,andPontusStenetorp.Fantasticallyordered\npromptsandwheretofindthem: Overcomingfew-shotpromptordersensitivity. arXivpreprint\narXiv:2104.08786,2021.\nLiangchen Luo, Yinxiao Liu, Rosanne Liu, Samrat Phatale, Meiqi Guo, Harsh Lara, Yunxuan Li,\nLeiShu,YunZhu,LeiMeng,JiaoSun,andAbhinavRastogi. Improvemathematicalreasoning\nin language models by automated process supervision, 2024. URL https://arxiv.org/\nabs/2406.06592.\nAman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri\nAlon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et al. Self-refine: Iterative refinement\nwithself-feedback.AdvancesinNeuralInformationProcessingSystems,36:46534–46594,2023.\nRajasekhar Reddy Mekala, Yasaman Razeghi, and Sameer Singh. Echoprompt: instructing the\nmodel to rephrase queries for improved in-context learning. arXiv preprint arXiv:2309.10687,\n2023.\nSwaroopMishraandElnazNouri. Helpmethink: Asimplepromptingstrategyfornon-expertsto\ncreatecustomizedcontentwithmodels. arXivpreprintarXiv:2208.08232,2022.\nOpenAI. Openaio1systemcard,2024. URLhttps://arxiv.org/abs/2412.16720.\nBaifengShi,SiyuGai,TrevorDarrell,andXinWang.Toast:Transferlearningviaattentionsteering.\narXivpreprintarXiv:2305.15542,2023.\nMingjie Sun, Xinlei Chen, J Zico Kolter, and Zhuang Liu. Massive activations in large language\nmodels. arXivpreprintarXiv:2402.17762,2024.\nMiracSuzgun,NathanScales,NathanaelScha¨rli,SebastianGehrmann,YiTay,HyungWonChung,\nAakankshaChowdhery,QuocVLe,EdHChi,DennyZhou,etal. Challengingbig-benchtasks\nandwhetherchain-of-thoughtcansolvethem. arXivpreprintarXiv:2210.09261,2022.\nQwenTeam. Qwen3technicalreport,2025. URLhttps://arxiv.org/abs/2505.09388.\nYuan Tian and Tianyi Zhang. Selective prompt anchoring for code generation. arXiv preprint\narXiv:2408.09121,2024.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez,\nLukaszKaiser,andIlliaPolosukhin. Attentionisallyouneed,2023. URLhttps://arxiv.\norg/abs/1706.03762.\nLeiWang,WanyuXu,YihuaiLan,ZhiqiangHu,YunshiLan,RoyKa-WeiLee,andEe-PengLim.\nPlan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large language\nmodels. arXivpreprintarXiv:2305.04091,2023.\nJasonWei,XuezhiWang,DaleSchuurmans,MaartenBosma,FeiXia,EdChi,QuocVLe,Denny\nZhou,etal. Chain-of-thoughtpromptingelicitsreasoninginlargelanguagemodels. Advancesin\nneuralinformationprocessingsystems,35:24824–24837,2022.\n12\nPreprint\nYuyang Wu, Yifei Wang, Ziyu Ye, Tianqi Du, Stefanie Jegelka, and Yisen Wang. When more is\nless: Understandingchain-of-thoughtlengthinllms. arXivpreprintarXiv:2502.07266,2025.\nGuangxuan Xiao, Yuandong Tian, Beidi Chen, Song Han, and Mike Lewis. Efficient streaming\nlanguagemodelswithattentionsinks. arXivpreprintarXiv:2309.17453,2023.\nXiaohanXu,ChongyangTao,TaoShen,CanXu,HongboXu,GuodongLong,Jian-GuangLou,and\nShuaiMa. Re-readingimprovesreasoninginlargelanguagemodels. InProceedingsofthe2024\nConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pp.15549–15575,2024.\nShunyu Yao, Binghui Peng, Christos Papadimitriou, and Karthik Narasimhan. Self-attention net-\nworkscanprocessboundedhierarchicallanguages. arXivpreprintarXiv:2105.11115,2021.\nShunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.\nReAct: Synergizing reasoning and acting in language models. In International Conference on\nLearningRepresentations(ICLR),2023.\nQingru Zhang, Chandan Singh, Liyuan Liu, Xiaodong Liu, Bin Yu, Jianfeng Gao, and Tuo\nZhao. Tell your model where to attend: Post-hoc attention steering for llms. arXiv preprint\narXiv:2311.02262,2023.\nXuechenZhang,XiangyuChang,MingchenLi,AmitRoy-Chowdhury,JiasiChen,andSametOy-\nmak. Selectiveattention: Enhancingtransformerthroughprincipledcontextcontrol. Advancesin\nNeuralInformationProcessingSystems,37:11061–11086,2024.\nHuaixiu Steven Zheng, Swaroop Mishra, Xinyun Chen, Heng-Tze Cheng, Ed H Chi, Quoc V Le,\nandDennyZhou. Takeastepback: Evokingreasoningviaabstractioninlargelanguagemodels.\narXivpreprintarXiv:2310.06117,2023.\nDenny Zhou, Nathanael Scha¨rli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuur-\nmans, Claire Cui, Olivier Bousquet, Quoc Le, et al. Least-to-most prompting enables complex\nreasoninginlargelanguagemodels. arXivpreprintarXiv:2205.10625,2022.\nPeiZhou,AmanMadaan,SrividyaPranaviPotharaju,AdityaGupta,KevinRMcKee,AriHoltzman,\nJay Pujara, Xiang Ren, Swaroop Mishra, Aida Nematzadeh, et al. How far are large language\nmodelsfromagentswiththeory-of-mind? arXivpreprintarXiv:2310.03051,2023.\nPeiZhou,JayPujara,XiangRen,XinyunChen,Heng-TzeCheng,QuocVLe,EdChi,DennyZhou,\nSwaroopMishra,andHuaixiuStevenZheng.Self-discover:Largelanguagemodelsself-compose\nreasoning structures. Advances in Neural Information Processing Systems, 37:126032–126058,\n2024.\n13\nPreprint\nA THE USE OF LARGE LANGUAGE MODELS (LLMS)\nWeleverageLargeLanguageModels(LLMs)primarilyforgrammarcheckingandpolishingforour\nmanuscript.\nB CALCULATING AVERAGE CONFIDENCE SCORES\nWeconductanablationstudytoevaluatedifferentmethodsforcalculatingconfidencescoresfrom\ntoken-level probabilities. Let P = {p ,p ,...,p } represent the set of token-level confidence\ni 1 2 m\nscoresfortokensgeneratedinthecurrentreasoningstepi.\nWecomparethreeapproachesforcalculatingaverageconfidencescoresatsequencelevel:\nHarmonicMean:\nn\np = (5)\nharmonic (cid:80)n 1\ni=1 pi\nGeometricMean:\n(cid:32) n (cid:33)1/n\n(cid:89)\np = p (6)\ngeometric i\ni=1\nArithmeticMean:\nn\n1 (cid:88)\np = p (7)\narithmetic n i\ni=1\nTable6presentstheresultsacrosstworeasoningbenchmarksusingLlama3.1andPhi-4-minimod-\nels. The harmonic mean consistently outperforms both geometric and arithmetic means across all\nsettings. Thisisbecausetheharmonicmeanismoresensitivetolowconfidencevalues,whichbet-\nter captures potential attention drift during reasoning. The geometric mean performs second-best,\nas it also penalizes low values more than the arithmetic mean, though less aggressively than the\nharmonic mean. The arithmetic mean shows the weakest performance, as it can be dominated by\nhigh-confidence tokens and may miss instances where attention drift occurs for specific reasoning\ncomponents.\nC SELF-ANCHOR PROMPT DETAILS\nYouareanexpertproblemsolver. Yourtaskistodecomposethegivenproblemintoaclear,\nstep-by-stepplan,reasoningtheplanandsolvetheproblemstepbystepinJSONformat.\nForeachplanstep,provideakey-valuepair: thekeyistheplanstep(asstated),thevalueis\nthedetailedreasoningandactionforthatstep.\nNow, implement a reasoning structure to follow step-by-step and arrive at correct answers\ninJSONformat. Concludewiththefinalanswerusingtheformat: ”Finalanswer”: ”<your\nanswer>”.\nOriginalproblem: {question}\nD ALTERNATIVE DESIGN\nAs described in Section 2.1, our primary SELF-ANCHOR design anchors attention to the original\nquestionandthecurrentplanstepduringreasoninggeneration. Weinvestigateanalternativedesign\nthat anchors to all prior plan steps in addition to the current step and the original question. The\nmotivation for this alternative is that maintaining attention to all previous planning steps might\nprovideadditionalcontextforthecurrentreasoningstep.\nWecomparetwoanchoringstrategies:\n14\nPreprint\n• SELF-ANCHOR (Primary): Anchorstotheoriginalquestionandcurrentplansteponly,\nwherea ={Question,Plan }\ni i\n• AnchortoAll:Anchorstotheoriginalquestion,currentplanstep,andallpriorplansteps,\nwherea ={Question,Plan ,Plan ,...,Plan }\ni 1 2 i\nTable 7 presents the results comparing these two approaches across AQuA and T4D benchmarks\nusing Llama3.1-8B and Phi-4-mini models. The primary SELF-ANCHOR design consistently out-\nperformsthealternativethatanchorstoallpriorsteps. Thisperformancedifferencemaybebecause\nthe alternative design dilutes attention across too many anchor points, reducing focus on the most\nrelevant current step. In contrast, the primary design maintains sharp focus on the most relevant\ncontextwhileavoidingattentiondilution.\nTable6: Meanselectionablationstudy. Resultsshowaccuracy(%)onAQuA-RATandT4Dbench-\nmarks.\nModel Method AQuA-RAT T4D\nCoT 50.79 26.77\nLLaMA3.1-8B\nSELF-ANCHOR(Harmonic) 55.51 40.01\nSELF-ANCHOR(Geometric) 55.11 35.28\nSELF-ANCHOR(Arithmetic) 54.72 35.99\nCoT 61.81 39.54\nPhi-4-mini\nSELF-ANCHOR(Harmonic) 68.50 49.47\nSELF-ANCHOR(Geometric) 67.72 49.11\nSELF-ANCHOR(Arithmetic) 67.71 48.40\nTable7: Alternativeanchoringdesigncomparison. Resultsshowaccuracy(%)onAQuA-RATand\nT4Dbenchmarks.\nModel Method AQuA-RAT T4D\nCoT 50.79 26.77\nLLaMA3.1-8B SELF-ANCHOR 55.51 40.01\nAnchortoAllPriorSteps 53.54 32.62\nCoT 61.81 39.54\nPhi-4-mini SELF-ANCHOR 68.50 49.47\nAnchortoAllPriorSteps 67.32 47.34\nE IMPLEMENTATION AND EVALUATION DETAILS\nE.1 PROMPTEXAMPLE\nChain-of-Thought.\nLet’sthinkstepbystep.\nPlan-and-solve+.WeadopttheimplementationfromPlan-and-solve+(Wangetal.,2023),formath-\nmaticalreasoningweapplyprompt:\nLet’sfirstunderstandtheproblem,extractrelevantvariablesandtheircorrespondingnumer-\nals,andmakeanddeviseacompleteplan. Then,let’scarryouttheplan,calculateinterme-\ndiatevariables(payattentiontocorrectnumericalcalculationandcommonsense),solvethe\nproblemstepbystep,andshowtheanswer.\nOtherwise,weuse:\nLet’sfirstpreparerelevantinformationandmakeaplan.Then,let’sanswerthequestionstep\nbystep(payattentiontocommonsenseandlogicalcoherence).\n15\nPreprint\nRe-Reading.\n{Question}\nReadthequestionagain:\n{Question}\nE.2 EVALUATIONDETAILS\nWeadoptstandardmetricsusedinpriorwork(Chuangetal.,2024;Wangetal.,2023;Zhouetal.,\n2024), including accuracy and exact match, for AQuA, BBH, T4D, and MATH. For GSM8K and\nStrategyQA,wefollowthefactualaccuracyevaluationprotocolintroducedbyChuangetal.(2024).\nTo ensure consistent answer extraction, we prompt all models to conclude their response with the\nphrase:“Concludewiththefinalanswerusingtheformat:“Finalanswer”:”<youranswer>”where\n<your answer> denotes either a multiple-choice option or a string answer. We then apply task-\nspecificheuristicstoextract<youranswer>fromtheoutput.\nFor the MATH dataset, we randomly sample 200 test instances and manually verify the extracted\nanswerstoensurecorrectness.\nE.3 IMPLEMENTATIONDETAILS\nWefollowthedefinitionsofreasoningstepsegmentationandtaskcomplexityfrom(Wuetal.,2025;\nJinetal.,2024). Theperformancegainofataskiscomputedasthedifferenceinaccuracybetween\ntwomethodsonthattask.\nTo measure the number of reasoning steps, we split the full reasoning chain by “\\n” and remove\nempty lines caused by consecutive breaks (“\\n\\n”). The remaining lines are counted as the CoT\nlength.\nF CASE STUDY\nInthissection,weprovidedaqualitativeexampletoillustratethereasoningtrajectorygeneratedby\neachmethod. Thetaskistodeterminewhetheraprimenumbercanberepresentedbythenumber\nofdaysinaweek. CoT1andRE3immediatelyarriveatanincorrectconclusionbymisidentifying\n7 as a non-prime number. PS+ 2 follows a more structured plan but also makes a critical error\nin its final conclusion, contradicting its own evidence. In contrast, SELF-ANCHOR 4 successfully\ndecomposestheproblem, correctlyidentifies7asaprimenumber, andreachesthecorrectanswer\nbysystematicallyexecutingitsreasoningplan.\nAlgorithm1Chain-of-Thought(CoT)\n1: Question:Canaprimenumberberepresentedbythenumberofdaysinaweek?\n2: Prompt: Let’sthinkstepbystep.\n3: Model Completion: No, a prime number cannot be represented by the number of days in a\nweekbecausethenumberofdaysinaweekis7,whichisnotaprimenumber. Primenumbers\narenumbersgreaterthan1thathavenopositivedivisorsotherthan1andthemselves. Since7\nisdivisibleby1and7,itisnotaprimenumber.\n4: Finalanswer: No\nG NUMERICAL EXPERIMENT RESULT ON BIG-BENCH-HARD\n16\nPreprint\nAlgorithm2Plan-and-Solve(PS+)\n1: Question:Canaprimenumberberepresentedbythenumberofdaysinaweek?\n2: Prompt: Let’sfirstpreparerelevantinformationandmakeaplan. Then,let’sanswertheques-\ntionstepbystep(payattentiontocommonsenseandlogicalcoherence).\n3: ModelCompletion: Step1: GatherInformation: Primenumbersarenaturalnumbersgreater\nthan1thathavenopositivedivisorsotherthan1andthemselves. Thenumberofdaysinaweek\nis7.\n4: Step2: PlantheSolution: Wewillfirstidentifyprimenumberslessthan7toseeifanymatch\nthenumberofdaysinaweek. -Then,wewilldetermineifanyprimenumbercanrepresentthe\nnumberofdaysinaweekbasedonourfindings.\n5: Step3: ExecutethePlan: Primenumberslessthan7are2,3,5,and7. -Amongthese,2,3,and\n5arelessthan7andareindeedprimenumbers. -Noneoftheseprimenumbers(2,3,5)match\nthenumberofdaysinaweek(7).\n6: Step4: AnalyzeandDrawaConclusion: Sincenoneoftheprimenumberslessthan7(2,3,5)\nmatchthenumberofdaysinaweek(7),aprimenumbercannotberepresentedbythenumber\nofdaysinaweek.\n7: Step5: FinalAnswer: ThefinalanswerisNo\nAlgorithm3Re-Reading(RE)\n1: Question:Canaprimenumberberepresentedbythenumberofdaysinaweek?\n2: Prompt: Readthequestionagain\n3: Model Completion: No, a prime number cannot be represented by the number of days in a\nweekbecausethenumberofdaysinaweekis7,whichisnotaprimenumber.\n4: Primenumbersarenumbersgreaterthan1thathavenopositivedivisorsotherthan1andthem-\nselves.\n5: Thenumber7isaprimenumber,butthequestionseemstobeaskingifthenumberofdaysina\nweek(7)canberepresentedbyaprimenumber,whichitalreadyis.\n6: However, if the question is interpreted as asking if there is a prime number that equals the\nnumberofdaysinaweek,theanswerwouldstillbe”No”because7isalreadyaprimenumber.\n7: If the question is asking if the number of days in a week (7) can be represented by any prime\nnumber,theanswerwouldbe”Yes”because7itselfisaprimenumber.\n8: However,thephrasingofthequestionsuggeststhatitisaskingifthenumberofdaysinaweek\ncanberepresentedbyaprimenumberotherthan7,inwhichcasetheanswerwouldbe”No.”\n9: For clarity, I will assume the question is asking if the number of days in a week (7) can be\nrepresentedbyaprimenumberotherthanitself,andthefinalansweris”No.”\n10: ”Finalanswer”: ”No”\nAlgorithm4SELF-ANCHOR\n1: Question:Canaprimenumberberepresentedbythenumberofdaysinaweek?\n2: Prompt:Decomposethegivenproblemintostep-by-stepplan,reasoningtheplanandsolvethe\nproblemstepbystepinJSONformat. Foreachplanstep,provideakey-valuepair: thekeyis\ntheplanstep,thevalueisthedetailedreasoningforthatstep.\n3: ModelCompletion: ”Understandthequestion.”: ”Thequestionasksifaprimenumbercanbe\nrepresentedbythenumberofdaysinaweek.”,\n4: ”Identifythenumberofdaysinaweek.”: ”Thereare7daysinaweek.”,\n5: ”Determineif7isaprimenumber.”: ”Aprimenumberisanaturalnumbergreaterthan1that\nhasnopositivedivisorsotherthan1anditself.”,\n6: ”Checkif7meetsthecriteriaofaprimenumber.”: ”7isgreaterthan1anditsonlydivisorsare\n1and7.”,\n7: ”Finalanswer”: ”Yes”\n17\nPreprint\nTable8: BBHdetails\nBBH\nModel Method\ndisambiguationqa causaljudgement dateunderstanding logicaldeduction salienttranslationerrordetection snarks\nCoT 100 91/187 182 67 110 125\nLlama3.1-8B PS+ 138 108 136 78 124 122\nre-read 124 98 190 85 121 127\nSELF-ANCHOR 152 100 160 128 132 127\nCoT 88/250 71 102 34 95 89\nLlama3.2-3B PS+ 104 63 97 86 98 105\nre-read 74 84 127 40 89 105\nSELF-ANCHOR 131 101 131 101 96 129\nCoT 162/250 113 154 114 149 134\nPhi4-mini-4B PS+ 160 126 138 130 136 124\nre-read 162 115 165 113 135 148\nSELF-ANCHOR 152 116 174 128 140 142\nCoT 183/250 121 174 208 167 148\nQwen3-mini-4B PS+ 179 108 165 207 160 150\nre-read 179 121 203 230 147 154\nSELF-ANCHOR 185 115 193 224 161 150\nCoT 180 120 203 169 152 160\nPhi-4-15B PS+ 180 117 140 186 155 156\nre-read 179 120 221 191 158 154\nSELF-ANCHOR 176 122 218 203 148 161\nCoT 105 125 182 185 172 155\nQwen3-30B PS+ 114 122 172 181 165 156\nre-read 113 125 185 210 174 156\nSELF-ANCHOR 110 123 196 200 160 157\n18\n",
    "tables": [],
    "images": []
  },
  {
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "text": "2025-10-06\nLow-probability Tokens Sustain Exploration in Reinforcement Learning\nwith Verifiable Reward\nGuanhuaHuang1,∗,TingqiangXu1,2,∗†,MingzeWang1,3,†,QiYi1,XueGong1,SihengLi1,4,†,\nRuibinXiong1KejiaoLi1,YuhaoJiang1,BoZhou1‡\n1LLMDepartment,Tencent 2TsinghuaUniversity\n3PekingUniversity 4TheChineseUniversityofHongKong\nAbstract\nReinforcementLearningwithVerifiableRewards(RLVR)haspropelledLargeLanguageModels\nincomplexreasoning,yetitsscalabilityisoftenhinderedbyatrainingbottleneckwhereperfor-\nmanceplateausaspolicyentropycollapses,signalingalossofexploration. Previousmethods\ntypicallyaddressthisbymaintaininghighpolicyentropy,yettheprecisemechanismsthatgovern\nmeaningfulexplorationhaveremainedunderexplored. Ouranalysissuggeststhatanunselective\nfocusonentropyrisksamplifyingirrelevanttokensanddestabilizingtraining. Thispaperinvesti-\ngatestheexplorationdynamicswithinRLVRandidentifiesakeyissue: thegradualelimination\nofvaluablelow-probabilityexploratorytokens,whichwetermreasoningsparks. Wefindthat\nwhileabundantinpre-trainedmodels,thesesparksaresystematicallyextinguishedduringRLVR\nduetoover-penalization,leadingtoadegeneracyinexploration. Toaddressthis,weintroduce\nLow-probabilityRegularization(Lp-Reg). Itscoremechanismregularizesthepolicytowardsa\nheuristicproxydistribution. Thisproxyisconstructedbyfilteringoutpresumednoisetokensand\nre-normalizingthedistributionovertheremainingcandidates. Theresultisaless-noisyproxy\nwheretheprobabilityofreasoningsparksisamplified,whichthenservesasasoftregularization\ntargettoshieldthesevaluabletokensfromeliminationviaKLdivergence. Experimentsshow\nthatLp-Regenablesstableon-policytrainingforaround1,000steps,aregimewherebaseline\nentropy-controlmethodscollapse.Thissustainedexplorationleadstostate-of-the-artperformance,\nachievinga60.17%averageaccuracyonfivemathbenchmarks,animprovementof2.66%over\npriormethods. Codeisavailableathttps://github.com/CarlanLark/Lp-Reg.\n1 Introduction\nThe advent of large reasoning models has reshaped the trajectory of artificial intelligence, with paradigmatic\nexamplesincludingOpenAIO1(OpenAIetal.,2024)andDeepSeek-R1(DeepSeek-AIetal.,2025). Acentral\ntechniqueunderpinningthesesystemsisreinforcementlearningwithverifiablereward(RLVR),whichassigns\nrewardtoverifiablesolutionsthroughrule-basedverification. Thesemodelsgenerateextendedchain-of-thought\n(CoT)reasoning(Weietal.,2023)tosolvechallengingproblemsindomainslikemathematicalolympiads(Heetal.,\n2024b). However,anotablebottleneckemergesduringRLtrainingthatlimitsitsscalability,frequentlyculminating\ninaperformanceplateauandsubsequentcollapse. Thisfailureisconsistentlyaccompaniedbyarapiddecayin\npolicyentropy,indicatingaseverelossofexplorationcapacity(Yuetal.,2025;Cuietal.,2025;Wangetal.,2025).\nPreviousapproacheshaverecognizedthisdecliningexploration,attemptingtoaddressitthroughvariousentropy\ncontrol mechanisms. Methods such as adaptive entropy regularization (He et al., 2025), high entropy change\nblocking(Cuietal.,2025),orselectivetokenupdates(Wangetal.,2025)aimtomaintainhigherentropyasaproxy\nforexploration. However,relyingonoverallentropycanbeanindirectandimprecisetool. Anindiscriminatefocus\non maximizing randomness risks amplifying noise and destabilizing training (O¨mer Veysel C¸ag˘atan & Akgu¨n,\n2025),suggestingadeeperissuebeyondsimplythequantityofrandomness.\nOur analysis suggests the performance bottleneck may stem from the systematic elimination of valuable low-\nprobabilityexploratorytokens.WetermthesetokensReasoningSparks;theyincludewordslike“wait”,“however”,\nor“perhaps”,whichoftenserveaslogicalconnectivesorexpressionsofuncertaintythatnaturallyinitiatediverse\nreasoningpathways(Figure1a).AstheaggregatedviolinplotsinFigure1cshow,standardGRPOtrainingsuppresses\nthelow-probabilitysamplingoftheseimportantexploratorytokens,causingthesuppressionofReasoningSparks.\nFurthermore,wefindthatindiscriminatelyboostingrandomnessamplifiesthelow-probabilitysamplingofirrelevant\ntokens(e.g.,“cost”,“fine”),whicharesemanticallyoutofcontextforthemathematicalreasoningtask. Werefer\ntothelow-probabilityappearanceoftheseirrelevanttokensasnoise. Thisamplificationleadstoanevenfaster\nperformancecollapsethanthebaseline,asshowninFigure1b.\n∗Equalcontribution.\n†WorkcompletedduringaninternshipatTencent.\n‡CorrespondencetoBoZhou:chaysezhou@tencent.com.\n1\n5202\ntcO\n3\n]GL.sc[\n1v22230.0152:viXra\n99% Answer: \\boxed{2}\nThe answer is 2.\nWait, …, Answer: \\boxed{3}\n1%\n(a)ReasoningSparks:low-probabilityexploratorytokensthatinitiatesanewreasoningpath.\n0.65\n0.60\n0.55\n0.50\n0.45\n0 200 400 600 800 1000\nTraining Steps\n)%(\nycaruccA\ntseT\n.gvA\nGRPO\nGRPO + Entropy Loss Lp-Reg\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0.0\n0 200 400 600 800 1000\nTraining Steps\nyportnE\nniarT\n1.00 0.75\n0.50\n0.25\n0.00\n1 256 512\nTraining Steps\nGRPO\nGRPO + Entropy Loss\nLp-Reg\n(b)TrainingDynamics\nytilibaborP\nGRPO GRPO+Entropy loss Lp-Reg\nn=1212 n=1212 n=1212 n=58413 n=34470 n=71346 n=42023 n=74079\n(c)Aggregateddistributionofobservedsamplingprobabilitiesforaclassof\nmeaningfulexploratorytokens(e.g.,“wait”,“however”).\n1.00\n0.75\n0.50\n0.25\n0.00 1 128 256\nTraining Steps\nytilibaborP\nGRPO GRPO+Entropy loss Lp-Reg\nn=192 n=192 n=192 n=324 n=2092 n=230 n=334 n=974 n=240\n(d)Aggregateddistributionofobservedsamplingprobabilitiesforaclassof\nirrelevanttokens(e.g.,“cost”,“fine”).\nFigure1: Selectivelypreservinglow-probabilitytokensiskeytoovercomingperformanceplateausinreasoning\nRL. (a) An illustration of a reasoning spark. (b) Standard GRPO training reaches a performance plateau and\ncollapses,accompaniedbydecayingentropy. Anindiscriminateentropybonus(GRPO+EntropyLoss)leadstoan\nevenfastercollapse. (c)Werevealthecause: GRPOsystematicallysuppressesthelow-probabilitysamplingof\nimportantexploratorytokens(like“wait”),andforcesthesetokens’samplingdistributionstocollapsetowardshigh\nprobabilities. Ent-Lossfailstofixthis. Incontrast,ourmethod,Lp-Reg,successfullypreservesahealthy,wide\ndistribution,sustainingexploration. (d)Thefailureofentropybonusesisexplainedbytheirindiscriminatenature:\ntheyamplifythelow-probabilitysamplingofirrelevanttokens,creatingnoiseandtherebydegradingexploration\nquality.Theaggregatedstatisticsin(c)and(d)demonstrateasystemiceffectbeyondsingle-tokeninstances.Detailed\nplotsforindividualtokensareavailableinAppendixB.1.\nThesefindingspresentacentralchallenge: asuccessfulexplorationstrategyshouldprotectvaluablereasoning\nsparkswithoutsimultaneouslyamplifyingthedestructiveeffectsofirrelevantnoise. Toaddressthischallenge,\nwe introduce Low-probability Regularization (Lp-Reg). The primary goal of Lp-Reg is to preserve valuable\nlow-probability tokens via regularization. To avoid amplifying noise, the method leverages a key observation:\nwithinthelow-probabilityrange,meaningfulexploratorytokens(like“wait”)consistentlyexhibitahigheraverage\nprobability than irrelevant noise (like “cost”) in the immediate next-token prediction. Based on this statistical\ndistinction, Lp-Regfirstdiscardslow-probabilitytokenspresumedtobenoiseusingaprobabilitythreshold. It\nthenredistributestheprobabilitymassfromthesediscardedtokensamongtheremainingcandidates. Thisprocess\nconstructsaless-noisyproxydistributionwherevaluablelow-probabilitytokensarepreservedandtheirrelative\nprobabilities amplified. Finally, Lp-Reg penalizes the deviation of the original policy from this proxy using a\nforwardKLdivergence,whichselectivelyprotectsthelow-probabilitytokensthatwerepreservedintheless-noisy\nproxydistribution.\nOur experimental evaluation demonstrates the effectiveness of Lp-Reg. Our method enables stable on-policy\ntrainingforaround1,000steps,aregimewheremanyentropy-controlmethodshavecollapsed,resultinginbetter\nperformance.Onfivewidelyusedmathbenchmarks,thisresultsina60.17%averageaccuracyonQwen3-14B-Base,\nimprovinguponpriormethodsby2.66%. Ourcontributionsaresummarizedasfollows:\n• Incontrasttopriorworkfocusingonoverallpolicyentropy, weidentifythesuppressionofreasoning\nsparksasakeyissueandprovideevidencethattheirpreservationiscrucialforsustainedperformance.\n• WeintroduceLow-probabilityRegularization(Lp-Reg),amethodthatcreatesamorestableexploratory\nenvironmentbyfilteringoutpresumedmeaninglessnoisetoprotecttheremaininglow-probabilitytokens.\n• WedemonstratethroughextensiveexperimentsthatLp-Regachievesstate-of-the-artperformance,while\nalsoenablingstableon-policytrainingoverextendedperiodswherebaselinescollapse.\n• Weprovideacomprehensiveanalysisshowingthatourapproachoffilteringpresumedmeaninglessnoise\nyieldssuperiorresultscomparedtoindiscriminateentropy-controlmethods.\n2\n2 RelatedWork\nReinforcementlearningforLLMs Recently,reinforcementlearninghasbecomethedominantframeworkfor\nenhancingthereasoningabilitiesoflargelanguagemodels(LLMs)(OpenAIetal.,2024;DeepSeek-AIetal.,2025).\nByleveragingautomaticcheckersorsymbolicverification,reinforcementlearningwithverifiablerewards(RLVR)\nachievedfurtherbreakthroughsinimprovingthereasoningcapabilityofLLMs(Shaoetal.,2024a;Yangetal.,2025;\nTeametal.,2025). BasedonRLVRandGRPO(Shaoetal.,2024a),subsequentmethodssuchasDAPOYuetal.\n(2025),VAPO(Yueetal.,2025),andotherpolicyoptimizationvariants(Zhaoetal.,2025;Cuietal.,2025;Zheng\netal.,2025)havebeenproposedtoimprovethestability,efficiency,andscalabilityofRLforreasoningmodels.\nEntropycollapseinRLtraining ArecurringdifficultyintrainingreasoningmodelswithRListherapidcollapse\nofpolicyentropyduringtheearlystagesoftraining. Thisphenomenon,whichreflectsexcessiveexploitationand\ninsufficientexploration,hasbeenwidelyrecognizedasabottleneckforscalingRLinreasoningmodels. Tomitigate\ncollapse,researchershaveexploredseveraldirections,includingselectivelyregularizingupdatesathigh-entropy\n“forking”tokens(Wangetal.,2025),amplifyingadvantagesatexploratorypositions(Chengetal.,2025),modifying\nclipping strategies (Yu et al., 2025; Zhao et al., 2025; Cui et al., 2025; Zheng et al., 2025), or doing weight\nclipping (MiniMax et al., 2025; Su et al., 2025). While these methods primarily operate by monitoring policy\nentropy,whichiscorrelationalratherthancausaltoexploration,ouranalysisdelvesdirectlyintothenext-token\npredictiondistribution. Thisallowsforamoresemanticallygroundedandcausally-informedinvestigationofthe\nprobabilitiesofindividualcandidatesandtheirroleinexplorationdynamics.\nIntrinsicconfidenceofLLMs AsthecapabilitiesofLargeLanguageModels(LLMs)haverapidlyadvanced,\ntheyhavedemonstratedanincreasinglystrongandreliablesenseofintrinsicconfidence(Sauravetal.,2022;Loka\netal.,2024;Amiretal.,2025). Researchinvestigateshowtheseintrinsicconfidencesignals,oftenreflectedinthe\nnext-tokenpredictiondistribution,canguidecomplexreasoningandexploration(Amirhoseinetal.,2025;Xuezhi\n&Denny,2024;Xuandongetal.,2025). Studieshaveshownthattokenswithhigherrelativeprobabilitiesinthe\nnext-tokenpredictionareoftenmorecontextuallyappropriatethantheirlower-probabilitycounterparts(Nguyen\netal.,2025;Xuetal.,2025;Fuetal.,2025). Buildingonthis,someworkhasexploredentropyminimization,which\nsharpensthemodel’sconfidencedistribution. Thisapproachcanimproveinferenceperformancebyencouragingthe\nmodeltocommittoconsistentandhigh-confidencesolutionpaths(Gaoetal.,2025;Agarwaletal.,2025). Ourwork\nbuildsuponasimilarinsight,leveragingthemodel’sintrinsicconfidencetodistinguishbetweenvaluablereasoning\nsparksandirrelevantnoisewithinthislow-probabilityrange.\n3 Preliminaries\n3.1 ReinforcementLearningwithVerifiableRewards\nReinforcementlearning(RL)hasplayedacriticalroleinLLMs(Murphy,2024). Formally,\nJ RL (θ) =E (q,a)∼D,o∼πθ (·|q) (cid:2) r(o,a) (cid:3) , (1)\nwherer(o,a)denotestherewardassignedtoanoutputogivenareferenceanswera. Inreinforcementlearningwith\nverifiablerewards(RLVR),thisrewardiscomputedthroughrule-basedfunctions,suchasMath-Verify1. Recent\nstudieshavedemonstratedthatlarge-scaleRLVRencouragesmodelstoperformmoredeliberativereasoningby\nproducingextendedchainsofthoughtpriortothefinalprediction,therebysubstantiallyimprovingtheircapacity\nto solve complex problems (DeepSeek-AI et al., 2025). In practice, Eq. 1 is typically optimized using policy\ngradientmethods,suchasProximalPolicyOptimization(PPO)(Schulmanetal.,2017)andGroupRelativePolicy\nOptimization(GRPO)(Shaoetal.,2024b).\n3.2 Group-RelativePolicyOptimization\nGRPOisarepresentativeactor-onlypolicygradientmethodforoptimizingLLMs.Itdirectlyestimatestheadvantage\nofeachtokenbyleveragingmultiplesamplesdrawnfromthesameprompt. Formally,theadvantageisdefinedas\nR(o )−mean(G)\nA = i , (2)\ni,t std(G)\nwhere{o ,...,o }areindependentoutputssampledfromthesameprompt,withgroupsizeG,G = {R(o ),...,R(o )}\n1 G 1 G\ndenotes their associated rewards, and R(o ) is the reward of output o. In this formulation, A represents the\ni i i,t\nadvantageofthe t-thtokenin o. ThepolicyisthenoptimizedonthebasisoftheseadvantagesusingthePPO\ni\n1https://github.com/huggingface/Math-Verify\n3\nsurrogateobjective:\nJ (θ) =E\nGRPO (q,a)∼D,{oi }\ni\nG\n=1\n∼πθold (·|q)\n1 ∑ G 1 ∑ |oi | (cid:104) (cid:2) (cid:0) (cid:1) (cid:3) (cid:105) (3)\nmin r A , clip r ,1−ϵ,1+ϵ A −βD (π ∥π ) ,\nG |o | i,t i,t i,t i,t KL θ ref\ni=1 i t=1\nwhereβcontrolsthestrengthofKLregularizationbetweenthecurrentpolicyπ andthereferencepolicyπ . The\nθ ref\nprobabilityratio\n(cid:0) (cid:1)\nr i,t = π π θo θ ld (cid:0) o o i,t i,t | | q q ,o ,o i,< i,< t t (cid:1) (4)\nservesastheimportancesamplingweightforoff-policytraining,whereπ denotesthebehaviorpolicy. The\nθold\nhyperparameterϵspecifiestheclippingratio,whichconstrainstheupdatedpolicyfromdeviatingexcessivelyfrom\nthebehaviorpolicy,therebyensuringstabilityduringoptimization.\n4 Low-probabilityRegularization\nToaddresstheprematureeliminationofvaluablereasoningsparks,weproposearegularizationmethodtermedLow-\nprobabilityRegularization(Lp-Reg). Thismethodisdesignedtobeintegratedintopolicygradientalgorithmsto\ncreateamorestableexploratoryenvironment. Thecentralideaistoleveragethemodel’sownpredictivedistribution\ntoconstructaless-noisyproxyforregularization,preservinglow-probabilitytokens.\n4.1 ProxyDistributionπproxy\nThefoundation ofLp-Reg istheconstruction ofaproxy distribution, whichrepresentsa filteredvariantofthe\ncurrentpolicyπ . Itisconstructedintwosteps:\nθ\n0.3\n0.2\n0.1\n0.0\n0 2 4 6 8 10 12 14 16 18\nToken Index\nytilibaborP\n(a) Original Policy (b) Renormalized Policy proxy\nRenormalized sum = 1\n=0.02\n0 2 4 6 8 10 12 14 16 18\nToken Index\nFigure2: Anexampleofprobabilityrenormalization. πproxy assignszeroprobabilitytotokenswithπ\nθ\n≤ τand\nrenormalizestheprobabilitymasstotokenswithπ > τ.\nθ\n1. FilteringNoiseTokens: Wefirstfilteroutasetoflow-confidencetokens,whicharepresumedtobenoise,\ndefinedasthosewhoseprobabilityπ (o|·)isunderathresholdτ. Thisthresholdcontrolsthefilteringstrategy,\nθ\nforwhichweexploretwoprimarychoices:\n• Fixedthreshold: Asimpleapproachwhereτisaconstanthyperparameter,e.g.,0.02.\n• Min-pthreshold: Following(Nguyenetal.,2025),τ isdefinedrelativetothepeakprobability: τ =\nκ·max o′∈V π θ (o′|·), where κ ∈ (0,1) is a hyperparameter. This makes the filtering adaptive to the\ndistribution’ssharpness.\nOur primary experiments employ the min-p strategy for its adaptiveness, though fixed thresholds are also\nshowntobeeffectiveinourablationstudies.\n2. ProbabilityRenormalization: AsshowninFigure2,theproxydistributionπproxy assignszeroprobabilityto\ntokensfilteredoutinthepreviousstepandrenormalizestheprobabilitymassacrosstheremainingtokens:\n(cid:40) πθ (o|·) ifπ (o|·) > τ\nπproxy (o|·) = ∑ o′s.t.πθ(o′|·)>τ πθ (o′|·) θ . (5)\n0 otherwise\nThisprocesseffectivelytreatstokenswithlowrelativeprobabilitiesaspotentialnoise,whilepreservingall\notherstoformahigh-confidencereference.\n4\n4.2 Low-probabilityRegularizationObjective\nThe Low-probability Regularization (Lp-Reg) penalty is integrated into the GRPO framework as a selective\nregularizationterm. Thefinalobjectivefunctionis:\nJ(θ) =E (cid:34) 1 ∑ G ∑ |oi | (cid:104) clip(r (θ),0,U)·A\nB∼D,(q,a)∼B,{oi } i G =1 ∼πθold (·|q) ∑ i G =1 |o i | i=1t=1 i,t i,t\n(cid:104) (cid:105)\n−β·I π θ (o i,t |q,o i,<t ) < δ ρ B∧πproxy (o i,t |q,o i,<t ) >0∧A i,t <0 (6)\n(cid:35)\n(cid:105)\n·D\nKL\n(πproxy (·|q,o\ni,<t\n)∥π\nθ\n(·|q,o\ni,<t\n))\nThefirsttermisthepolicygradientobjectivefromGRPO.Wemodifyitsclippingbyremovingthelowerboundto\navoidclippinglow-probabilityexploratoryactionsandaddingalargeupperboundUfornumericalstability.\nThesecondtermistheLp-Regpenalty,designedtoprotectreasoningsparks. Itisactivatedbytheindicatorfunction\nI[·] onlyfortokensthatsatisfythreeconditionssimultaneously: first, theirsamplingprobability π isbelowa\nθ\ndynamiclow-percentilethresholdδB,whichiscalculatedasthelowestρ-thpercentileofthesamplingprobabilities\nρ\nofalltokenswithinthecurrenttrainingbatchB;second,theirprobabilityintheproxydistributionπproxy isgreater\nthan zero; and third, the token receives a negative advantage signal (A < 0). This final condition ensures\ni,t\nthe regularization applies exclusively to tokens receiving a negative learning signal, preventing their potential\nover-penalizationwhileleavingupdatesfrompositiveexperiencesunaffected.\nWeusetheforwardKLdivergence,D\nKL\n(πproxy ∥π\nθ\n)astheregularizationfunction. Itimposesasignificantpenalty\nwhenπ\nθ\n(o|·)approacheszeroforatokenowithnon-zeroprobabilityinπproxy ,providingatargetedpenaltyagainst\ntokeneliminationwithoutforcingthepolicytostrictlymatchtheheuristicproxydistribution.\n5 Experiments\n5.1 ExperimentalSetup\nBaselines We compare Lp-Reg against a suite of strong baselines, including a foundational algorithm and\nseveralstate-of-the-artmethodsdesignedtoenhanceexplorationthroughentropycontrol. Ourprimarybaseline\nisGRPO(Shaoetal.,2024a),avalue-freepolicyoptimizationalgorithmthatemploysgroup-relativeadvantage\nestimation, making it a common choice for RLVR. To represent classical entropy regularization methods, we\nimplementGRPO+EntropyLoss,whichdirectlyincorporatestheprinciplesofMaximumEntropyRLbyadding\na policy entropy bonus to the GRPO objective function. We also compare against several advanced methods:\nClip-Higher(Yuetal.,2025),acorecomponentofDAPOthatencourageshigherentropybyusinganasymmetric\nclippingrangeinthePPOobjective;SelectiveHigh-EntropyTraining(80/20)(Wangetal.,2025),amethodthat\nrestrictspolicygradientupdatestoonlythetop20%oftokenswiththehighestgenerationentropy;KL-Cov(Cui\netal.,2025),whichpreventsentropycollapsebyapplyingaselectiveKL-divergencepenaltytotokenswiththe\nhighestcovariancebetweentheirlogprobabilitiesandadvantages;andGSPO(Zhengetal.,2025),whichmodifies\ntheclippingmechanismtooperateatthesequenceleveltopromotehighertrainingentropy.\nTrainingSettings Allexperimentsareconductedwithintheverl(Shengetal.,2024)frameworktoensurea\nstandardizedandfaircomparison. Weusetwobasemodelsforourexperiments: Qwen3-14B-BaseandQwen2.5-\n32B.The14Bmodelsaretrainedon32NVIDIAH20GPUs,whilethe32Bmodelistrainedon64NVIDIAH20\nGPUs, withanaveragetrainingsteptimeof600−1400seconds. Forthereinforcementlearningfromverifier\nrewards(RLVR)phase,modelsaretrainedontheDapo-Math-17KYuetal.(2025)datasetwithamaximumresponse\nlengthof8,192tokens. Weuseaglobalbatchsizeof256. Foroff-policymethods,weuseamini-batchsizeof\n32,resultingin8gradientupdatesperrollout. Toensureafaircomparison,a“step”inourexperimentalresults\nconsistently refers to a single rollout for all methods. Consequently, each reported step for off-policy training\ncorrespondsto8gradientupdates. Aconstantlearningrateof1×10−6isappliedwithoutawarmupschedule. We\nsetthegroupnumberas8forallGRPO-basedmethods. Toensurenumericalstability,wesetthepolicygradient’s\nclippingbysettingtheupperboundoftheimportancesamplingratiotoU =10. ForourproposedLp-Reg,which\nusesthemin-pthreshold,wesettheprobabilitypercentilethresholdρto0.5%forQwen2.5-32B-Baseand1%for\nQwen3-14B-Base,theKLregularizationcoefficientβto1.0,andthemin-pratioκto0.02. Theproxydistribution,\nπproxy ,isconstructedfromthedata-generatingpolicy(π\nθold\nintheoff-policysettingandthecurrentpolicyπ\nθ\nin\ntheon-policysetting). Forallbaselinemethods,weadoptthehyperparametersspecifiedintheiroriginalpublic\nimplementationstoensureafaithfulreproduction. SpecificallyfortheGRPO+EntropyLossbaseline,wesetthe\nentropycoefficientto0.002withintheverlframework.\n5\nEvaluation Forevaluation,weassessmodelperformanceacrossfivediversemathematicalreasoningbenchmarks:\nAIME24(MAA),AIME25(MAA),MATH-500(Hendrycksetal.,2021),OlympiadBench(Heetal.,2024a),and\nMinervaMath(Lewkowyczetal.,2022). Following(Cuietal.,2025), weemploydistinctdecodingstrategies\nbasedonthebenchmark. ForAIME24andAIME25,whichhavesmallertestsets,weusesampleddecodingwitha\ntemperatureof0.6andgenerate16independentresponsesperproblemtoobtainarobustperformanceestimate. For\ntheremainingbenchmarks,includingMATH-500,OlympiadBench,andMinerva,weutilizegreedydecodingto\nevaluateperformance.\n5.2 Results\nAsshowninFigure3andTable1,Lp-Regachievesstate-of-the-artperformanceacrossfivechallengingmathematical\nreasoningbenchmarksonboth14Band32Bmodelscales. OntheQwen3-14Bmodel,on-policyLp-Regsetsa\nnewbenchmarkwithanaverageaccuracyof60.17%,surpassingthenextbestmethod,80/20,by2.66%. Notably,\nLp-Reg’sadvantageismorepronouncedonthenewerQwen3-14BbasemodelcomparedtotheolderQwen2.5-32B.\nWe hypothesize that as base models improve, their capacity for nuanced, low-probability reasoning increases,\ncreating a richer substrate for the emergence of valuable reasoning sparks, which Lp-Reg can then effectively\nprotectandleverage.\nOurexperimentsconsistentlyshowthesuperiorityofon-policytrainingoveroff-policymethodsacross14Band\n32Bscales. Thisisduetotheinherentstabilityofon-policyupdates,whichavoiddistributionshiftscausedby\nmismatcheddata-samplingandtrainingpolicies. Off-policymethods,suchasClip-Higher,oftenrelyonimportance\nsamplingclipping,leadingtoinstability. WhilecompetitiveonQwen2.5-32B,Clip-Higher’sperformancedropson\nQwen3-14B,highlightingitsfragility. Incontrast,Lp-Reg’sself-contained,policy-intrinsicregularizationensures\nitseffectivenessinbothon-policyandoff-policysettings,unlikecompetingmethodsthatareheavilyrelianton\noff-policyimportancesampling.\nBeyondrawperformance,Lp-Regdemonstratesadistinctentropysignatureindicativeofahealthyexploration-\nexploitationbalance.AsshowninFigure3,methodslikeClip-Higherinduceacontinuous,oftenartificialincreasein\npolicyentropy. Lp-Reg,however,facilitatesadynamic,multi-phaseentropytrajectory:entropyinitiallydecreasesas\nthemodellearnscorereasoningpatterns,thengraduallyincreasestofosterexplorationasperformanceimproves,and\nfinallystabilizeswithinahealthyrangeasaccuracyconverges. Thisadaptivebehaviorstemsfromourconfidence-\nawareregularization,whichselectivelyprotectsreasoningsparkswithoutamplifyinglow-probabilityout-of-context\nirrelevantnoise.\nMethod AIME24 AIME25 Math-500 Minerva OlympiadBench Avg.\nQwen2.5-32B-Base\nGRPO(Shaoetal.,2024a)(off.) 30.63 22.29 88.00 41.18 54.37 47.29\nGSPO(Zhengetal.,2025)(off.) 33.33 22.29 87.60 48.53 55.56 49.46\nClip-Higher(Yuetal.,2025)(off.) 38.33 29.79 87.60 45.22 56.44 51.48\nKL-Cov(Cuietal.,2025)(off.) 35.62 27.50 87.40 44.49 55.11 50.02\n80/20(Wangetal.,2025)(off.) 38.12 28.75 87.00 45.22 58.37 51.49\nLp-Reg(off.) 37.71 24.58 90.20 40.81 59.70 50.60\nGRPO(Shaoetal.,2024a)(on.) 28.54 22.50 86.60 44.85 60.30 48.56\nGRPO+EntropyLoss(on.) 3.75 1.88 60.80 27.94 22.22 23.32\n80/20(Wangetal.,2025)(on.) 32.50 28.54 89.40 45.59 57.63 50.73\nLp-Reg(on.) 38.12 27.08 90.00 46.32 61.19 52.54\nQwen3-14B-Base\nGRPO(Shaoetal.,2024a)(off.) 34.38 27.08 89.20 49.26 55.70 51.13\nGSPO(Zhengetal.,2025)(off.) 41.46 34.58 88.60 50.74 59.85 55.05\nClip-Higher(Yuetal.,2025)(off.) 41.67 32.71 95.00 47.43 64.00 56.16\nKL-Cov(Cuietal.,2025)(off.) 49.17 34.79 93.00 47.43 62.07 57.29\n80/20(Wangetal.,2025)(off.) 43.96 34.58 91.80 48.16 60.89 55.88\nLp-Reg(off.) 46.25 34.17 92.40 48.16 64.44 57.08\nGRPO(Shaoetal.,2024a)(on.) 46.04 34.38 93.00 48.53 65.19 57.43\nGRPO+EntropyLoss(on.) 37.29 25.21 88.20 46.32 54.96 50.40\n80/20(Wangetal.,2025)(on.) 47.29 32.50 91.60 50.37 65.78 57.51\nLp-Reg(on.) 50.83 37.92 94.40 49.26 68.44 60.17\nTable1: Mainresultsonfivemathematicalreasoningbenchmarksacrosstwomodelscales. Ourmethod,Lp-Reg,\nachievesthebestaverageperformanceonbothmodels. On-policy(on.) andoff-policy(off.) trainingmethodsare\nhighlightedwithdistinctcolors.\n6\n8000\n7000\n6000\n5000\n4000\n3000\n2000\n1000\n0\n0 200 400 600 800 1000\nTraining Steps\nhtgneL\nesnopseR\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0.0\n0 200 400 600 800 1000\nTraining Steps\nyportnE\nniarT\n0.60\n0.55\n0.50\n0.45\n0 200 400 600 800 1000\nTraining Steps\n)%(\nycaruccA\ntseT\n.gvA\nClip-Higher(off.) GRPO(on.) Lp-Reg(on.)\nFigure3: TrainingdynamicsontheQwen3-14B-Basemodel. Tobestillustratetheperformancedifferences,we\ncomparethetop-performingmethods. Lp-Regdemonstratessuperiorandmorestableperformancethroughout\ntraining. FulltrainingdynamicsfortheQwen2.5-32BmodelareavailableinAppendixA.1.\n8000\n7000\n6000\n5000\n4000\n3000\n2000\n1000\n0\n0 200 400 600 800 1000\nTraining Steps\nhtgneL\nesnopseR\n1.4\n1.2\n1.0\n0.8\n0.6\n0.4\n0.2\n0.0\n0 200 400 600 800 1000\nTraining Steps\nyportnE\nniarT\n0.60\n0.50\n0.40\n0.30\n0.20\n0 200 400 600 800 1000\nTraining Steps\n)%(\nycaruccA\ntseT\n.gvA\nGRPO Lp-Reg w/ fixed Lp-Reg w/o Lp-Reg w/ dynamic\nFigure4: AblationstudiesforcorecomponentsofLp-RegontheQwen3-14B-Basemodel. Theresultsconfirmthat\ntargetingournoisefilteringthresholdτiscriticalforstableperformance. Theadaptivenessofthemin-pthresholdis\nalsoshowntobebeneficialoverafixedone.\n5.3 AblationStudy\nWeconductaseriesofablationstudiestoanalyzethecorecomponentsofLp-Regandvalidateourkeydesign\nchoices.\nImportance of Noise Filtering. Lp-Reg only protects tokens deemed meaningful by the proxy distribution\n(πproxy >0). Totestthis,weremovethefilterandforkalltokensbelowthenoisethresholdτfromcontributing\ntogradientupdating(Lp-Regw/oτ). Figure4showsthatthisleadstoacatastrophicperformancecollapseand\nentropyexplosion. Thisconfirmsthatfilteringiscriticaltoignoretheextremetailofthedistribution,whichconsists\nofirrelevantnoisethatdestabilizestrainingifregularized.\nDynamicvs. FixedThreshold. Weconductacomparisonbetweenthedynamicmin-pnoisethreshold(Lp-Reg\nw/dynamicτ)andthefixednoisethreshold(Lp-Regw/fixedτ)inSection4.1. AsshowninFigure4,thefixed\nthreshold underperforms compared to the dynamic threshold, which we adopt as the default. However, it still\nsignificantlysurpassesthestandardGRPO.Thisindicatesthatwhilethecorefilteringprincipleiseffective,the\ndynamicnatureofmin-pprovidesamorerobustestimateofthemodel’sconfidenceacrossdifferentcontexts,better\npreservinggenuinereasoningsparks.\nWeconductfurtherablationstudiesonthehigh-entropytokenregularizationandreverseKLregularization. For\ndetailedresultsandanalysis,pleaserefertoAppendixA.2.\n6 Analysis\nTounderstandthemechanismsbehindLp-Reg’sperformance,weconductaseriesofanalysesfocusingonhowit\novercomestheexplorationbottleneckbytargetingandpreservingvaluablereasoningtokens.\n6.1 Probability-EntropyDistributionofExploratoryTokens\nWebeginbyexploringthedistinctionbetweenlow-probabilitytokensandhigh-entropytokens. Figure5highlights\nthiscontrastbycomparingtokensfromthetop1%lowestprobabilitywiththosefromthetop1%highestentropy.\nThedifferenceisstriking: low-probabilitytokensfrequentlyincludesemanticallymeaningfulexploratorymarkers\nsuchas“But,”“Wait,”“Perhaps,”and“Alternatively,”whichoftensignalashiftinthereasoningtrajectory. In\n7\nHigh Entropy Tokens Low Probability Tokens\nFigure5: Thewordcloudstatistics.\ncontrast, high-entropytokensaredominatedbycommonfunctionalterms(e.g., “sqrt,” “times”)orformatting\nsymbols(e.g.,\\n),whichcarrylittleexploratoryintent. Thisexplainswhyentropy-basedregularizationoftenfails\ntoenhanceexploration: itconfusesnoisewithexploration.\nHowever, thesetoflow-probabilitytokensisalsonotuniformlyuseful. Italsoincludesnoisyartifactssuchas\nspuriousnewlinecharacters(\\n)orformattingdebris,whoseregularizationcandestabilizetrainingratherthan\nenhancereasoning. Tomitigatethis,Lp-Regappliesathresholdτthatfiltersoutsuchnoise. Ablationstudiesin\nSection5.3confirmthenecessityofthisstep: removingthethresholdresultsinunstabletrainingdynamicsand\ndegradedreasoningperformance. Thus,Lp-Reg’seffectivenessstemsnotonlyfromtargetinglow-probabilitytokens\nbutalsofromselectivelyexcludingirrelevantnoise.\n6.2 SamplingDynamicsofExploratoryTokens\n3.5\n3.0\n2.5\n2.0\n1.5\n1.0\n0.5\n0.0\n0.0 0.2 0.4 0.6 0.8 1.0\nSampled Probability\nyportnE\nGRPO\nn = 42023\nMean Prob: 0.9099 ± 0.2036\nMean Entropy: 0.1576 ± 0.2717\n10\n8\n6\n4\n2\n0\n0.0 0.2 0.4 0.6 0.8 1.0\nSampled Probability\nyportnE\nGRPO+entropy loss\n5\nn = 34470\nMean Prob: 0.4565 ± 0.3172\nMean Entropy: 1.5960 ± 1.4706\n4\n3\n2\n1\n0\n0.0 0.2 0.4 0.6 0.8 1.0\nSampled Probability\nyportnE\nLp-Reg\nn = 74079\nMean Prob: 0.7169 ± 0.3100\nMean Entropy: 0.6183 ± 0.5867\nFigure6: Probability–Entropyscatterplotsofexplorativetokens,displayingarandomsampleof5%ofalldata\npoints.\nFigure6showstheprobability–entropydistributionsofkeyexplorativetokens(“but”,“wait”,“perhaps”,“alterna-\ntively”,and“however”)underthreemethods: GRPO,GRPO+EntropyLoss,andourLp-Reg.\nWiththebaselineGRPO,thesetokensareconcentratedinlow-entropy,high-probabilityregions. Inthiscase,tokens\nlike“wait”tendtoappearonlywhenthemodelisalreadyconfident,turningthemintodeterministicpatternsrather\nthaninitiatinganewexplorationpathwithuncertainty.\nAddinganentropylosschangesthisbehavior,butinanuncontrolledway. Somesampled“wait”tokensappearat\nextremelyhighentropylevels(sometimesexceeding10),whichsuperficiallyboostsdiversitybutproduceslittle\nusefulexploratorysignal. Thesescatteredoccurrencesdonotintegratemeaningfullyintothereasoningprocess.\nOurLp-Regmethodyieldsamorebalanceddynamic. Explorativetokensaresampledacrossabroadrangeof\nentropy values, from high probability to low probability states. This balance prevents their probabilities from\ncollapsingundernegativefeedbackwhilekeepingtheminformativeforreasoning. Asaresult,tokenslike“wait”\nremainviableoptionsthroughouttraining,allowingthemodeltoexplorealternativereasoningpathsratherthan\noverfittingtofixedusagepatterns.\nFigure 7 further compares the frequency of explorative tokens (“but”, “wait”, “perhaps”, “alternatively”, and\n“however”) under GRPO and Lp-Reg. Our method consistently maintains a higher fraction of these tokens,\ndemonstratingthatLp-Regnotonlybroadenstheirprobability–entropydistributionbutalsosustainstheirpractical\nusethroughouttraining.\n8\n0.0035\n0.0030\n0.0025\n0.0020\n0.0015\n0.0010\n0.0005\n0.0000\nbut wait perhaps alternativelyhowever\nycneuqerF\nStep 256\n0.0035\n0.0030\n0.0025\n0.0020\n0.0015\n0.0010\n0.0005\n0.0000\nbut wait perhaps alternativelyhowever\nycneuqerF\nStep 512\n0.0035\n0.0030\n0.0025\n0.0020\n0.0015\n0.0010\n0.0005\n0.0000\nbut wait perhaps alternativelyhowever\nycneuqerF\nGRPO Lp-Reg\nStep 768\nFigure7: Frequencyofexplorativetokensduringtraining.\n6.3 ProbabilisticDistinctionbetweenReasoningSparksandNoise\n0.008\n0.007\n0.006\n0.005\n0.004\n0.003\n50 100 150 200 250 300 350 400\nTraining Step\nytilibaborP\nnaeM\nOurintroductionestablishedachallengeforasuccess-\nfulexplorationstrategy: itmustprotectvaluable,low-\nMean Probability of Tokens in (0, 0.1)\nprobability reasoning sparks without simultaneously\namplifying the destructive effects of irrelevant noise. Exploratory Token\nIrrelevant Token\nThisraisesacriticalquestion: isthereasystemic,ob-\nservabledifferencebetweenthesetwoclassesoftokens\nwithinthelow-probabilityrangethatourmethodcan\nexploit?\nToinvestigatethis,weanalyzethenext-tokenpredic-\ntiondistributionthroughoutthetrainingprocess.Dueto\nstoragelimitations,wefocusouranalysisonthetop-64\nmostprobabletokens, butspecificallyexaminethose\nwithinalow-probabilityrange(0to0.1)toisolatethe\nphenomenon from high-probability tokens. Figure 8\nplotstheaverageprobabilityoftwodistinctclassesof\nFigure 8: Probabilistic distinction between exploratory\ntokensovertime: agroupofmeaningfulexploratoryto-\nand irrelevant tokens across training steps in standard\nkens(e.g.,“wait”,“perhaps”)andagroupofirrelevant\nGRPOtraining.\ntokens(e.g.,“cost”,“fine”).\nTheresultsrevealaclearandconsistentstatisticaldis-\ntinction:acrossalltrainingstages,theaveragenext-tokenprobabilityofmeaningfulexploratorytokensispersistently\nhigherthanthatofirrelevanttokens. ItcanbeattributedtotheintrinsicconfidenceofLLMs(Nguyenetal.,2025;\nXuetal.,2025;Fuetal.,2025). Thispersistentprobabilisticgapprovidesthefoundationaljustificationforour\nLp-Regdesign.Itsuggeststhatwhileaperfectseparationisnotpossible,aprobabilitythresholdτ,asdefinedforour\nproxydistributioninSection4.1,canserveasaprincipledfilteringmechanism. Bysettingsuchathreshold,wecan\neffectivelyfilteroutasubstantialportionofthelowest-probabilityirrelevanttokens,whichconstitutedestabilizing\nnoise,whilesimultaneouslyretainingamajorityofthevaluableexploratorytokensthatgiverisetoreasoningsparks.\nThisallowsLp-Regtofocusitsregularizationontokensthataremorelikelytobemeaningful,providingatargeted\nandrobustapproachtopreservinghigh-qualityexploration.\n7 Conclusion\nInthiswork,weinvestigatedtheexplorationcollapseinReinforcementLearningwithVerifiableRewards. We\nidentifiedakeymechanismdrivingthisfailure: thesystematiceliminationofaclassofvaluable,low-probability\nexploratory tokens we term reasoning sparks. To address this, we introduced Low-probability Regularization\n(Lp-Reg),amethoddesignedtoselectivelypreservethesecrucialexploratorypathways. Lp-Regisfoundedon\nthekeyinsightthatwithinthelow-probabilityrange,meaningfulexploratorytokensconsistentlyexhibithigher\naverage probabilities than semantically irrelevant tokens, whose low-probability appearances act as noise. By\nleveragingthisstatisticaldistinctiontofilteroutirrelevantnoiseandregularizingthepolicytowardstheremainder,\nourmethodeffectivelyprotectsvaluablelow-probabilitytokensfrombeingextinguished. Thisfocusonexploration\nqualityoverquantityenablesstableon-policytrainingforaround1,000steps,resultingina2.66%testaccuracy\nimprovementoverbaselinesandunderscoringtheimportanceofpreservingthereasoningsparkswithinthepolicy’s\nlow-probabilitytail.\n9\nReferences\nShivamAgarwal,ZiminZhang,LifanYuan,JiaweiHan,andHaoPeng. Theunreasonableeffectivenessofentropy\nminimizationinllmreasoning,2025. URLhttps://arxiv.org/abs/2505.15134.\nTaubenfeldAmir,ShefferTom,OfekEran,FederAmir,GoldsteinAriel,GekhmanZorik,andYonaGal. Confidence\nimproves self-consistency in llms. arXiv preprint arXiv:2502.06233, 2025. URL https://www.arxiv.\norg/abs/2502.06233.\nGhasemabadiAmirhosein,MillsKeith,G.,LiBaochun,andNiuDi. Guidedbygut: Efficienttest-timescaling\nwithreinforcedintrinsicconfidence. arXivpreprintarXiv:2505.20325v1,2025. URLhttps://www.arxiv.\norg/abs/2505.20325v1.\nDaixuan Cheng, Shaohan Huang, Xuekai Zhu, Bo Dai, Wayne Xin Zhao, Zhenliang Zhang, and Furu Wei.\nReasoningwithexploration: Anentropyperspectiveonreinforcementlearningforllms,2025. URLhttps:\n//arxiv.org/abs/2506.14758.\nGanquCui,YuchenZhang,JiachengChen,LifanYuan,ZhiWang,YuxinZuo,HaozhanLi,YuchenFan,Huayu\nChen, Weize Chen, Zhiyuan Liu, Hao Peng, Lei Bai, Wanli Ouyang, Yu Cheng, Bowen Zhou, and Ning\nDing. Theentropymechanismofreinforcementlearningforreasoninglanguagemodels,2025. URLhttps:\n//arxiv.org/abs/2505.22617.\nDeepSeek-AI, Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu,\nShirongMa,PeiyiWang,XiaoBi,XiaokangZhang,XingkaiYu,YuWu,Z.F.Wu,ZhibinGou,ZhihongShao,\nZhuoshuLi,ZiyiGao,AixinLiu,BingXue,BingxuanWang,BochaoWu,BeiFeng,ChengdaLu,Chenggang\nZhao,ChengqiDeng,ChenyuZhang,ChongRuan,DamaiDai,DeliChen,DongjieJi,ErhangLi,FangyunLin,\nFucongDai,FuliLuo,GuangboHao,GuantingChen,GuoweiLi,H.Zhang,HanBao,HanweiXu,Haocheng\nWang, Honghui Ding, Huajian Xin, Huazuo Gao, Hui Qu, Hui Li, Jianzhong Guo, Jiashi Li, Jiawei Wang,\nJingchangChen,JingyangYuan,JunjieQiu,JunlongLi,J.L.Cai,JiaqiNi,JianLiang,JinChen,KaiDong,\nKaiHu,KaigeGao,KangGuan,KexinHuang,KuaiYu,LeanWang,LecongZhang,LiangZhao,LitongWang,\nLiyueZhang,LeiXu,LeyiXia,MingchuanZhang,MinghuaZhang,MinghuiTang,MengLi,MiaojunWang,\nMingmingLi,NingTian,PanpanHuang,PengZhang,QianchengWang,QinyuChen,QiushiDu,RuiqiGe,\nRuisong Zhang, Ruizhe Pan, Runji Wang, R. J. Chen, R. L. Jin, Ruyi Chen, Shanghao Lu, Shangyan Zhou,\nShanhuangChen,ShengfengYe,ShiyuWang,ShuipingYu,ShunfengZhou,ShutingPan,S.S.Li,ShuangZhou,\nShaoqingWu,ShengfengYe,TaoYun,TianPei,TianyuSun,T.Wang,WangdingZeng,WanjiaZhao,WenLiu,\nWenfengLiang,WenjunGao,WenqinYu,WentaoZhang,W.L.Xiao,WeiAn,XiaodongLiu,XiaohanWang,\nXiaokangChen,XiaotaoNie,XinCheng,XinLiu,XinXie,XingchaoLiu,XinyuYang,XinyuanLi,Xuecheng\nSu,XuhengLin,X.Q.Li,XiangyueJin,XiaojinShen,XiaoshaChen,XiaowenSun,XiaoxiangWang,Xinnan\nSong,XinyiZhou,XianzuWang,XinxiaShan,Y.K.Li,Y.Q.Wang,Y.X.Wei,YangZhang,YanhongXu,Yao\nLi,YaoZhao,YaofengSun,YaohuiWang,YiYu,YichaoZhang,YifanShi,YiliangXiong,YingHe,YishiPiao,\nYisongWang,YixuanTan,YiyangMa,YiyuanLiu,YongqiangGuo,YuanOu,YuduanWang,YueGong,Yuheng\nZou,YujiaHe,YunfanXiong,YuxiangLuo,YuxiangYou,YuxuanLiu,YuyangZhou,Y.X.Zhu,YanhongXu,\nYanpingHuang,YaohuiLi,YiZheng,YuchenZhu,YunxianMa,YingTang,YukunZha,YutingYan,Z.Z.Ren,\nZehuiRen,ZhangliSha,ZheFu,ZheanXu,ZhendaXie,ZhengyanZhang,ZhewenHao,ZhichengMa,Zhigang\nYan,ZhiyuWu,ZihuiGu,ZijiaZhu,ZijunLiu,ZilinLi,ZiweiXie,ZiyangSong,ZizhengPan,ZhenHuang,\nZhipengXu,ZhongyuZhang,andZhenZhang. Deepseek-r1: Incentivizingreasoningcapabilityinllmsvia\nreinforcementlearning,2025. URLhttps://arxiv.org/abs/2501.12948.\nYichaoFu,XueweiWang,YuandongTian,andJiaweiZhao. Deepthinkwithconfidence,2025. URLhttps:\n//arxiv.org/abs/2508.15260.\nZitianGao,LynxChen,HaomingLuo,JoeyZhou,andBryanDai. One-shotentropyminimization,2025. URL\nhttps://arxiv.org/abs/2505.20282.\nChaoqunHe,RenjieLuo,YuzhuoBai,ShengdingHu,ZhenThai,JunhaoShen,JinyiHu,XuHan,YujieHuang,\nYuxiangZhang,JieLiu,LeiQi,ZhiyuanLiu,andMaosongSun. OlympiadBench: Achallengingbenchmarkfor\npromotingAGIwitholympiad-levelbilingualmultimodalscientificproblems. InLun-WeiKu,AndreMartins,\nand Vivek Srikumar (eds.), Proceedings of the 62nd Annual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pp. 3828–3850, Bangkok, Thailand, August 2024a. Association for\nComputationalLinguistics. doi: 10.18653/v1/2024.acl-long.211. URLhttps://aclanthology.org/\n2024.acl-long.211/.\nChaoqunHe,RenjieLuo,YuzhuoBai,ShengdingHu,ZhenLengThai,JunhaoShen,JinyiHu,XuHan,Yujie\nHuang, Yuxiang Zhang, Jie Liu, Lei Qi, Zhiyuan Liu, and Maosong Sun. Olympiadbench: A challenging\nbenchmarkforpromotingagiwitholympiad-levelbilingualmultimodalscientificproblems,2024b.\n10\nJujieHe,JiacaiLiu,ChrisYuhaoLiu,RuiYan,ChaojieWang,PengCheng,XiaoyuZhang,FuxiangZhang,Jiacheng\nXu,WeiShen,SiyuanLi,LiangZeng,TianwenWei,ChengCheng,BoAn,YangLiu,andYahuiZhou. Skywork\nopenreasoner1technicalreport,2025. URLhttps://arxiv.org/abs/2505.22312.\nDanHendrycks,CollinBurns,SauravKadavath,AkulArora,StevenBasart,EricTang,DawnSong,andJacob\nSteinhardt. Measuring mathematical problem solving with the MATH dataset. In Thirty-fifth Conference\nonNeuralInformationProcessingSystemsDatasetsandBenchmarksTrack(Round2),2021. URLhttps:\n//openreview.net/forum?id=7Bywt2mQsCe.\nAitorLewkowycz,AndersJohanAndreassen,DavidDohan,EthanDyer,HenrykMichalewski,VinayVenkatesh\nRamasesh, AmbroseSlone, CemAnil, ImanolSchlag, TheoGutman-Solo, YuhuaiWu, BehnamNeyshabur,\nGuyGur-Ari,andVedantMisra. Solvingquantitativereasoningproblemswithlanguagemodels. InAliceH.\nOh,AlekhAgarwal,DanielleBelgrave,andKyunghyunCho(eds.),AdvancesinNeuralInformationProcessing\nSystems,2022. URLhttps://openreview.net/forum?id=IFXTZERXdM7.\nLiLoka,ChenZhenhao,ChenGuangyi,ZhangYixuan,SuYusheng,XingEric,andZhangKun.Confidencematters:\nRevisitingintrinsicself-correctioncapabilitiesoflargelanguagemodels. arXivpreprintarXiv:2402.12563,2024.\nURLhttps://www.arxiv.org/abs/2402.12563.\nMAA. American invitational mathematics examination (AIME). Mathematics Competition Series, n.d. URL\nhttps://maa.org/math-competitions/aime.\nMiniMax,:,AiliChen,AonianLi,BangweiGong,BinyangJiang,BoFei,BoYang,BojiShan,ChangqingYu,\nChaoWang,ChengZhu,ChengjunXiao,ChengyuDu,ChiZhang,ChuQiao,ChunhaoZhang,ChunhuiDu,\nCongchao Guo, Da Chen, Deming Ding, Dianjun Sun, Dong Li, Enwei Jiao, Haigang Zhou, Haimo Zhang,\nHanDing,HaohaiSun,HaoyuFeng,HuaiguangCai,HaichaoZhu,JianSun,JiaqiZhuang,JiarenCai,Jiayuan\nSong,JinZhu,JingyangLi,JinhaoTian,JinliLiu,JunhaoXu,JunjieYan,JuntengLiu,JunxianHe,KaiyiFeng,\nKeYang,KechengXiao,LeHan,LeyangWang,LianfeiYu,LihengFeng,LinLi,LinZheng,LingeDu,Lingyu\nYang,LunbinZeng,MinghuiYu,MingliangTao,MingyuanChi,MozhiZhang,MujieLin,NanHu,Nongyu\nDi,PengGao,PengfeiLi,PengyuZhao,QibingRen,QidiXu,QileLi,QinWang,RongTian,RuitaoLeng,\nShaoxiangChen,ShaoyuChen,ShengminShi,ShitongWeng,ShuchangGuan,ShuqiYu,SichenLi,Songquan\nZhu,TengfeiLi,TianchiCai,TianrunLiang,WeiyuCheng,WeizeKong,WenkaiLi,XiancaiChen,Xiangjun\nSong,XiaoLuo,XiaoSu,XiaoboLi,XiaodongHan,XinzhuHou,XuanLu,XunZou,XuyangShen,YanGong,\nYanMa,YangWang,YiqiShi,YiranZhong,YonghongDuan,YongxiangFu,YongyiHu,YuGao,Yuanxiang\nFan, Yufeng Yang, Yuhao Li, Yulin Hu, Yunan Huang, Yunji Li, Yunzhi Xu, Yuxin Mao, Yuxuan Shi, Yuze\nWenren,ZehanLi,ZelinLi,ZhanxuTian,ZhengmaoZhu,ZhenhuaFan,ZhenzhenWu,ZhichaoXu,Zhihang\nYu,ZhihengLyu,ZhuoJiang,ZiboGao,ZijiaWu,ZijianSong,andZijunSun. Minimax-m1: Scalingtest-time\ncomputeefficientlywithlightningattention,2025. URLhttps://arxiv.org/abs/2506.13585.\nKevinMurphy. Reinforcementlearning: anoverview. arXivpreprintarXiv:2412.05265,2024.\nMinhNhatNguyen,AndrewBaker,ClementNeo,AllenRoush,AndreasKirsch,andRavidShwartz-Ziv. Turning\nuptheheat: Min-psamplingforcreativeandcoherentllmoutputs,2025. URLhttps://arxiv.org/abs/\n2407.01082.\nOpenAI,:,AaronJaech,AdamKalai,AdamLerer,AdamRichardson,AhmedEl-Kishky,AidenLow,AlecHelyar,\nAleksanderMadry,AlexBeutel,AlexCarney,AlexIftimie,AlexKarpenko,AlexTachardPassos,Alexander\nNeitz,AlexanderProkofiev,AlexanderWei,AllisonTam,AllyBennett,AnanyaKumar,AndreSaraiva,Andrea\nVallone,AndrewDuberstein,AndrewKondrich,AndreyMishchenko,AndyApplebaum,AngelaJiang,Ashvin\nNair,BarretZoph,BehroozGhorbani,BenRossen,BenjaminSokolowsky,BoazBarak,BobMcGrew,Borys\nMinaiev,BotaoHao,BowenBaker,BrandonHoughton,BrandonMcKinzie,BrydonEastman,CamilloLugaresi,\nCaryBassin,CaryHudson,ChakMingLi,CharlesdeBourcy,ChelseaVoss,ChenShen,ChongZhang,Chris\nKoch,ChrisOrsinger,ChristopherHesse,ClaudiaFischer,CliveChan,DanRoberts,DanielKappler,Daniel\nLevy, Daniel Selsam, David Dohan, David Farhi, David Mely, David Robinson, Dimitris Tsipras, Doug Li,\nDragosOprica,EbenFreeman,EddieZhang,EdmundWong,ElizabethProehl,EnochCheung,EricMitchell,\nEricWallace,ErikRitter,EvanMays,FanWang,FelipePetroskiSuch,FilippoRaso,FlorenciaLeoni,Foivos\nTsimpourlas,FrancisSong,FredvonLohmann,FreddieSulit,GeoffSalmon,GiambattistaParascandolo,Gildas\nChabot,GraceZhao,GregBrockman,GuillaumeLeclerc,HadiSalman,HaimingBao,HaoSheng,HartAndrin,\nHessamBagherinezhad,HongyuRen,HunterLightman,HyungWonChung,IanKivlichan,IanO’Connell,Ian\nOsband,IgnasiClaveraGilaberte,IlgeAkkaya,IlyaKostrikov,IlyaSutskever,IrinaKofman,JakubPachocki,\nJamesLennon,JasonWei,JeanHarb,JerryTwore,JiachengFeng,JiahuiYu,JiayiWeng,JieTang,JieqiYu,\nJoaquinQuin˜oneroCandela,JoePalermo,JoelParish,JohannesHeidecke,JohnHallman,JohnRizzo,Jonathan\nGordon, Jonathan Uesato, Jonathan Ward, Joost Huizinga, Julie Wang, Kai Chen, Kai Xiao, Karan Singhal,\nKarinaNguyen,KarlCobbe,KatyShi,KaylaWood,KendraRimbach,KerenGu-Lemberg,KevinLiu,Kevin\nLu,KevinStone,KevinYu,LamaAhmad,LaurenYang,LeoLiu,LeonMaksin,LeytonHo,LiamFedus,Lilian\nWeng,LindenLi,LindsayMcCallum,LindseyHeld,LorenzKuhn,LukasKondraciuk,LukaszKaiser,LukeMetz,\n11\nMadelaineBoyd,MajaTrebacz,ManasJoglekar,MarkChen,MarkoTintor,MasonMeyer,MattJones,Matt\nKaufer,MaxSchwarzer,MeghanShah,MehmetYatbaz,MelodyY.Guan,MengyuanXu,MengyuanYan,Mia\nGlaese,MiannaChen,MichaelLampe,MichaelMalek,MicheleWang,MichelleFradin,MikeMcClay,Mikhail\nPavlov,MilesWang,MingxuanWang,MiraMurati,MoBavarian,MostafaRohaninejad,NatMcAleese,Neil\nChowdhury,NeilChowdhury,NickRyder,NikolasTezak,NoamBrown,OfirNachum,OlegBoiko,OlegMurk,\nOliviaWatkins,PatrickChao,PaulAshbourne,PavelIzmailov,PeterZhokhov,RachelDias,RahulArora,Randall\nLin,RaphaGontijoLopes,RazGaon,ReahMiyara,ReimarLeike,RennyHwang,RhythmGarg,RobinBrown,\nRoshanJames,RuiShu,RyanCheu,RyanGreene,SaachiJain,SamAltman,SamToizer,SamToyer,Samuel\nMiserendino,SandhiniAgarwal,SantiagoHernandez,SashaBaker,ScottMcKinney,ScottieYan,ShengjiaZhao,\nShengliHu, ShibaniSanturkar, ShramanRayChaudhuri, ShuyuanZhang, SiyuanFu, SpencerPapay, Steph\nLin,SuchirBalaji,SuvanshSanjeev,SzymonSidor,TalBroda,AidanClark,TaoWang,TaylorGordon,Ted\nSanders,TejalPatwardhan,ThibaultSottiaux,ThomasDegry,ThomasDimson,TianhaoZheng,TimurGaripov,\nTomStasi,TrapitBansal,TrevorCreech,TroyPeterson,TynaEloundou,ValerieQi,VineetKosaraju,Vinnie\nMonaco,VitchyrPong,VladFomenko,WeiyiZheng,WendaZhou,WesMcCabe,WojciechZaremba,Yann\nDubois,YinghaiLu,YiningChen,YoungCha,YuBai,YuchenHe,YuchenZhang,YunyunWang,ZhengShao,\nandZhuohanLi. Openaio1systemcard,2024. URLhttps://arxiv.org/abs/2412.16720.\nKadavathSaurav,ConerlyTom,AskellAmanda,HenighanTom,DrainDawn,PerezEthan,SchieferNicholas,\nHatfield-DoddsZac,DasSarmaNova,Tran-JohnsonEli,JohnstonScott,El-ShowkSheer,JonesAndy,Elhage\nNelson,HumeTristan,ChenAnna,BaiYuntao,BowmanSam,FortStanislav,GanguliDeep,HernandezDanny,\nJacobson Josh, Kernion Jackson, Kravec Shauna, Lovitt Liane, Ndousse Kamal, Olsson Catherine, Ringer\nSam,AmodeiDario,BrownTom,ClarkJack,JosephNicholas,MannBen,McCandlishSam,OlahChris,and\nKaplanJared. Languagemodels(mostly)knowwhattheyknow. arXivpreprintarXiv:2207.05221,2022. URL\nhttps://www.arxiv.org/abs/2207.05221.\nJohnSchulman,FilipWolski,PrafullaDhariwal,AlecRadford,andOlegKlimov. Proximalpolicyoptimization\nalgorithms. arXivpreprintarXiv:1707.06347,2017.\nZhihongShao,PeiyiWang,QihaoZhu,RunxinXu,JunxiaoSong,XiaoBi,HaoweiZhang,MingchuanZhang,\nY.K.Li,Y.Wu,andDayaGuo. Deepseekmath: Pushingthelimitsofmathematicalreasoninginopenlanguage\nmodels,2024a. URLhttps://arxiv.org/abs/2402.03300.\nZhihongShao,PeiyiWang,QihaoZhu,RunxinXu,JunxiaoSong,XiaoBi,HaoweiZhang,MingchuanZhang,\nYKLi,YWu,etal. Deepseekmath: Pushingthelimitsofmathematicalreasoninginopenlanguagemodels.\narXivpreprintarXiv:2402.03300,2024b.\nGuangmingSheng,ChiZhang,ZilingfengYe,XibinWu,WangZhang,RuZhang,YanghuaPeng,HaibinLin,and\nChuanWu. Hybridflow: Aflexibleandefficientrlhfframework. arXivpreprintarXiv: 2409.19256,2024.\nZhenpengSu,LeiyuPan,XueBai,DeningLiu,GuantingDong,JiamingHuang,WenpingHu,FuzhengZhang,\nKunGai,andGuoruiZhou. Klear-reasoner: Advancingreasoningcapabilityviagradient-preservingclipping\npolicyoptimization,2025. URLhttps://arxiv.org/abs/2508.07629.\nKimiTeam,AngangDu,BofeiGao,BoweiXing,ChangjiuJiang,ChengChen,ChengLi,ChenjunXiao,Chen-\nzhuangDu,ChonghuaLiao,ChuningTang,CongcongWang,DehaoZhang,EnmingYuan,EnzheLu,Fengxiang\nTang, FloodSung, Guangda Wei, GuokunLai, Haiqing Guo, Han Zhu, HaoDing, Hao Hu, Hao Yang, Hao\nZhang,HaotianYao,HaotianZhao,HaoyuLu,HaozeLi,HaozhenYu,HongchengGao,HuabinZheng,Huan\nYuan,JiaChen,JianhangGuo,JianlinSu,JianzhouWang,JieZhao,JinZhang,JingyuanLiu,JunjieYan,Junyan\nWu,LidongShi,LingYe,LonghuiYu,MengnanDong,NeoZhang,NingchenMa,QiweiPan,QuchengGong,\nShaoweiLiu,ShenglingMa,ShupengWei,SihanCao,SiyingHuang,TaoJiang,WeihaoGao,WeiminXiong,\nWeiranHe,WeixiaoHuang,WeixinXu,WenhaoWu,WenyangHe,XianghuiWei,XianqingJia,XingzheWu,\nXinranXu,XinxingZu,XinyuZhou,XuehaiPan,Y.Charles,YangLi,YangyangHu,YangyangLiu,Yanru\nChen,YejieWang,YiboLiu,YidaoQin,YifengLiu,YingYang,YipingBao,YulunDu,YuxinWu,YuzhiWang,\nZaidaZhou,ZhaojiWang,ZhaoweiLi,ZhenZhu,ZhengZhang,ZhexuWang,ZhilinYang,ZhiqiHuang,Zihao\nHuang,ZiyaoXu,ZonghanYang,andZongyuLin. Kimik1.5: Scalingreinforcementlearningwithllms,2025.\nURLhttps://arxiv.org/abs/2501.12599.\nShenzhiWang,LeYu,ChangGao,ChujieZheng,ShixuanLiu,RuiLu,KaiDang,XionghuiChen,JianxinYang,\nZhenru Zhang, Yuqiong Liu, An Yang, Andrew Zhao, Yang Yue, Shiji Song, Bowen Yu, Gao Huang, and\nJunyangLin. Beyondthe80/20rule: High-entropyminoritytokensdriveeffectivereinforcementlearningforllm\nreasoning,2025. URLhttps://arxiv.org/abs/2506.01939.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and\nDenny Zhou. Chain-of-thought prompting elicits reasoning in large language models, 2023. URL https:\n//arxiv.org/abs/2201.11903.\n12\nZenanXu, ZexuanQiu, GuanhuaHuang, KunLi, SihengLi, ChenchenZhang, KejiaoLi, QiYi, YuhaoJiang,\nBo Zhou, Fengzong Lian, and Zhanhui Kang. Adaptive termination for multi-round parallel reasoning: An\nuniversalsemanticentropy-guidedframework,2025. URLhttps://arxiv.org/abs/2507.06829.\nZhao Xuandong, Kang Zhewei, Feng Aosong, Levine Sergey, and Song Dawn. Learning to reason without\nexternalrewards. arXivpreprintarXiv:2505.19590v2,2025. URLhttps://www.arxiv.org/abs/2505.\n19590v2.\nWangXuezhiandZhouDenny. Chain-of-thoughtreasoningwithoutprompting. arXivpreprintarXiv:2402.10200v2,\n2024. URLhttps://www.arxiv.org/abs/2402.10200v2.\nAnYang,AnfengLi,BaosongYang,BeichenZhang,BinyuanHui,BoZheng,BowenYu,ChangGao,Chengen\nHuang,ChenxuLv,ChujieZheng,DayihengLiu,FanZhou,FeiHuang,FengHu,HaoGe,HaoranWei,Huan\nLin,JialongTang,JianYang,JianhongTu,JianweiZhang,JianxinYang,JiaxiYang,JingZhou,JingrenZhou,\nJunyangLin,KaiDang,KeqinBao,KexinYang,LeYu,LianghaoDeng,MeiLi,MingfengXue,MingzeLi,Pei\nZhang,PengWang,QinZhu,RuiMen,RuizeGao,ShixuanLiu,ShuangLuo,TianhaoLi,TianyiTang,Wenbiao\nYin,XingzhangRen,XinyuWang,XinyuZhang,XuanchengRen,YangFan,YangSu,YichangZhang,Yinger\nZhang,YuWan,YuqiongLiu,ZekunWang,ZeyuCui,ZhenruZhang,ZhipengZhou,andZihanQiu. Qwen3\ntechnicalreport,2025. URLhttps://arxiv.org/abs/2505.09388.\nQiyingYu,ZhengZhang,RuofeiZhu,YufengYuan,XiaochenZuo,YuYue,WeinanDai,TiantianFan,Gaohong\nLiu,LingjunLiu,XinLiu,HaibinLin,ZhiqiLin,BoleMa,GuangmingSheng,YuxuanTong,ChiZhang,Mofan\nZhang,WangZhang,HangZhu,JinhuaZhu,JiazeChen,JiangjieChen,ChengyiWang,HongliYu,Yuxuan\nSong, Xiangpeng Wei, Hao Zhou, Jingjing Liu, Wei-Ying Ma, Ya-Qin Zhang, Lin Yan, Mu Qiao, Yonghui\nWu, and Mingxuan Wang. Dapo: An open-source llm reinforcement learning system at scale, 2025. URL\nhttps://arxiv.org/abs/2503.14476.\nYuYue,YufengYuan,QiyingYu,XiaochenZuo,RuofeiZhu,WenyuanXu,JiazeChen,ChengyiWang,TianTian\nFan,ZhengyinDu,XiangpengWei,XiangyuYu,GaohongLiu,JuncaiLiu,LingjunLiu,HaibinLin,ZhiqiLin,\nBoleMa,ChiZhang,MofanZhang,WangZhang,HangZhu,RuZhang,XinLiu,MingxuanWang,Yonghui\nWu,andLinYan. Vapo: Efficientandreliablereinforcementlearningforadvancedreasoningtasks,2025. URL\nhttps://arxiv.org/abs/2504.05118.\nYuzhongZhao,YueLiu,JunpengLiu,JingyeChen,XunWu,YaruHao,TengchaoLv,ShaohanHuang,LeiCui,\nQixiangYe,FangWan,andFuruWei. Geometric-meanpolicyoptimization,2025. URLhttps://arxiv.\norg/abs/2507.20673.\nChujieZheng,ShixuanLiu,MingzeLi,Xiong-HuiChen,BowenYu,ChangGao,KaiDang,YuqiongLiu,Rui\nMen, An Yang, Jingren Zhou, and Junyang Lin. Group sequence policy optimization, 2025. URL https:\n//arxiv.org/abs/2507.18071.\nO¨merVeyselC¸ag˘atanandBarıs¸Akgu¨n. Failuremodesofmaximumentropyrlhf,2025. URLhttps://arxiv.\norg/abs/2509.20265.\n13\nAppendix\nA DetailsofExperiments\nA.1 FurtherTrainingDynamics\nThe training dynamics of Lp-Reg and other RLVR methods on the Qwen2.5-32B base model are presented in\nFigure9. TheresultsshowthatLp-Regmaintainsacomparableperformanceintestaccuracythroughoutthetraining\nprocess,underscoringthebenefitsofourlow-probabilitytokenregularizationstrategyforpreventingexploration\ncollapse.\n8000\n7000\n6000\n5000\n4000\n3000\n2000\n1000\n0\n0 200 400 600 800\nTraining Steps\nhtgneL\nesnopseR\n1.0\n0.8\n0.6\n0.4\n0.2\n0.0\n0 200 400 600 800\nTraining Steps\nyportnE\nniarT\n0.54\n0.52\n0.50\n0.48\n0.46\n0.44\n0.42\n0.40\n0 200 400 600 800\nTraining Steps\n)%(\nycaruccA\ntseT\n.gvA\nClip-Higher(off.) 80/20(on.) Lp-Reg(on.)\nFigure9: TrainingdynamicsontheQwen2.5-32B-Basemodel. Tobestillustratetheperformancedifferences,we\ncomparethetop-performingmethods.\nA.2 FurtherAblationStudy\n8000\n7000\n6000\n5000\n4000\n3000\n2000\n1000\n0\n0 200 400 600 800\nTraining Steps\nhtgneL\nesnopseR\n1.0\n0.8\n0.6\n0.4\n0.2\n0.0\n0 200 400 600 800\nTraining Steps\nyportnE\nniarT\n0.45\n0.43\n0.40\n0.38\n0.35\n0.33\n0.30\n0.28\n0.25\n0 200 400 600 800\nTraining Steps\n)%(\nycaruccA\nEMIA\n.gvA\nhighest regularization lowest regularization\nFigure10: Ablationstudycomparinglow-probabilitytokenregularizationversushigh-entropytokenregularization\nforLp-Reg(on-policy)ontheQwen3-14B-Basemodel. ThetestdatasetsusedareAIME-24andAIME-25,withthe\naveragescorereportedover16testruns.\nLowProbabilityvs. HighEntropy. Toverifythattargetinglow-probabilitytokensissuperiortotheconventional\nwisdomoftargetinghighentropy,weconductacomparisonbetweenthehigh-entropytokenregularization(w/\nhighest H regularization) and the low-probability regularization (w/ lowest π regularization, vanilla Lp-Reg).\nθ\nInsteadofapplyingLp-Regtothelowest1%probabilitytokens,weapplyanidenticalregularizationmechanismto\nthetokenswiththehighest1%entropy. AsshowninFigure10,thisapproachnotonlyfailstoimproveperformance\nbutalsofailstosustainhighentropy,whichcollapsesafteraninitialspike. Thisresultreinforcesourclaimfrom\nthe Introduction: high entropy is a poor proxy for valuable exploration. As our analysis in Section 6.1 further\ncorroborates,high-entropytokensareoftencommonfunctionwordsorformattingcharacters,notthemeaningful,\nlow-probabilityexploratorytokenswetermreasoningsparks.Regularizingthempollutesthelearningsignalwithout\nprotectingthestructured,low-probabilityreasoningpathsnecessaryforprogress.\nForwardKLvs. ReverseKL. Wecomparetheperformanceofourchosen“forwardKL”formulation,whichis\nD\nKL\n(πproxy ∥π\nθ\n),againstthe”reverseKL”formulation,D\nKL\n(π\nθ\n∥πproxy ),inEquation6. AsshowninFigure11,\nourforwardKLsignificantlyoutperformsthereverseKL.Thisresultstemsfromthefactthatourproxydistribution,\nπproxy ,isaheuristicreferencederivedfromthecurrentpolicy,notanidealtargetdistribution. ThereverseKL,\n14\nD\nKL\n(π\nθ\n∥πproxy ),penalizesanydeviationofπ\nθ\nfromπproxy ,effectivelyforcingthepolicytostrictlyimitatethis\nnon-ideal,heuristictarget. Thisaggressiveimitationconstrainstheprotectionofpotentiallyvaluableexploratory\ntokens. Incontrast,theforwardKL,D\nKL\n(πproxy ∥π\nθ\n),providesamuchsofterregularization: itonlypenalizesthe\npolicyforcompletelydiscardingtokensthatπproxy considersplausible,withoutforcingastrictmatch. Thisallows\nthepolicytouseπproxy asastabilizingguidewhileretainingthefreedomtoexplorebeyondit,whichempirically\nleadstobetterperformance.\n8000\n7000\n6000\n5000\n4000\n3000\n2000\n1000\n0\n0 200 400 600 800\nTraining Steps\nhtgneL\nesnopseR\n1.0\n0.8\n0.6\n0.4\n0.2\n0.0\n0 200 400 600 800\nTraining Steps\nyportnE\nniarT\n0.60\n0.55\n0.50\n0.45\n0.40\n0.35\n0.30\n0 200 400 600 800\nTraining Steps\n)%(\nycaruccA\ntseT\n.gvA\nKL( proxy) KL( proxy )\nFigure 11: Ablation study comparing the forward and reverse KL formulations for the Lp-Reg penalty on the\nQwen3-14B-Basemodel. TheresultsdemonstratethesuperiorityoftheforwardKL,whichusestheheuristicproxy\ndistributionasasoftguide,overthereverseKL,whichforcesastrictimitation.\n8000\n7000\n6000\n5000\n4000\n3000\n2000\n1000\n0\n0 100 200 300 400 500 600\nTraining Steps\nhtgneL\nesnopseR\n1.0\n0.8\n0.6\n0.4\n0.2\n0.0\n0 100 200 300 400 500 600\nTraining Steps\nyportnE\nniarT\n0.60\n0.55\n0.50\n0.45\n0.40\n0.35\n0.30\n0 100 200 300 400 500 600\nTraining Steps\n)%(\nycaruccA\ntseT\n.gvA\n=0.005 =0.010 =0.015\n(a)Ablationstudyonρwhichdefinedthelow-probabilitypercentilethresholdδB.\nρ\n8000\n7000\n6000\n5000\n4000\n3000\n2000\n1000\n0\n0 100 200 300 400 500 600\nTraining Steps\nhtgneL\nesnopseR\n1.0\n0.8\n0.6\n0.4\n0.2\n0.0\n0 100 200 300 400 500 600\nTraining Steps\nyportnE\nniarT\n0.60\n0.55\n0.50\n0.45\n0.40\n0.35\n0.30\n0 100 200 300 400 500 600\nTraining Steps\n)%(\nycaruccA\ntseT\n.gvA\n=0.01 =0.02 =0.03\n(b)Ablationstudyonκwhichdefinedthenoisethresholdτ=κ·max o′∈V π θ (o′|·)\nFigure12: TrainingdynamicsofLp-Regmethodwithdifferenthyperparameters.\nA.3 HyperparameterSensitivityAnalysis\nInthissection,weanalyzethesensitivityoftwocorehyperparametersinLp-Regtodemonstratetherobustnessof\nourmethod: thelow-probabilitypercentileρandthemin-pratioκ. TheresultsarepresentedinFigure12.\nTheparameterρ,asdefinedinourobjectivefunction(Equation6),determinesthepercentilethresholdforidentifying\nlow-probabilitytokensthatarecandidatesforregularization. Ahigherρmeansawiderrangeoftokensareprotected.\nAs shown in the top panel of Figure 12, we evaluated ρ with values of 0.005, 0.010, and 0.015. The training\ntrajectoriesforaveragetestaccuracyarecomparable,andthefinalperformanceacrossallthreesettingsishighly\ncomparable. ThisindicatesthatLp-Regisnotoverlysensitivetotheprecisescopeoftokensbeingprotectedwithin\nthisreasonablerange.\nThehyperparameterκcontrolstheadaptivenessofthemin-pfilteringthreshold,whichdefinestheboundaryfor\nwhatistreatedasnoise. Asmallerκresultsinamoreconservativefilteringstrategy,removingfewertokens. Our\n15\nsensitivityanalysisforκ,presentedinthebottompanelofFigure12,showsasimilartrendofstability. Acrossthe\ntestedvaluesof0.01,0.02,and0.03,thetrainingcurvesandfinalperformanceremainconsistentlyhighandtightly\nclustered. Takentogether,theseresultsdemonstratetherobustnessofLp-Reg. Themethod’seffectivenessisnot\ncontingentonextensive,fine-grainedhyperparametertuning,highlightingitspracticalapplicability.\nB FurtherAnalysis\nB.1 DetailsofSamplingProbabilityDensity\nThissectionprovidesadetailed,token-by-tokenbreakdownoftheaggregateddistributionspresentedinFigure1c\nandFigure1dofthemainpaper,reinforcingtheconclusionsdrawnfromouranalysis.\nFigure14exhibitstheindividualdistributionofobservedsamplingprobabilitiesforaclassofmeaningfullow-\nprobabilityexploratorytokenswetermreasoningsparks: “but”,“wait”,“perhaps”,“alternatively”,and“however”.\nAconsistenttrendisobservableacrossallfivetokens,validatingourclaimsintheintroduction. Withstandard\nGRPOtraining,theabilitytosamplethesetokensatlowprobabilitiesissystematicallyeliminated,causingtheir\ndistributionstocollapseandshifttowardshigherprobabilities. Theindiscriminateentropybonus(GRPO+Entropy\nLoss)islargelyineffectiveatrestoringthiscruciallow-probabilitytail. Instarkcontrast,ourproposedmethod,\nLp-Reg,consistentlymaintainsahealthy,widedistributionforeachofthesetokens,demonstratingitseffectiveness\ninpreservingthemodel’scapacityforexploration.\nConversely, Figure 15 details the behavior of a class of what we term irrelevant tokens (e.g. “cost”, “fine”,\n“balanced”,“ere”,and“trans”). Werefertothelow-probabilitysamplingofthesetokensasirrelevantnoise,which\ncanbedestructivetothetrainingprocess. Theseindividualplotsclearlyillustratethedetrimentalsideeffectof\nasimpleentropybonus. Fornearlyeverytoken,theGRPO+EntropyLossbaselinesignificantlyamplifiesthe\nsamplingofthisirrelevantnoise,which,asshowninourmainanalysis,contributestoafasterperformancecollapse.\nLp-Reg,bydesign,avoidsthisamplificationandmaintainsasuppressedprobabilitydistributionforthesetokens,\ncomparabletoorevenmoreconstrainedthanthestandardGRPObaseline.\nThesedetailedvisualizationsconfirmthattheeliminationofreasoningsparksandtheamplificationofirrelevant\nnoise are not artifacts of aggregation but are consistent patterns at the individual token level. This provides\nstrong,granularevidenceforthecentralchallengeourpaperaddressesandhighlightsthenecessityofaselective\npreservationmechanismlikeLp-Reg.\nB.2 DetailsofProbability-EntropyDistribution\nTo supplement the aggregated analysis presented in Figure 6 of the main text, this section provides a detailed\nbreakdownoftheprobability-entropydistributionsforindividualmeaningfulexploratorytokens. Figure16shows\naconsistentpatternacrossallrepresentativetokens,rangingfrom“but”(Figure16a)to“however”(Figure16e).\nForfrequentlyoccurringtokenssuchas“but”,“wait”,and“perhaps”,werandomlysubsampleoneoutofevery20\ninstancesforvisualization. UnderthebaselineGRPO,thesesparksareconsistentlyconfinedtoalow-entropy,high-\nprobabilityregion,indicatingacollapseintodeterministicusage. Incontrast,theadditionofanentropylosspushes\nthesetokensintohighlyscattered,oftenexcessivelyhigh-entropystates,suggestinganuncontrolledandpotentially\nnoisy form of exploration. Our method, Lp-Reg, strikes a crucial balance, maintaining a structured and broad\ndistributionacrossahealthyrangeofentropyvalues. Thisconsistentbehaviordemonstratesthatthetrendsidentified\nintheaggregateddataarenotartifactsofaveraging. Theindividualplotsofferstrong,disaggregatedevidencefor\nourcentralclaim: Lp-Regeffectivelypreservestheexploratorypotentialofreasoningsparksbypreventingboththe\ndeterministiccollapseseeninthebaselineandthechaoticscatteringinducedbytheindiscriminateentropybonus.\nB.3 TrainingDynamicsofRegularizedToken\nTobetterunderstandhowLp-Regoperatesduringtraining,weanalyzethedynamicsoftheprobabilitythreshold\nδB andtheproportionoflow-probabilitytokenssubjectedtoregularization |πθ (o|·)<δ ρ B∧πproxy(o|·)>0| . Asshownin\nρ |πθ (o|·)<δρ B|\nFigure13,thethresholdδB graduallydecreaseswithtrainingsteps. Inparallel,theregularizationratioalsodeclines\nρ\nsteadily. Thistrendsuggeststhatastrainingprogresses,theextremelow-probabilityrangebecomesincreasingly\ndominatedbyirrelevanttokens,constitutingwhatwetermirrelevantnoise. Inparallel,thesemanticallymeaningful\nexploratorytokensareliftedintohigher-probabilityregions,thusrequiringlessregularization.\nB.4 CaseStudy\nTofurtherillustratetheeffectofthefilterappliedonlow-probabilitytokens,Figure17presentsacasestudyofa\nmodel-generatedresponse,wherelow-probabilitytokensarehighlightedaccordingtowhethertheywerepreserved\norfiltered. Tokenswithprobabilitygreaterthanτ arethoseretainedbythefilter,whiletokenswithprobability\n16\n0.08\n0.06\n0.04\n0.02\n0.00\n128 256 384 512 640 768\nTraining Steps\ndlohserhT\nytilibaborP\nProbability Threshold and Regularization Ratio\nProbability Threshold 27.5\nRegularization Ratio\n25.0\n22.5\n20.0\n17.5\n15.0\n12.5\n10.0\n7.5\noitaR\nnoitaziralugeR\nFigure13: Trainingdynamicsoftheprobabilitythresholdandregularizationratio.\nsmaller than τ are suppressed. The preserved tokens include meaningful exploratory markers such as ”Then”,\n”Wait”,whichguidethereasoningtrajectory,whereasthediscardedsetlargelyconsistsofrelativelyirrelevanttokens\nsuchas”We”,”also”,”that”. Thisqualitativeevidencecomplementsourquantitativeanalysis,demonstratingthat\nLp-Regeffectivelyleveragesthemin-ptransformationtodistinguishbetweenvaluablelow-probabilityexploratory\ntokens(reasoningsparks)andtokensthatconstitutedestabilizing,irrelevantnoise.\n17\n1.00\n0.75\n0.50\n0.25\n0.00\n1 256 512\nTraining Steps\nytilibaborP\nGRPO GRPO+Entropy loss Lp-Reg\nn=656 n=656 n=656 n=25239 n=11311 n=28173 n=21728 n=35821\n(a)Densityofobservedsamplingprobabilitiesfortoken“but”.\n1.00\n0.75\n0.50\n0.25\n0.00\n1 256 512\nTraining Steps\nytilibaborP\nGRPO GRPO+Entropy loss Lp-Reg\nn=31 n=31 n=31 n=11454 n=15102 n=17153 n=8388 n=17157\n(b)Densityofobservedsamplingprobabilitiesfortoken“wait”.\n1.00\n0.75\n0.50\n0.25\n0.00\n1 256 512\nTraining Steps\nytilibaborP\nGRPO GRPO+Entropy loss Lp-Reg\nn=12 n=12 n=12 n=14965 n=4386 n=16465 n=6875 n=10859\n(c)Densityofobservedsamplingprobabilitiesfortoken“perhaps”.\n1.00\n0.75\n0.50\n0.25\n0.00\n1 256 512\nTraining Steps\nytilibaborP\nGRPO GRPO+Entropy loss Lp-Reg\nn=14 n=14 n=14 n=4891 n=1419 n=7355 n=3125 n=6150\n(d)Densityofobservedsamplingprobabilitiesfortoken“alternatively”.\n1.00\n0.75\n0.50\n0.25\n0.00\n1 256 512\nTraining Steps\nytilibaborP\nGRPO GRPO+Entropy loss Lp-Reg\nn=499 n=499 n=499 n=1864 n=2252 n=2200 n=1907 n=4092\n(e)Densityofobservedsamplingprobabilitiesfortoken“however”.\nFigure14: Individualdensityofobservedsamplingprobabilitiesformeaningfulexploratorytokens: “but”,“wait”,\n“perhaps”,“alternatively”,and“however”.\n18\n1.00\n0.75\n0.50\n0.25\n0.00\n1 128 256\nTraining Steps\nytilibaborP\nGRPO GRPO+Entropy loss Lp-Reg\nn=156 n=156 n=156 n=60 n=591 n=89 n=107 n=246 n=96\n(a)Densityofobservedsamplingprobabilitiesfortoken“cost”.\n1.00\n0.75\n0.50\n0.25\n0.00\n1 128 256\nTraining Steps\nytilibaborP\nGRPO GRPO+Entropy loss Lp-Reg\nn=3 n=3 n=3 n=13 n=411 n=32 n=23 n=130 n=23\n(b)Densityofobservedsamplingprobabilitiesfortoken“fine”.\n1.00\n0.75\n0.50\n0.25\n0.00\n1 128 256\nTraining Steps\nytilibaborP\nGRPO GRPO+Entropy loss Lp-Reg\nn=1 n=1 n=1 n=43 n=271 n=30 n=38 n=95 n=30\n(c)Densityofobservedsamplingprobabilitiesfortoken“balanced”.\n1.00\n0.75\n0.50\n0.25\n0.00\n1 128 256\nTraining Steps\nytilibaborP\nGRPO GRPO+Entropy loss Lp-Reg\nn=27 n=27 n=27 n=0 n=175 n=0 n=0 n=57 n=0\n(d)Densityofobservedsamplingprobabilitiesfortoken“ere”.\n1.00\n0.75\n0.50\n0.25\n0.00\n1 128 256\nTraining Steps\nytilibaborP\nGRPO GRPO+Entropy loss Lp-Reg\nn=5 n=5 n=5 n=208 n=644 n=79 n=166 n=446 n=91\n(e)Densityofobservedsamplingprobabilitiesfortoken“trans”.\nFigure15: Individualdensityofobservedsamplingprobabilitiesforirrelevanttokens: “cost”,“fine”,“balanced”,\n“ere”,and“trans”.\n19\n3.5\n3.0\n2.5\n2.0\n1.5\n1.0\n0.5\n0.00.0 0.2 0.4 0.6 0.8 1.0\nSampled Probability\nyportnE\nGRPO\nMeaMne Eannt Proropby:: 00..19138195n ±± = 00 2 ..1 217 482 408 01\n10\n8\n6\n4\n2\n00.0 0.2 0.4 0.6 0.8 1.0\nSampled Probability\nyportnE\nGRPO+entropy loss\nMeaMne Eannt Proropby:: 10..54530201n ±± = 10 1 ..1 333 821 871 27 5\n4\n3\n2\n1\n00.0 0.2 0.4 0.6 0.8 1.0\nSampled Probability\nyportnE\nLp-Reg\nMeaMne Eannt Proropby:: 00..57937263n ±± = 00 3 ..5 538 802 631 05\n(a) Scattered probability–entropy plot of observed sampling instances for the token\n“but”.\n2.0\n1.5\n1.0\n0.5\n0.00.0 0.2 0.4 0.6 0.8 1.0\nSampled Probability\nyportnE\nGRPO\nMeaMne Eannt Proropby:: 00..18794775 ±±n = 00.. 8 223 818 158 69\n10\n8\n6\n4\n2\n00.0 0.2 0.4 0.6 0.8 1.0\nSampled Probability\nyportnE\nGRPO+entropy loss\nMeaMne Eannt Proropby:: 10..35722444n ±± = 10 1 ..5 031 500 332 56\n4\n3\n2\n1\n00.0 0.2 0.4 0.6 0.8 1.0\nSampled Probability\nyportnE\nLp-Reg\nMeaMne Eannt Proropby:: 00..57433506n ±± = 00 1 ..7 531 305 877 38\n(b) Scatteredprobability–entropyplot of observed sampling instancesfor the token\n“wait”.\n2.00\n1.75\n1.50\n1.25\n1.00\n0.75\n0.50\n0.25\n0.000.0 0.2 0.4 0.6 0.8 1.0\nSampled Probability\nyportnE\nGRPO\nMeaMne Eannt Proropby:: 00..28182250 ±±n = 00.. 6 228 927 475 23\n10\n8\n6\n4\n2\n00.0 0.2 0.4 0.6 0.8 1.0\nSampled Probability\nyportnE\nGRPO+entropy loss\nMeaMne Eannt Proropby:: 20..13175327 ±±n = 10.. 4 923 698 536 51 4.0\n3.5\n3.0\n2.5\n2.0\n1.5\n1.0\n0.5\n0.00.0 0.2 0.4 0.6 0.8 1.0\nSampled Probability\nyportnE\nLp-Reg\nMeaMne Eannt Proropby:: 00..67603499n ±± = 00 1 ..0 638 115 419 87\n(c) Scattered probability–entropy plot of observed sampling instances for the token\n“perhaps”.\n1.6\n1.4\n1.2\n1.0\n0.8\n0.6\n0.4\n0.2\n0.00.0 0.2 0.4 0.6 0.8 1.0\nSampled Probability\nyportnE\nGRPO\nMeaMne Eannt Proropby:: 00..28462481 ±±n = 00.. 3 321 132 385 89\n10\n8\n6\n4\n2\n00.0 0.2 0.4 0.6 0.8 1.0\nSampled Probability\nyportnE\nGRPO+entropy loss\nMeaMne Eannt Proropby:: 20..03807943 ±±n = 20.. 1 024 781 719 66\n4.0\n3.5\n3.0\n2.5\n2.0\n1.5\n1.0\n0.5\n0.00.0 0.2 0.4 0.6 0.8 1.0\nSampled Probability\nyportnE\nLp-Reg\nMeaMne Eannt Proropby:: 00..76179460 ±±n = 00.. 6 531 915 650 09\n(d) Scatteredprobability–entropyplot of observed sampling instancesfor the token\n“alternatively”.\n1.6\n1.4\n1.2\n1.0\n0.8\n0.6\n0.4\n0.2\n0.00.0 0.2 0.4 0.6 0.8 1.0\nSampled Probability\nyportnE\nGRPO\nMeaMne Eannt Proropby:: 00..18895401 ±±n = 00.. 1 229 810 967 78\n10\n8\n6\n4\n2\n00.0 0.2 0.4 0.6 0.8 1.0\nSampled Probability\nyportnE\nGRPO+entropy loss\nMeaMne Eannt Proropby:: 20..03075811 ±±n = 20.. 2 132 315 132 60\n3.5\n3.0\n2.5\n2.0\n1.5\n1.0\n0.5\n0.00.0 0.2 0.4 0.6 0.8 1.0\nSampled Probability\nyportnE\nLp-Reg\nMeaMne Eannt Proropby:: 00..86402011 ±±n = 00.. 4 630 129 182 43\n(e) Scattered probability–entropy plot of observed sampling instances for the token\n“however”.\nFigure16: Individualscatteredprobability–entropyplotofobservedsamplinginstancesformeaningfultokens:\n“but”,“wait”,“perhaps”,“alternatively”,and“however”.\n20\nSingle Response Case Study\nHighlighting Lowest 2% Probability Tokens (threshold: 0.026208)\nResponse Text with Token Highlighting\nReserved tokens\nFiltered tokens\nNormal tokens\n\\n Assistant :\\n Alright , I have this problem about a square that 's divided into smaller squares , and the process keeps repeating indefinitely . Some parts are\nshaded , and I need to find out what fraction of the whole figure is shaded . The final answer should be in the form of a fraction \\ (\\ frac { m }{ n\n}\\ ), and I need to provide the value of \\( m + n \\ ). Let 's break this down step by step .\\n\\n ### Understanding the Problem \\n\\n First , let 's try\nto understand what 's happening :\\n\\n 1 . ** Initial Square **: We start with one big square .\\n 2 . ** First Division **: This square is divided into nine smaller\nsquares of equal area . So , it 's like a 3 x 3 grid .\\n 3 . ** Center Division **: The center square of this 3 x 3 grid is then further divided into\nnine even smaller squares ( 3 x 3 again ).\\n 4 . ** Pattern Contin ues **: This process repeats indefinitely â each new center square is divided into nine\nsmaller squares .\\n\\n From the As ym pt ote code , it seems that at each step , certain parts ( corn ers ) of the squares are shaded . Specifically , the\nfour corner squares of each smaller subdivision are shaded .\\n\\n Wait , looking at the code :\\n\\n ``` asy \\n fill ((- n ,n )-- (- 1 / 3 *n ,n )-- (- 1 / 3\n*n , 1 / 3 *n )-- (- n , 1 / 3 *n )-- cycle );\\n fill ((- n ,- n )-- (- 1 / 3 *n ,- n )-- (- 1 / 3 *n ,- 1 / 3 *n )-- (- n ,- 1 / 3 *n )-- cycle );\\n\nfill (( n ,- n )-- ( 1 / 3 *n ,- n )-- ( 1 / 3 *n ,- 1 / 3 *n )-- ( n ,- 1 / 3 *n )-- cycle );\\n fill (( n ,n )-- ( 1 / 3 *n ,n )-- ( 1 / 3 *n , 1\n/ 3 *n )-- ( n , 1 / 3 *n )-- cycle );\\n `` `\\n\\n This code seems to shade the four corner squares of each subdivision at each level . So , at each step\n, four of the nine smaller squares are shaded .\\n\\n ### Visual Representation \\n\\n Let 's try to visualize this :\\n\\n 1 . ** Level 0 **: The original big square\n.\\n 2 . ** Level 1 **: Div ided into 9 squares , and the four corners are shaded .\\n 3 . ** Level 2 **: The center square of Level 1 is divided\ninto 9 even smaller squares , and its four corners are shaded .\\n 4 . ** Level 3 **: The center of that latest division is divided again , and so on ,\ninfinitely .\\n\\n Wait , actually , looking back at the As ym pt ote code , it seems that at every level , the four corner squares of each current smallest subdivision\nare shaded . But in the description , it mentions the center square is divided , not necessarily the corners . Maybe I mis interpreted .\\n\\n Wait , the code sh\nad ings correspond to the corners of each subdivision , but the description says the center square is divided . Hmm , perhaps the shaded parts are always the\nfour corners of the current center square .\\n\\n But perhaps it 's better to assign a value .\\n\\n ### Assign ing Areas \\n\\n Let 's assign an area to the original\nsquare to make calculations easier . Let 's say the area of the original square is 1 .\\n\\n - ** Level 0 **: Total area = 1 . Fraction shaded = 0 ?\nWait , no , according to the As ym pt ote code , the parts shaded are the four corners of each subdivision , not clearly defined yet .\\n\\n Wait , perhaps\nit 's better to think in terms of geometric series .\\n\\n At each level :\\n\\n - The entire figure is divided into 9 equal smaller squares .\\n - Out of these ,\n4 are shaded ( the corners ).\\n\\n Wait , perhaps it 's not exactly that . Looking at the code , for each square at a certain level , its four corners in the\nnext subdivision are shaded . But the center square continues to be subdiv ided .\\n\\n Wait , perhaps it 's better to think recursively .\\n\\n ### Recursive Thinking\n\\n\\n Let 's denote :\\n\\n - \\( S _n \\ ) as the total shaded area after \\( n \\ ) levels of subdivision .\\n\\n But since it 's infinite , we need to consider the\nlimit as \\( n \\ ) approaches infinity .\\n\\n At each step :\\n\\n - The current smallest squares are divided into 9 even smaller squares .\\n - Out of these 9\n, 4 are shaded .\\n\\n Wait , perhaps it 's better to think of the entire figure and how much is shaded at each stage .\\n\\n Let 's consider the first level\n:\\n\\n - Original square is divided into 9 .\\n - Sh aded area : the four corners , each has area \\( \\ frac { 1 }{ 9 } \\ ), so total shaded at level 1\n: \\( 4 \\ times \\ frac { 1 }{ 9 } = \\ frac { 4 }{ 9 } \\ ).\\n\\n Wait , but then the center square is further divided , and in its corners , etc .\\n\\n\nWait , perhaps it 's better to think of it as :\\n\\n At each subdivision , for each existing square , we shade four of its nine smaller parts , and then the\ncenter is subdiv ided further .\\n\\n This seems like it might lead to a geometric series where at each step , a fraction is added to the shaded area .\\n\\n But\nI 'm not entirely clear on the pattern . Maybe I should try to compute the shaded area at each step .\\n\\n ### Computing Sh aded Area \\n\\n Let 's try to\ncompute the shaded area after a few levels to see if a pattern emerges .\\n\\n ** Level 0 **: Sh aded area = 0 .\\n\\n ** Level 1 **: The original square\nis divided into 9 , and 4 are shaded : \\( S _ 1 = \\ frac { 4 }{ 9 } \\ ).\\n\\n Wait , but then the process continues . The center square ( of area\n\\( \\ frac { 1 }{ 9 } \\ )) is further divided into 9 squares , each of area \\( \\ frac { 1 }{ 8 1 } \\ ), and 4 of these are shaded : \\( \\ frac {\n4 }{ 8 1 } \\ ).\\n\\n So , total shaded after Level 2 : \\( S _ 2 = \\ frac { 4 }{ 9 } + \\ frac { 4 }{ 8 1 } \\ ).\\n\\n Similarly , the center of this\nlatest subdivision ( which was a square of area \\( \\ frac { 1 }{ 8 1 } \\ )) has a center that gets divided further , and so on .\\n\\n Wait , perhaps it\n's better to think of it as an infinite series .\\n\\n Each time we divide a square into 9 and shade 4 , and then the center is divided again .\\n\\n This seems\nlike a geometric series where each term is a fraction of the previous shaded area .\\n\\n Wait , let 's see :\\n\\n At Level 1 : shaded area \\( \\ frac { 4 }{\n9 } \\ ).\\n\\n At Level 2 : shaded area \\( \\ frac { 4 }{ 8 1 } \\ ) ( from the center square at Level 1 ).\\n\\n At Level 3 : shaded area \\( \\ frac\n{ 4 }{ 7 2 9 } \\ ) ( from the center square at Level 2 ), and so on .\\n\\n Wait , perhaps the total shaded area is the sum of those :\\n\\n \\( S =\n\\ frac { 4 }{ 9 } + \\ frac { 4 }{ 8 1 } + \\ frac { 4 }{ 7 2 9 } + \\ cd ots \\ )\\n\\n This is a geometric series with first term \\( a = \\ frac\n{ 4 }{ 9 } \\ ) and common ratio \\( r = \\ frac { 1 }{ 9 } \\ ).\\n\\n The sum of an infinite geometric series is \\( S = \\ frac { a }{ 1 - r } \\ ).\\n\\n\nSo , \\( S = \\ frac {\\ frac { 4 }{ 9 }} { 1 - \\ frac { 1 }{ 9 }} = \\ frac {\\ frac { 4 }{ 9 }} {\\ frac { 8 }{ 9 }} = \\ frac { 4 }{ 8 }\n= \\ frac { 1 }{ 2 } \\ ).\\n\\n Wait , but I 'm not entirely confident this captures the entire shaded area because the shaded parts are at each subdivision\nlevel , and the pattern might be different .\\n\\n Wait , perhaps I should consider that at each subdivision , the shaded parts are not just in the outer squares\nbut are nested within the subdivisions .\\n\\n Alternatively , perhaps the correct approach is to consider that at each step , the shaded area added is \\( \\ frac\n{ 4 }{ 9 } \\ ) of the area being subdiv ided , and the un sh aded center continues to be subdiv ided .\\n\\n Wait , perhaps a better approach is to consider\nthe self -s im ilarity of the problem .\\n\\n ### Self -S im ilarity Approach \\n\\n Let 's denote \\( S \\ ) as the total shaded area of the original square .\\n\\n\nLooking at the first subdivision :\\n\\n - We have 9 smaller squares .\\n - 4 of them are shaded immediately : each has area \\( \\ frac { 1 }{ 9 } \\ ),\nso total \\( \\ frac { 4 }{ 9 } \\ ).\\n - The center square ( also of area \\( \\ frac { 1 }{ 9 } \\ )) is a smaller version of the original figure , and its\nshaded area would be \\( \\ frac { S }{ 9 } \\ ).\\n\\n Wait , no . Actually , the center square is undergoing the same pattern without the immediate shading\nof its corners initially ( in the context of the original shading ).\\n\\n Wait , perhaps it 's better to think that the entire figure maintains self -s im ilarity where\n:\\n\\n Total shaded area \\( S = \\ ) shaded in first level \\( + \\ ) shaded in scaled -down version \\( = \\ frac { 4 }{ 9 } + \\ frac { S }{ 9 } \\ ).\\n\\n\nWait , let 's think carefully :\\n\\n At the first level :\\n\\n - Sh aded area : \\( \\ frac { 4 }{ 9 } \\ ) ( the four corner squares ).\\n - The center square (\nof area \\( \\ frac { 1 }{ 9 } \\ )) also follows the same pattern , but in its divisions , its corners will be shaded in the next level , and so on .\\n\\n Wait\n, perhaps the recursive relation is :\\n\\n \\( S = \\ frac { 4 }{ 9 } + \\ frac { S }{ 9 } \\ ).\\n\\n Wait , let 's see :\\n\\n The total shaded area is the shaded\narea from the first subdivision plus the shaded area from the pattern that would have been applied to the center square if it were the original , but scaled\ndown by a factor of \\( \\ frac { 1 }{ 9 } \\ ).\\n\\n Wait , but in the first subdivision , only the outer squares are immediately shaded , and the center continues\nto be subdiv ided indefinitely .\\n\\n Wait , perhaps it 's better to think of it as :\\n\\n At each step , we shade four out of nine parts of each square at the\ncurrent level , and then the center square is treated as a new \" original \" square at the next level .\\n\\n Thus , the total shaded area \\( S \\ ) satisfies :\\n\\n\n\\( S = \\ frac { 4 }{ 9 } + \\ frac { S }{ 9 } \\ ).\\n\\n Wait , let 's verify :\\n\\n The first term \\( \\ frac { 4 }{ 9 } \\ ) accounts for the four shaded\ncorner squares at the first level .\\n\\n Then , the center square ( of area \\( \\ frac { 1 }{ 9 } \\ )) has its own version of the problem , so its shaded\narea is \\( \\ frac { S }{ 9 } \\ ).\\n\\n Thus , the equation \\( S = \\ frac { 4 }{ 9 } + \\ frac { S }{ 9 } \\ ) seems correct .\\n\\n Now , solve for\n\\( S \\ ):\\n\\n \\( S - \\ frac { S }{ 9 } = \\ frac { 4 }{ 9 } \\ )\\n\\n \\( \\ frac { 8 S }{ 9 } = \\ frac { 4 }{ 9 } \\ )\\n\\n Multiply both sides by\n9 :\\n\\n \\( 8 S = 4 \\ )\\n\\n Div ide both sides by 8 :\\n\\n \\( S = \\ frac { 4 }{ 8 } = \\ frac { 1 }{ 2 } \\ ).\\n\\n So , the total shaded fraction\nis \\( \\ frac { 1 }{ 2 } \\ ).\\n\\n But the problem states that the answer should be in the form \\( \\ frac { m }{ n } \\ ) where \\( \\ gcd (m , n ) =\n1 \\ ), and we need to find \\( m + n \\ ).\\n\\n Here , \\( \\ frac { m }{ n } = \\ frac { 1 }{ 2 } \\ ), so \\( m = 1 \\ ), \\( n = 2 \\ ), and\nthus \\( m + n = 3 \\ ).\\n\\n Wait , but before final izing , let 's double -check the recursive relation .\\n\\n ### Ver ifying the Recursive Relation \\n\\n Let\n's consider a simpler case to verify :\\n\\n Sup pose we only do the first level of subdivision . Then , the shaded area is \\( \\ frac { 4 }{ 9 } \\ ).\\n\\n According\nto our recursive relation \\( S = \\ frac { 4 }{ 9 } + \\ frac { S }{ 9 } \\ ), if we only do level 1 , then perhaps the \\( \\ frac { S }{ 9 } \\ )\nshould be zero , but our initial assumption that \\( S = \\ frac { 4 }{ 9 } + \\ frac { S }{ 9 } \\ ) holds for infinite subdivisions .\\n\\n Alternatively , perhaps\nit 's better to think that at each level , the shaded area added is correctly captured by \\( \\ frac { 4 }{ 9 } \\ ) of the current area being considered ,\nand the process continues similarly .\\n\\n Given that , our calculation seems consistent .\\n\\n ### Final Answer \\n\\n The fractional part of the figure that is shaded\nis \\( \\ frac { 1 }{ 2 } \\ ). Therefore , \\( m = 1 \\ ), \\( n = 2 \\ ), and \\( m + n = 3 \\ ).\\n\\n Wait , but looking back at the problem , it\nmentions that the answer is in the form \\( \\ frac { m }{ n } \\ ) with \\( \\ gcd (m , n ) = 1 \\ ), and we need to find \\( m + n \\ ). Here ,\n\\( \\ frac { 1 }{ 2 } \\ ) satisfies this with \\( m = 1 \\ ), \\( n = 2 \\ ), so \\( m + n = 3 \\ ).\\n\\n But before final izing , I recall that sometimes\nsuch problems have the shaded area as \\( \\ frac { 5 }{ 1 2 } \\ ), but based on our reasoning , it 's \\( \\ frac { 1 }{ 2 } \\ ). Double -check ing\nthe recursive relation seems correct .\\n\\n Alternatively , perhaps the shaded parts are not just the immediate corners but also within the subdivisions in a different\npattern . However , based on the As ym pt ote code and the description focusing on the center 's subdivision , our approach seems valid .\\n\\n Thus , the\nfinal answer is :\\n\\n \\ (\\ boxed { 3 }\\ )\\n\\n Wait , but according to our calculation , the shaded fraction is \\( \\ frac { 1 }{ 2 } \\ ), so \\( m + n =\n3 \\ ).\\n\\n But to ensure accuracy , let 's consider another approach .\\n\\n ### Alternative Approach : Ge ometric Series with Proper Sh ading \\n\\n Perhaps a\nbetter approach is to consider at each level \\( k \\ ):\\n\\n - The original square is divided into \\( 3 ^ 2 = 9 \\ ) smaller squares .\\n - At each subdivision\n, 4 of these squares are shaded .\\n\\n But as we go deeper , the center square 's subdivisions continue , and it 's like the same pattern repeats with a\nscaling factor .\\n\\n Let 's think differently : label the initial square as level 0 . At each subsequent level , each existing square is divided into 9 , and\n4 are shaded .\\n\\n But the center square continues to be subdiv ided , effectively repeating the process .\\n\\n Thus , the total shaded area can be thought\nof as the shaded area directly plus the shaded area from all subsequent levels of the center squares ' subdivisions .\\n\\n Math em atically , if \\( S \\ ) is the\ntotal shaded area , then :\\n\\n \\( S = \\ frac { 4 }{ 9 } + \\ frac { S }{ 9 } \\ )\\n\\n Because at each level , we add \\( \\ frac { 4 }{ 9 } \\ ) of\nthe current area being subdiv ided , and the remaining one -n inth contributes to the next level 's scaling .\\n\\n S olving :\\n\\n \\( S = \\ frac { 4 }{ 9\n} + \\ frac { S }{ 9 } \\ )\\n\\n Multiply both sides by 9 :\\n\\n \\( 9 S = 4 + S \\ )\\n\\n Sub tract \\( S \\ ) from both sides :\\n\\n \\( 8 S = 4\n\\ )\\n\\n Div ide both sides by 8 :\\n\\n \\( S = \\ frac { 4 }{ 8 } = \\ frac { 1 }{ 2 } \\ )\\n\\n Thus , the shaded fraction is \\( \\ frac { 1 }{ 2 }\n\\ ), and \\( m + n = 1 + 2 = 3 \\ ).\\n\\n Therefore , the final answer is :\\n\\n \\ (\\ boxed { 3 }\\ )\\n\\n ** Answer :** \\ (\\ boxed { 3 }\\ ) <|endoftext|>\nFigure17: AnExamplegeneratedbyQwen3-14B-BasemodeltrainedbyLp-Regfrommathreasoning.\n21\n",
    "tables": [],
    "images": []
  },
  {
    "metadata": {
      "id": "2510.03217v1",
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "authors": [
        "José Cambronero",
        "Michele Tufano",
        "Sherry Shi",
        "Renyao Wei",
        "Grant Uy",
        "Runxiang Cheng",
        "Chin-Jung Liu",
        "Shiying Pan",
        "Satish Chandra",
        "Pat Rondon"
      ],
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "published": "2025-10-03T17:53:28Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03217v1"
    },
    "text": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in\nAgentic Program Repair\nJoséCambronero1,MicheleTufano1,SherryShi1,RenyaoWei1,GrantUy1,RunxiangCheng1,\nChin-JungLiu1,ShiyingPan1,PatRondon1,SatishChandra2 ∗\n1Google,USA\n2Meta,USA\n{jcambronero,tufanomichele,sherryyshi,renyaow,grantuy,chengsam,chinjungliu,shiyingp,rondon}@google.com\nschandra@acm.org\nAbstract codechanges,whichisessentialforAItooladoption[4,24].This\nAgenticAutomatedProgramRepair(APR)isincreasinglytackling workaimstotacklethischallengebyproposingtwopolicies.\ncomplex,repository-levelbugsinindustry,butultimatelyagent- First,inspiredbyabstentioninclassification[6,12,13],weintro-\ngenerated patches still need to be reviewed by a human before ducebugabstention(Section3.1).WeuseanLLMtopredictifour\ncommittingthemtoensuretheyaddressthebug.Showingunlikely APRsystemislikelytoproduceanacceptablepatchforagivenbug,\npatchestodeveloperscanleadtosubstantialnoise,wastingvaluable usingonlythebugreportinformation.Thischeckisperformed\ndevelopertimeanderodingtrustinautomatedcodechanges.We beforetheagentattemptsarepair.Ifthepredictedprobabilityof\nintroducetwocomplementaryLLM-basedpoliciestoreducesuch successisbelowathreshold,weabstainfromrunningtherepair\nnoise:bugabstentionandpatchvalidationpolicies.Bugabstention agent.Thisavoidsshowingdevelopersunlikelypatchesandsaves\nexcludesbugsthattheagenticAPRsystemisunlikelytofix.Patch computecostsfromfutilerepairattempts.\nvalidationrejectspatchesthatareunlikelytobeagoodfixforthe Second,foranypatchesproduced,weemployamulti-stagepatch\ngivenbug.Weevaluatebothpoliciesonthreesetsofbugsfrom validationpolicytopredictifthepatchiscorrect(Section3.2).This\nGoogle’scodebase,andtheircandidatepatchesgeneratedbyan policycomposesdeterministicchecks(e.g.,runningtests)andan\ninternalagenticAPRsystem.Onasetof174human-reportedbugs, LLM-basedfilter.TheLLMfilterfirstgeneratesa“fixspecification”\nremovingbugsandpatchtrajectoriesrejectedbyourpoliciescan —aguidelineforacorrectfix—basedonthebugdescriptionandorig-\nraisesuccessratesbyupto13percentagepointsand15percentage inalsourcefiles,withoutknowledgeofanyground-truthsolution.\npoints,respectively,andbyupto39percentagepointsincombina- AsecondLLMcallusesthisspecificationandtheagent’strajectory\ntion.Onnullpointerexceptionsandsanitizer-reportedbugswith toproduceaboolean(fixedornot)outcome,anexplanation,anda\nmachine-generated bug reports, patch validation also improves confidencescorederivedfromtoken-levellogprobabilities.\naveragesingle-samplesuccessrates.Thistwo-policyapproachpro- Weevaluatethebugabstentionandpatchvalidationpolicies\nvidesapracticalpathtothereliable,industrial-scaledeploymentof bothindependentlyandincombination(Section4).Ourcombined,\nagenticAPRsystems. two-policyapproachfirstemploysbugabstentiontoscreenoutbugs\nunlikelytobefixed,thenrunstheAPRsystemontheremaining\nbugs,andfinallyusespatchvalidationtofilterthegeneratedpatches.\n1 Introduction\nOurevaluationshowsthesepoliciesarecomplementary,improving\nAsubstantialportionofsoftwaredevelopmentinvolvesdiagnosing\nsuccessratesmosteffectivelywhencombined.\nandrepairingbugs.Tomitigatethiscost,theresearchcommunity\nWeevaluateourpoliciesonthreesetsofbugsfromGoogle’s\nhaslonginvestedinAutomatedProgramRepair(APR)[16–18,23].\ncodebase(Section5).Similartorecentwork[14,20,27],thefirstset\nMorerecently,advancedlanguagemodelshaveenabledmorecom-\nhas174human-reportedbugswithknownground-truthfixesand\nplex,autonomous“repository-level”programrepair,whereasys-\nfail-to-passreproductiontests.Weevaluatebothpoliciesonrepair\ntemmanagesdiagnosis,localization,andrepair.SystemslikeSWE-\ntrajectoriesgeneratedbyourReAct-styleAPRsystemforthisset.\nAgent [35], AutoCodeRover [36], SpecRover [28], and RepairA-\nWefurtherstudypatchvalidationon198machine-reportedJava\ngent [3] show that agent-based APR can tackle such challenge,\nnullpointerexception(NPE)bugsfromalivedeploymentand50\nachievingpass@1bugresolutionratesupto75.20%onbenchmarks\nhistorical,sanitizer-reportedbugswithknownreproductiontests.\nlikeSWE-Bench-Verified(TRAEasof09/02/2025[11]).\nBecause our goal is to reduce developer noise, we introduce\nInanindustrysetting,however,maximizingtherateofsuccessful\n“filtered-success@k”.Thismetriccomputessuccess(e.g.,fail-to-pass\npatchesshowntoadeveloperfromanAPRsystemisasimportantas\norhumanacceptance)onlyonthesubsetofpatchesandbugsthat\nmaximizingthesystem’soverallbugresolutionrate.Whilepass@1\nare“allowed”byourpolicies,ratherthanovertheentirepopulation.\nrates are improving, deploying these agents in production still\nOn our human-reported bug set, the baseline fail-to-pass@1\nrequiresahumandevelopertoreviewandvalidatethegenerated\nrate is 0.11. Applying bug abstention or patch validation alone\npatches.Becausedevelopertimeislimited,reviewingpatchesfor\nraisesthisrateto0.21or0.29,respectively.Whencombined,these\nintractablebugsorunlikelyfixeswastesvaluabletime.Reducing\npoliciesformaconfigurablefunnelthatsignificantlyimprovesthe\nsuchnoisefromunproductiveAPRattemptsisthuscrucial,notonly\nqualityofpatchesshowntodevelopers.Amoderatelypermissive\ntosavedevelopertimebutalsotobuilddevelopertrustinautomated\nsettingraisesthefilteredfail-to-pass@1to0.35.Astricterfunnel\nconfigurationraisesthisrateto0.53—a1-in-2successrate—at\n∗WorkdonewhileatGoogle.\n5202\ntcO\n3\n]ES.sc[\n1v71230.0152:viXra\nGoogleetal.\nFigure1:BugabstentionrejectsissuesthatareunlikelytobefixedbyourAPRsystem.Aftertheagentgeneratespatches,\nvalidationdecideswhetherthesearelikelytohaveaddressedtheissue.JointlytheyreducedevelopernoisefromAPR.\nthecostofshowingpatchesforfewerbugs.Onmachine-reported correspondingto“unknown”(i.e.abstainingfrommakingadeci-\nbugsets,patchvalidationalonealsoshowssignificantgains:for sion).Analogously,intherepairsetting,wesayasystemabstains\nNPEbugs,itraisesthefiltered-accept@1from0.38to0.62,andfor fromabugifitdecidesthatitwillnotattemptrepair.\nsanitizerbugs,itimprovestheratebyupto15percentagepoints Importantly,theabstentionpolicycanonlyaccessthebug,which\noverabaselineusingknownreproductiontests. comprisestextualbugtitle,description,andaccompanyingmeta-\nTosummarize,ourcontributionsinthisworkare: data,tomakeitsdecision;itdoesnotreceiveanyadditionalhuman\n• Abugabstentionpolicytoselectbugssuitableforagentic feedback.Wealsochoosenottoprovidecodebaseaccesstothe\nAPR. abstentionpolicy,whichmayotherwiserequiremakingthepolicy\n• Amulti-stagepatchvalidationpolicytoassesscandidate agenticandlosingsomeefficiencygains.\npatchcorrectness. Wechoosetomodelthisprobleminaprobabilisticfashionto\n• Anextensiveevaluationonthreeindustrialbugsets. produceascore,ratherthanabooleandecision.Intuitively,we\nwantthisscoretoapproximatetheinherentprobabilityofasingle\n2 Background:ReAct-styleAgenticAPR repairattemptsucceeding.Wethenconvertthisintoadecisionby\ncomparingittoaconfigurablethreshold,𝜏.\nOuragenticAPRsystemconsistsofanLLM-drivenReAct-styleloop\nwithcodingtoolsdesignedtointeractwithanisolatedGoogleenvi-\nronment[26].Atthestartoftheprocess,theagentisprovidedwith\nabugreport,whichmaycontainvaryingdegreesofinformation 3.1.1 Formalization. Let𝑏 ∈Bbeabuginasetofbugsthathas\nbeenprovidedtoourrepairsystemastheyrequirecodechangesfor\nabouttheunderlyingbug.Theagentthenproceedsforasequence\ntheirresolution.Weassumethatknowingthatthesebugsrequire\nofupto𝑁 steps,whereeachstepisdefinedasoneLLMoutputand\nexplicitcodechangesisalreadydeterminedinapre-filteringphase\nanassociatedtoolexecution.Thetoolsare:codesearch,viewinga\norbecauseauserhasinformedthesystem.Lettherebe𝑛indepen-\nfile,editingafile,runningtests,andfinishingtherepairtrajectory.\ndentBernoullitrialsreflecting𝑛independentrepairattemptsby\nTheLLMoutputconsistsoftwoportions:athought,describing\ntherepairagenton𝑏.Theoutcomeofthe𝑖-thtrialforbug𝑏,𝑋 ,is\ntheagent’sintentionsinnaturallanguage,andanaction,asimple 𝑏,𝑖\n1iftheagentgeneratesasuccessfulpatchintrial𝑖and0otherwise.\nUnix-stylefunctioncallingformatwhichweparseandthenuse\ntoexecutetheassociatedtool∗.TheLLMoutputandenvironment\nAccordingly,wedefinetheempiricalprobabilityoftheagent’s\nresponsesareaddedtoanappend-onlyhistory.Formoredetailson successonbug𝑏as𝜋ˆ 𝑏 = 𝑛 1 (cid:205)𝑛 𝑖=1 𝑋 𝑏,𝑖 ,ortheexpectedvalueofa\nrepairtrial.\ntheunderlyingagent,werefertheinterestedreaderto[27].\nThisempiricalvalue𝜋ˆ isanobservation-basedestimateofthe\n𝑏\n3 AbstentionandValidationPolicies\nunknown,trueprobabilityofsuccessforbug𝑏,withrespect\nWeintroducetwokeycomponentsintoanagenticAPRsystem\ntoaparticularrepairsystem,whichwedenoteas𝜋\n𝑏\n=𝑃(𝑋\n𝑏,𝑖\n=1).\nEstimating𝜋ˆ requiresasuccesscriterion,suchasatestoracleor\ntoreducedevelopernoise.InFigure1,weaugmentthecoreAPR 𝑏\nhumanreviewer.Duringdeployment,however,suchcriterionis\nAgentmodule(inblue)withacomponentbeforetherepairloop\neitherunavailable(notest),orrenderstheestimationunnecessary\n(Bug Abstention) and a component after the repair loop (Patch\n(manualreviewonallpatches). Thus,foragivenbug𝑏,weleverage\nValidation).ThebugabstentionpolicyfiltersoutbugsthattheAPR\nanabstentionmodel𝑃\n𝑎\ntoproduce𝑃 𝑎(𝑏),whichthenisusedto\nagentisunlikelytofix,whilethepatchvalidationpolicyfiltersout\npatchesthatareunlikelytobeacorrectfixforagivenbug.Wenow\nestimate𝜋ˆ\n𝑏\n,apriori.Weaimtoturn𝑃 𝑎(𝑏)intoadecisionpolicy\nthatallowsustofilterdowntheoriginalbugsetBtoanewsetB′,\ndescribethesepoliciesinmoredetail.\nsuchthatB′ ⊆ BandE 𝑏′∈B′[𝜋 𝑏′] > E 𝑏∈B [𝜋 𝑏],demonstratinga\nreducedprobabilityofwastedrepairattempts.\n3.1 BugAbstentionPolicy\nExplicitly,theabstentionmodel’spredictioncanbeturnedinto\nAbstention is a well-known technique in classification [8], and adecisionpolicythroughathreshold.Letthisbeexpressedasa\namountstoallowinga𝐾-labelclassifiertoproduceanextralabel function,𝐷 ,whichmapsthemodel’spredictedsuccesslikelihood\n𝑎\n∗OneofourexperimentsreliesonGeminifunctioncallinginsteadofcustom\ntoanactionfromtheset{AttemptRepair,Abstain}.Givenapre-\nparsing. definedthreshold,𝜏 ∈ [0,1],thedecisionruleisformalizedas:\nAbstainandValidate:ADual-LLMPolicyforReducingNoiseinAgenticProgramRepair\nInourimplementation,wecompute𝑃 usingamulti-stageap-\n𝑣\n(cid:40)\n𝐷 𝑎(𝑃 𝑎(𝑏),𝜏)= A\nA\nt\nb\nt\ns\ne\nt\nm\na\np\ni\nt\nn\nRepair i\ni\nf\nf\n𝑃\n𝑃\n𝑎\n𝑎\n(\n(\n𝑏\n𝑏\n)\n)\n≥\n<\n𝜏\n𝜏\np\np\nr\na\no\ntc\na\nh\nch\nes\n.W\nth\ne\nat\nfi\nh\nrs\na\nt\nv\np\ne\ne\nk\nrf\nn\no\no\nr\nw\nm\nn\nbu\nis\ni\ns\nld\nue\na\ns\nn\n.\nd\nSp\nte\ne\ns\nc\nt\nifi\nre\nc\ng\na\nr\nl\ne\nly\ns\n,\nsi\nw\non\neu\nch\nse\nec\nG\nk\no\ns\no\nto\ngl\nr\ne\ne\n’\nm\nsu\no\nn\nv\ni\ne\n-\nfiedbuildsystemtoextracttargetsthathaveanymodifiedfilesas\nOurabstentionpolicyqueriesanLLMtoproduceapredictionof\nadirectdependency.Alternatively,ifthebugwearetacklinghasa\nthe(unobserved)probabilityofanattemptsuccessfullyaddressing\nknownreproductiontest,wereplacethisregressioncheckwitha\nagivenbug.Weuseaninstruction-stylepromptandinstructthe\nfilterthatrejectsanypatchesthatfailtopassthereproductiontest.\nmodeltoproduceoneoftwopossibleoutcomes,success(attempt\nNext,ourreviewerappliesasimpleheuristicwhichremoves\nrepair)orfailure(abstain),givenapromptwithsomerepresenta-\ntrajectoriesthathaveafinaltestcommandissuedbytheagent\ntion𝑟(𝑏)ofthegivenbug𝑏.Wedefine𝑃 𝑎(outcome)asthemodel\nthatresultsinafailure.Notethatthismaycapturedifferenttest\npredictedprobabilityofthattoken.Sincesuccessandfailureare\ntargetsthanthebuild/testcheckastheagentisnotrestrictedto\ntheonlytwopossibleoutputsbasedontheinstructions,theLLM’s\nexecutingonlydirectdependencies.Finally,ourvalidationemploys\ndecodingshouldplacerelativelylittleweightonothertokensand\natwo-stagedLLMprediction,whichwenowdescribeindetail.\nso𝑃 𝑎(success|𝑟(𝑏))+𝑃 𝑎(failure|𝑟(𝑏)) ≈1.Weconfirmedthis\npropertyonaheld-outsetofbugsduringourdevelopment. 3.2.2 Fixspecification. PastliteratureintheareaofLLMs-as-judges\nhasexploredtheuseofgeneratedrubricstoperformmoreaccurate\n3.1.2 Bugrepresentations. Asiswellknown,thepromptusedto scoringofananswer[32].However,thisrubricisoftenbasedon\nqueryanLLMcanhaveasubstantialimpactonitsperformance[19,\nadditionalinformationsuchasthereferenceanswer[37],whichis\n31].Wedescribetwopossiblebugrepresentationsforourprompt.\nnaturallyunavailableinoursetting,whereweareattemptingto\n• 𝑟 1(𝑏)InstructionPromptingwithTitleandDescrip- repairaprogramwithoutknowingthefixaheadoftime.\ntion.TheLLMisprovidedwiththetitleanddescription However,wedotakeinspirationfromthislineofresearch,and\noffromthebugreport,alongwiththecapabilitiesofthe exploretheLLM’sabilitytogenerateasetofcriteriafordetermin-\nagentusedinourexperiments.Specifically,weprovidein- ingifanagentattempthassuccessfullyaddressedabugwithout\nformationonthecommandsavailabletotheagent,aswell access to any ground truth—we refer to this as a “fix specifica-\nastheexecutionbudgetfortheexpectedagentruns.The tion.”WesimplyprovidethisspecificationaspartoftheLLMjudge\nassociatedprompt(shownintheAppendixasListing1)in- prompttoproduceascoreforthepatch.Togeneratethefixspecifi-\nstructsthemodeltoanalyzethebug’stitleanddescription cation,wepromptanLLMwiththebuginformationandtheoriginal\nandoutputonlysuccessorfailure. sourcecodecontentsofthefilesthatwereeditedintheagent’s\n• 𝑟 2(𝑏)InstructionPromptingAddingGuidelines.This candidatepatch.Importantly,thisconnectsthefixspecificationand\nrepresentationbuildsontopof𝑟 1(𝑏)byincorporatingguide- theagent’sattemptbyre-usingthelocalizationinformationfrom\nlinesthatcanbeusedtodeterminethelikelihoodofsuccess- theagent’strajectorytogeneratethefixspecification.Notethat\nfulbugresolution.Wederivedtheseguidelines—detailed thisagenttrajectorydoesnot containanyinformationfromthe\ninListing2(Appendix)—throughamanualprocessona ground-truthfix—thatis,thespecificationcanonlybederivedfrom\nheld-outsetof50human-filedbugs.Fourauthorsinspected informationknownatthestartoftherepairattempt.Wedonot\nthebugtitlesanddescriptions,determinedsubjectivediffi- imposeanyformatorstructureonthegeneratedspecificationand\ncultylevels,andprovidedshortguidelinethatwouldhelp insteadallowtheLLMtofreelygeneratethiscontent.Inpractice,\nidentifyingbugsthatcouldberesolvedbyreasonableat- themodeloftengeneratesclearMarkdownwithadiagnosisand\ntemptsfromanagent.Oneauthorcollatedtheinspection listofexpectedpropertiesofacorrectchange.\noutcomesinto5basicguidelinecategories,suchas“Clear\nProblem&Action”and“PreciseCodeLocalization”.These 3.2.3 Reviewingwithaspecification. OncetheLLMhasgenerated\nguidelinesareaddedtotheprompt. afixspecification,asecondLLMcalljudgestheagent’sattempt.\nThispromptincludesthebuginformation,theunified-diff-format\n3.2 PatchValidationPolicy patchproducedfromtheagent’strajectory,testresultinformation\n(extractedfromthetrajectory)foranytesttargetsrunbytheagent,\nPatchvalidationperformsananalogousaccept/rejectdecisionat\nandthegeneratedfixspecification.\nthepatch-level.Specifically,itpredictswhetheraparticularrepair\nAtestresultconsistsofanumberedtestattemptforaparticular\ntrajectoryproducedasuccessfulpatchforaspecificbug.\ntestsuitetarget,andtheassociatedenvironmentresponse(includ-\n3.2.1 Formalization. Let𝑡beaparticulartrajectoryfromtherepair inglogsforafailure).Ifnotestresultinformationisfound,we\nagentwhenattemptingtorepairbug𝑏.Givensomerepresenta- simplystate“Notestinginformationisavailable”.\ntionofthetrajectory,𝑟(𝑡),thepolicypredictsatriplet𝑃 𝑣(𝑏,𝑟(𝑡)) ∈\n3.2.4 Reviewingwithoutaspecification. Besidesourspecification-\n{false,true}×Σ∗×R,wherethefirstelementisabinaryjudgment\nbasedvalidation,weexperimentwithavariantofvalidationthat\nforpatchcorrectness,thesecondelementisanaturallanguageex-\nconsumesthebugdescriptionandtheconcatenationofallprompt\nplanationofthejudgment,andthethirdelementisanoptional\nmessagesandresponsesthatwereproducedduringtheagent’s\nconfidencescoreforthepatch’scorrectness.Wethendefineadeci-\nexecution.Recentwork[25]hasusedthisrepresentationtojudge\nsionfunctionoverthistriplet,whichcanusethebinaryjudgment\nanagent’sattemptstosolveSWE-Benchtasks.\northepatchcorrectnessconfidencescoretofilteroutpatchesand\nallowfortheintelligentallocationofhumaneffort,filteringout 3.2.5 Patchvalidationoutputs. Asdescribedpreviously,theoutput\nlesslikelypatchesasnoiseandreducingreviewtime. of the validation policy is a triplet consisting of a judgment, a\nGoogleetal.\nnatural-languageexplanation,andareal-valuedconfidencescore. Wethengenerated20trajectorieswitha25-steplimitforeach\nToenforcethisformat,weemployconstraineddecoding[10,29]. ofthe174bugsusingouragenticAPRsystem(Section2)using\nWedefinethepatchcorrectnessconfidencescorefortheresponse Gemini2.5Pro[7]withtemperature0.2andtop_p0.95.\nheuristically.Ifvalidationreturnsanegativebinaryjudgment,this Weconsiderthesuccesscriteriontobewhethertheheld-outfail-\nscoreissettozero.Ifthevalidationreturnsapositivebinaryjudg- to-passtestsucceeds.Wehavefoundthiscriterioncloselymatches\nment,wesetthisscoretotheexponentialoftheaveragetokenlog correctnessinhuman-reportedbugsfromourcodebase[27].\nprobabilities.Whilenotawell-definedprobability,ourevaluation\nshowsthisscorecanimproveperformanceoverbinarylabels. 5.1.2 Nullpointerexception(NPE)bugs. Wecollectedasetof198\nmachine-reportedNPEbugsthatouragentattemptedtorepair\nduringalivedeployment.Everybugreportincludesastacktraceof\n3.2.6 Decisionsoverpatchvalidationoutputs. Wecanmakede-\ntheexception.Thereportmayalsoincludeasection(messageblob)\ncisions based on the binary judgment or the patch correctness\nthatprovidesadditionalmachine-generateddebugginginformation.\nconfidencescoreextractedfromthevalidationoutputs.Wecon-\nDuringdeployment,oursystemusedpatchvalidationwithfix\nsidertwovariants(1)binary,whereweusethebinaryjudgment\nspecification to filter patches, normalize patches, and choose a\nandacceptpatcheswithapositivelabel;(2)percentileofpatch\nsinglepatchperbugbasedonmajorityvoting.Thenormalization\ncorrectnessconfidencescore,whereweestimateaparticular\nstepincludesnormalizingidentifierstrings(mappingeachunique\npercentilecutoffacrossallpatchesforallbugsinthegivensetand\nlikelyidentifierstringtoauniqueindex)andpost-patchleast-line-\nthenacceptpatcheswithascoreatorabovethatcutoff.Whileper-\ncounttie-breakers.Apatchwasthensentforhumanreview,and\ncentilethresholdingneedsasetofpatchestoperformajudgment,\nsubmittedtothecodebaseifacodeowneraccepteditasfix.\nitmitigatestherisksofscoredrift,e.g.duetopopulationormodel\nDuringlivedeployment,ourAPRsystemsetupdifferedinthe\nchanges,andcloselyalignswiththeideaofbudget-basedreviewing\nfollowing:function-callingisthroughGeminiinsteadofcustom\n(i.e.,ahumanreviewsthetop≤𝑘patches).\nReActparsing,asynchronousstepexecutiontoallowlong-running\ncallswithoutblockingconcurrentrepairsnoroverloadingservices,\n4 ComposingAbstentionandValidation atmost5trajectoriesweregeneratedwith25-steplimitperbug.\nWhileabstentionandvalidationpoliciescanbeusedindependently,\n5.1.3 Sanitizerbugs. Wecollectedasetof50sanitizer-reported\nthesetwopoliciescanalsobecombined.Wepresentandevaluate\nbugswithaknownground-truthfixfollowingthecurationpro-\nasimplesequentialcombinationofthetwopolicies.\nceduredescribedinourpastwork[27].Thesebugscoverissues\nLet𝑅 representourrepairsystem,which,givena𝑏 bug,gen-\nsuchasmemoryerrors,dataraces,datatypeoverflows,typecasting\neratesmultipletrajectoriesindependently.Eachtrajectory𝑡 hasa\nerrors, and fuzzer-detected errors. We use the same APR agent\n.patchpropertyrepresentingallchangesmadebytheagent.Let\nconfigurationasforourhuman-reportedbugset.\n𝑃 𝑎(𝑏) be the probability predicted by the abstention policy for\nsamplingasuccessfulfixforbug𝑏.Let𝑃 𝑣(𝑏,𝑡)bethepatchvali-\n5.2 Metrics\ndationpolicyoutput.Let𝜏 betheabstentionthresholdand𝐷 be\n𝑎 𝑣\nWe report precision and recall for both policies. For repair per-\nthedecisionfunctionoverthevalidation’soutput.Thenthesetof\nformance,wefocusonastandardpass@kmetric,andavariant\npatchesultimatelyshownforhumanreviewis:{𝑡.patch|𝑃 𝑎(𝑏)≥\nwherebugsandpatchesarefilteredbythecorrespondingpolicies.\n𝜏 𝑎 ,𝑡 ∈ 𝑅(𝑏),𝐷 𝑣(𝑃 𝑣(𝑏,𝑡))}.Weleavealternatecompositions(e.g.,\nprobability-based)orfurtheroptimizations(e.g.,accountingfor\nLetB′ bethesetofbugswithatleastonerepairrun/trajectory\navailableafterbugabstentionhasfilteredbugsandpatchvalidation\nbug/reviewcostandfixvalue)forfuturework.\nhasfilteredpatches,𝑛′bethetotalnumberofrunsremainingafter\napplyingpatchvalidation,and𝑐′bethesuccessfulcountamong\n5 Evaluation those.Thenthefiltered-success@kmetricisdefinedas:\nWenowdescribeourdatasets,metrics,andresearchquestions.\n(cid:0)𝑛′−𝑐′(cid:1)\n5.1 Datasets\nfiltered-success@𝑘 =E B′[1−\n(cid:0)𝑛\n𝑘\n′(cid:1)\n]\n𝑘\nWeusethreeindustrialbugdatasets(Table1)forevaluation.Bug Thesuccesscriteriondiffersbybugtypes.Forhuman-reported\nabstentiononlyappliestohuman-reportedbugs.Machine-reported bugs, we use the held-out ground-truth test to compute fail-to-\nbugs(i.e.,NPEandsanitizerbugs)areallgoodcandidatesforAPR passandreportfiltered-fail-to-pass@k.ForNPEbugs,whichwere\nbyconstruction,astheycontainreproductiontestsorstacktraces. openatthetimeofcollectionandmaynothaveanytests,weuse\nhumanacceptanceannotationsandreportfiltered-accept@k.The\n5.1.1 Human-reported bugs: From Google’s monorepo, we col- annotationsarefromrealcodeowners,orauthorsifthepatchhad\nlected a set of 174 human-reported bugs filed within a year by notbeenreviewedbyownersduringlivedeployment,e.g.,apatch\nfollowingacurationprocesssimilartothatforpopularbenchmarks notpickedbymajorityvoting(§5.1.2).Forsanitizerbugs,which\nlikeSWE-BenchandrecentagenticAPRworkinindustry[20,27]. haveknownground-truthfixesandareproductiontestatreporting\nSpecifically,weadheretothecurationprocessdetailedin[27]and timeforfilteringpatches,wemanuallycomparepatchestoground-\nadditionallyrestrictexamplestothosewithatmost31testtargets truthfixesforsemanticequivalence,andreportfiltered-accept@k.\nthatdependontheassociatedgroundtruthfiles.Bugcurationsteps Forbothbugpolicies,wealsoincludecomparisonstoano-skill\ndetailedinAppendixA. policywhichalwaysacceptsbugs(orpatches,respectively).Under\nAbstainandValidate:ADual-LLMPolicyforReducingNoiseinAgenticProgramRepair\nSet Description # Policies SuccessCri-\nteria 1.2\nHuman Human- 174 Abstention Passesheld-\n1.0\nreportedbugs +Validation outreproduc-\nwithknown tiontest.\n0.8\nfix.\nNPE Openbugs 198 Validation Confirmed 0.6\nfromalive correctby\ndeployment codeowner 0.4\nofarepair ormanual\nsystem. inspection. 0.2\nSanitizer Sanitizer- 50 Validation Confirmed\nreportedbugs correctby 0.0 0% 20% 40% 60% 80% 100%\nwithknown manualin- Probability\nfix. spection.\nTable1:Benchmarks,policiesapplied,andsuccesscriteria.\nthisno-skillpolicy,theprecisionofpredictionscorrespondstothe\nprevalencesuccessfulcasesinthepopulation.\n5.3 ResearchQuestions\nWeaimtoanswerthefollowingfourresearchquestions:\nRQ1:Canbugabstentionsuccessfullyabstainonourhuman-reported\nbugs?Doesthisimprovefiltered-fail-to-pass@k?\nRQ2:Canpatchvalidationsuccessfullypredictifapatchshouldbe\nrejectedonourhuman-reportedbugs?Doesthisimprovefiltered-\nfail-to-pass@k?\nRQ3:Doescombiningbugabstentionandpatchvalidationfurther\nimprovefiltered-fail-to-pass@konourhuman-reportedbugs?\nRQ4:Howdoespatchvalidationimprovefiltered-accept@konbugs\nwithsystematically-generatedreports(NPEandsanitizerbugs)and\nknownreproductiontests(sanitizerbugs)?\n6 Results\nWe now present our experimental results. At the time of these\nexperiments,ourabstentionpolicyusesGemini2.0Flash(newer\nmodelsarenowavailable)patchvalidationpolicyusesGemini2.5\nPro,andbothperformgreedydecoding(temperature=0).Weexpect\ntouseasmallermodelforabstentionforefficiencyasitrunsona\nlargernumberofinputsthanpatchvalidation.\n6.1 RQ1:BugAbstentionPolicy\nWeevaluatebugabstentiononthetwobugrepresentationvariants:\nwithandwithouttheuseofgeneralguidelines(Section3.1.2).\nFigure2showsacomparisonofmodel-predictedprobabilities\nandtheempiricalsuccessrate(Section3.1.1)ofrepairrunsforthe\n174human-reportedbugs.Theempiricalsuccessrate(green)isthe\nfractionoftrajectoriesthathaveapassingoutcomeontheheld-out\nreproductiontest,whichindicatestheinherentdifficultyofAPR.As\nshown,itisheavilyskewed,withthevastmajorityofbugshaving\naverylowtruesuccessrate,concentratedinthe0–15%range.The\nskewnessconfirmsthatanagenticAPRsystemcanbenefitfroman\nabstentionmechanismtoavoidwastinghumanrevieweffort.\nytisneD\nDistribution of Empirical vs. Model Probabilities\nSource\nR1 - Abstention\nR2 - Abstention w/ Guidelines\nEmpirical Success Rate\nFigure 2: Using abstention with guidelines better aligns\nmodelprobabilitieswithobserved(left-skewed)rates.\nAbstentionwithrepresentation𝑟 (i.e.,withoutguidelines)pro-\n1\nducesamoreuniformdistributionofrepairsuccessprobability.In\ncontrast,abstentionwith𝑟 (i.e.,withguidelines)producesadistri-\n2\nbutionthatmuchmorealignstothatoftheempiricalsuccessrate.\nWefurthermeasuredtheWassersteindistance[1]betweeneach\npredicteddistributionandtheempiricalsuccessratedistribution:\nthedistancefrom𝑟 (0.126)wasnearlythreetimessmallerthan\n2\nthatfrom𝑟 (0.363),indicatingthat𝑟 isamuchbetteroverallfitfor\n1 2\nbugabstention.Liketheempiricaldata,abstentionpredictionswith\n𝑟 arecorrectlyconcentratedatlowerprobabilityvalues,whilestill\n2\nassigningahigherrepairsuccessprobabilitytoeasierbugs.\nFigure3presentsprecision-recallcurvesforbothabstentionpol-\nicyvariants,ahorizontallinefortheprevalenceofasuccess,anda\nsummaryaverageprecision(AP)score.Forpurposesofthisclassi-\nfication,wedefinesuccessasanybugthathasatleastonerepair\ntrajectorythatpassestheheld-outreproductiontestamongthe20\ntrajectoriesofthebug.Theprevalenceofsuccesscorrespondsto\ntheprecisionthatcouldbeexpectedfromano-skillpolicy,which\njustacceptsallbugs,andallpatchesforthesebugs.Forourhuman-\nreportedbugset,thisprevalencecorrespondsto27%ofallbugs\nhavingatleastonesuccessfulrepairtrajectorywithoutanyab-\nstentionfiltering.Weobservethatbothabstentionpolicyvariants\ncanimproveoverprevalence;addingguidelinesfurtherprovides\nimprovementsacrossarangeofrecallvalues.\nToturntheabstentionpredictionsintoadecisionpolicy,we\nselect𝜏 =0.5asasensibledefaultfortheabstentionpolicythreshold\nbased on a separate development bug set. Using this threshold\nproducesaprecision/recallof0.44/0.41inthatset.Thisthreshold\nis also intuitive, as it prioritizes bugs with a predicted success\nprobabilitygreaterthanfailure.Moreimportantly,itachievesa\nstrongbalancebetweenprecisionandrecall,effectivelyfiltering\noutalargenumberofbugsunlikelytobefixedwhileretaininga\nsignificantportionofthefixableones.\nFigure4showsthepass@k(whenabstensionisnotapplied)\nandthecorrespondingfiltered-fail-to-pass@k(whenabstention\nisapplied)ofouragenticAPRsystemonthesetof174human-\nreportedbugs.Weuse𝜏 =0.5whenapplyingabstention.Applying\nabstentionimprovesthesystem’sefficacy,andthe𝑟 abstention\n2\nvariantdemonstratesthemostsignificantgain.Thebaseline(no\nGoogleetal.\n1.0\n0.8\n0.6\n0.4\n0.2\n0.0 0.0 0.2 0.4 0.6 0.8 1.0\nRecall\nnoisicerP\nNo-Skill Classifier (Prevalence = 0.27)\nR1 - Abstention (AP = 0.389)\nR2 - Abstention w/ Guidelines (AP = 0.434)\nFigure3:Bothabstentionvariantsoutperformrandomlysam-\npling to identify bugs with at least one successful repair.\nAddingguidelineshelps.(AP=averageprecision)\n1.0\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0.0\n1 2 3 4 5 6 7 8 91011121314151617181920\nk (Number of Attempts)\n)k@ssap(\netaR\nssaP\n1.0\n0.8\n0.6\n0.4\n0.2\n0.0\n0.0 0.2 0.4 0.6 0.8 1.0\nRecall\nPolicy\nR2 - Abstention w/ Guidelines\nR1 - Abstention\nNo Abstention\nFigure4:Abstentioncanraisefail-to-pass@kbyremoving\nbugsthatarelesslikelytosucceedwithourAPRsystem.\nabstention)achievespass@1of11.29%.Byfilteringbugswiththe\n𝑟 abstentionpolicy,thefiltered-fail-to-pass@1rateincreasesto\n1\n16.81%.The𝑟 abstentionachievesanevenhigherfiltered-fail-to-\n2\npass@1of21.05%.Thistrendofimprovementcontinuesasmore\nrepairattemptsaremade:when𝑘 =20,(filtered-fail-to-)pass@k\nclimbsfrom27.01%(noabstention)to44.74%(𝑟 abstention).Ifwe\n2\nconsiderhavingatleastonepassingtrajectoryin20asaground-\ntruthpositivelabelforabugandanabstentionprobabilityabove\nourthresholdasapredictedpositivelabel,ourabstentionpolicy\nresults in a 16.5% false positive rate, defined as a ratio of false\npositivestoground-truthnegatives.Theseresultsstronglysuggest\nthatabstentioneffectivelydiscardsbugswithalowfixprobability,\nallowingtheAPRsystemtoconcentrateonmore-promisingbugs.\n6.2 RQ2:PatchValidationPolicy\nWecomparethreepatchvalidationpolicyvariants:(1)no-skillpolicy,\ni.e.,prevalence,whichreportsthefractionofsuccessfultrajectories\nafterfilteringpatchesthatfailbuildandtestregressionchecks,(2)\nnoisicerP\nConfiguration\nvalidation\nno-spec-validation\nno-skill policy (prevalence)\nFigure5:Patchcorrectnessscoreallowsmoreaggressiveval-\nidation,withprecisionupto3×thesuccessprevalence.\nvalidationthatusesfixspecification(Section3.2.3),and(3)no-spec-\nvalidationthatdoesnotusefixspecificationandreviewstheagent’s\nwholetrajectory(Section3.2.4).\nTodeterminethebuildandtestregressionchecks,weextract\nfromGoogle’sunifiedbuildsystemanytargetsthathaveamodified\nfileasadirectdependency.Weretrievethisdirectdependencyby\nidentifyingthebuildsystemrulesthatincludethemodifiedfilein\ntheirdefinitions.GivenGoogle’smonorepo,transitivedependencies\ncanquicklygrow,andsoweusethisrestrictedsetofrulesasa\npracticalapproximationtoidentifyingandremovingregressions.\nOur experiments show that while using fix specification im-\nprovesbothprecisionandrecallovertheablation,theabsolute\nprecisionremainsmodestat0.3.Theno-specvalidation’sbinary\njudgmentisheavilybiasedtowardspositivejudgment,providing\nlowrecalloffailingpatchesandprevalence-levelprecisionforsuc-\ncessfulpatches.Theno-specvalidation’sbiastowardspositivejudg-\nmentresultsinahighfalsepositiverate(ratiooffalsepositivesto\nground-truthnegatives)of0.64comparedto0.28forthevariant\nthatusesthefixspecification.\nWeshowthatdespitethemodestpredictivepowerofbinary\njudgment,thevalidation’spatchcorrectnessscorecanbeusedto\ndistinguishbetweenpredictions.Asareminder,wedefinethisscore\naszerofornegativebinaryjudgmentsandastheexponentialof\ntheaveragelogprobabilitiesoftheresponsetokensforpositive\nbinaryjudgments.Figure5showsprecision-recallcurvesforboth\nthevalidationandtheno-specvalidation,aswellasahorizontalline\nfortheno-skillpolicyafterregressionchecks.Atstricterthresholds,\nourspec-basedvalidation(inblue)canyieldaprecisionuptothree\ntimeshigher(atthecostofrecall)thanthatoftheprevalencerate,\nofferingasubstantialnoisereductionforasubsetofbugs.wefind\nthattheno-specvalidationcanimproveovertheno-skillpolicy\nbutachieveslowerprecisionatthesamerecallthanthespec-based\nvalidation. With the 75th and 90th percentile cutoffs, the spec-\nbasedvalidationachievesafalsepositiverate(FPR)of0.13and0.04,\nrespectively,whiletheno-specvalidationachievesanFPRof0.15\nand0.06,respectively.\nWenowstudytheimpactofdifferentdecisionproceduresfor\npatchvalidationwithfiltered-fail-to-pass@k.Weevaluatetwode-\ncisionproceduresdescribedinSection3.2.6forvalidation.Specifi-\ncally,oneprocedureusesbinaryjudgment:validation-binaryand\nAbstainandValidate:ADual-LLMPolicyforReducingNoiseinAgenticProgramRepair\nno-spec-validation-binary.Theotherusesthe75thand90thper- 1.0\ncentile thresholds of all patches’ correctness scores: validation\n-p75 and validation-p90 (and similarly for no-spec-validation). 0.8\nFigure6comparesthefilteredfail-to-pass@kofthesepatchvali-\ndationvariantsagainstbuild-and-test,whichisabaselinethat 0.6\nsamplespatchesthatpassbuildandtestregressionchecks.The\nfilteredfail-to-pass@kofbuild-and-testare0.14and0.19when 0.4\n𝑘equalsto1and3,respectively.Onno-specvalidation,usingbi-\nnaryjudgmentprovidesnoimprovement.However,usingthe75th 0.2\nand90thpercentilethresholdsofpatchcorrectnessscores,no-spec\nvalidationraisesfilteredfail-to-pass@1to0.16and0.22,respec- 0.0 1234567891011121314151617181920\ntively. Similarly, on spec-based validation, using 75th and 90th k\npercentilethresholdsofpatchcorrectnessscoresbetterimprovefil-\nteredfail-to-pass@1thanusingbinaryjudgment.Binaryjudgment\nonlymodestlyimprovesfilteredfail-to-pass@1(0.16),whilethe\n75thand90thpercentilethresholdsimprovefilteredfail-to-pass@1\nmore substantially to 0.21 (+7 percentage points, +50% relative\nimprovement)and0.29(+15percentagepoints,+100%relativeim-\nprovement),respectively.Overall,usinganaggressivevalidation\npolicyresultsinfewerbugsthathaveatleastonepatchthatcanbe\nsurfaced.However,giventhatourgoalistoreducedevelopernoise,\nweprioritizeincreasingthelikelihoodofsuccessforanypatches\nthatremain.\nInFigure6,filtered-fail-to-pass@kimprovesfurtherasavalida-\ntionvariantwithmoreaggressivefilteringisapplied.Whilethis\nimprovementtrendmatchesourgoalonreducingdevelopernoise,\nitalsopresentsatradeoffoccurringinpatchvalidationbetween\nreducingdevelopernoise(bydiscardingmoreagenttrajectories)\nandincreasingbugresolutionrate.\nTobetterunderstandthistradeoff,wecompute“(pass&valida-\ntion)@k”,whereatleastonepatchmustbothpassthereproduction\ntestandsatisfythevalidation,andpresenttheresultsinFigure7.\nFigure7showsthat:moreaggressivefilteringinvalidationreduces\noverallbugresolutionrate.Forexample,(pass&validation)@1\ndecreasesby2,4,and7percentagepointsforbinaryjudgment,\n75thpercentilethresholdjudgment,and90thpercentilethreshold\njudgment,respectively.Insummary,whenemployingavalidation\npolicy,thereisthistradeoffbetweenwastedcomputeanddeveloper\nattentiontoconsider.Thevalidationpolicyultimatelyrejectsmany\ngeneratedpatches,whichlowersoverallbugresolutionratesand\nleadstoearlyflatteninginFigure6,butensuresthepatchesshown\ntodevelopersaremorelikelytobeplausible.\n6.3 RQ3:CombinedAbstention-and-Validation\nWenowevaluateadual-policyframeworkthatcombinesabsten-\ntionandvalidation:itfiltersbugsviatheabstentionpolicy,then\nfilterspatchesviathevalidationpolicy(Section4).Forevaluation,\nwe set the abstention threshold to 0.5, rejecting any bugs with\napredictedvaluebelowthat.Weusespec-basedvalidation,and\nconsiderbothbinaryandpercentile-thresholdjudgments.Figure8\ncompares(filtered-)fail-to-pass@kbetweenthecombinedvariants\n(combined-*),apolicythatonlyappliesabstentionandexcludes\ntrajectoriesthatproducenopatches(abstention),andabaseline\nthatappliesneitherabstentionandvalidation(no-filter).\nCombinedabstentionandbinaryvalidationcanraisefilteredfail-\nto-pass@1to0.29overabstentionalone(+5percentagepoints)or\nk@ssap-ot-liaf\nderetlif\nnaeM\nConfig\nbuild-and-test(bugs=163) no-spec-validation-binary(bugs=161)\nvalidation-binary(bugs=146) no-spec-validation-p75(bugs=119)\nvalidation-p75(bugs=107) no-spec-validation-p90(bugs=79)\nvalidation-p90(bugs=59)\n0.300\n0.275\n0.250\n0.225\n0.200\n0.175\n0.150\n1234567891011121314151617181920\nk\nk@ssap-ot-liaf\nderetlif\nnaeM\nConfig\nbuild-and-test(bugs=163) no-spec-validation-binary(bugs=161)\nvalidation-binary(bugs=146) no-spec-validation-p75(bugs=119)\nvalidation-p75(bugs=107) no-spec-validation-p90(bugs=79)\nvalidation-p90(bugs=59)\nFigure6:Validationcanraisefiltered-fail-to-pass@1upto\n15percentagepointscomparedtousingonlybuildandtest\nregressionchecks.Weshowthesameplotzoomedinforeasy\ncomparison.Parenthesesshownumberofbugswithatleast\nonepatchaftervalidation.\nvalidationalone(+13percentagepoints).Moreaggressivefiltering,\nsuchas75thpercentilecanincreasefiltered-fail-to-pass@1to0.35\n(+11percentagepointsrelativetoabstentionaloneand+14tothe\nsamevalidationalone).Thesepercentilethresholdscreateaconfig-\nurablefunnelfordeveloperreview.Astrictpolicy(combined-p90)\nnarrowstheintaketojust12bugs,butitsoutputishigh-confidence,\nwithafilteredfail-to-pass@1of0.53(a1-in-2successrate).Amore\npermissivepolicy(combined-p75)widenstheintake,doublingthe\nnumberofbugsforinspectionwhilestillyieldingahighsuccess\nrateofroughly1-in-3.\nWhileitisnotsurprisingthatusingvalidationcanimproveon\nbug-abstention-onlysuccessrates,asvalidationhasaccesstomore\ninformation(e.g.,theagent-generatedpatch)andisjudgingasingle\ninstance,wealsoobserveimprovementsoverthevalidation-only\nversion.Thisisinterestingbecausepatchvalidation—justlikethe\nbugabstentionpolicy—hasaccesstothebugreport.Wehypothesize,\nthatgivenapatch,validationismorelikelytobepersuadedofthe\nGoogleetal.\n1.0\n0.8\n0.6\n0.4\n0.2\n0.0\n1234567891011121314151617181920\nk\nk@)noitadilav\n&\nssap(\nnaem\nConfig\nno-validation validation-p75\nvalidation-binary validation-p90\nFigure7:Moreaggressivefilteringtradeoffsbetweenreduc-\ningdevelopernoiseandincreasingbugresolutionrate.\n1.0\n0.8\n0.6\n0.4\n0.2\n0.0\n1234567891011121314151617181920\nk\nk@ssap-ot-liaf\nderetlif\nnaeM\nFigure9:AbstentionandValidationFunnel.Ourcombined\npoliciesfilteraninitialsetof174bugs,progressivelynar-\nrowingthesettoincreasethequalityofpatchesshownto\nadeveloper.Eachstagereducesthenumberofbugsbutin-\ncreasesthefilteredfail-to-pass@1rate,fromabaselineof\n11.29%to53%forthemostselectiveconfiguration.\n6.4 RQ4:ValidationonNPEandsanitizerbugs\nWefurtherevaluatepatchvalidationinbugcategoriesthathave\nConfig\nno_filter(bugs=174) combined-p75(bugs=25) moresystematicinformationintheirbugreports,andsoareas-\nabstention(bugs=39) combined-p90(bugs=12) sumedgoodcandidatesforAPRbyconstruction(i.e.,thesebugs\ncombined-binary(bugs=33)\npassabstentionbyconstruction).Weconsiderthemachine-reported\nNPEandsanitizerbugs,whosebugreportsalwayshaveastack\nFigure 8: Abstention and validation are complementary,\ntraceandreproductiontest,respectively.\njointlytheycanraisefilteredfail-to-pass@k.\nFigure10showsfiltered-accept@kbymanuallyinspectingthe\ncorrectnessofpatchesforNPEbugs,whosebugreportshavestack\ntraces.Thebaseline(build-and-test)filterspatchesthatdidnot\nsuccessoftheattempt,whiletheabstentionpolicyismorelikely passbuildandtestregressionchecks.Weobservethatvalidation\ntoreflectoverallqualityofbugreport. usingbinaryjudgmentprovidelittleimprovementoverthesere-\nFigure9visualizestheprocessofourdual-policyframeworkasa gressionchecks.However,validationusingthemore-aggressive\nconfigurablefunnel.Thefunnelpresentsthefilteredfail-to-pass@1 percentile-thresholdjudgmentcanresultinimprovementstofiltered-\nrateonhuman-reportedbugsateachstage.Startingwiththefull accept@1of+8percentagepointsand+24percentagepoints,with\nset of 174 bugs, where our APR system has a baseline pass@1 75thand90thpercentilethresholds,respectively.No-specvalida-\nrateof11.29%,theabstentionpolicyfirstfiltersthisdownto39 tionat90thpercentileproducesabiggerfiltered-accept@1improve-\nmorepromisingbugs,increasingthefilteredfail-to-pass@1rate mentthanthatat75thpercentile(+20percentagepointsvs+24\nto 21.5%. The combined validation policies (combined-*) further percentagepointsrelativetoregressionchecks),butbothofthem\nrefinethisset.Thecombined-binarypolicyleaves33bugswitha performworsethanthespec-basedvariantat90thpercentile(i.e.,\nrateof29%.Moreaggressivefilteringwithcombined-p75andthe validation-p90).\nstrictestcombined-p90variantnarrowthefunnelto25and12bugs, Figure11showsmeanfiltered-accept@k(basedonmanualin-\nrespectively,boostingthequalityofpatchestoachievehighfiltered spectionofpatchcorrectness)forsanitizerbugs,whosebugreports\nfail-to-pass@1ratesof35%and53%.Overall,Figure9demonstrates havereproductiontests.Asaresult,wefilteranypatchesfirstby\nthetrade-offbetweenthevolumeofbugsattemptedandthepreci- thereproductiontestandthenapplythevalidationpolicy.The\nsionofthepatchesultimatelyshowntodevelopers. baseline(repro-test)filterspatchesthatdidnotpassreproduction\nAbstainandValidate:ADual-LLMPolicyforReducingNoiseinAgenticProgramRepair\n1.0\n0.8\n0.6\n0.4\n0.2\n0.0\n1 2 3 4 5\nk\nk@tpecca\nderetlif\nnaem\nConfig\nbuild-and-test(bugs=135) no-spec-validation-binary(bugs=132)\nvalidation-binary(bugs=104) no-spec-validation-p75(bugs=53)\nvalidation-p75(bugs=43) no-spec-validation-p90(bugs=24)\nvalidation-p90(bugs=21)\nFigure10:Moreaggressivevalidationcanincreasefiltered\naccept@kforNPEbugs.\n1.0\n0.8\n0.6\n0.4\n0.2\n0.0\n1234567891011121314151617181920\nk\nk@tpecca\nderetlif\nnaem\nSanitizer #Bugs repro-test validation-binary validation-p75 validation-p90\ndata_race 17 3.11 2.93 2.43 3.04\nFuzz+propertytesting 3 NA NA NA NA\nheap_buffer_overflow 1 1.43 1.43 1.54 1.54\ninvalid_bool_load 2 1.49 1.65 1.25 NA\ninvalid_enum_load 1 NA NA NA NA\nleak_detected 2 1.52 1.72 4.29 3.81\nmisaligned_pointer_use 6 1.34 1.33 2.14 1.43\nnull_pointer_use 1 2.86 3.33 NA NA\nsigned_integer_overflow 2 1.2 1.27 1.56 2.5\nstack_use_after_scope 2 1.85 1.85 1.67 3.33\nuse_of_uninitialized_value 13 2.05 1.93 2.05 1.95\nTable2:Lift(filtered-accept@1/originalaccept@1)varies\nfordifferentsanitizerbugtypes.Thehigherthebetter.\nMetric Abstain AttemptRepair\nAverage#code-likeidentifiers 3.03 5.28\nAveragecharacterlength 771.67 1239.26\nFractionwithrepositoryroot 0.12 0.31\nFractionpossiblebuildrule 0.01 0.03\nFractionMarkdowncodeticks 0.17 0.20\nTable3:Abstention-acceptedbugsmorefrequentlyhavethe\npresenceofthemonoreporootdirectory.\ntoreproductiontestfilteringslightlyreduceslift,whileaddingthe\n70thpercentilevalidationkeepsthesamelift.Fordataraces,adding\nvalidationactuallyreducesliftcomparedtojustusingreproduction\ntests.Wehypothesizethat:forthesebugs,apatchthataddslock-\ningmechanismindeedresolvesthedataraceandcanpasspatch\nvalidation,butstillmaynotbeanacceptablesolutionforaGoogle\nConfig\nrepro-test(bugs=48) no-spec-validation-binary(bugs=48) developerifitintroducesdownsidessuchaslargercriticalsections.\nvalidation-binary(bugs=45) no-spec-validation-p75(bugs=32)\nvalidation-p75(bugs=30) no-spec-validation-p90(bugs=21) Forsomecategories,e.g.leaksandmisalignedpointerusage,aless\nvalidation-p90(bugs=15) aggressivevalidation(75thpercentile)achievesbetterliftthana\nmoreaggressiveone(90thpercentile).\nFigure11:Aggressivevalidationincreasesfilteredaccept@1\nWehypothesizethatatruebugreproductiontest,suchasthat\nforsanitizerbugs.Butjustreviewingmorepatchescanlead\nincludedinthesanitizer’sbugreport,resultsinasetofplausible\ntohigherfiltered-accept@k,with4patchessufficing.\npatchesthatareincreasinglydifficultforvalidationtoassess,com-\nparedtothepatchesproducedfortheless-constrainedbugssuchas\nthehuman-reportedones.Thispointstoafewfutureresearchdi-\ntests.Forsanitizerbugs,validationcanliftfiltered-accept@1but\nrections.First,generatingadditionalexecutableteststohelpassess\nincreasing𝑘quicklyoutstripsthevalidationpolicy.At𝑘 =4,sam-\npatchcorrectnessisaparticularlypromisingdirection.Forexam-\nplingpatchesfromthesetthatpassesthereproductiontestprovides\nple,AutoCodeSherpa[15]generatesproperty-basedteststoassist\nbetterresults(0.74)thanusingthevalidation’sfiltering.Whenwe\nreviewingandfilteringagent-generatedpatches.Aspointedout,\nconsider𝑘 =1andusing90thpercentilethreshold,no-specvariant\nno-spec-validation-p90(0.65)outperformsthespec-basedvariant\nafterfilteringwiththereproductiontest,sampling𝑘 =4produces\nameanfilteredacceptrateof0.74.Supportingdeveloperswhen\nvalidation-p90(0.62)andbaselinerepro-test(0.5).\ninspectingmorepatchesmayhelpmaintainahighsuccessrate.\nWe inspected whether patch validation performs differently\nbasedonthesanitizerbugtype.Table2showstheliftforeach\nsanitizerbugcategory,definedastheratiooffiltered-accept@1to 7 Discussion\ntherawaccept@1,whereper-bugaccept@1isaveragedbysani- Theabstentionpolicyhasaccesstothebugreportwhenmakinga\ntizertype.Ifapolicyremovesallpatchesassociatedwithasanitizer judgment.Wecomputebasicpropertiesonourhuman-reportedbug\nbugtypeortherearenopatches(intheunfilteredset)thatare settocharacterizetheirinfluenceonpolicyoutcomes.Asshown\ncorrect,weenterNAinthetable.Wefindthatpatchvalidation inFigure12andTable3,bugsacceptedbyabstentiontendtohave\nperformanceindeedvariesbybugtype.Forthetwomaincategories longertitlesanddescriptions(combined),andhighercountofwords\nofbugsinourevaluationset—dataracesanduseofuninitializedval- thatarepossiblecodeidentifiers(basedonunderscoreorcapital-\nues—validationdoesnotprovideameaningfulimprovementover izationchanges).Similarly,acceptedbugstendtohaveaslightly-\njustfilteringwithreproductiontests.Foruseofuninitializedvalue higherpresenceofGoogle’ssourcerepositoryrootdirectoryand\nerrors,addingthebinaryvalidationand90thpercentilevalidation possiblecodeMarkdown,indicatedbytriplebackticks.\nGoogleetal.\n1.0\n0.8\n0.6\n0.4\n0.2\n0.0\n0 2000 4000 6000 8000 10000 12000\nCharacter length of title and description\nnoitubirtsid\nevitalumuc\nlaciripmE\n1.0\n0.8\n0.6\n0.4\nAbstention policy accepts 0.2\nFalse\nTrue\n0.0\n0 10 20 30 40\nNumber of code-like identifiers in title and description\n(a)Descriptionlength\nnoitubirtsid\nevitalumuc\nlaciripmE\nAbstention policy accepts\nFalse (a)Description\nTrue\n(b)Code-likeidentifiers\nFigure12:Bugsacceptedbytheabstentionpolicytendto\nhaveslightlylongertitleanddescriptionsandmorewords\nthatcouldbepossiblecodeidentifiers. (b)Ground-truth\nSimilarly,weconsideredthesizeofthepatchesacceptedbythe\n75thpercentile-basedpatchvalidationforourhuman-reportedbug (c)Agent-generatedcandidatepatch\nset.WeonlyconsiderpatchesthatunderwentLLMpolicyjudgment.\nWecountthenumberofline-leveloperations(addition/deletions) Figure13:Abugreportindicatesacase-dependentchange.\nperpatch.Wefindthatvalidation-acceptedpatcheshadonaverage Thevalidation’sgeneratedspecificationdoesnotmakethis\n18.38operations,comparedto22.69forrejectedpatches. distinctionsothepolicyincorrectlyacceptsthecandidate.\nWenowlookatanexampleofapatchthatvalidation(at90th\npercentile)incorrectlyaccepted.Figure13showstheassociated\nWecarriedoutexperimentsusingGemini2.5Proand2.0Flash,\nreportindicatingcasesforachangeinnumberformatting(when\nandproducedrepaircandidatesusingourpreviouslypublished\n“pointsarechosentobeburnt”).Thereportleavesunspecifiedwhat\nagent[27].AsnewLLMsbecomeavailable,weexpectpolicyper-\nshouldhappeninothercases,butahumanwouldlikelytakethis\nformancetovary(andimprove),comparedtowhatwereporthere.\ntomeanthatothercasesshouldstillrenderthedecimalpoint.\nThe ground-truth patch makes decimal rendering a function\n9 RelatedWork\nargumentandmodifiesnecessarycallsites(notshownforbrevity).\nWeusedPasserine,ourexistingagenticAPRsystem[27],toevaluate\nIncontrast,theagentpatchmodifiestheconstanttruetofalse,\nbothbugabstentionandpatchvalidation.SpecRover[28]produces\nwhichwillimpactallcallsites.Thegeneratedspecificationidentifies\nfunction-levelspecificationstoguidetherepairagent.Similarly,our\nthecorrectmethodtochange,butdoesnotscopetoparticularcall\nvalidationpolicyemploysaspecificationgenerationsteptoguide\nsites.Thevalidationpolicythenincorrectlyaccepts.\nthepatchjudgmentbutthisspecificationisatthefilelevel,canbe\nderivedfrommultiplefiles,andisusedonlyaftertherepairagent\n8 ThreatstoValidity hasconcluded.Panetal[25]showedthatafine-tunedLLMcanbe\nHumanandsanitizer-reportedbugsweredrawnfromasetthat usedtopickthebestpatchperbugbasedontheagent’strajectory.\nhasaknownground-truthpatch,andsomeofourfilteringrelies Ourno-specvalidationemploysasimilarconcatenationoftrajec-\nonground-truthpatchproperties(e.g.,existenceofatest).These torypromptmessages.However,ourLLMpatchvalidationrelies\nconstraintsallowustofocusonpatcheswithinscopeforanagent onpromptingonlyandisusedtofilteroutpatchesratherthanpick\nandemployground-truthtestsasanevaluationoracle.Forsanitizer- apatchperbug.Ourpatchvalidationfiltersonbuild/testregression\nreportedbugs,wherereproductiontestsarealreadyavailableatthe checks,orareproductiontestifavailable.Similarly,Agentless[34]\ntimeofreporting,havingtheground-truthpatchallowsustoper- uses(generated)teststofilteroutunlikelycandidates.\nformamanualcomparisontodeterminecorrectness.Thiscuration Abstention[5]haslongbeenemployedinclassificationtoreduce\napproachcloselymirrorsthatusedtocreatepopularbenchmarks mispredictionsresultingfromambiguityorlackofinformation.\nlikeSWE-Bench,aswellasindustrypractices[20,27]. Pastworkhasexploredthistopicextensively,learningabstention\nManualcorrectnessassessmentmaydivergefromthedecisions policiesinboostingalgorithms[8],fairnessguarantees[30],and,\nthatwouldhavebeenmadebyrealcodeownersforpatchesthat morerecently,inthecontextofgenerativemodels[33].\ntheydidnotinspect.Tomitigatethisrisk,weemployedmultiple Concurrenttoourwork,BouncerBench[22]introducesthecon-\nannotators,consultingothersincasesofambiguity. ceptof“bouncers”toreducetheoverconfidenceofanagenticsoft-\nLikeotherlarge-scaleindustrialsoftwareengineeringstudies[2, wareengineer.Bouncersrejectunderspecifiedtasksandunlikely\n12,21],thebugsandcodeinthisworkaredrawnfromasinglecom- patches,closelymatchingourabstentionandvalidationpolicies.\npany(Google)andreflectinternalpractices.Projectsorcompanies ThebenchmarkBouncerBenchopensupthischallengetothecom-\nthatwritesubstantiallydifferentbugreports,oradheretodifferent munityandrepresentsacomplementaryanalysistoourown,which\ndevelopmentpractices,mayobservedifferentpolicyimpacts. focusesonevaluatingthesepoliciesinanindustrialcontext.\nAbstainandValidate:ADual-LLMPolicyforReducingNoiseinAgenticProgramRepair\nMaddilaetal.[20]concurrentlyintroducedapatchcriticinan llm-basedagentforsoftwareengineeringwithtest-timescaling.arXivpreprint\nindustrialagenticAPRsystem.Ourworkshowsthatabstention arXiv:2507.23370,2025.\n[12] PhilipJGuo,ThomasZimmermann,NachiappanNagappan,andBrendanMur-\ncan reduce developer noise further and can be complementary\nphy.Characterizingandpredictingwhichbugsgetfixed:anempiricalstudyof\ntoavalidationpolicy.Ourevaluationalsocoversadditionalbug microsoftwindows.InProceedingsofthe32ndACM/IEEEInternationalConference\ncategories(withandwithoutknownreproductiontests). onSoftwareEngineering-Volume1,pages495–504,2010.\n[13] RaduHerbeiandMartenHWegkamp. Classificationwithrejectoption. The\nWorksinLLM-as-judgeforcode,suchasCodeJudge[32]and CanadianJournalofStatistics/LaRevueCanadiennedeStatistique,pages709–721,\nCrupietal.[9],arecloselyrelatedtoourpatchvalidationpolicy. 2006.\nInparticular,reference-freejudgingisacloseanaloguetopatch [14] CarlosEJimenez,JohnYang,AlexanderWettig,ShunyuYao,KexinPei,OfirPress,\nandKarthikNarasimhan.Swe-bench:Canlanguagemodelsresolvereal-world\nvalidation,butwefocusexclusivelyonprogramrepairanduse githubissues?arXivpreprintarXiv:2310.06770,2023.\njudgmentstofilterpatchestoreducenoise(attheexpenseofrecall). [15] SungminKang,HaifengRuan,andAbhikRoychoudhury. Autocodesherpa:\nSymbolicexplanationsinaicodingagents.arXivpreprintarXiv:2507.22414,2025.\n[16] ClaireLeGoues,ThanhVuNguyen,StephanieForrest,andWestleyWeimer.\n10 Conclusion\nGenprog:Agenericmethodforautomaticsoftwarerepair.Ieeetransactionson\nsoftwareengineering,38(1):54–72,2011.\nWe present a dual-policy framework to reduce developer noise [17] ClaireLeGoues,MichaelPradel,andAbhikRoychoudhury.Automatedprogram\nfromanagenticAPRsystem.Abugabstentionpolicyrejectsbugs\nrepair.CommunicationsoftheACM,62(12):56–65,2019.\n[18] FanLongandMartinRinard.Stagedprogramrepairwithconditionsynthesis.In\nunlikelytobesolvedbytheAPRsystem,whileapatchvalidation Proceedingsofthe201510thJointMeetingonFoundationsofSoftwareEngineering,\npolicyrejectsunlikelycandidatefixes.Weevaluatethesepolicies pages166–178,2015.\n[19] ShengLu,HendrikSchuff,andIrynaGurevych.Howarepromptsdifferentin\nonthreesetsofbugsdrawnfromGoogle’scodebaseandonpatches termsofsensitivity?InProceedingsofthe2024ConferenceoftheNorthAmeri-\nproducedbyouragenticAPRsystem.Onasetofhuman-reported canChapteroftheAssociationforComputationalLinguistics:HumanLanguage\nbugswithknownfixes,abstentionandvalidationcanraisesuc- Technologies(Volume1:LongPapers),pages5833–5856,2024.\n[20] ChandraMaddila,AdamTait,ClaireChang,DanielCheng,NaumanAhmad,\ncessratesupto13percentagepointsand15percentagepoints, VijayaraghavanMurali,MarshallRoch,ArnaudAvondet,AaronMeltzer,Victor\nrespectively,andupto39percentagepointsincombination. Montalvao,etal.Agenticprogramrepairfromtestfailuresatscale:Aneuro-\nInpracticalterms,thisimprovementtransformsthedeveloper symbolicapproachwithstaticanalysisandtestexecutionfeedback. arXiv\npreprintarXiv:2507.18755,2025.\nexperience:insteadofexpectingasuccessfulpatchroughly1in10 [21] AlexandruMarginean,JohannesBader,SatishChandra,MarkHarman,YueJia,\ntimes,developerscannowexpectacorrectpatchin1in2cases KeMao,AlexanderMols,andAndrewScott.Sapfix:Automatedend-to-endrepair\natscale.In2019IEEE/ACM41stInternationalConferenceonSoftwareEngineering:\npresentedfortheirreview(combined-p90).Amorerelaxedpolicy SoftwareEngineeringinPractice(ICSE-SEIP),pages269–278.IEEE,2019.\nconfiguration(combined-p75)doublesthenumberofpatchesfor [22] NobleSajiMathewsandMeiyappanNagappan. Isyourautomatedsoftware\ninspectionwhilestillyieldingahighsuccessrateofroughly1in3. engineertrustworthy?arXivpreprintarXiv:2506.17812,2025.\n[23] HoangDuongThienNguyen,DaweiQi,AbhikRoychoudhury,andSatishChan-\nThepatchvalidationpolicycanalsobeusedtoimprovesuccess dra. Semfix:Programrepairviasemanticanalysis. In201335thInternational\nratesfornullpointerexceptionsandsanitizer-reportedbugs. ConferenceonSoftwareEngineering(ICSE),pages772–781.IEEE,2013.\n[24] YannicNoller,RidwanShariffdeen,XiangGao,andAbhikRoychoudhury.Trust\nenhancementissuesinprogramrepair,2022.\n[25] JiayiPan,XingyaoWang,GrahamNeubig,NavdeepJaitly,HengJi,AlaneSuhr,\nReferences\nandYizheZhang. Trainingsoftwareengineeringagentsandverifierswith\n[1] MartinArjovsky,SoumithChintala,andLéonBottou.Wassersteingenerative SWE-gym.InForty-secondInternationalConferenceonMachineLearning,2025.\nadversarialnetworks. InInternationalconferenceonmachinelearning,pages [26] RachelPotvinandJoshLevenberg.Whygooglestoresbillionsoflinesofcodein\n214–223.PMLR,2017. asinglerepository.https://cacm.acm.org/research/why-google-stores-billions-\n[2] ChristianBird,NachiappanNagappan,BrendanMurphy,HaraldGall,and of-lines-of-code-in-a-single-repository/,July2016.Accessedon2025-09-22.\nPremkumarDevanbu. Don’ttouchmycode!examiningtheeffectsofown- [27] PatRondon,RenyaoWei,JoséCambronero,JürgenCito,AaronSun,Siddhant\nershiponsoftwarequality.InProceedingsofthe19thACMSIGSOFTsymposium Sanyam,MicheleTufano,andSatishChandra.Evaluatingagent-basedprogram\nandthe13thEuropeanconferenceonFoundationsofsoftwareengineering,pages repairatgoogle.arXivpreprintarXiv:2501.07531,2025.\n4–14,2011. [28] HaifengRuan,YuntongZhang,andAbhikRoychoudhury. SpecRover:Code\n[3] IslemBouzenia,PremkumarDevanbu,andMichaelPradel. RepairAgent:An IntentExtractionviaLLMs.In2025IEEE/ACM47thInternationalConferenceon\nautonomous,LLM-basedagentforprogramrepair.InInternationalConference SoftwareEngineering(ICSE),pages963–974,LosAlamitos,CA,USA,May2025.\nonSoftwareEngineering(ICSE),2025. IEEEComputerSociety.\n[4] AdamBrown,SarahD’Angelo,AmbarMurillo,CieraJaspan,andCollinGreen. [29] TorstenScholak,NathanSchucher,andDzmitryBahdanau.PICARD:Parsing\nIdentifyingthefactorsthatinfluencetrustinaicodecompletion.InProceedings incrementallyforconstrainedauto-regressivedecodingfromlanguagemodels.\nofthe1stACMInternationalConferenceonAI-PoweredSoftware,pages1–9,2024. InMarie-FrancineMoens,XuanjingHuang,LuciaSpecia,andScottWen-tauYih,\n[5] C.Chow.Onoptimumrecognitionerrorandrejecttradeoff.IEEETransactions editors,Proceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLan-\nonInformationTheory,16(1):41–46,1970. guageProcessing,pages9895–9901,OnlineandPuntaCana,DominicanRepublic,\n[6] Chi-KeungChow. Anoptimumcharacterrecognitionsystemusingdecision November2021.AssociationforComputationalLinguistics.\nfunctions.IRETransactionsonElectronicComputers,(4):247–254,2009. [30] NicolasSchreuderandEvgeniiChzhen.Classificationwithabstentionbutwith-\n[7] GheorgheComanici,EricBieber,MikeSchaekermann,IcePasupat,Noveen outdisparities. InCassiodeCamposandMarloesH.Maathuis,editors,Pro-\nSachdeva,InderjitDhillon,MarcelBlistein,OriRam,DanZhang,EvanRosen, ceedingsoftheThirty-SeventhConferenceonUncertaintyinArtificialIntelligence,\netal. Gemini2.5:Pushingthefrontierwithadvancedreasoning,multimodal- volume161ofProceedingsofMachineLearningResearch,pages1227–1236.PMLR,\nity,longcontext,andnextgenerationagenticcapabilities. arXivpreprint 27–30Jul2021.\narXiv:2507.06261,2025. [31] MahanTafreshipour,AaronImani,EricHuang,EduardoSantanadeAlmeida,\n[8] CorinnaCortes,GiuliaDeSalvo,andMehryarMohri.Boostingwithabstention. ThomasZimmermann,andIftekharAhmed.Promptinginthewild:Anempirical\nAdvancesinneuralinformationprocessingsystems,29,2016. studyofpromptevolutioninsoftwarerepositories. In2025IEEE/ACM22nd\n[9] GiuseppeCrupi,RosaliaTufano,AlejandroVelasco,AntonioMastropaolo,Denys InternationalConferenceonMiningSoftwareRepositories(MSR),pages686–698.\nPoshyvanyk,andGabrieleBavota. Ontheeffectivenessofllm-as-a-judgefor IEEE,2025.\ncodegenerationandsummarization.IEEETransactionsonSoftwareEngineering, [32] WeixiTongandTianyiZhang. CodeJudge:Evaluatingcodegenerationwith\n51(8):2329–2345,2025. largelanguagemodels. InYaserAl-Onaizan,MohitBansal,andYun-Nung\n[10] DanielDeutsch,ShyamUpadhyay,andDanRoth.Ageneral-purposealgorithm Chen,editors,Proceedingsofthe2024ConferenceonEmpiricalMethodsinNatural\nforconstrainedsequentialinference. InProceedingsofthe23rdConferenceon LanguageProcessing,pages20032–20051,Miami,Florida,USA,November2024.\nComputationalNaturalLanguageLearning(CoNLL),pages482–492,2019. AssociationforComputationalLinguistics.\n[11] PengfeiGao,ZhaoTian,XiangxinMeng,XinchenWang,RuidaHu,Yuanan [33] BingbingWen,JihanYao,ShangbinFeng,ChenjunXu,YuliaTsvetkov,BillHowe,\nXiao,YizhouLiu,ZhaoZhang,JunjieChen,CuiyunGao,etal.Traeagent:An andLucyLuWang.Knowyourlimits:Asurveyofabstentioninlargelanguage\nGoogleetal.\nmodels.TransactionsoftheAssociationforComputationalLinguistics,13:529–556, [36] YuntongZhang,HaifengRuan,ZhiyuFan,andAbhikRoychoudhury. Au-\n2025. tocoderover:Autonomousprogramimprovement. InProceedingsofthe33rd\n[34] ChunqiuStevenXia,YinlinDeng,SorenDunn,andLingmingZhang. Agent- ACMSIGSOFTInternationalSymposiumonSoftwareTestingandAnalysis,pages\nless:Demystifyingllm-basedsoftwareengineeringagents. arXivpreprint 1592–1604,2024.\narXiv:2407.01489,2024. [37] ChangshengZhuge,MingchenZhao,DylanR.Ashley,WenyiWang,Dmitrii\n[35] JohnYang,CarlosEJimenez,AlexanderWettig,KilianLieret,ShunyuYao,Karthik Khizbullin,YunyangXiong,ZechunLiu,ErnieChang,KrishnamoorthiRaghura-\nNarasimhan,andOfirPress. Swe-agent:Agent-computerinterfacesenable man,YuandongTian,YangyangShi,VikasChandra,andJürgenSchmidhuber.\nautomatedsoftwareengineering. AdvancesinNeuralInformationProcessing Agent-as-a-judge:Evaluateagentswithagents.arXivpreprintarXiv:2410.10934v2,\nSystems,37:50528–50652,2024. 2025.\nAbstainandValidate:ADual-LLMPolicyforReducingNoiseinAgenticProgramRepair\nA Human-ReportedBugCuration - Precise Code Localization: The report points to the\nInthissection,wedescribethecriteriaforcuratinghuman-reported exact file, code line, function, or configuration\nthat needs attention, or it's easily identifiable\nbugsthathaveaknowngroundtruthpatchforcompleteness.The\nfrom provided information (e.g., stack traces).\ncriteriacloselyfollows[27],withtheadditionofthetesttarget - Simple, Localized Fix Anticipated: The likely solution\ncriteria.Namely,eachbugmustsatisfythefollowing: involves a small, straightforward, and localized\nchange.\n(1) Wasreportedduringaperiodofayearandclosedwith\n- Actionable Reproduction & Sufficient Context: The\ncodechangesafteramodel-basedcutoffdateintherecent\nissue can be easily and reliably reproduced with\npast–weusethecutofftopreventoldcodechangesthat the information provided, and sufficient context is\naremorelikelytobestale. available within the report for the agent to\n(2) Hasaknownground-truthfixandanassociatedfail-to- proceed effectively.\n- Self-Contained and Complete: All necessary information\npasstestthatcouldbeusedasaheld-outtestoracle.This\nfor addressing the bug is provided and self-\nfail-to-passtestmustexecutewithoutanybuilderrorsand contained within the report, requiring minimal\nfailinthepre-patchcodeandexecuteandsucceedinthe external look-up or inference.\npost-patchcode.\n(3) Thebugandsubmittedcodechangeshavea1:1relationship, C PatchValidationPrompts\nmitigatingriskoftangledcommits\nThis section contains the full prompts for the patch validation\n(4) Didnothavescreenshotsintheirdescription(multimodal\npolicydescribedinSection3.2.Listing3showsthepromptforthe\nrepairsareoutofscopeforthiswork)\nspecificationgenerationstep.\n(5) Affectedfilesforanyofthefollowinglanguages:C++,C,\nDart,Java,Kotlin,Typescript,Javascript,Go,andPython Listing3:Usingtheoriginalbugdescriptionandfilecontents\nandconverselyexcludedchangesthataffectedSQL,HTML, togenerateaspecification.\nCSS,configurationlanguages,binarydatafiles,ormultime- SYSTEM:\ndiadatafiles You are an expert software engineer that reviews a bug\nand lists out a specification for the desired\n(6) Hadaunidiffground-truthcommitoflessthan150lines\nbehavior.\n(7) Had<=31testtargetsthatdependedonthefileschanged\nYou should cover properties desirable for a fix. Be\nintheground-truthpatch. specific, do not provide general properties that\napply to all bugs. Do not provide properties that\nB BugAbstentionPrompts are about artifacts like documentation.\nThesectioncontainsthefullpromptsforthebugabstentionpolicies\ndescribedinSection3.1.2. USER:\nHere is a bug, please create a fix specification:\nListing1:Promptforbugrepresentation𝑟 1(𝑏).\nYou are tasked to predict whether an LLM-based agentic\napproach will successfully fix a bug. # Bug Title\nThe agent can use a suite of tools by issuing commands, {bug.title}\nincluding:\n- `code_search` to find relevant code. # Bug Description\n- `cat` to read file contents. {bug.description}\n- `ls` to list directory contents.\n- `find_and_replace_text` to modify files.\n- `bazel` to run tests. # Original source code\nThe agent is presented with a bug report and can perform $ cat {file_path}\na maximum of 25 steps. {file_content}\nAnalyze the following bug and predict if the agent will\nsucceed. Your output must be a single word: either \" # Specification\nsuccess\" or \"failure\". Do not provide any other text Listing4showstheLLMpromptusedforvalidatingapatch,\n, explanation, or punctuation. alongwiththeuseofthegeneratedspecification.\n# Bug Title Listing4:Usingtheoriginalbugreport,candidatepatch,any\n{bug.title}\ntestinformation,andthefixspecificationgeneratedinthe\n# Bug Description priorstep,todecideifapatchislikelytofixabug.\n{bug.description} SYSTEM:\nSETTING: You are a software engineer reviewing code\nListing2:Promptforbugrepresentation𝑟 2(𝑏). changes to fix bugs. Your job is to review how a\nbug2code agent tried to fix a bug.\n# GUIDELINES\nReturn a ReviewResponse with whether the bug is fixed and\nThese guidelines provide criteria for determining if a\nexplaining why.\nbug is likely to be solved by the agent.\n- Clear Problem & Action: The bug report explicitly and\nclearly describes the incorrect behavior, and the USER:\nrequired change is well-understood.\nGoogleetal.\n1.0\n0.8\n0.6\n0.4\n0.2\n0.0\n12345678901234567890\n11111111112\nk\nk@)llacer\nnoitadilav(\nnaem\nConfig\nvalidation-binary validation-p90\nvalidation-p75\nFigure14:Ifweconsidersamplesofsizekoftrajectories\nthat pass the held-out reproduction test, more aggressive\nvalidationismorelikelytoincorrectlyrejectpatches.\n1.0\n0.8\n0.6\n0.4\n0.2\n0.0\n0 100 200 300 400\nPatch line-level operations count\nnoitubirtsid\nevitalumuc\nlaciripmE\nHere's a log of an attempt by a bug2code agent to fix a\nbug:\n# Bug Title\n{bug.title}\n# Bug Description\n{bug.description}\n# Patch\n{patch}\n# Test information\n{test_information}\n# Specification:\nBased on the bug report and source code, here is a\nspecification for the desired behavior of the fix.\n### Fix Specification\n{specification}\nC.1 AdditionalResults\nTable4presentstheper-labelprecision/recallforbinaryvalidation\npolicies.\nTofocusonthevalidation’sabilitytoidentifysuccessfultrajec-\ntories,wealsoconsideravariantofrecall.Specifically,wecompute\ntheaverage(overbugs)probabilitythatatleastonetrajectoryis\nacceptedbythevalidation,givenasampleofktrajectoriesthat\nsatisfytheheld-outreproductiontest.Ineffect,ifourrepairsystem\nproducedonlygoodfixes,howoftenwouldweshowatleastone\nrepairtoauserifwegeneratedktrajectories.Wedenotethismean\nValidation accepts (validationrecall)@k.Tocomputepercentile-basedthresholding\nFalse wedeterminecutoffsoveralltrajectoriesthatpassbuildandtest\nTrue regressionsfirst,beforefiltering.\nAsshowninFigure14,percentile-basedthresholdingresultsin\nmorefalsenegatives–rejectingpatchesthatweshouldhaveshown\ntohumans.Whensamplingasinglesuccessfulpatch,thebinary\nvalidationwillshowapatchatarateof0.54,comparedto0.36and\n0.16for75thand90thpercentilethresholding,respectively.\nFigure15showsthatpatchesacceptedbythevalidationpolicy\nhaveslightlymoreline-leveloperationscomparedtothoserejected.\nC.2 PatchValidationDecisions:FalsePositives\nListingC.2showsthegeneratedspecificationandvalidationpolicy\noutputforthefalsepositiveexamplediscussedinSection7.\n\"Here is a fix specification for the bug.\nFigure15:Patchesacceptedbythepatchvalidationpolicy\nhaveslightlyfewerline-leveloperationscomparedtothose ### Desired Behavior Specification\nitrejected.\n1. **Conditional Decimal Formatting for Amounts**\nThe amount displayed in the amount input field must\nApproach BinaryLabel Precision Recall be formatted based on whether it is an integral\nvalue.\nPrevalence(build/test) TRUE 0.19 - * If the `Money` object represents an integer (e.g\nNo-specvalidation(binary) FALSE 0.99 0.07 ., the fractional part is zero), it must be\nNo-specvalidation(binary) TRUE 0.2 1 formatted as a string without decimal places (e.\ng., \"500\").\nValidation(binary) FALSE 0.91 0.58\nValidation(binary) TRUE 0.3 0.76\nTable4:Precision/RecallTableonthebinaryjudgment:val-\nidation’sbinaryjudgmentprovidesmodestpredictiveper-\nformance.Removingthespecificationusagereducesperfor-\nmancesubstantially.\nAbstainandValidate:ADual-LLMPolicyforReducingNoiseinAgenticProgramRepair\nexplanation: \"The patch correctly fixes the bug. The bug\ndescription states that integral amounts are being\ndisplayed with unnecessary decimal points (e.g., \\\"\nXXX.00\\\") after rewards are applied. The fix\nspecification requires conditional formatting: show\ndecimals only for non-integer amounts. The patch\nmodifies the `_updateAmountVariable` method by\n(a)Description changing the `alwaysShowDecimals` parameter from `\ntrue` to `false` in the `newAmount.toString()` call.\nThis change ensures that the `Money` object\\'s\nstring representation will only include decimal\nplaces if the amount is not an integer, which\ndirectly addresses the root cause of the bug and\nfulfills all requirements of the specification.\"\ninternal_score: 0.62615377\nInthenextcase(Figure16),thebugreportprovidesrelatively\nhigh-leveldiscussionoftheissuebutdoesnotspecifywhatproperty\n(b)Ground-truth\nshouldbeusedtocheckforlinksforatestsequencermodule.\nThe ground-truth patch adds conditional handling based on\nthepresenceofaparticularfield(ts_version)inaninputrow.The\nagent’spatchmodifiesthisintoanif-elsestatement.Theelsebranch\nisequivalenttothefall-throughcaseintheground-truthpatch.\nHowever,theifguardchecksadifferentfield(archive_file),which\nitinferredfromtheexistingtestfiles.\n(c)AgentPatch\nThegeneratedspecificationcorrectlypointsoutthatlinksfora\ndifferentmodulewillneedtobegeneratedinaconditionalfashion.\nFigure16:Afalsepositiveinpatchvalidation.\nItalsoelaboratesonwherethesechangesshouldbemadeandwhat\nfieldtocheckintheinput.Thevalidation’soutputcorrectlyreflects\n* If the `Money` object represents a non-integer thespecification.However,thespecificationwaswrongtobegin\nvalue (e.g., the fractional part is non-zero), with,asthefieldtobecheckedintheinputisactuallydifferent:the\nit must be formatted with the standard two fieldthattheagentinferredwasultimatelyincorrect.Incasessuch\ndecimal places (e.g., \"500.50\"). asthese,itislikelythatasmallpieceofhumanfeedbackonthe\nfinalpatchwouldalloweitherthevalidationpolicytomakethe\n2. **Consistent Formatting on Reward Application**\nrightdecision(reject)ortherepairagenttoupdatethepatch.\nWhen a user applies <redacted> points (or any other\ndeduction) that results in an integral final Here is a specification for the fix.\namount, the amount field must update to show the\nnew integral amount without adding trailing ### Fix Specification\ndecimals. For example, if the original amount is\n\"500\" and points worth \"10\" are applied, the The root cause of the bug is that the `test_details_href`\nfield must display \"490\", not \"490.00\". function unconditionally generates links to the `\ntest_details` page, even for test runs originating\n3. **Consistent Formatting on Reward Removal** from the \"Test Sequencer\", which require a different\nWhen the user deselects the applied points and the details page (`/query/sequences`).\namount reverts to its original integral value,\nthe display must also revert to the format The fix will involve modifying the `test_details_href`\nwithout decimals. For example, if the amount function to correctly identify Test Sequencer runs\nwith points was \"490\" and the points are removed and generate the appropriate URL.\n, the field must revert to displaying \"500\".\n1. **Conditional Link Generation in `test_details_href\n4. **Scope of Formatting Change** `**\nThe conditional decimal formatting logic should be * The function `test_details_href` in `url_builder.\napplied in the `_updateAmountVariable` method. py` must be modified to conditionally generate\nThis ensures that any programmatic update to the one of two different URLs based on the\namount field, including the initial amount load properties of the test run.\n, application of charges, and application/\nremoval of deductions, follows the same 2. **Identification of Test Sequencer Runs**\nconsistent formatting rule * A test run shall be identified as a \"Test\nSequencer\" run if the `row` dictionary passed to\n---- `test_details_href` contains the key `'\narchive_file'`. The presence of this key is the\nis_bug_fixed: true designated indicator for a sequencer test result\n.\n3. **URL Generation for Test Sequencer Runs**\nGoogleetal.\nC.3 PatchValidationDecisions:TruePositives\nForthetwobugsbelow,theagentpatchisabletopasstheheld-out\nground-truthreproductiontest.Additionally,manualinspection\nshowstheseareequivalenttothechangesmadeintheground-truth\npatch.\nThefirstbug(Figure17)requiresthattheagentaddanemptiness\nchecktoavoidprocessingcaseswheretherearenochildtasks.The\nground-truthpatchtightensaguardtoaddthischeck.\n(a)Description\nThespecificationgenerationstepclearlyoutlineswhatthechanges\nnecessaryshouldbeandthereviewexplanationshowsthatthe\nagentpatchadherestothatspecificationandsoisjudgedtobe\ncorrect.\n\"Based on the bug report, here is a specification for the\n(b)Groundtruth\nfix.\n### Desired Behavior Specification\n1. **Conditional Common Data Fetch Execution:**\n* In the `<redacted>` function, the call to `\nExecuteCommonDataFetchUsingEua` must only be\nperformed if the list of generated `child_tasks`\n(c)AgentPatch is not empty.\n2. **Graceful Handling of No-Op Syncs:**\nFigure17:Atruepositiveinpatchvalidation. * If `CreateChildTasks` returns an empty vector of\n`child_tasks` (for example, because all entities\nfor the connector are already in a `RUNNING`\n* If a test run is identified as a Test Sequencer state), the `HandleParent` function must skip\nrun (i.e., `'archive_file' in row` is true), the the common data fetch logic.\n`test_details_href` function must delegate the * The function should then proceed to return a `<\nURL creation to the existing `sequences_href` redacted>::Success` with an empty list of tasks.\nfunction. This indicates that the parent task has\n* The `parms` and `row` arguments received by ` completed successfully without scheduling any\ntest_details_href` must be passed directly to ` new work.\nsequences_href` to ensure all necessary\nparameters (`archive_file`, `module`, `test_case 3. **Preservation of Existing Validations:**\n`, `name`, `param`) are available for building * The argument validation inside `\nthe correct `/query/sequences` URL. ExecuteCommonDataFetchUsingEua` which checks if\nthe `entity_payloads` vector is empty and\n4. **Preservation of Existing Behavior for Non-Sequencer returns an `InvalidArgumentError` must not be\nRuns** removed. The fix must prevent this function from\n* If a test run is not identified as a Test being called with an empty vector, rather than\nSequencer run (i.e., `'archive_file'` is not in altering the function's internal guards.\n`row`), the function must retain its original\nbehavior. ----\n* It must proceed to build a URL pointing to `/ is_bug_fixed: true\nquery/test_details` (or the page specified by explanation: \"The bug occurs when the common data fetch\nthe optional `page` parameter) using the logic (`ExecuteCommonDataFetchUsingEua`) is called\nexisting `_build_url_from_parms_and_row` call with an empty list of child tasks, leading to an \\\"\nand its original list of parameters. Atleast one entity payload must be present\\\" error.\nThe patch correctly fixes this by wrapping the\n---- entire common data fetch logic, including the\nunpacking of payloads and the call to `\nis_bug_fixed: true ExecuteCommonDataFetchUsingEua`, inside a\nexplanation: \"The patch correctly addresses the bug by conditional block `if (!child_tasks.empty())`. This\nmodifying the `test_details_href` function. It now ensures that the data fetch is only attempted when\nchecks if the `row` data contains an `archive_file` there are actual child tasks to process, preventing\nkey, which is the designated indicator for a test the error and allowing the parent task to complete\nsequencer run. If the key is present, it correctly successfully with no new tasks scheduled, which is\ncalls the `sequences_href` function to generate the the correct behavior for a no-op sync.\"\nappropriate link. If not, it maintains the original internal_score: 0.65\nbehavior, generating a link to the older `\nInthenextexample(Figure18),thebugdescriptionprovides\ntest_details` page. This conditional logic perfectly\nmatches the fix specification and resolves the instructionsontheexpectededitstoacalculation.Theground-truth\nissue of incorrect link generation.\" patchupdatesthecalculationandinadditionremovesaconstant\ninternal_score: 0.59506536\nAbstainandValidate:ADual-LLMPolicyforReducingNoiseinAgenticProgramRepair\nthatisnolongerused.Theagentpatchonlyupdatesthecalculation,\nbutdoessointhecorrectway. - **Location:** `<redacted>`, line 111\n- **Current Code:** `return (totalDataSize + (\nadditionalDataSize * BACKUP_STORAGE_MULTIPLIER))\n/ PD_COMPRESSION_RATIO`\n- **Required Code:** `return (totalDataSize +\nadditionalDataSize) / PD_COMPRESSION_RATIO`\n2. **Correct Aggregation of Storage Components:**\nThe final estimated storage value must be the result\nof summing the initial full backup size (`\ntotalDataSize`) with the aggregated incremental\nchanges (`additionalDataSize`), and then\ndividing the sum by the `PD_COMPRESSION_RATIO`.\n(a)Description\n#### **3. Invariants (Behaviors that must not change)**\n1. **Scope of Change:** The modification must be\nstrictly confined to the `<redacted>`. Calculations\nfor other Backup and DR services must not be\naffected.\n2. **Compression Ratio:** The `PD_COMPRESSION_RATIO` (\nvalue 1.6) must continue to be applied to the total\n(b)Ground-truth sum of the base data and all incremental data.\n3. **Incremental Data Calculation:** The logic for\ncalculating the `additionalDataSize` (as performed\nby the `<redacted>` function) must remain unchanged.\nThe fix only addresses how this value is used in\nthe final aggregation, not how it is derived.\n4. **Base Data Inclusion:** The `totalDataSize` (\n(c)AgentPatch\nrepresenting the initial full backup) must continue\nto be included as the base amount of data stored\nFigure18:Atruepositiveinpatchvalidation. before incremental changes are added.\nThegeneratedspecificationcloselyreflectsthebugdescription, ----\ngiventhelevelofdetailinthatreport.However,noticeithasaddi- is_bug_fixed: true\ntionalrequirementssuchaslimitingthescopeofthechanges.The explanation: \"The patch correctly addresses the bug by\nremoving the multiplication by `\ngeneratedvalidationoutputjudgesthepatchiscorrectbasedon\nBACKUP_STORAGE_MULTIPLIER` in the `<redacted>` file.\nthespecificationproduced. The bug report explicitly requested the removal of\nHere is a fix specification for the bug. a hard-coded factor of 2 that was being applied to\nthe incremental backup data size. The code change\n### **Specification for <redacted> Calculation Fix** from `(totalDataSize + (additionalDataSize *\nBACKUP_STORAGE_MULTIPLIER)) / PD_COMPRESSION_RATIO`\nThis specification outlines the required changes to to `(totalDataSize + additionalDataSize) /\ncorrect the Total Cost of Ownership (TCO) PD_COMPRESSION_RATIO` directly implements this\ncalculation for the <redacted> in the pricing requirement, thus fixing the over-estimation in the\ncalculator. <redacted> calculation.\"\nIngeneral,moredetailedbugreportsarelikelytoproducebetter\n#### **1. Functional Behavior** bugabstentionandpatchvalidationresults.Fortheformer,the\nvalidationpolicycancreateamoreprecisesetofguidelines,which\nThe estimated backup storage calculation for <redacted>\nmust be corrected to no longer multiply the canthenbeusedtojudgetheagent’spatches.\nincremental backup data size by a factor of 2.\nC.4 OptimizabilityofDecisionsBasedonBug\n- **Current Incorrect Calculation Logic:**\nAbstentionandPatchValidationpolicies\n`Estimated Storage = (Total Data Size + (Incremental\nData Size * 2.0)) / 1.6` Whileinthiswork,wefocusonreducingnoiseforhumandevel-\nopersbyavoidingshowingthempatchesthatareunlikelytobe\n- **Required Correct Calculation Logic:**\ncorrect,thedecisionofwhatbugstotackleandwhatpatchesto\n`Estimated Storage = (Total Data Size + Incremental\nData Size) / 1.6` surfacecanbeapproachedasamorecomplexoptimizationprob-\nlem.Forexample,wemightexplicitlymodeltheeffortandcostof\n#### **2. Specific Requirements** humanreview,andusethistoguideourchoices.Belowwebriefly\nintroducesomesimplemetricsthatcouldbeusedandleavethisfor\n1. **Removal of Redundant Multiplier:**\nIn the `calculateEstimatedBackupStorage` function futurework.\nwithin the `<redacted>` file, the multiplication\nby the `BACKUP_STORAGE_MULTIPLIER` constant\nmust be removed.\nGoogleetal.\nLet𝑉 bethevalueofsuccessfullyclosingabug𝑏 withafix. Let𝐻 bethecostofhavingahumanreviewapatchfromtrajec-\n𝑏 𝑐\nLet𝐶 bethecostonthecodebaseofleavingthebugunrepaired. tory𝑡.Theanalogousexpectednetvalueforthepatchvalidation\n𝑏\nLet𝑅 bethecosttoproducearepairtrajectory.Let𝑝∗bethetrue, policyisthen:\n𝑐\nunknown,probabilityofatrajectorysolvingbug𝑏.\n(cid:40)\nTheexpectednetvalueoftheabstentionpolicyisthen: 𝑙𝑙𝑝∗(𝑉 𝑏)+(1−𝑝∗)(−𝐶 𝑏)−𝐻\n𝑐\nif𝐷 𝑣(𝑃 𝑣(𝑏,𝑡))\n(cid:40)\n−𝐶\n𝑏\notherwise\n𝑙𝑙𝑝∗(𝑉 𝑏)+(1−𝑝∗)(−𝐶 𝑏)−𝑅\n𝑐\nif𝑃 𝑎(𝑏)≥𝜏\n𝑎\n−𝐶\n𝑏\notherwise\n",
    "tables": [],
    "images": []
  },
  {
    "metadata": {
      "id": "2510.03215v1",
      "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language\n  Models",
      "authors": [
        "Tianyu Fu",
        "Zihan Min",
        "Hanling Zhang",
        "Jichao Yan",
        "Guohao Dai",
        "Wanli Ouyang",
        "Yu Wang"
      ],
      "summary": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.",
      "published": "2025-10-03T17:52:32Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03215v1"
    },
    "text": "Preprintversion\nCACHE-TO-CACHE: DIRECT SEMANTIC COMMUNICA-\nTION BETWEEN LARGE LANGUAGE MODELS\nTianyuFu∗1,2,ZihanMin∗1,HanlingZhang∗3,JichaoYan1,\nGuohaoDai5,2,WanliOuyang3,4,YuWang†1\n1TsinghuaUniversity 2InfinigenceAI 3TheChineseUniversityofHongKong\n4ShanghaiAILaboratory 5ShanghaiJiaoTongUniversity\nABSTRACT\nMulti-LLM systems harness the complementary strengths of diverse Large Lan-\nguageModels,achievingperformanceandefficiencygainsunattainablebyasin-\nglemodel. Inexistingdesigns,LLMscommunicatethroughtext,forcinginternal\nrepresentationstobetransformedintooutputtokensequences. Thisprocessboth\nloses rich semantic information and incurs token-by-token generation latency.\nMotivated by these limitations, we ask: Can LLMs communicate beyond text?\nOracleexperimentsshowthatenrichingtheKV-Cachesemanticscanimprovere-\nsponse quality without increasing cache size, supporting KV-Cache as an effec-\ntivemediumforinter-modelcommunication. Thus, weproposeCache-to-Cache\n(C2C),anewparadigmfordirectsemanticcommunicationbetweenLLMs. C2C\nusesaneuralnetworktoprojectandfusethesourcemodel’sKV-cachewiththatof\nthetargetmodeltoenabledirectsemantictransfer. Alearnablegatingmechanism\nselectsthetargetlayersthatbenefitfromcachecommunication. Comparedwith\ntextcommunication,C2Cutilizesthedeep,specializedsemanticsfrombothmod-\nels, while avoiding explicit intermediate text generation. Experiments show that\nC2Cachieves8.5-10.5%higheraverageaccuracythanindividualmodels. Itfur-\nther outperforms the text communication paradigm by approximately 3.0-5.0%,\nwhile delivering an average 2.0× speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.\n1 INTRODUCTION\n(a) (b)\ncontext s-prompt t0 tn-1 context t0 … tn query r0 context context query r0\nS-Cache Cache\nSharer LLM: S-Cache S … S Receiver LLM: R-Cache R … S&R-Cache R-Cache R …\nR-Cache Fuser\ncommunication text: t0 t1 tn response text: r0 r1 response text: r0 r1\nFigure1: (a)PreviousText-to-Text(T2T)communicationpassesinformationthroughexplicittext\ngeneration. (b)OurCache-to-Cache(C2C)communicationdirectlyprojectsandmergesKV-Cache\nwithrichsemanticsfromdifferentLLMs.\nWith the rapid progress of Large Language Models (LLMs) (Guo et al., 2025; Yang et al., 2025a;\n!\nOpenAI,2025), theyarenowappliedacrossincreasinglydiversedomainsandtasks. Tomeetver-\nsatile demands, LLMs are trained with distinct focuses, such as coding (Hui et al., 2024), mathe-\nmatics(Yangetal.,2024a), visualunderstanding(Baietal.,2025), edgecomputing(Zhangetal.,\n2024b), and so on. Meanwhile, general-purpose LLMs can also simulate specialized capabilities\nthroughpromptengineering,enablingflexibleroleadaptationacrossdownstreamapplications.\nLeveragingthediversityofLLMs,manymulti-LLMsystemsareproposedtofurtherenhanceoverall\nperformance and efficiency (Guo et al., 2024; Tran et al., 2025). In collaborative multi-LLM\n∗Equalcontribution.\n†Correspondingauthor:YuWang(yu-wang@tsinghua.edu.cn).\n1\n5202\ntcO\n3\n]LC.sc[\n1v51230.0152:viXra\nPreprintversion\nUser Coder LLM (a) Text-to-Text (T2T) & Writer LLM L do not know what <p> means\nText KV-Cache: embedding User: “Help Chatbot code.” <p>: don’t know this word “Sorry, I don’t know the specific\n“<!doctype html> <!doctype html>: start of doc Coder: “Write contentinside … location to insert. Writing plain\n<section> <section>: start of section the <section> wrapper.” wrapper: some structure text:I’m Tom…”\n<title></title> <title>: start of title\n<p></p> </title>: end of title (b) Cache-to-Cache (C2C) Writer LLM J know <p> from Coder cache\n</section>… <p>: start of content Neural KV-Cache projection the start of content “<title>Introduction</title>\nInsert my self-introduction … <p>→ … <p>I’m Tom...</p>\nin the right place” place: after <p> place→ … after <p> </section>”\nFigure2: ConceptualcomparisonofT2TandC2CcommunicationinaCoder-Writercollaboration\nexample. In T2T, the Coder’s ambiguous text instruction fails to convey the structural semantics\nof<p>asaparagraphseparator,causingtheWritertomisplacethecontent. C2Cdirectlyprojects\nthe Coder’s KV-Cache into the Writer, transferring both the semantic understanding and precise\ninsertionlocationwithoutintermediatetextgeneration.\nsystems(Lietal.,2023;Wuetal.,2023),LLMsareassigneddistinctrolesandproactivelyexchange\ntext messages. Mirroring human collaboration, these systems accumulate partial understandings\nor sub-solutions from different agents via verbal communication. They harnessing the collective\ncapabilitiesofmultipleLLMstosolvecomplexproblemsthatasinglemodelcannot. Bycontrast,\nrouting-basedmulti-LLMinferencesystemsrelyonpassivecontextinheritanceratherthanactive\nmessageexchange.Thesesystemscoordinatemodelsofvaryingparametersizesorreasoningdepths\nformoredynamicandefficientresponses(Lietal.,2024;Fuetal.,2025;Ongetal.,2024;OpenAI,\n2025).Downstreammodelsinheritthecontextfromprecedingmodelsinmulti-roundconversations,\nthen generate follow-up responses to the new questions based on their own understanding of the\nconversationhistory.\nHowever,currenttext-to-text(T2T)interfacesrestrictinformationexchangeamongLLMs,particu-\nlarlywhenconveyingrichordiversesemanticinterpretationsofasharedcontext. Asillustratedin\nFigure2,theselimitationsarisefromseveralinherentconstraintsofT2Tcommunication. First,as\na low-bandwidth medium, text introduces an information bottleneck. The high-dimensional inter-\nnalrepresentationsmustberepeatedlycompressedintolinearstringsandthendecompressedbythe\nreceiverLLM.Whenmodelsdifferinknowledgeorassignedroles,somesignalsmaybeirrecover-\nable(e.g.,interpreting<p>asasectionmarker). Second,naturallanguageisinherentlyambiguous,\nwith idioms, underspecified references, and vague expressions. Although recent agent protocols\naimtostandardizetextmessages(Anthropic,2024;Surapanenietal.,2025),rigidtemplatesremain\ninsufficient for flexible, open-domain collaboration. Third, T2T communication incurs noticeable\nlatency.Everyexchangerequiresexhaustive,token-by-tokendecodingofcontextualexplanationsin\nsequence. Theselimitationsmotivateakeyquestion:\nCanLLMscommunicatebeyondtext?\nInthiswork,weexploreusingKV-CacheasthemediumforLLMcommunication. KV-Cacheisa\nnaturallyricherrepresentationthantext. Italsoenablesfullyparallelcommunicationthroughdirect\nprojection,avoidingtheslowsequentialdecodingintextexchanges. Ouroracleexperimentsshow\nthat(1)EnrichingKV-Cacheunderthesamecontextlengthcanleadtoanincreaseinaccuracy. (2)\nKV-CacheisconvertiblebetweenLLMs. (3)DifferentLLMsencodedistinctsemanticunderstand-\ningsandcontextualknowledgeofthesameinput,reflectingtheircomplementarystrengths.\nEncouraged by these oracles, we propose Cache-to-Cache (C2C), a new paradigm for richer and\nfaster multi-LLM communication. As shown in Figure 1(b), C2C projects the KV-Cache from a\nsource model into the space of a target model and merges them through a neural Cache Fuser.\nExperiments show that C2C achieves 8.5-10.5% higher average accuracy than individual models.\nIt further outperforms the T2T paradigm by approximately 3.0-5.0%, while delivering an average\n2.0×speedupinlatency.\n2 RELATED WORK\n2.1 KV-CACHESHARINGANDREUSE\nBased on the similarity of KV-Cache between layers, intra-model cache sharing methods (Yang\netal.,2024b;Wu&Tu,2024;Sunetal.,2024;Brandonetal.,2024;Wuetal.,2025)areproposed\n2\nPreprintversion\nto reuse shallow layers’ KV-Cache for deeper layers to accelerate single LLM inference. Another\nresearchfocusistoreuseaportionofKV-Cache(e.g.,commonprefix,referencedocuments)forthe\nsamemodelinmultipleuserqueries(Bang,2023;Yeetal.,2024;Yaoetal.,2024;Qinetal.,2024;\nYang et al., 2025b). DroidSeek Liu et al. (2024a) extends cache reuse to models fine-tuned from\nthesamebasemodel. Unlikeexistingworksthatfocusoncomputationalefficiencythroughcache\nreuse, our approach leverages the KV-Cache as a medium for semantic transfer between LLMs.\nFurthermore, unlike existing cache sharing methods that are restricted to only a single model or\nmodelswithidenticalstructureandsize,ourmethodsupportssharingacrossdifferentmodelfamilies\nandvaryingmodelsizes.\n2.2 MULTI-LLMSYSTEMS\nCollaborative multi-LLM systems. Collaborative systems treat multiple LLMs as peers that ex-\nchangeinformationtoimprovecollectiveperformance. Chain-of-Agents(Zhangetal.,2024c)and\nMetaGPT(Hongetal.,2023)createsequentialmessageflowswhereagentsdirectlycommunicate\nusing natural language interfaces. Mixture-of-Agents Wang et al. (2024) and DyLAN (Liu et al.,\n2024b)introducelayeredcommunicationarchitectures.TargetLLMsaggregatemessagesfrommul-\ntiplemodelsusingvotingorsummarizationmechanisms. Multi-agentdebatemethods(Estornell&\nLiu,2024;Liangetal.,2024;Duetal.,2023)involveiterativecommunicationrounds,lettingLLM\nagentsdiscussandrefineresponses. RecentworkssuchasMCPAnthropic(2024)andA2ASura-\npaneni et al. (2025) establish formal text protocols beyond natural language, standardizing agent\ninteractionandtoolusageincollaborativemulti-LLMsystems. Theseapproachesrelyontext-level\ninterfaces,wherecommunicationrequiresonemodeltogeneratetexttoken-by-tokenandanotherto\ningestitasinput. Ourworkexploresadeeperandmoreefficientcollaborationbydirectlysharing\ninternalKV-Cacherepresentations.\nRouting-based multi-LLM inference systems. To accelerate LLM inference, several systems\nleverage multiple models with different capabilities and costs. Dynamic model selection meth-\nods (OpenAI, 2025; Ong et al., 2024; Feng et al., 2024) route queries to different models with\nvaryingsizesandconfigurationstobalanceefficiencyandperformance. Token-levelroutingmeth-\nods(Zhangetal.,2024a;Shenetal.,2024;Zhengetal.,2025;Fuetal.,2025)enablefiner-grained\nselection,utilizingsmallermodelsforsimpletokengenerationwithinthereasoningprocessofcom-\nplex tasks. While these systems achieve efficiency through strategic model switching, they either\ncompletelydropcontextfromothermodels,orsimplyrelyontheirownunderstandingsofthecon-\ntext. Withoutunderstandingsharing,smallermodelscannotbenefitfromthericherrepresentations\nalreadycomputedbylargermodels.\n3 METHOD\n3.1 PRELIMINARIES\nLLM inference. Autoregressive LLM inference involves two stages: prefill and decode. Prefill\nencodes the full input to produce the first output token; decode then generates subsequent tokens\niteratively using the last token and the cached key–value (KV) states. Formally, let X =\n[0:n]\n[x ,...,x ] be the input token sequence. After prefill, LLM produces a per-token KV-Cache\n0 n−1\nC(X ) = [c ,...,c ] ∈ Rn×d. Fornotationbrevity,ddenotestheKVdimensionalitythatis\n[0:n] 0 n−1\nflattenedfromalllayersintoasinglevectorpertoken. Therangesubscriptsareomittedwhenclear.\nDuringdecoding,withcurrenttokeny andcachesfromtheinputandthegeneratedprefix,thenext\ni\ntokenispredictedas\n(cid:0) (cid:1)\ny =P y |C(X) ⊕ C(Y ) , (1)\ni+1 i [0:i]\nwhere⊕denotessequence-wiseconcatenation.ThecacheupdatesasC(Y )=C(Y )⊕C(y ).\n[0:i+1] [0:i] i\nLLM communication. In LLM communication scenarios, we define the LLM that provides con-\ntextualunderstandingorknowledgeasSharer,andtheonethatutilizesitasReceiver.\n3.2 ORACLESFORCACHE-TO-CACHECOMMUNICATION\nWe aim to explore whether LLMs can have direct semantic communication through KV-Cache.\nSpecifically,wedesigntwooracleexperimentstoanswerthefollowingquestions: (1)Benefit: can\n3\nPreprintversion\nSource KV Target KV Transformed KV\n20 65\n10 60\n55\n0\n50\n10\n45\n20 1 2 3 4 5 6 7 8 9 10\n40 30 20 10 0 10 20 Number of Layers\nFigure3: Thet-SNErepresentationsofsource,\ntarget,andtransformedKV-Cache.\n)%(\nycaruccA\nTop-K Last-K Direct Few-shot Oracle\nFigure4: Accuracyinfluenceofaccumulatively\naugmentingdifferentnumberoflayers.\nAverageEffectiveRank\nMethod CacheLen. CacheAugment Acc.(%)\nType Sharer Receiver C2C\nDirect |X| No 58.42\nFew-shot |E|+|X| Yes 63.39 KCache 539 388 395\nOracle |X| Yes 62.34 VCache 689 532 560\nTable1: Cacheenrichmentexperiment. Oracle Table 2: Average effective rank of KV-Cache\nprefillsonE andX,thendiscardE. fromSharer,Receiver,andtheC2Cfusedone.\na model’s capabilities be improved through KV-Cache semantic enrichment without extending se-\nquencelength?(2)Convertibility:cantheKV-Cacheofonemodelbeeffectivelyutilizedbyanother\nmodel?\n3.2.1 CACHEENRICHMENTORACLE\nTovalidatethebenefitofcacheenrichment,wefirstexplorewhetherthesemanticqualityofafixed-\nlength question KV-Cache can be improved without increasing cache size. Few-shot prompting\nsuggeststhismightwork: providingexemplarsE beforethequestionX oftenimprovesaccuracy.\nButdoesthisarisefromattendingtomorecontexttokens,orfromEenrichinghowX isembedded\ninKV-Cache?\nWeevaluatethisviathreesetups:(1)Direct:prefillonX onlyanddecodewithC(X);(2)Few-shot:\nprefillonE⊕XanddecodewithC(E⊕X)(longercache);(3)Oracle:prefillonE⊕Xbutdiscard\ntheexemplarsegmentandkeeponlythequestion-alignedslice\nC∗(X) = C (E⊕X), (2)\n[|E|:|E|+|X|]\nso that decoding uses a question-length cache with no extra tokens. Here, |·| denotes sequence\nlength. InEquation1,thiscorrespondstosubstitutingC(X)withC∗(X)beforedecoding.\nComparingDirectandOracleisolatestheeffectofcacheenrichment:anygainarisesfromthericher\nquestionembeddingsinducedbyE, notfromattendingtoadditionaltokencachesasinFew-shot.\nAsshowninTable1,theOraclesetupimprovesresponsequalityatthesamecachelength.\nAdditionally,weanalyzedhowcacheenrichmentaffectsdifferenttransformerlayers. Ourfindings\nshow substantial variation across layers: while some layers benefit from cache enrichment, others\nexperience performance degradation (details in Appendix A.2.1). Furthermore, these layer-wise\neffectsaccumulateasmorelayersareaugmented. AsshowninFigure4,selectivelyapplyingcache\nenrichmenttothetop-10performinglayersyieldshigheraccuracythanenrichingalllayers, while\ntargeting the worst-performing layers leads to accuracy decline. This finding guides the gating\nmechanismofourcacheFuser(Section3.3.2).\n3.2.2 CACHETRANSFORMATIONORACLE\nToverifythatonemodel’sKV-Cachecanbeutilizedbyanother,weconductedcross-modeltransfor-\nmationexperiments. Wetraineda3-layerMLPtomaptheKV-CachefromasourceLLM(Qwen3-\n4B)toatargetLLM(Qwen3-0.6B),withmoresetupsdetailedinAppendixA.3.2.\n4\nPreprintversion\nSharer Fuser\ncache dynamic weighting Gate Receiver\nprojection + cache reply\nReceiver\nfeature fusion ×\ncache\nFigure5: C2CFuserarchitectureandtrainingscheme.\nT-SNE visualizations in Figure 3 reveal that the raw KV-Caches of the two LLMs are far apart in\nrepresentationspace. Aftertransformation,themappedKV-CacheisinsidetheKV-Cacherepresen-\ntationspaceofthetargetmodel. TheseresultsdemonstratethatKV-Cachesfromdifferentmodels\nare,ingeneral,convertibleasthetransformedcacheintherepresentationspaceofthetargetmodel.\nOnethingtonoteisthatthetransformedcacheoccupiesonlyasmallersubsetofthetarget’sspace.\nItindicatesthatthesourcemodel’ssemanticinformationcannotfullycoverthetarget’s,despitethe\nsourcebeinglarger. Thisreflectsinherentdifferencesinhoweachmodelencodescontext. Another\nobservationalsosupportsthisinterpretation:thecorrect-answersetsofdifferentmodelsexhibitlim-\nited overlap (Figure 7), despite the comparable aggregated accuracy of respective models. These\nfindingssuggestthatifspecializedcontextualunderstandingfromdifferentmodelscanbesuccess-\nfullyprojectedandfused,itmayharnessthecomplementarystrengthsofrespectivemodels.\n3.3 C2CDESIGN\n3.3.1 OVERVIEW\nBuildingontheoracleexperiments,weproposetheC2CFuserarchitecture. Itscoreobjectiveisto\nextractusefulcontextualunderstandingorknowledgefromonemodel(theSharer)andfuseitinto\nanothermodel(theReceiver).\nIngeneral,theC2Cparadigmcontainsasetofkey/valuecachefusersFandalayermappingstrategy\nG. Duringtheprefillstage,fuserF takesthenthlayercacheoftheReceiverModelC (X)andthe\nn n\ncorrespondingG(n)thlayercacheoftheSharerModelCS (X)andandgeneratethecorresponding\nG(n)\nfusedcache:\nCF ={F (C (X),CS (X))}N (3)\nn n G(n) n=1\nDuringdecoding,withthecurrenttokeny andcachesfromtheinputandthegeneratedprefix,the\ni\nnexttokenispredictedas:\ny\ni+1\n=P (cid:0) y\ni\n(cid:12) (cid:12)CF(X)⊕C(Y\n[0:i]\n) (cid:1) (4)\n3.3.2 FUSERSTRUCTURE\nToenhancetheReceiver’sKVCachewithoutdestructiveoverwritingofitsinformation,thefuseris\ndesignedunderaresidualintegrationprinciple.AsshowninFigure5,itcontainsthreekeymodules:\n(1) Projection module concatenates the Receiver’s KV-Cache with the Sharer’s KV-Cache, then\nprocessestheconcatenatedfeaturethroughaprojectionlayerfollowedbyafeaturefusionlayer.\n(2) Dynamic weighting module applies an input-aware head modulation layer to dynamically\nreweighttheprojectedinformation.\n(3) Learnable gate introduces a trainable per-layer gate value that decides whether to inject the\nSharer’s context. The value applies a Gumbel-sigmoid with temperature annealing to smoothly\ntransitionfromdifferentiableduringtrainingtobinaryatinference.\n3.3.3 MODELALIGNMENT\nFusingKV-Cachesacrossmodelfamiliesandsizesrequiresalignmentattwolevels:tokensandlay-\ners. Fortokenalignment, differenttokenizersmayproduceslightlyvariedtokensequencesforthe\n5\nPreprintversion\nsameinput. WealignthembydecodingeachReceivertokenintoitsstringformandre-encodingit\nusingtheSharer’stokenizer. Whenone-to-manymappingsoccasionallyoccur,weselecttheSharer\ntokenwithmaximalstringcoveragetopreserveinformation. Forlayeralignment,weadoptatermi-\nnalalignmentstrategy: thefinallayersofbothmodelsarealignedfirst,thenthepenultimatelayers,\nand so on in reverse order until reaching the shallower model’s first layer. Detailed specifications\nareprovidedinAppendixA.1.\n3.3.4 TRAININGSCHEME\nDuring training, we freeze both the Sharer and Receiver models, training only the C2C module\nfor KV-Cache fusion. We employ standard next-token prediction loss on the Receiver’s response\npredictions,similartosupervisedfine-tuning(SFT).ThekeydifferenceisthattheReceiverpredicts\nresponsesconditionedonfusedKV-Cacheratherthanitsown.\nThetrainingprocedureconsistsofthreestages: (1)Forward: bothmodelsencodetheinputcontext\nto produce their respective KV-Caches. (2) Fusion: the C2C module fuses both KV-Caches and\nreplaces the Receiver’s cache. (3) Supervision: the Receiver prefills the response using the fused\ncache,andgradientsbackpropagatethroughC2Ctominimizepredictionloss.\n4 EXPERIMENT\n4.1 SETUP\nWehighlightkeysetupshere,withmoredetailsinAppendixA.3.\nModels. We evaluate C2C across various model families, including Qwen2.5 (Yang et al., 2024a;\nHuietal.,2024),Qwen3(Yangetal.,2025a),Llama3.2(Dubeyetal.,2024),andGemma3(Team\net al., 2025). To test generalizability, we select different configurations for the Sharer-Receiver\nmodel combinations, including models of different generations (Qwen3 and Qwen2.5), different\nfamilies(Qwen,Llama,andGemma),differentsizes(0.6Bto14B),differentspecializations(gen-\neral, code, and math model), and different training stages (pretrained and instruction fine-tuned\nmodels). For ablative and diagnostic analyses (scaling behavior, ablation study, behavior analy-\nsis),wefixtheReceiverandSharertoQwen3modelsunlessotherwisespecified. Thisconsistency\neliminatesconfoundersfrommodelalignmentandisolatesthecoreimpactofC2C.\nBaselines. We compare C2C over two LLM collaboration methods to contextualize performance:\n(1) Text-to-Text (T2T) communication: Collaborate by analyze-response hand-off for each query.\nThe Sharer generates analytical text of key information to solve the input question. This text is\nconcatenated with the original question and fed to the Receiver to mirror standard collaborative\npipelines.CorrespondingpromptsareinAppendixA.3.6.(2)Query-levelrouting(Ongetal.,2024):\nCollaborate by selecting the appropriate LLM for different queries. We also include individual\nmodelperformance(SharerorReceiveralone)toestablishalowerboundforcollaborativegains.\nBenchmarks. We evaluate on four widely used benchmarks spanning reasoning, knowledge,\nand language domains to ensure comprehensive coverage. OpenBookQA (Mihaylov et al., 2018)\nfor fact-based reasoning, MMLU-Redux (Gema et al., 2025) for knowledge in the general do-\nmain, ARC-Challenge (ARC-C) (Clark et al., 2018) for scientific and logistic reasoning, and C-\nEval(Huangetal.,2023)forcomprehensiveknowledgeintheChinesedomain.\nTraining dataset. To ensure the generalizability of C2C, we utilize the first 500k samples of the\nOpenHermes2.5 Dataset (Teknium, 2023), a general finetuning dataset, to train C2C Fusers. For\nbudgetingtrainingpurposes,weutilizetheMMLUasthetrainsetonscalingbehaviorandbehavior\nanalysis,unlessspecified.\nEvaluationsettings. Weuseaverageaccuracyastheperformancemetric. Weusetextgeneration\nandanswerextractionastheevaluationmodeforC2Candbaselines,withthemaxgenerationlength\nsetto64formulti-choicebenchmarks. Allexperimentsareconductedinthezero-shotsettingwith\nzerogenerationtemperaturetoensurereproducibility.Weuseaverageinferencetimeastheefficient\nmetric,measuredusingasingleNVIDIAA100GPU(Choquetteetal.,2021)withbatchsize=1.\n6\nPreprintversion\nTable 3: Comparison of communication methods across benchmarks. We use Qwen3-0.6B as the\nReceivermodel.\nSharer Task Metric Receiver Sharer Routing Text-to-text Cache-to-cache\nAcc 35.53 38.42 35.58 41.03 42.92\nMMLU-Redux\nTime 0.29 0.34 0.27 1.52 0.40\nAcc 39.20 45.60 40.80 44.00 52.60\nOpenBook\nTime 0.27 0.35 0.29 0.81 0.30\nQwen2.5-0.5B\nAcc 41.04 42.09 40.70 49.48 54.52\nARC-C\nTime 0.29 0.39 0.29 1.00 0.36\nAcc 32.04 40.21 34.61 35.88 41.77\nC-Eval\nTime 0.26 0.31 0.26 1.51 0.34\nAcc 35.53 32.30 33.38 43.32 44.42\nMMLU-Redux\nTime 0.29 0.06 0.18 0.75 0.50\nAcc 39.20 32.60 36.40 41.20 47.80\nOpenBook\nTime 0.26 0.07 0.17 0.70 0.43\nLlama3.2-1B\nAcc 41.04 33.57 37.22 50.00 53.39\nARC-C\nTime 0.28 0.07 0.18 0.70 0.47\nAcc 32.04 31.31 31.92 35.27 40.77\nC-Eval\nTime 0.25 0.04 0.15 0.71 0.49\nAcc 35.53 1.03 16.39 43.87 43.95\nMMLU-Redux\nTime 0.29 2.06 0.28 7.54 0.45\nAcc 39.20 2.20 22.20 46.40 53.20\nOpenBook\nTime 0.26 1.98 0.27 5.08 0.34\nQwen3-4B-Base\nAcc 41.04 1.48 19.65 53.91 55.39\nARC-C\nTime 0.28 2.06 0.28 6.56 0.40\nAcc 32.04 5.65 15.10 38.92 42.79\nC-Eval\nTime 0.25 2.02 0.26 3.59 0.39\n4.2 PERFORMANCEANDEFFICIENCY\nAsshowninTable8, C2CconsistentlyimprovestheReceivermodelperformanceacrossdifferent\nsettingsandbenchmarks. AfterapplyingC2C,weseeanaverageincreaseofaccuracyby11.00%,\n9.64%, and 11.88% across three different Sharers. Compared with text-to-text communication,\nC2Cachievesanaverageaccuracyincreaseof5.36%,4.15%,and3.06%. Italsoachievesobvious\nspeedupsof3.46×,1.51×,and14.41×,thankstothewaivingofintermediatetextmessagegener-\nation. In contrast, query-level routing prioritizes efficiency but limits accuracy to the better of the\ntwooriginalmodels.\nNotably, whenusingQwen3-4BBaseastheSharer, thegeneratedtextsometimesignoresinstruc-\ntions and exceeds the expected length. This results in extremely long text-to-text communication\ntime,whileC2Cbypassesthisissue. ThesetuphighlightsaninterestingusecaseofC2C,wherea\nweak SFT model enables a strong pre-trained base model to follow instructions. We also observe\nthatLlama3.2-1Bexhibitsexceptionallyfastinference,analyzedinAppendixA.4.3.\n4.3 SCALINGBEHAVIOR\nScalingsequencelengths. WeevaluatehowC2Cscaleswithrespecttosequencelengthonlong-\ncontexttasksfromtheLongBenchV1benchmark. AllC2Cfusersaretrainedandtestedondifferent\nsetsofLongBenchV1. AsshowninTable4,C2Cconsistentlyoutperformstext-to-textcommunica-\ntionacrossallsequence-lengthintervals. ItindicatesC2C’sadvantagesacrossinputlengthranges.\nMoredetailedsetupsandresultsareinAppendicesA.2.2andA.3.4.\nScalingmodelsizes. WeinvestigatehowC2CscaleswithrespecttotheSharerandReceivermodel\nsizes. AllC2CfusersaretrainedonMMLU’sauxiliarytrainsplitandevaluatedonMMLU-Redux.\n7\nPreprintversion\n(a) (b)\nFigure6:Accuracyimprovements(∆Accuracy)ontheMMLU-Reduxbenchmark.(a)C2Ccommu-\nnication. (b)T2Tcommunication. Thex-axisdenotestheSharermodelfromtheQwen2.5-Instruct\nseries,whilethecurvescorrespondtoReceivermodelsfromtheQwen3series.\nLength Receiver Sharer T2T C2C Setting #Param. OpenBook ARC-C MMLU C-Eval\n0-4k 27.39 21.89 29.47 36.64 Single 596M 45.80 47.65 36.81 35.81\n4-8k 24.97 18.55 26.30 31.71 Identical 529M 50.60 52.52 42.17 40.34\n8k+ 22.20 14.04 24.54 25.37 C2C 478M 52.60 54.52 42.92 41.77\nTable 4: LongBenchV1 scores with Table5:Performancecomparisonofdifferenttrainingset-\nQwen3-0.6B (Receiver) and Qwen2.5- tings. SingledirectlyfinetunestheReceivermodel. Iden-\n0.5B(Sharer)acrossinputlengths. ticalusesthesamemodelforSharerandReceiver.\nAs shown in Figure 6, the x-axis denotes Sharer size (Qwen2.5-Instruct series), the y-axis shows\naccuracy gains of C2C over Receiver-only baselines (∆ Accuracy), and each curve represents a\nReceiverfromtheQwen3series.WefindthattheaccuracyimprovementsofC2Cgenerallyincrease\nfasterthanT2T.ThistrendshowsthatwhentheSharerpossessesricherknowledge,C2Cisableto\nmoreeffectivelytransmitusefulinformationtotheReceiver. Notethattherelativegainsforlarger\nReceiversarelesspronouncedduetotheirstrongerbaselinesandhigheroverlapwiththeSharer’s\nknowledge.\nDifferentmodelcombinations.WetestdifferentSharer-Receivercombinations,includingdifferent\nmodelfamiliesanddifferenttask-specificmodels.TheresultinTable6showsthatC2Coutperforms\ntext-to-textcommunicationonallfivecombinationsbyanaverageincreaseof8.59%. Thissupports\nthat by employing C2C, the Receiver model can effectively utilize contextual understanding from\ndifferent model to enhance performance. Notably, when using Qwen2.5-Math as the Sharer, the\ninferenceandcommunicationtimebecomessubstantiallylonger, analyzedinAppendixA.4.3. To\nfurthertestthegeneralizabilityofC2C,weswaptheSharerandReceivermodel. Theresultshows\nthat C2C robustly brings an 5.05% increase in accuracy while applying T2T results in a 6.3% de-\ncreaseinperformance.\nTogether, these experiments support the scalability of C2C as an effective and efficient new LLM\ncommunicationparadigm.\n4.4 ABLATIONSTUDY\nSourcesofimprovement. InTable5,weablatethesourceofC2Cperformancegainbyfixingthe\nReceiver(Qwen3-0.6B)andvaryingtheSharer. Singledenotesstandardfullfine-tuningoftheRe-\nceiverwithoutSharer. IdenticaldenotesC2CwherebothSharerandReceiverareQwen3-0.6B.Our\ndefaultC2CusesQwen2.5-0.5BastheSharer. Underthesametrainingconfiguration,C2Cconsis-\ntentlyattainshigheraccuracythanbothSingleandIdentical. ThisconfirmsthatC2Cimprovements\ndonotpurelycomefromaddedtrainablecapacityoroverfittingtothetrainingset. Instead,itpoints\ntocomplementarycontextualunderstandingcontributedbytheheterogeneousSharer. Identicalstill\noutperformssingle,indicatingthatcache-levelself-communicationcanprovideusefulauxiliaryun-\nderstanding, echoing effects observed in latent reasoning and recurrent transformers (Zeng et al.,\n2025;Saunshietal.,2025).\n8\nPreprintversion\nPairType Receiver Sharer Metric Receiver Sharer T2T C2C\nAcc 39.20 31.75 41.35 45.90\nQwen3-0.6B Gemma3-1B\nTime 0.27 0.54 1.04 0.30\nHeterogeneous Acc 39.20 39.86 43.71 46.13\nQwen3-0.6B Qwen2.5-Math-1.5B\nTime 0.27 8.71 6.60 0.27\nAcc 39.20 25.09 39.74 46.89\nQwen3-0.6B Qwen2.5-Coder-0.5B\nTime 0.27 0.26 1.59 0.27\nAcc 38.42 39.20 32.12 43.47\nQwen2.5-0.5B Qwen3-0.6B\nTime 0.34 0.27 0.98 0.21\nSwap\nAcc 39.20 38.42 41.03 46.50\nQwen3-0.6B Qwen2.5-0.5B\nTime 0.27 0.34 1.52 0.26\nTable6: ComparisonofReceiver-only, Sharer-only, T2T,andC2Cacrossaccuracyandtime. The\npairsaregroupedintoHeterogeneoussettings(wheretheReceiverispairedwithSharersofdifferent\ncapabilities)andSwapsettings(whereReceiverandSharerrolesareexchanged).\nMethod MMLU ARC-C OpenBook CEval Average\nProject 20.01 19.57 21.80 21.41 20.70\n+Fuse 43.36 51.65 47.60 36.91 44.88\n+Gate(=C2C) 42.92 54.52 52.60 41.77 47.95\nTable7: PerformancecomparisononMMLU,ARC-C,OpenBook,andCEvalbenchmarks.\nFuserarchitecture.InTable7weshowtheeffectofdifferentcomponentsintheC2Cdesign.Com-\nparedwithpureprojection,keepingtheReceiver’soriginalKV-CacheandfusingwiththeSharer’s\nKV-Cachecombinesabilityfrombothmodelandincreasestheaccuracyby24.18%. Addingagate\nforfusedlayerselectionalsohelpsincreasingtheaverageaccuracyby3.07%.\n4.5 BEHAVIORANALYSIS\nEffective rank analysis. We analyze the effective rank of KV-Cache before and after cache-to-\ncachecommunication. Effectiverank(Roy&Vetterli,2007)isacommonapproachformeasuring\nthe intrinsic dimension of model weight or activation value; a higher intrinsic dimension means\nrichersemanticinformation,asformalizedinAppendixA.4.1. AstheTable.2shows,aftercache-\nto-cache fusing, the K and V’s effective rank increased from 388 to 395 and from 532 to 560,\nrespectively. This indicates that C2C enriches the semantic space by successfully transforming in\ntheSharermodelandinjectingknowledgeintotheReceivermodel.\nProgressivebehavior.WeanalyzetheprogressivebehaviorofC2Cbygraduallyincreasingtheper-\ncentageofcontextKV-CachebeingupdatedbyC2C.Whenthepercentageisabove50%,increasing\nthepercentagecontinuouslyyieldsbetterperformance. Detailedsetupandanalysiscanbefoundat\nAppendixA.2.4\nGatebehavior. WeanalyzethebehaviorofC2C’slearnablegatesunderdifferenttrainingregimes\nasdetailedinAppendixA.4.2.\n5 FUTURE WORK\nAsageneralLLMcommunicationparadigm,C2Ccanbeexpandedtovariousfields. Somepoten-\ntialscenariosinclude:(1)Privacy-awarecloud–edgecollaboration:acloud-scalemodelcantransmit\ncuratedKV-Cachesegmentstoanedgemodeltoboostcapabilitywithoutemittingrawtext,reduc-\ning bandwidth and limiting content exposure. (2) Integration with current inference acceleration\nmethod: useC2Ctoenhancespeculativedecodingandenabletoken-levelroutingacrossheteroge-\nneousmodelsforlowerlatencyandcost. (3)Multimodalintegration: alignandfusecachesamong\n9\nPreprintversion\nlanguage reasoning LLMs, vision–language models (VLMs), and vision–language–action (VLA)\npoliciessothatlinguisticandvisualcontextcandrivemoreaccurateactions.\n6 CONCLUSION\nIn conclusion, we demonstrate that LLMs can communicate beyond text. We introduce Cache-to-\nCache(C2C),ageneralparadigmthattransformsandfuseskey–value(KV)cachesacrossmodels\nto enable direct semantic communication. Across diverse tasks and model configurations, C2C\nconsistentlyachieveshighertaskperformanceandbetterefficiencythantext-to-textcommunication.\nTheseresultsestablishcache-to-cacheasapracticalalternativetotoken-basedcommunicationand\nhighlightitspromiseforscalable,low-latencymulti-LLMsystems.\n10\nPreprintversion\nREFERENCES\nAnthropic. Introducingthemodelcontextprotocol. Online; Nov.25, 2024, 2024. URLhttps:\n//www.anthropic.com/news/model-context-protocol. Accessed: 2025-09-08.\nShuaiBai,KeqinChen,XuejingLiu,JialinWang,WenbinGe,SiboSong,KaiDang,PengWang,\nShijie Wang, Jun Tang, et al. Qwen2. 5-vl technical report. arXiv preprint arXiv:2502.13923,\n2025.\nFu Bang. Gptcache: An open-source semantic cache for llm applications enabling faster answers\nand cost savings. In Proceedings of the 3rd Workshop for Natural Language Processing Open\nSourceSoftware(NLP-OSS2023),pp.212–218,2023.\nWilliam Brandon, Mayank Mishra, Aniruddha Nrusimha, Rameswar Panda, and Jonathan Ragan-\nKelley.Reducingtransformerkey-valuecachesizewithcross-layerattention.AdvancesinNeural\nInformationProcessingSystems,37:86927–86957,2024.\nJackChoquette,WishweshGandhi,OlivierGiroux,NickStam,andRonnyKrashinsky.Nvidiaa100\ntensorcoregpu: Performanceandinnovation. IEEEMicro,41(2):29–35,2021.\nPeterClark,IsaacCowhey,OrenEtzioni,TusharKhot,AshishSabharwal,CarissaSchoenick,and\nOyvindTafjord. Thinkyouhavesolvedquestionanswering? tryarc,theai2reasoningchallenge.\narXivpreprintarXiv:1803.05457,2018.\nYilunDu,ShuangLi,AntonioTorralba,JoshuaBTenenbaum,andIgorMordatch. Improvingfac-\ntualityandreasoninginlanguagemodelsthroughmultiagentdebate. InForty-firstInternational\nConferenceonMachineLearning,2023.\nAbhimanyuDubey,AbhinavJauhri,AbhinavPandey,AbhishekKadian,AhmadAl-Dahle,Aiesha\nLetman,AkhilMathur,AlanSchelten,AmyYang,AngelaFan,etal. Thellama3herdofmodels.\narXive-prints,pp.arXiv–2407,2024.\nAndrewEstornellandYangLiu. Multi-llmdebate: Framework,principals,andinterventions. Ad-\nvancesinNeuralInformationProcessingSystems,37:28938–28964,2024.\nTaoFeng,YanzhenShen,andJiaxuanYou. Graphrouter: Agraph-basedrouterforllmselections.\narXivpreprintarXiv:2410.03834,2024.\nTianyu Fu, Yi Ge, Yichen You, Enshu Liu, Zhihang Yuan, Guohao Dai, Shengen Yan, Huazhong\nYang,andYuWang.R2r:Efficientlynavigatingdivergentreasoningpathswithsmall-largemodel\ntokenrouting. arXivpreprintarXiv:2505.21600,2025.\nAryo Pradipta Gema, Joshua Ong Jun Leang, Giwon Hong, Alessio Devoto, Alberto Carlo Maria\nMancino,RohitSaxena,XuanliHe,YuZhao,XiaotangDu,MohammadRezaGhasemiMadani,\netal.Arewedonewithmmlu? InProceedingsofthe2025ConferenceoftheNationsoftheAmer-\nicas Chapter of the Association for Computational Linguistics: Human Language Technologies\n(Volume1: LongPapers),pp.5069–5096,2025.\nDaya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu,\nShirongMa,PeiyiWang,XiaoBi,etal. Deepseek-r1: Incentivizingreasoningcapabilityinllms\nviareinforcementlearning. arXivpreprintarXiv:2501.12948,2025.\nTaichengGuo,XiuyingChen,YaqiWang,RuidiChang,ShichaoPei,NiteshVChawla,OlafWiest,\nand Xiangliang Zhang. Large language model based multi-agents: A survey of progress and\nchallenges. arXivpreprintarXiv:2402.01680,2024.\nSirui Hong, Xiawu Zheng, Jonathan P. Chen, Yuheng Cheng, Ceyao Zhang, Zili Wang, Steven\nKa Shing Yau, Zi Hen Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, and Chenglin Wu.\nMetagpt: Meta programming for multi-agent collaborative framework. ArXiv, abs/2308.00352,\n2023. URLhttps://api.semanticscholar.org/CorpusID:260351380.\nYuzhen Huang, Yuzhuo Bai, Zhihao Zhu, Junlei Zhang, Jinghan Zhang, Tangjun Su, Junteng Liu,\nChuanchengLv,YikaiZhang,YaoFu,etal. C-eval: Amulti-levelmulti-disciplinechineseeval-\nuation suite for foundation models. Advances in Neural Information Processing Systems, 36:\n62991–63010,2023.\n11\nPreprintversion\nBinyuanHui,JianYang,ZeyuCui,JiaxiYang,DayihengLiu,LeiZhang,TianyuLiu,JiajunZhang,\nBowenYu,KemingLu,etal. Qwen2.5-codertechnicalreport. arXivpreprintarXiv:2409.12186,\n2024.\nGuohaoLi,HasanHammoud,HaniItani,DmitriiKhizbullin,andBernardGhanem. Camel: Com-\nmunicativeagentsfor”mind”explorationoflargelanguagemodelsociety. AdvancesinNeural\nInformationProcessingSystems,36:51991–52008,2023.\nYuhuiLi,FangyunWei,ChaoZhang,andHongyangZhang. Eagle: Speculativesamplingrequires\nrethinkingfeatureuncertainty. arXivpreprintarXiv:2401.15077,2024.\nTian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Shuming\nShi,andZhaopengTu. Encouragingdivergentthinkinginlargelanguagemodelsthroughmulti-\nagentdebate. InProceedingsofthe2024ConferenceonEmpiricalMethodsinNaturalLanguage\nProcessing,pp.17889–17904,2024.\nYuhanLiu,YuyangHuang,JiayiYao,ShaotingFeng,ZhuohanGu,KuntaiDu,HanchenLi,Yihua\nCheng,JunchenJiang,ShanLu,etal.Droidspeak:Kvcachesharingforcross-llmcommunication\nandmulti-llmserving. arXivpreprintarXiv:2411.02820,2024a.\nZijunLiu,YanzheZhang,PengLi,YangLiu,andDiyiYang.Adynamicllm-poweredagentnetwork\nfortask-orientedagentcollaboration. InFirstConferenceonLanguageModeling,2024b.\nTodorMihaylov,PeterClark,TusharKhot,andAshishSabharwal.Canasuitofarmorconductelec-\ntricity? anewdatasetforopenbookquestionanswering. InProceedingsofthe2018Conference\nonEmpiricalMethodsinNaturalLanguageProcessing,pp.2381–2391,2018.\nIsaac Ong, Amjad Almahairi, Vincent Wu, Wei-Lin Chiang, Tianhao Wu, Joseph E Gonzalez,\nMWaleedKadous,andIonStoica. Routellm: Learningtoroutellmswithpreferencedata. arXiv\npreprintarXiv:2406.18665,2024.\nOpenAI. Introducinggpt-5. https://openai.com/index/introducing-gpt-5/,Au-\ngust72025. Accessed: 2025-09-11.\nRuoyu Qin, Zheming Li, Weiran He, Mingxing Zhang, Yongwei Wu, Weimin Zheng, and Xinran\nXu. Mooncake: A kvcache-centric disaggregated architecture for llm serving. arXiv preprint\narXiv:2407.00079,2024.\nOlivierRoyandMartinVetterli. Theeffectiverank: Ameasureofeffectivedimensionality. In2007\n15thEuropeansignalprocessingconference,pp.606–610.IEEE,2007.\nNikunj Saunshi, Nishanth Dikkala, Zhiyuan Li, Sanjiv Kumar, and Sashank J Reddi. Reasoning\nwith latent thoughts: On the power of looped transformers. arXiv preprint arXiv:2502.17416,\n2025.\nZejiang Shen, Hunter Lang, Bailin Wang, Yoon Kim, and David Sontag. Learning to decode col-\nlaboratively with multiple language models. In Proceedings of the 62nd Annual Meeting of the\nAssociationforComputationalLinguistics(Volume1: LongPapers),pp.12974–12990,2024.\nYutaoSun,LiDong,YiZhu,ShaohanHuang,WenhuiWang,ShumingMa,QuanluZhang,Jianyong\nWang,andFuruWei. Youonlycacheonce: Decoder-decoderarchitecturesforlanguagemodels.\nAdvancesinNeuralInformationProcessingSystems,37:7339–7361,2024.\nRaoSurapaneni,MikuJha,MichaelVakoc,andToddSegal. Announcingtheagent2agentprotocol\n(a2a). GoogleDevelopersBlog,April2025. URLhttps://developers.googleblog.\ncom/en/a2a-a-new-era-of-agent-interoperability/. Accessed: 2025-09-08.\nGemma Team, Aishwarya Kamath, Johan Ferret, Shreya Pathak, Nino Vieillard, Ramona Merhej,\nSarahPerrin,TatianaMatejovicova,AlexandreRame´,MorganeRivie`re,etal.Gemma3technical\nreport. arXivpreprintarXiv:2503.19786,2025.\nTeknium. Openhermes 2.5: An open dataset of synthetic data for generalist llm assistants, 2023.\nURLhttps://huggingface.co/datasets/teknium/OpenHermes-2.5.\n12\nPreprintversion\nKhanh-Tung Tran, Dung Dao, Minh-Duong Nguyen, Quoc-Viet Pham, Barry O’Sullivan, and\nHoang D Nguyen. Multi-agent collaboration mechanisms: A survey of llms. arXiv preprint\narXiv:2501.06322,2025.\nJunlinWang,JueWang,BenAthiwaratkun,CeZhang,andJamesZou. Mixture-of-agentsenhances\nlargelanguagemodelcapabilities. arXivpreprintarXiv:2406.04692,2024.\nHaoyiWuandKeweiTu.Layer-condensedkvcacheforefficientinferenceoflargelanguagemodels.\nIn Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics\n(Volume1: LongPapers),pp.11175–11188,2024.\nQingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li,\nLiJiang,XiaoyunZhang,andChiWang. Autogen:Enablingnext-genllmapplicationsviamulti-\nagentconversationframework. arXivpreprintarXiv:2308.08155,3(4),2023.\nYouWu, HaoyiWu, andKeweiTu. Asystematicstudyof cross-layerkvsharingforefficient llm\ninference. In Proceedings of the 2025 Conference of the Nations of the Americas Chapter of\ntheAssociationforComputationalLinguistics: HumanLanguageTechnologies(Volume2: Short\nPapers),pp.396–403,2025.\nAnYang,BeichenZhang,BinyuanHui,BofeiGao,BowenYu,ChengpengLi,DayihengLiu,Jian-\nhongTu,JingrenZhou,JunyangLin,etal.Qwen2.5-mathtechnicalreport:Towardmathematical\nexpertmodelviaself-improvement. arXivpreprintarXiv:2409.12122,2024a.\nAn Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu,\nChang Gao, Chengen Huang, Chenxu Lv, et al. Qwen3 technical report. arXiv preprint\narXiv:2505.09388,2025a.\nJingbo Yang, Bairu Hou, Wei Wei, Yujia Bao, and Shiyu Chang. Kvlink: Accelerating large lan-\nguagemodelsviaefficientkvcachereuse. arXivpreprintarXiv:2502.16002,2025b.\nYifei Yang, Zouying Cao, Qiguang Chen, Libo Qin, Dongjie Yang, Hai Zhao, and Zhi Chen.\nKvsharer: Efficient inference via layer-wise dissimilar kv cache sharing. arXiv preprint\narXiv:2410.18517,2024b.\nJiayiYao, HanchenLi, YuhanLiu, SiddhantRay, YihuaCheng, QizhengZhang, KuntaiDu, Shan\nLu,andJunchenJiang. Cacheblend: Fastlargelanguagemodelservingwithcachedknowledge\nfusion. arXive-prints,pp.arXiv–2405,2024.\nLuYe,ZeTao,YongHuang,andYangLi.Chunkattention:Efficientself-attentionwithprefix-aware\nkvcacheandtwo-phasepartition. InProceedingsofthe62ndAnnualMeetingoftheAssociation\nforComputationalLinguistics(Volume1: LongPapers),pp.11608–11620,2024.\nBoyiZeng, ShixiangSong, SiyuanHuang, YixuanWang, HeLi, ZiweiHe, XinbingWang, Zhiyu\nLi,andZhouhanLin. Pretraininglanguagemodelstoponderincontinuousspace. arXivpreprint\narXiv:2505.20674,2025.\nKaiyan Zhang, Jianyu Wang, Ning Ding, Biqing Qi, Ermo Hua, Xingtai Lv, and Bowen Zhou.\nFastandslowgenerating: Anempiricalstudyonlargeandsmalllanguagemodelscollaborative\ndecoding. CoRR,2024a.\nMingjinZhang,XiaomingShen,JiannongCao,ZeyangCui,andShanJiang. Edgeshard: Efficient\nllminferenceviacollaborativeedgecomputing. IEEEInternetofThingsJournal,2024b.\nYusenZhang,RuoxiSun,YanfeiChen,TomasPfister,RuiZhang,andSercanArik.Chainofagents:\nLarge language models collaborating on long-context tasks. Advances in Neural Information\nProcessingSystems,37:132208–132237,2024c.\nWenhao Zheng, Yixiao Chen, Weitong Zhang, Souvik Kundu, Yun Li, Zhengzhong Liu, Eric P\nXing,HongyiWang,andHuaxiuYao. Citer: Collaborativeinferenceforefficientlargelanguage\nmodeldecodingwithtoken-levelrouting. arXivpreprintarXiv:2502.01976,2025.\n13\nPreprintversion\nA APPENDIX\nA.1 DESIGNCHOICEEXPLORATION\nWedetailthedesignsofC2Cwithdiscussionsonalternativepossibledesignchoicesinthissection.\nA.1.1 LAYERALIGNMENT\nTerminal alignment. In this strategy, the layers of the two models are aligned starting from the\noutput side. Specifically, the final layer of the smaller model is paired with the final layer of the\nlargermodel, thepenultimatelayerwiththepenultimatelayer, andsoon. Thisschemeprioritizes\nalignmentbetweenthedeeperlayersacrossmodels,whichtypicallycaptureshigher-levelsemantic\nrepresentations.\nDepth-normalizedalignment. Inthisstrategy,bothmodels’layerindicesarenormalizedto[0,1]\nbydividingby(L−1),whereListhetotalnumberoflayersinthemodel.Letthemodelwithfewer\nlayers(L )serveastheanchor. Foreachanchorlayeri(withnormalizedindexi/(L −1)),we\nmin min\nselectthelayerj intheothermodel(L )whosenormalizedindexj/(L −1)isclosest:\nmax max\n(cid:12) (cid:12)\nj⋆ = argmin(cid:12) i − j (cid:12). (5)\nj\n(cid:12)Lmin−1 Lmax−1(cid:12)\nThis method produces an alignment that distributes correspondences approximately uniformly\nacrossthemodeldepth.\nC2CChoice. Inourdesign,weadoptterminalalignment,asitprovidesasimplerandmoredirect\nlayermappingstrategythatempiricallyperformsslightlybetterinourexperiments.\nA.1.2 TOKENIZATIONALIGNMENT\nFordialogueinputs,wefirstapplythechattemplateofeachtokenizer,whichproducesasequence\nconsistingofalternatingsectionsof(1)templatetokensand(2)messagetokens. Thesetwotypesof\nsectionsarehandleddifferentlyduringalignment.\nTemplatesections. Templatetokensarestructuralmarkers(e.g.,roledelimiters,formattingtokens)\nthatdifferacrosstokenizersandcarrynosemanticcontent. Topreservesequenceconsistencywith-\nout introducing unnecessary distortions, these sections are aligned by simple length padding: the\nshortersideispaddedwith<pad>tokensuntilbothtokenizers’sequencesareofequallength.\nMessage sections. Message tokens correspond to the actual textual content of user or assistant\ndialogs.Eachtargetmodeltokeninamessagesectionisdecodedintoitsstringformandre-encoded\nusing the source model tokenizer. Special tokens (e.g., <pad>, <eos>) are mapped directly if\npossible;otherwise,thesourcemodelunknowntokenisused. Forregulartokens,ifthere-encoding\nproducesasinglesourcemodeltoken,adirectone-to-onemappingisestablished.Ifmultiplesource\nmodeltokensareproduced(aone-to-manycase),oneofthetwoselectionstrategiesisapplied: (1)\nfirst-occurrence selection: choose the first source model token from the candidate set, yielding a\ndeterministicandcomputationallyefficientmapping. (2)Maximal-coverageselection: decodeeach\ncandidate token, compute its string length, and select the longest; this heuristic aims to preserve\nmaximalsurfacecorrespondencewiththeoriginaltargetmodeltoken.\nC2C choice We observed that the two selection strategies generally produce very similar results,\nwith more than 80% of sequences yielding identical alignments across strategies. Based on this\nobservation,weempiricallyadoptMaximal-coverageselectionasthedefaultstrategytoreducethe\nriskoflosinginformationinone-to-manytokenizationcases.\nThroughthisdesign,templatesectionsarealignedstructurallyviapadding,whilemessagesections\narealignedsemanticallyatthetokenlevel, ensuringrobustcorrespondencesbetweentargetmodel\nandsourcemodelrepresentationsinchat-formattedinputs.\nA.1.3 FUSERARCHITECTURE\nBeyond the C2C Fuser, we also examined a more complex yet potentially more powerful variant,\nwhich we denote as C2C-C (Complex). The main complexity comes from the introduction of an\n14\nPreprintversion\nTable8: PerformancecomparisonacrossbenchmarkswithPGRandoverallnormalizedtime.\nC-Eval ARC-C MMLU-Redux OpenBook\nMethod Acc PGR Time Acc PGR Time Acc PGR Time Acc PGR Time\nQ3-4B 68.09 100% 0.24 87.48 100% 0.24 71.38 100% 0.24 79.40 100% 0.25\nQ3-0.6B 32.04 0% 0.18 41.04 0% 0.19 35.53 0% 0.18 39.20 0% 0.21\nT2T 36.96 14% 0.92 52.00 24% 0.80 42.95 21% 0.99 46.40 18% 1.70\nC2C 44.40 34% 0.27 60.17 41% 0.27 45.92 29% 0.27 55.20 40% 0.28\nC2C-C 60.63 79% 0.21 80.96 86% 0.23 62.78 76% 0.15 70.40 78% 0.26\nadditionalprojectionstage: insteadofdirectlyconcatenatingSharerandReceivercachesasinC2C,\nSharer cache is first projected into the receiver’s dimensionality through a 3-layer MLP. The con-\ncatenated representation is then processed along two familiar routes—feature fusion and dynamic\nweighting—toyieldthefinalS&Rcache.\nThemainexperimentresultsarepresentedinTable8.Notethatwefixthemaximumresponselength\nto8tokensandthemaximumcommunicationlengthto256tokensinthisexperimenttoreduceeval-\nuationcost.C2C-CattainsstrongerperformancethanthedefaultC2C,suggestingthatincreasingthe\narchitecturalsophisticationofFusercanfurtheramplifythebenefitsofC2Ccommunication. Inthis\ntable,wealsoreportPerformanceGapRecovered(PGR)(Ongetal.,2024)metric,whichquantifies\nhowmuchoftheperformancegapbetweenaweakandastrongmodelisrecovered. Nevertheless,\nthefocusofthisworkisonintroducingtheC2Cparadigmitself.Forthispurpose,weadoptasimple\nyeteffectiveFuserdesign,leavingsystematicinvestigationofmoreelaboratearchitecturestofuture\nwork.\nA.2 ADDITIONALEXPERIMENTALRESULTS\nA.2.1 CACHEENRICHMENTDETAIL\nIn Table 9 we show the effect of single-layer cache enrichment. Layer 4 and 16 benefit from the\ncacheenrichmentapproachbyreplacingtheKV-Cachewiththefew-shotone,whilecacheenrich-\nmentonotherlayersshowsperformancedegradation.\nTable9: Accuracyofsingle-layercacheenrichment\nLayer Acc. Layer Acc.\n0 56.36 14 54.24\n1 56.36 15 58.06\n2 57.14 16 58.45\n3 57.53 17 57.88\n4 58.52 18 57.21\n5 56.45 19 56.71\n6 54.56 20 55.93\n7 56.82 21 57.74\n8 55.01 22 57.23\n9 56.78 23 55.22\n10 55.29 24 55.75\n11 57.05 25 56.16\n12 55.04 26 55.79\n13 54.83 27 55.01\nA.2.2 STRONG-TO-WEAKCOMMUNICATION\nTable10reportstheresultsonLongBenchV1whenpairingtheweakreceiverQwen3-0.6Bwitha\nmuch stronger sharer, Qwen3-4B, under different input lengths. Across all length regimes, C2C\nconsistentlyoutperformsboththereceiveraloneandtheT2Tbaseline. Onaverage,C2Cachievesa\n40.45%PGRovertheweak-to-stronggap.Theseresultsdemonstratethatinstrong-to-weaksettings,\n15\nPreprintversion\nTable 10: LongBenchV1 results with Qwen3-4B as the Sharer and Qwen3-0.6B as the Receiver\nacrossdifferentinputlengths.\nLength Receiver Sharer T2T C2C\n0–4k 27.39 48.76 31.71 37.07\n4–8k 24.97 46.27 27.54 32.08\n8k+ 22.20 42.78 26.14 31.00\nAverage 25.01 46.12 28.62 33.55\nC2C C2C\nReceiver\n157 Receiver\n564 188\n751\n405\n206\n1330\n629\n1569\n498 174 235\n886\n910\nSharer Sharer\n(a)Sharer:Q2.5-Math-1.5B,Receiver:Q3-0.6B (b)Sharer:Q3-4B,Receiver:Q3-0.6B\nFigure7: Venndiagramsofcorrectlyansweredquestionsunderdifferentmodelpairings.\nC2Ccaneffectivelytransferthestrongermodel’scontextualunderstanding,yieldingnotablegains\nfortheweakerreceiver.\nWe additionally evaluated the strong-to-weak setting (Qwen3-0.6B as receiver and Qwen3-4B as\nsharer) on other benchmarks beyond LongBenchV1. The detailed results are provided in Sec-\ntionA.1.3,Table8.\nA.2.3 ACCURACYBREAKDOWN\nWeanalyzewheretheaccuracygainsofC2CcomefrombyusingVenndiagramsontheMMLU-\nReduxbenchmark,asillustratedinFigure7. Forthisanalysis,weusetheC2C-Cvariantintroduced\nin Section A.1.3, as it has the potential to achieve stronger performance amd provides a clearer\nbreakdownofwhereC2C’saccuracyoriginates.\nModels with comparable capacity. When the Receiver (Qwen3-0.6B, denoted as Q3-0.6B) and\ntheSharer(Qwen2.5-Math-1.5B-Instruct,denotedasQ2.5-Math-1.5B)havecomparableoverallca-\npacitybutcomplementarystrengths,C2CnotonlyinheritspartoftheSharer’sabilitybutalsosolves\nadditionalquestionsbyintegratingunderstandingfrombothmodels.\nModelswithdisparatecapacity. WhentheSharer(Qwen3-4B,denotedasQ3-4B)issubstantially\nstronger than the Receiver (Qwen3-0.6B), C2C tends to integrate more of the stronger model’s\nunderstanding. Quantitatively,inthedisparate-capacitycase(Figure7b),amongthequestionsthat\ntheSharercananswercorrectly,C2Calsoanswers72.11%correctly. Incontrast,inthecomparable-\ncapacitycase(Figure7a),C2Csucceedsononly50.97%.\n16\nPreprintversion\nA.2.4 PROGRESSIVEBEHAVIOR\n70\n60\n50\n40\n30\n20\n0% 25% 50% 75% 100%\nProportion of C2C Fused KV-Cache\nycaruccA\nFormer\nLatter\nSharer Model\nFigure8: accuracychangeswithC2Cproportionincreases\nToinvestigatetheimpactoffusedKV-Cacheproportionontheaccuracyofthereceivermodel,we\ngradually added the proportion of fused KV-Cache derived from the sharer to the receiver model\nbefore generating outputs. Specifically, former and latter refer to progressively replacing the re-\nceiver’sKV-CachewiththefusedKV-Cachefromfronttobackandbacktofront,respectively. We\nobservethattheoverallaccuracyfirstdecreasesandthenincreasesasthereplacementratiogrows.\nTheperformancereductionmaystemfromthegapbetweentrainingandtesting,whereonlythefull\nreceiver KV-Cache is used during training. When the fused proportion goes up to over 50%, the\nperformanceofC2Ccontinuestoincreasewithrespecttotheproportion,reflectingtheprogressive\nbenefitsofC2C.Notethatprojectingusinglattercachegenerallyhaslargerimpactthanprojecting\ntheformer,sinceitisclosertothefinalresponse.\nA.3 ADDITIONALEXPERIMENTSETUP\nA.3.1 CACHEENRICHMENT\nWe conducted Oracle experiments with Qwen3-0.6B and Qwen3-4B to examine how KV-Cache\nenrichmentinfluencesmodelperformance. TheevaluationwasperformedonMMLU-Redux. The\nfew-shotexamplesareselectedfromMMLUwhileexcludingoverlapswithMMLU-Reduxtoensure\nfairness.Toprobedifferentwaysofapplyingcacheenrichment,wecomparedfourcacheenrichment\nstrategies: All-layerCacheEnrichment(applycacheenrichmentonalllayers),Single-LayerCache\nEnrichment(applycacheenrichmentonlyonsinglelayers),SelectiveCacheEnrichment-Best(se-\nlectnlayersthathavethehighestaccuracyaccordingtoSingle-LayerCacheEnrichment),Selective\nCacheEnrichment-Worst(selectnlayersthathavethelowestaccuracyaccordingtoSingle-Layer\nCache Enrichment). All methods utilized Few-Shot–optimized KV-Caches while maintaining the\nsamecachelengthasZero-Shot,enablingacontrolledevaluationofcacheenrichmentanditslayer-\nspecificeffects.\nA.3.2 CACHETRANSFORMATION\nWeemployedtheMMLU-Reduxdatasettotraina3-layerMLPthatmapstheKV-Cacheofasource\nLLM to that of a target LLM. For visualization, 300 samples were randomly selected from the\ndataset. The source, target, and transformed KV-Cache were all projected into two-dimensional\nspaceusingt-SNE,allowingustoexaminethealignmentofrepresentationsbetweenthetwomodels.\nFort-SNEgeneration,wesetperplexityto50andmaxiterationsto1000.\nA.3.3 QUERY-LEVELROUTING\nQuery-levelroutingaimstoimprovetheperformance–efficiencytrade-offbydynamicallyassigning\nharderqueriestoastrongerLLM.Followingpriorwork,weadoptamatrixfactorizationframework.\nQuery embeddings are obtained from the OpenAI text-embedding-3-small encoder, while model\nembeddings are taken from pretrained vectors of gpt-4-1106-preview and mixtral-8x7b-instruct-\nv0.1. Theseembeddingsareusedtocomputeastrongwinratescoreforeachquery,whichreflects\n17\nPreprintversion\nitsrelativedifficulty.Queriesarethenrankedbythisscore.Foreachevaluatedmodelpair,wedefine\nthestrongmodelastheoneachievinghigherstandalonebenchmarkaccuracyandtheweakmodel\nasthelower-performingone.Queriesintheupperhalfoftherankingareroutedtothestrongmodel,\nwhilethoseinthelowerhalfareroutedtotheweakmodel.\nA.3.4 EVALUATIONMETHOD\nMainevaluation. WeevaluateC2Confourmultiple-choicebenchmarks: OpenBookQA,MMLU-\nRedux,ARC-Challenge,andC-Eval. ForMMLU-Redux,weexcludequestionsannotatedwiththe\nerrortypenocorrectanswer. Forallevaluations,weadoptadeterministicgenerationconfiguration\nwithoutsampling, usinggreedydecodingtoensurereproducibility. Specifically, weuseNon-CoT\nprompts,followingtheunifiedformatdescribedinSectionA.3.6. Modeloutputsarethenmatched\nto the correct option labels to compute accuracy. To control evaluation cost, we set the maximum\nresponselengthto64tokensunlessotherwisespecified,wheretheresponsereferstothefinalanswer\ngeneratedbytheReceiver,sincethebasemodelsdonotalwaysfollowinstructionsandlongerlimits\nwouldsubstantiallyincreaseinferencetime. FortheT2Tsetting,weadditionallysetthemaximum\ncommunicationlengthto256tokens,wherethecommunicationreferstothemessagespassedfrom\ntheSharertotheReceiver.\nLongBenchevaluation. WeevaluateC2ContheLongBench-Edataset,whichcomprisesatotalof\n13individualdatasets. Weadoptthebest-practicegenerationconfigurationofQwen3,withtemper-\naturesetto0.6,topPto0.95,topKto20,minPto0,repetitionpenaltyof1.2,andsamplingenabled.\nThe prompts and evaluation procedures are strictly aligned with the official LongBench settings,\nwithamaximumoutputlengthof2,048tokens.\nA.3.5 C2CTRAINING\nTrainingdata.(1)Performanceexperiment.TheFuserwastrainedontheOpenHermes-2.5Dataset\nwith a maximum sequence length of 2,048 tokens. Training used 500,000 samples for one epoch\nwithamacrobatchsizeof256,correspondingto1,929totaltrainingsteps.\n(2) Scaling sequence lengths experiment. The Fuser was trained on the LongBench-E benchmark\nwithamaximumsequencelengthof12,000tokens.Thedatawasrandomlysplitinto3/4fortraining\nand1/4forevaluationtoensureindependencebetweentrainingandevaluation. Trainingused1,896\nsamplesforoneepochwithamacrobatchsizeof16,correspondingto118totaltrainingsteps.\n(3)Scalingmodelsizesexperiment. TheFuserwastrainedontheauxiliary trainsplitoftheMMLU\ndataset with a maximum sequence length of 1,024 tokens. Training used 15,000 samples for one\nepochwithamacrobatchsizeof128,correspondingto116totaltrainingsteps.\nTrainingscheme. Allexperimentswereconductedwithafixedrandomseedof42toensurerepro-\nducibility.Unlessotherwisenoted,thetrainingconfigurationwasasfollows:optimizationemployed\nalearningrateof1×10−4withalinearscheduleranda10%warmupratio,aweightdecayof0.01,\nandamaximumgradientnormof1.Thetemperaturewaslinearlyannealedfrom1.0to0.001across\nthe total number of training steps. Layer alignment was configured with the last aligned scheme\nacrossallexperiments. Tokenizationalignmentwasappliedonlywhenthepairedmodelsemployed\ndifferenttokenizers,inwhichcasethelongeststrategywasused. Fordatapreparation,eachdataset\nwaspartitionedintoatrainingsplit(99%)andasmallheld-outvalidationsplit(1%). Thevalidation\nsplitwasnotusedformodelupdatesbutwasmonitoredduringtrainingtoreportevaluationloss.\nA.3.6 EVALUATIONPROMPTS\nTexts 1 and 2 present the exact prompts used for the main evaluation on multiple-choice datasets.\nText3providesthepromptfortheSharermodelintheT2Tevaluation,theReceivermodelusesthe\nsamepromptasintheC2Csetting. Text4showsthepromptusedincacheenrichmentexperiment.\nFor zero-shot method, no shots are included in the prompt. The few-shot method uses exactly\nthe same prompt as Text 4. For Oracle methods, we adopt the few-shot prompt but remove the\nKV-Cacheassociatedwiththeshotsaftertheforwardpass. ThepromptforLongBenchevaluation\nstrictlyfollowsitsofficialconfiguration,whichvariesacrossthedifferentsub-datasets.\n18\nPreprintversion\nText1. PromptforNon-CoTEvaluation\nAccuratelyanswerthefollowingquestion:\n{QUESTION}\nChoices:\n{CHOICES}\nInstructions:\n-Carefullyreadthequestionandalloptions.\n-Selectthesinglemostcorrectanswer.\n-RespondONLYinthefollowingformat: ”ThecorrectanswerisA/B/C/D”.\n-Donotincludeanyexplanations,additionaltext,orpunctuationbesidestheanswer.\nThecorrectansweris\nText2. PromptforCoTEvaluation\nAccuratelyanswerthefollowingquestion:\n{QUESTION}\nChoices:\n{CHOICES}\nInstructions:\n-Carefullyreadthequestionandalloptions.\n-Let’sthinkstepbystepandexplainyourreasoningbriefly.\n-ThengivethefinalanswerstartingwithThecorrectansweris.\nText3. PromptforSharermodelinT2TEvaluation\nInoneclearsentence,describethemostessentialbackgroundknowledgeneededtoanswer\nthequestion: {QUSETION}DoNOTdirectlysolveorgiveanswertothequestion.\n19\nPreprintversion\nText4. PromptforOracleExperiment\nThefollowingaresinglechoicequestions(withanswers)about{SUBJECT}.\nShot1:\nQuestion: {QUSETION}\nOptions:\n{OPTIONS}\nAnswer: {ANSWER}(A,B,CorD)\n...\nShotN:\nQuestion: {QUSETION}\nOptions:\n{OPTIONS}\nAnswer: {ANSWER}(A,B,CorD)\nQuestion: {QUSETION}\nOptions:\n{OPTIONS}\nAnswer:\nA.4 ADDITIONALANALYSIS\nA.4.1 EFFECTIVERANK\nWelistthedefinitionofeffectiverankthatwasproposedbyRoy&Vetterli(2007)hereasarefer-\nence. ForamatrixWthathassizeM ×N,thesingularvaluedecompositionofitcanbeexpressed\nasW =UΣV andthesingularvaluesσ =(σ ,σ ,...,σ )T arethenon-negativediagonal\n1 2 min(M,N)\nentriesofthematrixΣ. Thesingularvaluedistributionisdenoteas:\nσ\np = i (6)\ni ∥σ∥\n1\nDenotetheShannonEntropyas:\nmin(M,N)\n(cid:88)\nH(p ,p ,...,p )=− p logp (7)\n1 2 min(M,N) i i\ni=1\nTheeffectiverankisdefineas:\nerank(W)=e−(cid:80)m\ni=\ni\n1\nn(M,N)pilogpi\n(8)\nIn Figure 9, we present the effective rank of key and value caches across all the layers. The plot\nshows a continuous increase in the effective rank of value caches after applying C2C, especially\nin the shallow layers. Key caches after applying C2C also have a comparable effective rank and\nincreaseatdeeplayers.\n20\nPreprintversion\n600\n500\n400\n300\n200\n100\n0 5 10 15 20 25\nLayer\n)yeK(\nknaR\nevitceffE\n700\n600\nSharer\n500\nReceiver\nC2C 400\n0 5 10 15 20 25\nLayer\n(a)EffectiverankoftheKeycache.\n)eulaV(\nknaR\nevitceffE Sharer\nReceiver\nC2C\n(b)EffectiverankoftheValuecache.\nFigure9: EffectiverankofKeyandValuecachesacrosslayersforQwen3-4B(Sharer)andQwen3-\n0.6B(Receiver).\nA.4.2 GATINGBEHAVIOR\nWe analyze the behavior of the learnable gates by contrasting models trained on general-purpose\nversus task-specific data. This comparison reveals markedly different gating dynamics across the\ntworegimes.\nGeneral-purposetraining. WhenC2CistrainedontheOpenHermes-2.5dataset,thelearnedkey\nand value gates remain almost fully open. Across the three model combinations reported in Ta-\nble3, theaveragegateactivationratioexceeds98.21%. Despitethisnear-completeactivation, we\nobservethatincertainlayersthedynamicweightsareconcentratedatverysmallvalues—forexam-\nple,theaveragekeyweightinsomelayersfallsbelow0.1. Thissuggeststhatundergeneral-purpose\ntraining,C2Cleveragesthedynamicweightingmechanismtomodulatehowmuchinformationisin-\ncorporatedfromtheshareronaper-querybasis,effectivelytreatingdynamicweightsastheprimary\ncontrolsignalwhileleavingmostgatesopen.\nTask-specific training. In contrast, when C2C is trained on the MMLU auxiliary train split, the\ngatesexhibitamuchsparseractivationpattern. AcrossmodelcombinationsshowninTable6, the\naverage gate activation ratio drops to 52.67%. For the layers where gates do open, however, the\ndynamic weights are substantially larger, with most layers exhibiting average weights above 0.4.\nThis indicates that under task-specific training, the gating mechanism selects a smaller subset of\nlayers that are consistently useful, while the dynamic weights primarily regulate the contribution\nstrengthoftheseselectedlayers.\nOverall,thesefindingshighlighttheadaptiveinterplaybetweengatesandweights: general-purpose\ntrainingfavorsbroadgateactivationwithfine-grainedmodulationviaweights,whereastask-specific\ntrainingfavorssparsegateactivationwithstrongerrelianceontheselectedlayers.\nA.4.3 OUTLIERCASESININFERENCETIME\nLlama3.2. We observe that the Llama3.2 model achieves significantly lower inference time com-\npared to other baselines in Table 3. This improvement can be attributed to two factors. First, the\nLlama3.2modelitselfhasfasterinferencespeedduetoitsimplementation. Second,undertheNon-\nCoTevaluationpromptsdescribedinSectionA.3.6,themodeltendstooutputonlyasingleoption\nletter(e.g.,“A”or“B”),ratherthanalongerformattedstringsuchas“ThecorrectanswerisA.”The\nshorteroutputsfurtherreducetheaveragedecodingtime,leadingtotheobservedadvantage.\nQwen2.5-Math. Incontrast,theQwen2.5-Mathmodelexhibitsconsiderablylongerinferencetime,\nas shown in Table 6. The primary cause is its tendency to ignore the Non-CoT evaluation and\nT2TpromptsdescribedinSectionA.3.6,producingverbose,step-by-stepsolutionsratherthancon-\nciseanswers. Toaccommodatetheselongoutputsandavoidtruncation,wesetboththemaximum\nresponselengthandthemaximumcommunicationlengthto1024tokensduringevaluation. Under\nthisconfiguration,themodeldecodessubstantiallymoretokensonaverage,resultinginsignificantly\nlongerinferencetime.\n21\nPreprintversion\nA.4.4 EXAMPLEMODELOUTPUT\nInthisphysicsproblem,theShareraloneintroducesproportionalerrorsinitsreasoningchain,while\nthe Receiver alone skips the reasoning step. Thus, both models are given the wrong answer. T2T\npasses reasoning through text to point out the important knowledge - the force between two point\ncharges is directly proportional to the product of their charges and inversely proportional to the\nsquareofthedistancebetweenthem-butdidnotprovidemoreunderstandingforitandhowtouse\ntheinformationtosolvetheproblem. Therefore,thoughgivenanimportanthint,themodelfailedto\ngivethecorrectanswer. Incontrast,C2CdirectlytransferstheKV-Cache,allowingtheReceiverto\ngainrichcontextualunderstandingfromtheSharerandthuscorrectlyanswerthequestion.\nText5. Question\nAccordingtoCoulomb,apairofchargedparticlesplacedtwiceasclosetoeachotherexpe-\nrienceaforce...\nChoices:\nA) twiceasstrong\nB) fourtimesasstrong\nC) halfasstrong\nD) one-fourthasstrong\n22\nPreprintversion\nText6. Qwen3-0.6BResponse Text 7. Qwen2.5-0.5B-Instruct Re-\nsponse\nThe correct answer is **A. twice as\nstrong**. According to Coulomb’s law, Toanswerthisquestion,let’sbreakdown\nthe force between two charged particles Coulomb’s law and understand the rela-\nisdirectlyproportionaltotheproductof tionship between the force experienced\ntheir charges and inversely proportional by two charged particles when they are\nto the square of the distance between closertogetherandwhentheyarefarther\nthem.Ifthedistanceistwiceasclose,the apart.Coulomb’slawstatesthattheforce\nforceis**twiceasstrong**. Thecorrect F between two point charges q and q\n1 2\nansweris**A.twiceasstrong**. separatedbyadistancerisgivenby:\nq q\nF =k 1 2\nr2\nwherekisCoulomb’sconstant.\nNow,let’sconsiderthetwoscenarios:\n1. **When the particles are very close\ntogether(verysmallr)**: -Theforceis\nverystrongbecausethedistancerisvery\nsmall. - The force is also very strong\nbecause the charges q and q are very\n1 2\nlarge.\n2.**Whentheparticlesareveryfarapart\n(verylarger)**:-Theforceisveryweak\nbecause the distance r is very large. -\nThe force is also very weak because the\nchargesq andq areverysmall.\n1 2\nGiven this reasoning, we can conclude\nthattheforceexperiencedbytheparticles\nwhentheyareclosertogetherisstronger\nthanwhentheyarefartherapart. There-\nfore,thecorrectansweris: **A.twiceas\nstrong**.\nText8. Text-to-TextResponse Text9. C2CResponse\nContextfromQwen2.5-0.5B:. The correct answer is B. According to\nCoulomb, a pair of charged particles\nCoulomb’s law, which states that the\nplaced twice as close to each other ex-\nforce between two point charges is di-\nperience a force. The reason is that the\nrectlyproportionaltotheproductoftheir\nforcebetweentwochargedparticlesisin-\nchargesandinverselyproportionaltothe\nversely proportional to the square of the\nsquare of the distance between them, is\ndistance between them. So, if the dis-\nthe most essential background knowl-\ntanceisdoubled,theforceisreducedby\nedgeneededtoanswerthequestion.\na factor of 4. Therefore, the force be-\nResponsefromQwen3-0.6B:. tweenthepairofchargedparticlesplaced\ntwiceasclosetoeachotherisfourtimes\nThe correct answer is **D. one-fourth\nasstrong.\nas strong**. Coulomb’s law states that\nthe force between two charged particles\nisdirectlyproportionaltotheproductof\ntheir charges and inversely proportional\nto the square of the distance between\nthem. Ifthedistanceishalved,theforce\nbecomes four times stronger. However,\nthequestionstatesthedistanceis””twice\nas close,”” which would make the force\n**one-fourth as strong**. The correct\nanswer is **D. one-fourth as strong**.”\n23\n",
    "tables": [],
    "images": []
  },
  {
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "text": "Joint Bidding on Intraday and Frequency Containment Reserve\nMarkets\n∗ † ‡\nYiming Zhang Wolfgang Ridinger David Wozabal\nOctober 6, 2025\nAbstract\nAs renewable energy integration increases supply variability, battery energy storage systems\n(BESS) present a viable solution for balancing supply and demand. This paper proposes a novel\napproach for optimizing battery BESS participation in multiple electricity markets. We develop a\njoint bidding strategy that combines participation in the primary frequency reserve market with\ncontinuoustrading inthe intradaymarket, addressinga gap inthe extant literaturewhichtypically\nconsidersthesemarketsinisolationorsimplifiesthecontinuousnatureofintradaytrading. Ourap-\nproachutilizesamixedintegerlinearprogrammingimplementationoftherollingintrinsicalgorithm\nforintradaydecisionsandstateofchargerecovery,alongsidealearnedclassifierstrategy(LCS)that\ndetermines optimal capacity allocation between markets. A comprehensive out-of-sample backtest\nover more than one year of historical German market data validates our approach: The LCS in-\ncreasesoverallprofitsbyover4%comparedtothebest-performingstaticstrategyandbymorethan\n3% over a naive dynamic benchmark. Crucially, our method closes the gap to a theoretical perfect\nforesight strategy to just 4%, demonstrating the effectiveness of dynamic, learning-based allocation\nin a complex, multi-market environment.\n1 Introduction\nThe increasing share of variable renewable sources of electricity (VRES), such as wind and solar energy,\nchangeselectricitysystemsaroundtheworld. Asaconsequence,unexpectedandcostlyimbalancescaused\nby the unpredictability of VRES output may lead to grid instability and even blackouts. Electricity\nstorage can offer flexibility to help mitigate these problems and stabilize electricity systems, thereby\ngenerating welfare gains (Sioshansi, 2010).\nTraditionally, electricity storage is a scarce resource and pumped-hydro storage facilities have been\ntheprimaryformoflarge-scaleelectricitystorageavailable. Thesesystemsofferimmenseenergycapacity,\nbut their deployment is limited by strict geographical requirements – namely, the need for significant\nelevationdifferencesbetweentwolargereservoirs. Consequently,thepotentialforexpandingthecapacity\nof pumped hydro storage is severely limited in most electricity systems, creating a pressing need for\nalternative flexibility solutions to accommodate the growing share of VRES.\n∗The Hong Kong Polytechnic University, Hong Kong; this work was mainly carried out at the Technical University of\nMunichandEntrixGmbH,Munich,Germany,yiming1.zhang@connect.polyu.hk\n†EntrixGmbH,Munich,Germany,wolfgang.ridinger@entrixenergy.com\n‡VrijeUniversiteitAmsterdam,Amsterdam,Netherlands,d.wozabal@vu.nl\n1\n5202\ntcO\n3\n]PC.nif-q[\n1v90230.0152:viXra\nTofillthisgap,anewportfolioofflexibilitytechnologiesisemerging,includingbatteryenergystorage\nsystems (BESS), green hydrogen for long-duration and seasonal energy storage, and demand response\nprogramsthatprovideflexibilitybyactivelymanagingconsumptionpatterns. Amongthesetechnologies,\nBESS stands out for their rapid response times and locational flexibility, making them particularly\nsuitableforshort-termenergyarbitrageandancillaryservices. Theirhighpower-to-capacityratiomakes\nthem well-suited for grid stabilization services, where supply-demand imbalances must be corrected on\na second-to-second basis, and for participation in short-term electricity markets.\nDue to the dramatic and ongoing reduction in battery costs, BESS are becoming an increasingly\nviable option for grid-level electricity storage. For instance, lithium-ion battery pack prices have seen a\ndropofmorethan75%inthepast10yearswithpricesdecreasingfrom$463/kWhin2015to$115/kWh\nin 2024 (BloombergNEF, 2024). This downward trend is projected to continue, with costs expected to\ndrop below $100/kWh well before 2030 (Cole and Karmakar, 2023).\nIn this paper, we propose a joint model for the participation in the market for primary frequency\nreserveandtheintradaymarket(IDM),explicitlymodelingorderbook-basedcontinuoustradingtomax-\nimize the potential to reoptimize positions multiple times.\nWhilealargenumberofliteratureaddressesoptimalbiddingstrategiesforelectricitystorage,studies\nthat jointly consider the intraday and frequency control markets remain rare. Most existing approaches,\nsuchas(DeBoecketal.,2025;FletenandKristoffersen,2008),focusexclusivelyontheday-aheadmarket.\nAlthough some papers incorporate both the day-ahead and intraday markets, the intraday market is\ntypically represented as a single rebalancing decision. This simplification allows the decision maker to\nadjust positions taken in the day-ahead market but overlooks the continuous nature of intraday trading\nandtheresultingopportunitiesformultiplerebalancingactions. Examplesofsuchpapersinclude(Faria\nandFleten,2011;L¨ohndorfetal.,2013;Kongelfetal.,2019;L¨ohndorfandWozabal,2023). Wozabaland\nRameseder (2020) consider the problem of coordinated bidding in sequential auctions for a renewable\npower producer without storage in the Spanish intraday market.\nIn recent years, the intraday market has attracted an increasing number of participants seeking to\ncorrect short-term deviations from planned generation and load schedules. Various trading strategies in\nthe IDM were proposed. Dynamic programming approaches that model the intraday bidding process\nare proposed in (Jiang and Powell, 2015) and (A¨ıd et al., 2016), although neither accounts for intraday\nproducts with different times to maturity; and while A¨ıd et al. (2016) model the intraday market, they\ndo not consider storage. Bertrand and Papavasiliou (2019a,b) train a threshold policy for a storage\nunit on German limit order book data using reinforcement learning. The authors report significant\ngains for their trading strategy over a greedy strategy. Boukas et al. (2021) deploy a markov decision\nprocess–based modeling framework with a distributed fitted Q-iteration algorithm to optimize to decide\nwhen to employ the rolling intrinsic algorithm to trade on the intraday market.\nA limited amount of research literature has been devoted to the bidding strategy in the in reserve\nmarkets. A small body of work (Dimoulkas et al., 2016; Kraft et al., 2020) has concentrated on the\nprediction of frequency containment reserve (FCR) prices. The former predicted the SE2 price and\nvolume in the Nordic balancing market using a hidden Markov model. The latter study employed a\nstatistical model and neural networks in a rolling one-step framework to estimate the capacity-weighted\naverage price. The authors of both papers did not propose a bidding strategy based on their forecasts.\nA bidding strategy for the Nordic FCR is proposed in (Divshali and Evens, 2020), where the trading\nproblem is modeled as a non-linear constrained optimization problem, explicitly taking into account\ndegradation, energy, and balancing costs. Thien et al. (2017) investigates the profitability of different\n2\nstrategiesfortheGermanFCRmarketandBrivioetal.(2016)comparesrevenuesontheItalianprimary\nreservemarketwitharbitragestrategiesonthewholesalemarket. AsteroandEvens(2020);Ansarietal.\n(2015); Sortomme and El-Sharkawi (2012) consider using electric vehicle batteries in the FCR, while\nBroneske and Wozabal (2017) consider the same problem in the secondary reserve market.\nAn important topic when participating in the primary reserve market is the issue of state-of-charge\n(SoC)recoveryafterafrequencyexcursionevent. In(Zhangetal.,2016),atheoreticalstochasticdynamic\nprogrammingframeworkwasproposedtoplanandcontrolaBESSthatparticipatesinfrequencyreserves.\nXu et al. (2014) propose a SoC recovery by trading on the IDM. An online control mechanism was\nproposed in (Divshali and Evens, 2020).\nIn the papers reviewed so far, either the balancing market or the IDM are considered. The authors\nin (Biggins et al., 2022) propose a bidding strategy in the frequency reserves and day-ahead markets in\nGreatBritainbasedonmachinelearning. Theirresultsshowthatthefirmfrequencyresponse(FFR)isa\nstrongersourceofrevenuethantheday-aheadmarketforbatterystorageandhighlightthatthesimulta-\nneousperformanceintheFFRandtheday-aheadmarketincreasesprofits. Usingmachinelearning-based\nprice prediction and uncertainty metrics, three bidding strategies are devised to trade in different fre-\nquency reserves in (Kempitiya et al., 2020). Although multiple power markets were considered in the\naforementioned papers, they do not consider the IDM in their strategies.\nIn this paper, we propose the first approach that combines a realistic representation of a continuous\nintradaymarketwithparticipationonafrequencycontrolmarket. Weuseaversionoftherollingintrinsic\n(RI) strategy to make trading decisions on the IDM and recovery SoC and machine learning classifier to\ndecide how much capacity to commit to which market. The aim of the overall approach is to define an\nalgorithm that can be used for high-frequency automatized decision-making.\nIn particular, the main contributions of the paper are:\n1. We propose a mixed-integer linear programming version of the intrinsic policy that can handle\norderbook-based continuous trading. Furthermore, we detail a rolling intrinsic algorithm that,\ngiven commitments on the primary reserve market, coordinates the repeated re-computation of\nthe intrinsic strategy with the necessary SoC recovery necessary for participation on the primary\nreserve market.\n2. We devise a machine learning classifier that decides how much of the available battery capacity to\ncommit on the reserve market. The decision is based on features that are available at the time of\nFCR bidding and the aim is to predict the times when the RI is more profitable than the FCR\nmarket and to optimally split the BESS’ capacity between the two markets.\n3. Wepresentacomprehensiveandrealisticout-of-samplestudythatbenchmarkstheproposedstrat-\negy against a battery of alternatives using two years of real market data. Using detailed historical\ndata from these two markets, our results show that using our algorithm to combine FCR and\nIDMtradingreturnsupto4%morerevenuethandeliveringFCRonlyanddelivers96%morethan\ntradinginthecontinuousintradaymarketonly. Ouralgorithmclearlyoutperformsnaivestrategies\nand is only 4% worse than a clairvoyant strategy that always chooses the right mix between the\ntwo markets.\nTherestofthepaperisstructuredasfollows: InSection2,wewilldiscusstheIDMandFCRmarkets\nwithafocusontheEuropeanand,morespecifically, theGermansituation. Weoutlinemarketrulesand\ndescribe interactions in the form of constraints that bids in one market imply for the other. Section 3\n3\nStart Day-aheadAuction\n08:00 15:00\n00:00 12:00 Time (CET)\nFCR Closure Intraday Auction/Continuous\nFigure 1: Order of events on any given trading day for EPEX day-ahead and intraday markets and the\nFCR auctions in Germany.\nFCR Intraday\n2020 2021 2022 2023 2020 2021 2022 2023\nTraded quantity 573 562 555 570 77 85 92 120\nBidding frequency Daily, 4-hour blocks Continuous\nPricing mechanism Uniform price auction Order book based\nTable 1: Daily volumes auctioned in the German FCR market (in MW) from Bundesnetzagentur (see\nhttps://data.bundesnetzagentur.de/), combined EPEX intraday annual trading volumes (in TWh)\nfor the CWE region (AT, BE, DE/LU, FR, NL) taken from the EPEX Spot annual reports (EPEX\nSPOT SE, 2020-2023).\ndescribes our implementation of the RI method, as well as the classifier that decides between the two\nmarkets. Section 4 is devoted to the results of our case study. We first give some insight into stylized\nfacts related to strategies in order to motivate our choices for the out-of-sample study and then present\na detailed comparison of our proposed strategy with a set of benchmarks for the years 2023 and 2024.\nSection 5 concludes the paper.\n2 Setting & Markets\nIn this section, we describe the relevant features of the FCR market and the IDM. To fix ideas and since\nour numerical study in Section 4 uses Germany as an example, we focus on the German situation as a\ntypical example of a European market design.\nIn Figure 1, we show the order and clearing times for the relevant markets. On any given day, the\nFCR auctions close at 8 am. The IDM market opens at 3 p.m. for the hourly products and at 4 p.m.\nfor the quarter hourly products. Hence, in our setting, we have to first decide about the bids on the\nFCRmarketbeforethetradingontheIDMstarts. Inthefollowing, wegiveadetaileddescriptionofthe\nrelevant aspects for both markets. Table 1 gives a first impression in terms of size, bidding frequency,\nand traded volumes.\n2.1 The Market for Frequency Containment Reserve\nMaintaining a balance between electricity production and consumption is crucial for the stability of\nthe power grid. In a situation where production and consumption do not exactly match, the grid\nfrequency deviates from the nominal frequency, which could damage electronic devices, lead to a failure\nof components, and may result in selective power cuts or even system-wide blackouts. The FCR is\n4\n1.00\n0.75\n0.50\n0.25\n0.00\n0.25\n0.50\n0.75\n1.00\n49.6 49.7 49.8 49.9 50.0 50.1 50.2 50.3 50.4\nGrid Frequency f (Hz)\nP\nrewoP\nnoitavitcA\nPower Activation Based on Grid Frequency\nP(f)\nFigure 2: Required activation of reserve power for a bid of P MW as a function of the frequency\nbid\ndeviation ∆f.\na service organized by the transmission system operators with the goal of recovering from frequency\ndeviations and outages by stabilizing frequencies near the nominal value.\nThe four German transmission system operators hold a joint procurement auction for FCR capacity\neachdayat8amforthefollowingday. Thedayissplitintosixblocksoffourconsecutivehours,so-called\nEFA (electricity forward agreement) blocks. There are six simultaneous uniform-price procurement\nauctions, one for each EFA block of the following day, in which companies offer their capacity. The\nminimum bid size in the auction is 1 MW with increments of 1 MW (Figgener et al., 2022). Divisible\nand indivisible bids are both allowed, and the maximum size of an indivisible bid is 25 MW.\nSuccessful bidders for a specific EFA block are required to instantaneously provide an amount of\npower proportional to the size of the accepted bid and the deviation of the grid frequency f from the\nnominal frequency fn (50 Hz in Germany), defined as ∆f := f −fn. More specifically, FCR market\nparticipants have the obligation to provide upward and downward regulations if the absolute deviation\n∆f of the grid frequency exceeds a deadband of 0.01 Hz: If ∆f <0 upward regulation is provided, that\nis, additional energy must be fed into the grid. In contrast, if ∆f >0, that is, the frequency exceeds the\nnominal frequency, the FCR providers are required to increase energy consumption. The activation P\nresulting from an accepted bid of P MW is defined as (see Figure 2),\nbid\n\n 0, if |∆f|≤ 0.01 Hz\nP = ∆f ·P , 0.01 Hz <|∆f|≤ 0.2 Hz (1)\n0.2 bid\n\n∆f−0.2 ·P , |∆f|> 0.2 Hz,\n|∆f−0.2| bid\nwhere a positive P implies that energy has to be absorbed from the grid while a negative sign indicates\nthat additional energy has to be provided (Thien et al., 2017).\nFirms must deliver at least 50% of activation within 15 seconds after receiving the signal ∆f and\nshould be fully ramped up/down after 30 seconds. Furthermore, firms have to guarantee an energy\ncapacity large enough to cover the full activation P for at least 15 minutes per incident (Figgener\nbid\netal.,2022). Failuretoofferthepromisedbalancingserviceresultsinapenalty. Ifanimbalancepersists\nfor more than 30 seconds, the TSO dispatches secondary reserves that relieve the providers of primary\nreserve. If there is still a positive |∆f| after 5 minutes, the manually controlled tertiary reserve and\n5\npossible redispatch mechanisms are used to return the system to equilibrium.\nIn order to guarantee the 15-minute criterion, the energy stored in the BESS has to remain in the\nrange of [0.25P ,E¯ − 0.25P ], where E¯ is the battery’s energy capacity. However, there may be\nbid bid\nmore than one frequency excursion event in an EFA block and participants are obliged to provide the\nservice for all incidents. Therefore, after each FCR activation, the providers must restore their SoC\nto an acceptable range that allows them to service the next event. The above also implies an upper\nbound0.25P ≤0.5E¯ forthebidpower,whichis,however,rarelyofpracticalrelevancesincethepower\nbid\ncapacity (in MW) usually does not exceed the energy capacity (in MWh) for BESS.\nClearly, at the time of bidding capacities for the FCR market, the direction and magnitude of P is\nuncertain. For storage, this has two implications: Firstly, the operators have to ensure that the SoC is\nin a range where it is guaranteed that they can honor their commitments made on the FCR. Secondly,\nalthough cumulative activations are, in most periods, close to zero, it often happens that the SoC at the\nend of a 4-hour EFA block significantly differs from the initial SoC, i.e., that activations do not average\nout. Thiseffectisfurtherexacerbatedbythefactthatbatteryefficiencylosses(charginganddischarging\ninefficiencies) result in a net energy loss even if positive and negative FCR activations within an EFA\nblock cancel out on average.\n2.2 The Intraday Market\nThe European intraday market framework is designed around the principle of market integration and\nconvergence toward a single European electricity market. The European Commission established a\ntarget model to integrate all intraday markets based on continuous trading through the Commission\nRegulation (EU) 2015/1222 establishing guidelines on capacity allocation and congestion management.\nThis integration is facilitated by the Cross-Border Intraday (XBID) platform, which operates with a\nshared order book that enables market participants to trade electricity continuously across European\nborders, provided that sufficient cross-border transmission capacity is available. The aim of this single\nintraday coupling is to create a single EU cross-zonal intraday electricity market where buyers and\nsellerscanworktogetheracrossEuropetotradeelectricitycontinuouslyonthedaytheenergyisneeded\n(European Commission, 2015). It serves as a complementary market to the day-ahead market and is\nused to continuously buy or sell electricity to manage short-term deviations from sudden changes in\nenergy supply and demand.\nThe intraday market in Germany is mainly organized by the European Power Exchange (EPEX),\nthe largest intraday power exchange in Europe. In recent years, the intraday market has been growing\nsteadily, as can be seen from the traded volumes in Table 1. The market is organized as an order book-\nbased continuous trading market that features hourly, half-hourly, quarter-hourly, and block products.\nCurrently, market participants in Germany can trade until 5 minutes before physical delivery in their\ncontrol areas and until up to 30 minutes before delivery in a combined national market (Kuppelwieser\nand Wozabal, 2023).\nEachbuyandsellorderontheintradaymarketforagivenproductcontainsbasicinformationabout\nquantity,limitprice,andvaliditytime. Amarket order isclearedimmediatelyagainstthebestavailable\norder in the limit order book (LOB), while a limit order is only executed with matching orders on the\nother side of the market up to a certain price (the limit). If this is not possible, the order is kept in the\nLOB until its end validity date to be cleared with future orders. If the quantities of two matched orders\ndo not agree, the order with the higher order quantity is only partially cleared and remains in the order\n6\n200e,50MW\n80e,2MW\n45e,12MW\n37e,22MW\n35e,17MW\n32e,97MW\n22e,12MW\n-20e,42MW\n...\nT =1\n... Offer\nBid\n200e,50MW 80e,2MW 200e,50MW 999e,72MW\nOffer Stack 80e,2MW 50e,29MW 50e,29MW 200e,50MW\n45e,12MW 45e,12MW 45e,12MW 80e,2MW\n37e,22MW 37e,22MW 37e,22MW 45e,5MW\nBid-Ask\nSpread\n35e,17MW 35e,17MW 35e,17MW 35e,17MW\n32e,97MW 32e,97MW 32e,97MW 32e,97MW\nBid Stack 22e,12MW 22e,12MW 22e,12MW 22e,12MW\n-20e,42MW -20e,42MW -20e,42MW -20e,42MW\n...\nT =1\n...\n...\nT =2\n...\n...\nT =2\n...\n...\nT =2\n...\nNewbuyorder Matching Updatedbook\nFigure 3: Illustration of the limit order book clearing mechanism. Source (Graf et al., 2024).\nbook with the remaining quantity. The minimum bid volume is 0.1 MW, and the price per MWh ranges\nfrom −9999 to 9999 euros.\nMarket participants can add the usual order qualifiers such as immediate-or-cancel (IOC) or fill-or-\nkill (FOK). Additionally, iceberg orders are allowed for which only a fraction of the order quantity is\nvisibletoothermarketparticipants. Assoonasthevisiblequantityiscleared,thenextpartoftheorder\nis automatically placed in the limit order book.\nThe basic mechanism of continuous trading is illustrated in Figure 3 by a concrete example (taken\nfrom Graf et al., 2024): In the left panel, the state of the order book at T = 1 is displayed with the\norders sorted according to their limit price and organized into a bid stack and ask stack. The state of\nthe LOB changes with the placement of a new order, with the modification of an order, and at the end-\nvalidity-time of an active order. The limit price of the order with the lowest sell price is called best-ask,\nwhile the order with the highest buy price defines the best-bid, and the difference between the two prices\nis the bid-ask-spread. In the right panel, the clearing of a new hypothetical buy order is illustrated: A\nnewbuyorderwithapriceof50e isaddedtothebookatT =2andisthenclearedagainstthecheapest\npossible offers until either the whole order is fulfilled (as is the case in the figure) or there are no offers\nwith lower prices left. In this example, 22MW out of 29MW are cleared against the sell order with\nprice 37e and the remaining 29MW−22MW = 7MW are cleared against the sell order with price\n45e. The remaining quantity of 12MW−7MW = 5MW of the latter order stays in the order book.\nNote that the clearing is instantaneous, i.e., columns 2 and 3 in the right panel are purely illustrative\nand do not correspond to market states that can be observed by traders.\n3 A Joint Optimization Method for Intraday FCR Trading\nParticipating in both the FCR and the IDM involves (i) bidding in the FCR auction one day ahead\nof delivery and (ii) trading in the IDM while honoring the battery’s FCR commitments. Finding an\noptimal combined bidding strategy for the FCR and the IDM thus involves solving a fairly complicated\nstochastic optimization with a large number of intraday trading stages that model the possibility of\nfrequent rebalancing. Solving this problem exactly is computationally intractable.\nWe therefore propose a heuristic policy that selects one of finitely many FCR bidding strategies and\n7\nthen uses the RI policy to solve the intraday bidding problem. To that end, we frame the problem of\nselecting an optimal FCR strategy as a classification problem that picks the strategy with the highest\noverall expected profits.\nWe discuss the strategy space for the FCR market in Section 3.1, a version of the rolling intrinsic\npolicyadaptedtocontinuoustradinginSection3.2,andfinallytheclassificationproblemforthedifferent\nstrategies in Section 3.3.\n3.1 Overview of Joint Bidding Model\nFor each EFA block i, suppliers can bid the price (EUR/MW) as the requested compensation for the\nservice. In this paper, we assume that the bidding strategy only includes the quantity and that the\nbidding price is zero. Due to the pay-as-cleared mechanism, even with the bidding price being zero,\nproviders still get the uniform market clearing price as their final remuneration.\nMore specifically, we use a vector X = (X ,X ,X ,X ,X ,X ) with six components to represent a\n1 2 3 4 5 6\nbid strategy in the six FCR markets, where X denotes the capacity (in MW) that is committed to the\ni\nmarket i. For a battery with capacity X¯, this implies that in principle (X¯ −X ) MW are available for\ni\ntrading on the intraday market in the time period covered the EFA block i. Hence, the FCR strategy\ndetermines the feasible bids on the intraday market.\nThe regulation of the FCR market in Germany stipulates that a storage can provide the maximum\nup-regulation or down-regulation of the full reserve bid X for at least 15 minutes without interruptions\ni\n(see Section 2). Therefore, the storage level must be in [Xi/4,E¯ −Xi/4] at any time during the period\ncovered by the market i. Furthermore, we limit the maximum FCR bid to 80% of the asset’s power\ncapacity. Note that this restriction is not required by market rules but is based on backtesting evidence,\nwhich shows that larger bids often caused SoC management issues. This assumption is reasonable for\nBESS with a power-to-energy ratio, as considered in this study (approximately 1).\nAs described in Section 2.1, admissible bids are in whole MW with a minimum bid size of 1 MW.\nHence, for a storage with capacity X, there are ⌊0.8·X+1⌋6 different admissible bidding strategies for\nthe FCR markets of a single day in our setting.\nIf X = 0, the lower limit on stored energy in the corresponding time periods t covered by market i\ni\nequals α×E¯ while the upper limit is α×E¯. These limits are in place to preserve battery health and to\navoid complete discharge as well as overcharging. In case that X >0 these bounds tighten according to\ni\nthe rules outlined above. Hence, for any time t in the time span covered by market i, we get that the\nstate of charge c has to be in the interval\nt\n[c\nt\n,c\nt\n]:= (cid:2) max(α×E¯,Xi/4),min(α×E¯, X¯ −Xi/4) (cid:3) . (2)\nThis limitation is incorporated into the RI as a constraint as described in the next section. If the\nFCR activation causes the battery charge to exceed the boundary, the constraint requires the RI to\nimmediately restore the SoC to acceptable limits by corresponding IDM trades.\nAlthough positive and negative deviations from activations on the FCR market tend to cancel out,\nparticipation in the market can produce a slight drift in the state of charge of a storage. This is\nacerbatedbytheefficiencylossesofstorage. Theenergydriftinthetimeinterval[t,t+∆t]isdependent\non fluctuations of the national grid frequency and can be expressed as\n(cid:90) t+∆t ∆t(cid:88) K\nD = P(∆f )η(P(∆f ))ds≈ P(∆f )η(P(∆f )), (3)\nt,t+∆t t s s K k=1 t+k∆ K t t+k∆ K t\n8\nwhere P is defined in (1) and ∆f is the deviation of the national frequency at time s. Furthermore, η\ns\nmapsthepositiveandnegativedeviationstothecharginganddischargingefficiency,respectively,andK\nis a positive integer defining the discretization grid in the approximation of the integral by a Riemann\nsum.\nWhen making a bidding decision on the FCR market, the BESS trades off revenues for every EFA\nblock with the revenues that can be potentially earned on the intraday market. The total daily profits\nπ are the sum of the profits π from bidding on the FCR market and the profits π from trading\nFCR IDM\non the intraday market.\n6\n(cid:88)\nπ(X)= Pk X +π (X), (4)\nFCR k IDM\nk=1\n(cid:124) (cid:123)(cid:122) (cid:125)\nπFCR(X)\nwhere Pk is the clearing price of the FCR for the EFA block k and the profits profits on the IDM are\nFCR\na function of X as will be discussed in the next section. Since neither Pk nor π (X) is known at\nFCR IDM\nthe time of bidding on the FCR market, π(X) is a random quantity.\nTherefore, in order to select an FCR strategy for the six markets of one day, we aim to solve the\nmulti-stage stochastic optimization problem\nmax E[π(X)], (5)\nX∈X\nwhere bids X are the first-stage decisions, X is the feasible set, and the bids on the IDM represent the\nrecourse decisions. Since the intraday market is continuous, the problem has an excessive amount of\nstages and therefore solving (5) exactly is computationally intractable.\n3.2 The Continuous Rolling Intrinsic Strategy for Intraday Trading\nThe intrinsic value of a storage asset is the profit that can be realized by exploiting the currently\nobservable price spreads in the market. A static intrinsic strategy therefore determines an optimal set\nof buy and sell positions based on the forward curve at a single point in time. This strategy focuses on\nlocking in guaranteed profits without speculating on future price movements.\nTheRIpolicy,originallyintroducedin(GrayandKhandelwal,2004)fortheevaluationofgasstorage,\nis a dynamic extension of the intrinsic value. Starting from an initial SoC and a portfolio of forward\npositions acquired in previous periods on the intraday market, the RI repeatedly checks for chances\nof profitable rebalancing by re-solving the intrinsic problem. Although the resulting decisions are still\nmyopic, since the policy at no point trades on anticipated future price changes, the RI clearly represents\nan improvement over the static intrinsic that does not adapt positions at all. Furthermore, the myopic\nnature of decisions has the advantage that the RI only enters immediately profitable positions and\nthereforedoesnotruntheriskofaccumulatinglossesbasedonwrongassumptionsaboutthefuture. For\nthese reasons and because of its conceptual simplicity and low computational cost, the RI has attained\nwidespread industry adoption.\nThe classic version of the RI is based on a price taking intrinsic strategy. To be able to employ the\nalgorithm to the continuous intraday market, we adapt the intrinsic algorithm to explicitly take into\naccount the LOB and corrections based on energy drift from FCR market activations when trading. In\nparticular, for every rebalancing decision, the algorithm receives a snapshot of the current state of the\norderbookandsubsequentlycheckswhetherthepositionsofforwardcontractsbuiltupinprevioussteps\ncan be profitably updated.\n9\nIn order to discuss the RI, we first formally define the intrinsic problem for continuous intraday\nmarkets, which is solved repeatedly in the process. To that end, we define the set of tradeable contracts\n(cid:83)\nT atthetimetheintrinsicpolicyisexecuted,aswellastheorderbookinformationO = O ,which\nt∈T t\ncontainsordernumbersofallbidsandaskscurrentlyintheorderbookO forcontractt. Inaddition, we\nt\ndefine the set of contracts that go into delivery on the current day as T . For an order i∈O, we denote\n0\nby P its limit price (in EUR/MWh), by σ its direction (−1 for bid and 1 for ask), and finally by Q\ni i i\nthequantity. Inordertocapturethehistoryoftradingdecisions, wedenotebyc andb0 theenergyand\n0 t\npower commitments resulting from previous trades where c is adjusted for the energy drift that results\n0\nfrom call offs on the FCR market and by products that go into delivery (see below). To model the cost\nof battery degradation, we use a simple linear approximation by multiplying the absolute magnitude of\nplanned charging/discharding by the degradation cost κ>0 (in EUR/MWh).\nNote that the last tradeable contract t is always the last period traded in a day. We fix a terminal\nstorage level C at the end of a trading day, i.e., at time T =max T. With these preparations in place,\nT\nwe can formulate the intrinsic problem, which decides for every order i ∈ O about the quantity q (in\ni\nMW) that is matched by the intrinsic policy as follows.\n(cid:88) (cid:88) (cid:88)\nmax ∆ P σ q −κ∆ (b++b−) (6a)\ni i i t t\nqi,ct,bt,b±\nt t∈T i∈Ot t∈T\ns.t. 0≤q ≤Q , ∀i∈O, (6b)\ni i\n(cid:88)\nb =b0− σ q , ∀t∈T, (6c)\nt t i i\ni∈Ot\nb =b+−b−, ∀t∈T, (6d)\nt t t\nb+ ≤δ b , ∀t∈T, (6e)\nt t t\nb− ≤(1−δ )(−b ), ∀t∈T, (6f)\nt t t\n(cid:88) (cid:88) 1\nc =c +∆ η b+−∆ b−, ∀t∈T, (6g)\nt 0 ch a η a\ndis\na≤t a≤t\nb ≤b ≤b , ∀t∈T, (6h)\nt t t\nc ≤c ≤c ∀t∈T, (6i)\nt t t\nb+,b− ≥0, ∀t∈T (6j)\nt t\nδ ∈{0,1}, ∀t∈T (6k)\nt\nc =C , (6l)\nT T\n∆ (cid:80) (b++b−)\nt∈T t t ≤C¯0, (6m)\n2E¯\nwhere ∆ is the duration of the delivery period of the traded contracts (e.g., one hour or 15 minutes),\nb , c ∈ R+, b ∈ R−, c ∈ R+ are upper and lower bounds on stored energy and charged discharged\nt t t t\npower in period t ∈ T (see discussion above), respectively and η ,η < 1 is the charging/discharging\nch dis\nefficiency factor (depending on the direction of the trade). Note that the bounds on power and energy\ndepend on the commitments on the FCR market for the corresponding EFA block (see last section).\nThevariablesb definedin(6c)modeltheaccumulatedpower(inMW)ofallorderswiththedelivery\nt\nperiodtanddependonthecorrespondingvaluesfromprevioustradesb0 andthedecisionsinthecurrent\nt\nproblem, where b+,b− are the positive and negative parts of b , respectively, as modeled by (6d) to\nt t t\n(6f), where the constraints make sure that for every product energy is either bought or sold, which is\nimportant for contracts with negative prices where simultaneous charging and discharging is potentially\n10\nprofitable, depending on efficiencies and the observed bid/ask spread. Similarly, the variables c in (6g)\nt\ndefine the total energy stored in the storage until the end of period t. Note that the factor ∆ translates\npower (in MW) into energy (in MWh). The constraints (6h) and (6i) represent the limits for power and\nenergy imposed by the physical limitations of the storage as well as commitments on the FCR market.\nThe last constraint (6l) requires that the storage level is equal to C at the end of the planning horizon.\nT\nThe constraint (6m) enforces a daily cycling limit, where C¯0 is the number of permissible cycles left\non the current day, which is updated in the RI Algorithm 1. Finally, the first term of the objective\nfunction (6a) models the profits from trading, while the second term yields the planned losses from\nbattery degradation.\nNote that while on the intraday market different types of contracts are traded (hourly, half-hourly,\nquarter-hourly), we only consider one type in the above formulation. Clearly, at the expense of a more\ninvolved notation, the problem could easily be extended to cover different types of contracts. However,\nforthesakeofsimplicityandbecauseweonlyuseonetypeofcontractinournumericalstudy,werefrain\nfrom this complication.\nThe intrinsic problem (6) is the main building block of the rolling intrinsic policy, which is detailed\nin Algorithm 1. The RI reoptimizes a given position either periodically or every time there is a change\nin the LOB. The policy is myopic in the sense that trades are only executed if the resulting immediate\nprofit is positive. This leads to profits that are guaranteed to be non-negative and a strategy that is\nnot able to anticipate future prices foregoing potential profits of more speculative strategies but also\neliminating any downside risks.\nNotethattheRIprofitsarenottakenfromtheobjectiveoftheproblem(6),butcalculatedoutsideof\nthe optimization problem in Algorithm 1. The reasons for this are twofold: Firstly, to not count battery\ndegradation costs for the same periods multiple times, the degradation cost is accounted for in lines 6\nand 20 for the periods that are no longer traded and go into physical delivery. Secondly, some of the\ntrades found by the linear program (6) may not be feasible, since they are not forced to be multiples\nof the minimum bid size δ. Note that this happens only for the most expensive accepted ask and the\ncheapest accepted bid per period. We correct for these inaccuracies in line 14.\nOn a related note, we remark that the initial schedule (c0) for any of the intrinsic solves need not\nt t∈T\nbe physically feasible due to the rounding after the solution of the last problem, as well as due to the\nenergy drift that occurs between two consecutive runs of the intrinsic policy. Everytime (6) is solved,\ntheseviolationsarecorrected. IftherearenotenoughordersintheLOBforcorrection,theproblem(6)is\npotentiallyinfeasible. Hence,theif-statementinline13. Ifsuchassituationpersistsoveralongerperiod\nof time, we theoretically could end up with a physically infeasible schedule that has to be corrected on\nthe balancing market. However, in Section 4, we demonstrate that this case does not occur in practice\nfor sufficiently conservative limits to storage operation.\n3.3 Strategy selection as a classification task\nIn this section, we describe how we approximate (5). The main idea is to simplify the problem by first\ndecidingamongthefinitelymanyfeasibleX ∈X andthenrelegatingtherecoursedecisionstotherolling\nintrinsic alogrithm.\nTo be able to choose among the strategies in X, we fit a classification model with the objective of\npicking the strategy X ∈X that, paired with the RI trading strategy in the IDM, produces the highest\naverage profits. We base the predictor on a supervised learning method that uses a set of features and\n11\nData: Storage level C , planned final storage level C , T, minimal bid size δ\n0 T\n1 ∀t∈T :b0 t ←0, c 0 ←C 0 ;\n2 π←0, T− ←T;\n3 while T ̸=∅ do\n/* Correct for drift and calculate realized battery degradation cost */\n4 Set ∆T ←T−\\T, fetch order books O t and FCR SoC drift D since last optimization;\n5 c 0 ←c 0 –D+∆ (cid:80) t∈∆T η ch b+ t −∆ (cid:80) t∈∆T ηd 1 is b− t ;\n6 π←π−∆κ (cid:80) t∈∆T |b0 t |;\n/* Update cycling limit */\n7 if a new day has started since the last solve then\n8 C¯0 ←Ncycles ;\n9 else\n10 C¯0 ←C¯0− ∆(cid:80) t∈ 2E ∆ ¯ T |bt| ;\n11 end\n/* Initialize new contracts */\n12 b0 t ←0 for all T \\T− ;\n/* Solve the intrinsic and round results to implementable trades */\n13 Solve the intrinsic problem resulting in optimal (b t ) t∈T , (c t ) t∈T and (q i ) i∈O ;\n14 if intrinsic is feasible then\n15 q i ←round(q i /δ)×δ, ∀i∈O;\n(cid:80)\n16 π←π+∆ i∈O P i σ i q i ;\n17 b0 t ←b0 t − (cid:80) i∈Ot σ i q i , ∀t∈T;\n18 end\n/* Prepare next iteration */\n19 T− ←T, wait for next trading time, and update T;\n20 end\n(cid:80)\n21 π←π−∆κ t∈T |b t |;\nAlgorithm 1: Rolling-intrinsic algorithm for one day of trading on the intraday market.\nis calibrated using historical data. More specifically, for every day d ∈ D in our training data, we have\na feature vector f and profits π (X) as calculated in (4) dependent on the FCR strategy and on IDM\nd d\ntrading by the RI.\nThus, we frame the optimal strategy selection for the FCR market as a classification task where the\nfeatures f are used to forecast the labels X∗ with X∗ the strategy X that maximizes trading profits on\nd d d\nday d, i.e.,\nX∗ =argmax{E[π (X)]:X ∈X}.\nd d\nTo do so, we fix a hypothesis class H such that h:F →X for every h∈H, where F is the feature space\nand solve\n1 (cid:88)\nh∗ =argmax L(X∗,h(f )), (7)\n|D| d d\nh∈H\nd∈D\nwith L the cross entropy loss.\nNotethatinordertocalculatethelabelsoftheaboveproblem,wehavetoevaluatetheprofitsπ (X)\nd\nfor every strategy X ∈X for all days d∈D in the training data. However, evaluating IDM trading with\norder book data for every of the ⌊0.8·X +1⌋6 candidate FCR strategies is computationally expensive.\nForthisreasonandinordertolimitthepotentialclassimbalancein(7),werestrictthesetX ofpossible\n12\nstrategies.\nIn order to do this, we proceed in two steps. In a first step, we limit the set X to a reduced set of\nstrategies M ⊆ X based on our analysis of the interaction between the revenues that can be generated\ninthetwomarketsinSection4. WeevaluateprofitsforalldaysD andallstrategiesX ∈M. Tofurther\nreduce class imbalance, we reduce the strategy space to S ⊆ M base strategies. An approach to do\nthis would be to simply select a fixed set of strategies from M that yield the highest average profits.\nHowever, this does not necessarily yield an optimal subset of strategies, since rather similar strategies\nmight be chosen instead of designing S to consist of complementary strategies.1\nInordertofindawellperformingyetsmallstrategypoolsetofsizeS <|M|,wepickasubsetS ⊆M\nproducing the highest overall profit on the training data under the hypothesis of perfect classification,\ni.e., under the assumption that for every day the best strategy X ∈S is chosen by the classifier. We do\nthis by solving the following mixed integer linear program\n(cid:88) (cid:88)\nmax w π (X) (8a)\nXd d\nzX,wXd\nX∈Md∈D\ns.t. z ∈{0,1}, X ∈M (8b)\nX\nw ∈[0,1], ∀X ∈M, ∀d∈D (8c)\nXd\nw ≤z , ∀X ∈M, ∀d∈D (8d)\nXd X\n(cid:88)\nw =1, ∀d∈D (8e)\nXd\nX∈M\n(cid:88)\nz =S. (8f)\nX\nX∈M\nIntheaboveproblem, thevariablesz determinewhetherastrategyisinS andconstraint(8f)enforces\nX\nthat only S strategies can be chosen. The variables w model whether a strategy X is chosen for day\nXd\nd. Note that since the objective is linear in w the optimal values of w will be in {0,1} and the sum\nXd Xd\nin (8e) ensures that only one strategy is chosen per day. Clearly, if z =0, w =0 for any day d due\nX Xd\nto (8d). Given the optimal solution of the above problem, we define\nS ={X ∈M:z =1}\nX\nand define our labels as X ∈argmax{π (X):X ∈S}.\nd d\nIn order to solve the ensuing classification problem based on the data (X ,f ) as our training\nd d d∈D\nset, we use XGBoost (Chen and Guestrin, 2016), a gradient boosting method based on decision trees.\nEnsemble methods such as gradient boosting are the current state of the art for tabular data and often\noutperform other methods (e.g. Shwartz-Ziv and Armon, 2022; Grinsztajn et al., 2022) and specifically\nXGBoost has shown remarkable performance in machine learning competitions since its inception and\noffers high computational efficiency, the ability to manage class imbalance, and has powerful feature\nselection capabilities.\n1Toseethisconsiderthecasewhere|M|=3and|S|=2andwheretherearetwostrategiesX1 andX2 thatperform\nbest on average but are rather similar as well as a third strategy X3 which yields good results on those days where X1\nandX2 havepoorperformance. Inthiscase,itisclearlyadvantageoustochooseS={X1,X3}asasetofcomplementary\nstrategieswhichcontainsagoodstrategyforeverydayratherthansimplychoosingthebesttwostrategies.\n13\n4 A Numerical Case Study\nThis section discusses a numerical out-of-sample study that puts the method developed in the previous\nsections to the test. Throughout we assume a 10MW/10MWh battery, i.e., a battery with a power\ncapacity of 10MW and an energy capacity of 10MWh and use α = 0.01 and α = 0.985 to define SoC\nlimits. We use historical limit order books from the German continuous intraday market from EPEX\nSpot and historical FCR clearing prices from Regelleistung.net from 01/01/2023 until 30/09/2024 for\nour study.\nWebeginbyinvestigatingsomestaticFCRstrategiesX,whichmeansaconstantallocationofbattery\npower to the FCR and IDM markets for every day of the observation period. We show that, contrary\nto intuition, revenue per market does not change linearly with the allocated battery power. We also\nexplainwhatdrivestheobservedrelationship. Havingbuiltsomeintuitionaroundtheoptimalallocation\nof battery power between FCR and IDM, we then move to the results of the dynamic FCR strategy as\na classification problem.\n4.1 Decreasing Intraday Returns\nWe start by discussing the fact that per MW revenues in the IDM are a decreasing function of the\namount of battery capacity left for intraday trading. There are essentially two reasons for this: Firstly,\nlimited liquidity of the IDM favors strategies with less capacity, since these do not experience a large\npriceresponsewhentrading(KuppelwieserandWozabal,2021). Secondly,thelesscapacityiscommitted\non the FCR market the higher the duration of the remaining storage that can be traded on the intraday\nmarket, which tends to decrease profits per unit of capacity. We will discuss this less obvious aspect\nbelow.\nThe battery power allocated to the FCR market determines not only the battery power left on for\nIDM trading, but also the energy capacity of the battery still available for use on the IDM market. In\nparticular,theFCRregulationstatesthatthebatterymustatalltimesbeabletodeliverythecommitted\npower for at least 15 minutes in both directions (see discussion in Sections 2 and 3). In our case this\nmeansthatwithacommitmentof8MWintheFCRmarketthe10MW/10MWhbatteryhastomaintain\nachargelevelbetween2MWhand8MWh. Thisleaves2MWand6MWhofflexibilityontheIDMmarket,\nincreasing the energy to power ratio from 1 (of the original 10MW/10MWh battery) to 3 on the IDM\nmarket.\nThe increase in total profits from intraday trading when duration changes depends on the price\npatterns. The two most extreme cases are depicted in Figure 4: The left panel shows a situation where\nthe prices in the first 12 hours of the day are low, enabling the storage to continuously charge in that\ntime and sell back the energy in the second half of the day for high prices. In this case, a perfectly\nefficient battery with a duration of 12 hours is optimal. Contrast this with the situation in the right\npanel, where prices alternate between high and low prices every hour and the storage would only charge\nfor 1 hour before discharging again and therefore durations above 1 do not yield additional profits.\nInreality,pricepatternsfallbetweenthetwoextremesdepictedinFigure4,showingamorenuanced\neffect of duration on profits. We explore this relationship in Figure 5 by computing the profits of a\n10MW storage with varying energy capacity resulting in different storage duration. The experiment is\ncarried out with price data from January 2023. In the experiment, the energy capacity varies from 10\nMWh, that is, a duration of 1, to 60 MWh, i.e., a duration of 6.\nThe left panel of Figure 5 shows how the duration of the storage on the IDM increases with the size\n14\nFigure 4: Two extreme price patterns for one day.\n3.00\n2.75\n2.50\n2.25\n2.00\n1.75\n1.50\n1.25\n1.00\n0 1 2 3 4 5 6 7 8\nPower in the FCR\noitaR\n1200\n1000\n800\n600\n400\n200\n0\n0 1 2 3 4 5 6\nDuration\nstiforP\nMDI\nFigure 5: The left panel shows the relationship between the bid size in the FCR and the duration ratio,\nwhile the right panel depicts the how the capacity to power ratio affects the profits in the IDM.\noftheFCRbidandtherightpanelshowstheconnectionbetweendurationandoverallaverageprofitsfor\none day of trading with the rolling intrinsic. This analysis reveals that there is a concave and increasing\nrelationship between duration and per-MW revenue on the IDM.\nOverall, thisdemonstratesthatduetothewaypowerandcapacityareregulatedintheFCRmarket,\nrevenues in the IDM market fall more slowly than may naively be expected when increasing the battery\npower committed in the FCR market. Since FCR revenues per MW are constant in the FCR bid size,\nit also shows that strategies with a higher power committed to FCR tend to be more attractive for the\n10MW/10MWh battery under consideration.\n4.2 Pre-selection of FCR Strategies\nIn our case, there are in total 96 different possible FCR bids, making it impractical to backtest all of\nthem. The findings in the last section and initial experiments show that allocation of a large proportion\noftheBESS’capacitytotheFCRmarketispreferable. However, theafternoonandeveningEFAblocks\nfour, five, and six can on some days exhibit substantial volatility with big price spikes in the intraday\nmarket. In these instances having more power capacity to trade in the IDM market to benefit fully from\nthese spikes may outweigh the lost revenue in the FCR market.\nBased on these findings, we choose the 28 strategies listed in Table 2 as the set M for backtesting.\nAll strategies are computed by reoptimizing once every minute in the rolling intrinsic strategy with a\n15\n2023 2024\nStrategy Overall IDM FCR Best Overall IDM FCR Best\n(5,5,5,8,8,8) 2815 827 1988 14 3559 750 2809 19\n(8,8,8,5,5,5) 3079 1077 2003 3 3535 919 2616 0\n(8,8,8,0,0,0) 2992 1744 1247 23 2945 1533 1412 3\n(8,8,8,0,0,5) 3033 1601 1432 20 3057 1399 1658 4\n(8,8,8,0,0,8) 2985 1442 1543 6 3061 1256 1805 2\n(8,8,8,0,5,0) 2928 1436 1492 0 3029 1253 1777 0\n(8,8,8,0,5,5) 2969 1292 1677 1 3124 1102 2022 1\n(8,8,8,0,5,8) 2899 1111 1788 3 3128 959 2169 1\n(8,8,8,0,8,0) 2863 1224 1639 3 3046 1051 1995 1\n(8,8,8,0,8,5) 2874 1051 1824 2 3136 896 2241 0\n(8,8,8,0,8,8) 2799 865 1935 2 3143 755 2388 0\n(8,8,8,5,0,0) 3174 1601 1573 26 3388 1381 2007 2\n(8,8,8,5,0,5) 3185 1427 1758 17 3478 1226 2252 1\n(8,8,8,5,0,8) 3110 1241 1869 3 3476 1077 2399 3\n(8,8,8,5,5,0) 3090 1273 1818 4 3451 1080 2371 1\n(8,8,8,5,5,8) 2998 885 2114 0 3540 777 2763 2\n(8,8,8,5,8,0) 2989 1024 1965 1 3460 871 2589 1\n(8,8,8,5,8,5) 2973 823 2149 4 3549 714 2835 1\n(8,8,8,5,8,8) 2894 634 2260 3 3554 572 2982 1\n(8,8,8,8,0,0) 3242 1473 1769 77 3604 1241 2363 29\n(8,8,8,8,0,5) 3221 1267 1953 27 3683 1075 2608 11\n(8,8,8,8,0,8) 3141 1076 2064 20 3682 927 2756 17\n(8,8,8,8,5,0) 3127 1114 2013 10 3663 936 2727 8\n(8,8,8,8,5,5) 3106 908 2198 11 3745 773 2973 7\n(8,8,8,8,5,8) 3025 716 2309 2 3750 630 3120 11\n(8,8,8,8,8,0) 3014 854 2160 9 3664 718 2946 12\n(8,8,8,8,8,5) 2999 654 2345 28 3751 560 3191 20\n(8,8,8,8,8,8) 2925 469 2456 46 3761 422 3338 116\nTable 2: Results of static strategies for 2023 and the first three quarters of 2024. The reported profits\nare in EUR per day and the results of the column best indicate on how many days a strategy is the best\nstrategy. Boldface in the columns Overall and Best indicate the best five strategies in the respective\nyear with regard to profits and number of times a strategy is the best strategy.\nsnapshot of the order book that contains the best four orders in either direction. In order to separate\ndaysandgetrevenuesperdayoftrading,westarttradingat7p.m. ofthepreviousdayforeverytrading\nday and assume an initial storage level of 2 MWh, which proved to be a good choice in our tests.\nTable 2 reveals that the best strategy in the year 2023 was (8,8,8,8,0,0), reducing the allocation of\npowertoFCRinthelateafternoonandeveningblockstotakeadvantageofpricespikesintheIDMinthe\ncorrespondinghours. Generally,strategiesthatselllesspowerintheFCRmarketintheseblocksperform\nbest in 2023. Interestingly in 2024 the situation changes and the strategy (8,8,8,8,8) that commits the\nmaximum capacity on the FCR market comes out on top with respect to average daily profits and the\nnumber of days the strategy dominates all the other strategies.\n16\n8.0%\n6.0%\n4.0%\n2.0%\n0.0%\n0 5 10 15 20 25 30\n#Strategies\n82-VC\not\nevitaler\nssoL\nFigure 6: Number of strategies S versus profit percentages loss relative to CV-28. The results comes\nfrom 01/01/2023 to 30/09/2024\nLookingattheIDMandFCRprofits,wefindaveragevaluesofEUR1111andEUR1905in2023and\nEUR 959 and EUR 2468 in 2024. This implies that while the IDM market appears to have become less\nprofitable for storage in 2024 the opposite appears to have happened to the FCR prices, which explains\nthe change in the type of optimal strategies between years. Overall, the average profit is higher in 2024.\nWe furthermore observe that there are strategies that are not particularly good on average but are\nthe best strategy on a significant amount of days. Examples include strategies (8,8,8,8,8) and (8,8,8,8,5)\nin 2023. This supports our approach of selecting S ⊆ M strategies that complement each other in an\noptimal way, rather than simply choosing the strategies that perform best on average.\nAlthoughwelimitthesetMtoareducedstrategypoolwithonly28strategies,pickinguptheoptimal\nstrategy for any given day from the such pool, equivalent to a classification problem of 28 classes, which\nis made difficult by the inherent class imbalance in the data. To this end, we propose to select a subset\nS ⊆M to reduce the size of the strategy pool while staying close to the revenue potential of the entire\nset M.\nFigure6showsthelosswithoptimalstrategyselectionrelativetotheclairvoyantstrategythatalways\nchooses the best strategy from M under the assumption that the best among the S chosen strategies is\nused on every day. It can be clearly seen that for a small number of strategies S the loss reduces rapidly\nbut starts to level off around S = 4. This presents valuable insights in choosing the optimal number of\nstrategies: Too many classes not only increase the difficulty of the task, but also offer only marginally\nincreased profits.\n4.3 Features\nTo select the most profitable FCR bidding strategy for a given day, we train our classification model\non a set of features designed to capture the prevailing and expected market conditions. This feature\nset comprises primary predictors derived from market data and forecasts, as well as carefully selected\ninteraction terms to model non-linear relationships between market drivers.\nOur model is built upon a foundation of four groups of base features:\n1. Priceoftheday-aheadauction(DAA):Naturally, theday-aheadmarketpricesaregoodpredictors\n17\nof continuous intraday prices (Uniejewski et al., 2019; Marcjasz et al., 2020; Narajewski and Ziel,\n2020). Weincorporateday-aheadauctionpricesasinputfeatures,focusingonfourselectedregions\n— ‘DE-LU’, ‘IT-North’, ‘NO2’, and ‘SE4’ — due to their relatively low price correlations, which\nintroducesgreaterregionaldiversityintothemodel. Tobettercapturetemporalmarketdynamics,\nwe compute the average day-ahead prices within each EFA block. In addition, we calculate the\nstandarddeviationforeachEFAblocktoreflectpricevolatility,whichcanbeinformativetocapture\nrisk and uncertainty in market behavior. In all this yields 4×6×2=48 features for our model.\n2. VRES producers typically sell their products on the DAM on the basis of production forecasts.\nLarger forecast RES production therefore also yields to potentially larger absolute forecast errors,\nprompting more significant rebalancing on the intraday market. Hence, renewable generation\nforecasts are a major driver of intraday prices and, in particular, intraday price variance. This\nin turn influences the profitability of trading with the storage on the intraday market and is\ntherefore a good feature in our strategy selection. See also (Karanfil and Li, 2017; Goodarzi\net al., 2019; Kulakov and Ziel, 2019; Kuppelwieser and Wozabal, 2023) for a discussion on the\nimpact of renewable generation forecasts on intraday prices. Therefore, we also utilize public\npowerforecasting(PPF)data,whichincludesforecastsforsolargeneration,onshorewind,offshore\nwind, and electricity load in Germany. To align with the temporal structure of our model, we\ncalculate the average values of these forecasts within each EFA block, as well as the standard\ndeviation of hourly values within each block, which yields an additional 6×2×4=48 features.\n3. Historical FCR clearing prices serve as strong indicators of the potential profitability of the FCR\nmarket for the next day. To take advantage of this information, we include the FCR clearing price\nofthepreviousdayforeachofthe6EFAblocksasfeaturesinourmodel. Thishelpscapturerecent\nmarket conditions and short-term trends relevant to price formation.\n4. We add eight dummy features to capture temporal patterns. These include the weekday, ranging\nfrom 0 (Sunday) to 6 (Saturday); a weekend indicator, equal to 1 for Saturday and Sunday and\n0 otherwise. Furthermore, we include the day of year, denoting the i-th calendar day (1–365);\nand a trend variable, representing the i-th day in the backtesting period (0–636). To account for\nseasonality,wefurtherincludebothannual seasonality terms2 aswellasweekly seasonality terms3.\nWhilethebasefeaturesareinformative,theoptimalstrategyoftendependsonthecomplexinterplay\nbetweendifferentmarketdrivers(e.g., theimpactofahighwindforecastmaybedifferentonadaywith\nhighpriorFCRpricesversuslowones). Tomodeltheserelationships,weintroducequadraticinteraction\nterms. However, creating all possible pairwise interactions from the base features would result in an\nunmanageablylargefeatureset(roughly10000interactions),increasingtheriskofoverfittingandmaking\nthebacktestingprocesscomputationallyprohibitive. Wethereforeadoptamulti-stepheuristicapproach\nto construct a concise yet powerful set of interaction features:\n1. Focus on Primary Drivers: We generate interactions using only the average values of DAA prices\nand PPF forecasts for each EFA block, excluding the standard deviations to reduce the initial\nscope.\n(cid:16) (cid:17) (cid:16) (cid:17)\n2sin 2π·dayofyear ,cos 2π·dayofyear\n365 365\n(cid:16) (cid:17) (cid:16) (cid:17)\n3sin 2π·weekday ,cos 2π·weekday\n7 7\n18\n1\n2\n3\n4\n5\nduration\ndlof\nTrain set\nValidation set\nFigure 7: Anchored walk-forward validation.\n2. Prioritize Cross-Group Interactions: We hypothesize that the most significant effects arise from\nthe interplay between different feature groups. We therefore limit the interactions to two specific\ntypes: Day-ahead price averages × Historical FCR prices as well as Renewable forecast averages\n× Historical FCR prices\n3. Remove Redundancy via Correlation Filtering: This process results in an intermediate feature set\nof approximately 400 base and interaction terms. To mitigate multicollinearity and further reduce\ndimensionality, we perform a final filtering step. We compute the Pearson correlation matrix for\nthis expanded set of features and iteratively remove one feature from any pair with a correlation\ncoefficient exceeding a threshold of 0.94.\nThis structured approach yields a final, manageable set of under 300 features that captures key linear\nand non-linear market dynamics.\n4.4 Rolling Horizon Evaluation\nIn our out-of-sample model evaluation, we mimic how the model would be used in trading practice on\na day-to-day basis. For any given day in the out-of-sample window, we estimate an optimal policy to\nbid on the FCR market for one day with a model trained with data from the last N days. Then we\nimplement the policy and record its profits. Subsequently, we refit the model for the next trading day\nupdating the training data with the last day. We generate out-of-sample profits by rolling through our\nentire data in this fashion.\nMore specifically, we evaluate the out-of-sample performance of the model in the rolling horizon\nfashion described above using data from January 1, 2023, to September 30, 2024. Each day, a training\nwindowofN =240daysisused. Inthisway,wegenerateasetof396out-of-sampledailyprofitscovering\nthe period from August 30, 2023, to September 30, 2024.4 Evaluating performance on this large and\ndiverse set of days helps ensure that the results are not unduly influenced by any specific time frame or\nby particular patterns or anomalies that might appear in a smaller subset of the data.\nEvery time we retrain the model for a day of trading, we first solve equation (8) to select a subset of\nsize S = 3 from M that achieves the highest average profits on the training sample, and then train an\nXGBoost classifier to further identify the optimal strategy from this subset. The size of S =3 strikes a\n4Notethatsinceweuselaggedprices,weactuallyneed241daysinsampledatatogeneratedatafor240trainingdays.\n19\nStrategy FCR IDM Overall % of CV-28 Equals CV-3 Equals CV-28 Beats LCS\nCV-28 1113 407 1520 0.0 46.4 100.0 59.3\nCV-3 1127 370 1497 -1.5 100.0 46.4 27.8\nLCS 1146 313 1459 -4.0 72.2 38.9 0.0\nDB 1063 349 1412 -7.1 36.9 20.1 16.4\nSB 969 433 1402 -7.8 4.3 0.3 30.3\nOnly FCR 1238 170 1408 -7.4 57.1 37.1 14.14\nOnly IDM 0 774 774 -49.1 0.0 0.0 17.7\nTable3: Overallout-of-sampleprofits(thousandEuro)ofallstrategiessplitintoFCRandIDMprofits.\nThe last four columns give the shortfall from CV-28 (in % of profit), the fraction of days (%) where\npolicies take the same bidding decisions as CV-3 and CV-28, as well as the fraction of days where\npolicies outperform the LCS strategies, respectively.\ngoodbalancebetweentheprofitofthecombinedstrategiesandthedifficultyoftheensuingclassification\nproblem (see Section 3.1).\nWhen using XGBoost, we optimize the hyperparameters of the method. Specifically, we optimize\nthe parameters eta (0.01, 0.05, 0.1), gamma (0, 0.5, 1, 2), subsample (0.8, 1), colsample bytree (0.8, 1),\nmax depth (3,4,5),n estimators (200,400)usingcrossvalidation. Weuserandomgridsearchtofindthe\nbest combination of hyperparameters selecting from the values in brackets. In particular, we randomly\nchose 20 possible combinations of hyperparameters without replacement and test their performance in\nthevalidationsetsandadditionallyincludethebestparametercombinationfoundforthelastdayinthe\nsample.\nDue to the periodicity and autocorrelation inherent in sequential data, traditional cross-validation\nmaydisrupttemporaldependencies,resultinginasignificantdiscrepancybetweenthevalidationandtest\nsets. Weuseanchoredwalk-forwardvalidation,whichpreservesthesequentialorderbyalwaysvalidating\non future data, to find the best set of hyperparameters, see Figure 7. Specifically, we employ five folds,\nwiththelast15daysineachfoldreservedforvalidation. Notethatbyanchoring,thetrainingdatagrows\nin later folds. Instead of using accuracy or F-score as the criterion for hyperparameter tuning, we adopt\nuse the negative trading profit in the validation sets as loss function for hyperparameter tuning. This is\nbecause accuracy and F-score may overlook misclassifications that have a significant negative impact on\nprofitability, whereas a profit-based score penalizes such errors more appropriately.\nWhen generating and evaluating the generated policy for every day, we add up FCR and intraday\nrevenues, the latter of which is the result of executing the RI on the order book data for that specific\nday. The total profits are calculated by subtracting the battery degradation cost as described in Section\n2 from these revenues. As for the training data, in order to run the rolling intrinsic, we use snapshots of\nthe LOB consisting of the top four prices for each traded product and rerun the intrinsic every minute.\nForeveryday, westarttradingat7p.m. onthepreviousdayandassumeastartingstoragelevelof20%\n(2MWh). Furthermore, we use the historical market clearing price of the FCR market to calculate the\nFCR revenues of the different strategies.\n20\n4.5 Results & Discussion\nIn this section, we compare the results of the trained classifier strategy (LCS) described in the previous\nsections with some benchmark strategies. The first benchmark is the 8-8-8-8-0-5 strategy, also referred\nto as the static baseline (SB), which is the most profitable single strategy in M calculated for the whole\ndata. In addition, we compare our policy with the strategy that selects the strategy that was most\nprofitable for the training data associated to a specific day. We refer to this as the dynamic baseline\n(DB).TheperfectdynamicstrategydenotedbyCV-3denotesanidealpolicythatalwaysselectsthebest\nperforming strategy from the optimal group S on any given day. Finally, as another theoretical upper\nbound, weincludetheCV-28thatalwayschoosesthebeststrategyfromMforeveryout-of-sampleday.\nFurthermore, we also evaluate the strategies to bid only on the IDM and to bid the maximum amount\nallowed on the FCR market, that is, the strategies (8,8,8,8,8) and (0,0,0,0,0,0).\nThe results of this analysis are summarized in Table 3, which allows for the following conclusions:\nFirst, our proposed LCS performs exceptionally well, achieving an overall profit that is only 4.0% lower\nthan the theoretical maximum achievable with perfect foresight (CV-28). This gap represents the com-\nbined loss from two distinct steps: the initial selection of the top-three strategy pool in (8) and the\nsubsequent classification error. Critically, the gap shrinks to a mere 1.5% when compared to CV-3, the\nclairvoyant strategy restricted to the same three strategies. This demonstrates the high accuracy of\nthe XGBoost classifier in selecting the best option from the available pool on any given day. In stark\ncontrast, the naive dynamic (DB) and static (SB) benchmarks fall short of the theoretical maximum by\n7.1% and 7.8%, respectively, highlighting the significant value added by the learning-based approach.\nFurthermore, strategies focusing exclusively on a single market are clearly suboptimal; the ’Only FCR’\nstrategy underperforms the CV-28 benchmark by 7.4%, while the ’Only IDM’ strategy lags by a sub-\nstantial 49.1%. The later results also shows that the FCR market is more profitable than the IDM in\nthe observation period.\nSecond, a breakdown of the revenue sources reveals that the performance difference between the\ntop strategies is primarily driven by profits from the intraday market. Both CV-28 and CV-3 achieve\nhigher IDM revenues than our LCS. This indicates that the main challenge, and the primary source of\nthe remaining performance gap, lies in perfectly identifying the specific days where the intraday market\noffers exceptionally high profit opportunities.\nThird,theeffectivenessoftheclassifierisfurtherconfirmedbyanalyzingthedailydecisionalignment\nshown in Table 3. LCS selects the same strategy as CV-3 for an impressive 72.2% of the days, a high\nhit rate that directly corresponds to its strong profit performance. The alignment with the best overall\nstrategy (CV-28) is naturally lower at 38.9%, as the LCS is limited to strategies from S. The fact that\ntheCV-3strategyitselfonlymatchestheCV-28decisionon46.4%ofdaysunderscorestheimportanceof\ntheinitialstrategypoolselectionandexplainswhyagapbetweenourLCSandthetheoreticalmaximum\nremains.\nFinally, the daily decision metrics in Table 3 provide further insight into the performance of the\nmodel. The CV-3 strategy, which has perfect foresight over the same pool of three strategies available\nto our LCS, outperforms it on only 27.8% of the days. This implies a high classification accuracy for\nthe XGBoost model, as it correctly identifies the best strategy within its pool more than 70% of the\ntime. AnuancedobservationariseswhencomparingLCStotheSBstrategy. WhileSBoutperformsLCS\non a higher fraction of days (30.1%). This occurs because SB can be the strategy outside the curated\nthree-strategypoolusedbyLCS;however,themarginalprofitsgainedonthosedaysarenegligible,which\n21\nCV-28\n1400 CV-3\nLCS\nDS\n1200\nSB\nOnly FCR\n1000\nOnly IDM\n800\n600\n400\n200\n0\n2023-09-01 2023-11-01 2024-01-012024-03-01 2024-05-01 2024-07-01 2024-09-01\nFigure 8: Cumulative profits for the LCS and all benchmarking strategies over the whole OOS period.\n1.0\nCV-28\nCV-3 0.8\nLCS\n0.6\nDS\n0.4\nSB\nOnly FCR 0.2\nOnly IDM\n0.0\n2023-08-\n2\n3\n0\n0 23-09-\n2\n2\n0\n7 23-10-\n2\n2\n0\n5 23-11-\n2\n2\n0\n2 23-12-\n2\n2\n0\n0 24-01-\n2\n1\n0\n7 24-02-\n2\n1\n0\n4 24-03-\n2\n1\n0\n3 24-04-\n2\n1\n0\n0 24-05-\n2\n0\n0\n8 24-06-\n2\n0\n0\n5 24-07-\n2\n0\n0\n3 24-07-\n2\n3\n0\n1 24-08-28\n)dezilamroN(\nstiforP\nylkeeW\nFigure 9: A heatmap presents the normalized weekly profits across different strategies over the entire\nevaluation period. The horizontal axis denotes time (from August 2023 to August 2024), while the\nvertical axis lists the strategies. The color scale ranges from purple (low profits) to yellow (high profits).\nexplains why SB’s overall profit remains substantially lower.\nThe data also allows to evaluate the quality of our initial strategy pool selection. The fact that the\nglobally optimal strategy from all 28 candidates was contained within our chosen pool of three on 46.4%\nofthedaysconfirmsthatourselectionprocesseffectivelycapturesthebest-performingstrategyinnearly\nhalf of all trading scenarios. Finally, the results reaffirm the market dynamics of the study period: the\n’Only FCR’ strategy proved to be the single best choice on a remarkable 37.1% of all days, underscoring\nthedominanceoftheFCRmarketandexplainingwhythetop-performingstrategiesareheavilyweighted\ntowards FCR commitments.\nFigure 8 shows the cumulative profits of the strategies during the out-of-sample period. We can see\nthat Only IDM is clearly the worst strategy, while all mixed strategies earn profits in a comparable\nrange. In accordance with the risk-free nature of the RI, the profits increase monotonically over time,\nand the slope substantially increases around the middle of the observation period, which is mainly due\nto the increase in profits in the FCR market.\nFigure9displaysnormalizedweeklyprofitsofdifferentstrategies5. Theresultsrevealcleartemporal\n5normalizedweeklyprofits= weeklyprofits-min(weeklyprofits)\nmax(weeklyprofits)-min(weeklyprofits)\n22\nand strategic patterns. In particular, the dynamic strategies (CV-28, CV-3, LCS) consistently achieve\nhigher profits compared to the other four strategies. In particular, there is a pronounced increase in\nprofitability between May and July 2024, when most dynamic strategies reach their peak performance\n(indicated by the yellow regions). In contrast, during late 2023 and early 2024, profits remain relatively\nlow across all strategies. Furthermore, LCS exhibits a more stable and resilient performance compared\nto DS and SB. In particular, during the low-profit months from November 2023 to February 2024, LCS\nsustainshigherprofitlevels,avoidingthesharpdeclinesseeninDSandSB.Similarly,inMarchandApril\n2024, LCS continues to outperform both strategies, maintaining moderate profitability where DS and\nSBweaken. Moreover, duringthepeakperiodbetweenMayandJuly2024, LCStrackscloselywithCV-\n28 and CV-3, showing consistently high profit levels (yellow regions), while DS and SB display greater\nvariability. This highlights that LCS is not only more robust in low-profit phases but also competitive\nwith the strongest combined strategies in high-profit periods.\nThecomputationalrequirementsofourapproachcanbedividedintotwophases: theinitialbacktest\nandthedailyoperationaldeployment. Theinitialbacktest,whichinvolvessimulatingtheRIperformance\nfor each FCR strategy over the entire dataset, is computationally intensive and requires approximately\n7 hours per strategy. However, this process is highly parallelizable, as simulations for strategies are\nindependent of each other. We managed this workload by performing the evaluations on 48 AWS Batch\ninstances, each equipped with 4 vCPUs and 24 GB of memory.\nIn a live trading environment, the daily computational workflow is highly efficient. The process\nbegins by updating the training data, which involves running a one-day backtest for each of the 28\ncandidate strategies using market data from the most recently completed day. This simulation step\ntakes approximately one minute. Immediately following the data update, the optimal strategy pool is\nre-selected and the XGBoost classifier is retrained to generate a bid for the upcoming day. The entire\ndaily process, from the initial data update to the final prediction, is completed in under two minutes\non a standard desktop computer. This rapid execution time confirms that our LCS framework is not\ncomputationally prohibitive and is well suited for practical deployment in real-world trading operations.\n5 Conclusion\nThis paper introduces a novel hierarchical approach to optimize BESS participation in the frequency\ncontainment reserve and intraday markets. Our method effectively decouples the complex problem into\ntwo manageable stages: a high-frequency rolling intrinsic algorithm handles the continuous intraday\ntrading and state of charge management, while an XGBoost-based classifier selects the optimal FCR\ncommitment from a pre-screened pool of complementary strategies. Our out-of-sample backtest on\nhistorical market data validates the practical value of this approach; the proposed learned classifier\nstrategy substantially outperforms static and naive dynamic benchmarks, closing a significant portion of\nthe gap to theoretical maximum profit.\nDespite its strong performance, the framework has limitations that open clear avenues for future\nresearch. A primary constraint is the reliance on a small and curated set of FCR strategies. Prevailing\nmarket conditions have heavily favored the FCR market, causing the most profitable strategies to be\nhighly similar, allocating maximum capacity to FCR. This clustering creates a difficult classification\nproblem with severe class imbalance, limiting the performance ceiling of the LCS. Furthermore, for\ntractability,ourmodelassumeszero-pricebidsinthepay-as-clearedFCRauctionandusesthesuboptimal\nmyopic RI for intraday trading.\n23\nFutureworkshoulddirectlyaddresstheselimitations. First,enhancingtheintradaytradingalgorithm\nisakeypriority. BymovingbeyondtheRItomoresophisticatedmethodssuchasreinforcementlearning,\ntheprofitabilityoftheIDMcouldbeincreased. Thiswouldnaturallyleadtoamorediversesetofviable\nstrategies, mitigating the class imbalance and making the classification task more effective. Second, a\npromisingextensionistoendogenizetheFCRbidprice. Insteadofassumingzero-pricebids,aforecasting\nmodel could estimate the opportunity cost of FCR participation, effectively the IDM profit foregone for\neach EFA block. This would enable a more sophisticated bidding strategy that optimizes both the\nquantity and the price of the FCR commitment, further enhancing overall profitability.\nReferences\nR.A¨ıd,P.Gruet,andH.Pham.Anoptimaltradingprobleminintradayelectricitymarkets.Mathematics\nand Financial Economics, 10:49–85, 2016.\nM. Ansari, A. T. Al-Awami, E. Sortomme, and M. A. Abido. Coordinated bidding of ancillary services\nfor vehicle-to-grid using fuzzy optimization. IEEE Transactions on Smart Grid, 6(1):261–270, 2015.\ndoi: 10.1109/TSG.2014.2341625.\nP.AsteroandC.Evens. Stochasticbiddingstrategyforelectricalvehiclechargingstationstoparticipate\nin frequency containment reserves markets. IET Generation, Transmission & Distribution, 14(13):\n2566–2572, 2020.\nG.BertrandandA.Papavasiliou.Reinforcement-learningbasedthresholdpoliciesforcontinuousintraday\nelectricity market trading. In 2019 IEEE power & energy society general meeting (PESGM), pages\n1–5. IEEE, 2019a.\nG. Bertrand and A. Papavasiliou. Adaptive trading in continuous intraday electricity markets for a\nstorage unit. IEEE Transactions on Power Systems, 35(3):2339–2350, 2019b.\nF. Biggins, S. Homan, J. Ejeh, and S. Brown. To trade or not to trade: Simultaneously optimising\nbattery storage for arbitrage and ancillary services. Journal of Energy Storage, 50:104234, 2022.\nBloombergNEF. Lithium-ionbatterypackpricesseelargestdropsince2017,fallingto$115perkilowatt-\nhour. Technical report, BloombergNEF, 2024. URL https://about.bnef.com/insights/commodit\nies/lithium-ion-battery-pack-prices-see-largest-drop-since-2017-falling-to-115-per\n-kilowatt-hour-bloombergnef/. Accessed: August 23, 2025.\nI. Boukas, D. Ernst, T. Th´eate, A. Bolland, A. Huynen, M. Buchwald, C. Wynants, and B. Corn´elusse.\nA deep reinforcement learning framework for continuous intraday market bidding. Machine Learning,\n110:2335–2387, 2021.\nC. Brivio, S. Mandelli, and M. Merlo. Battery energy storage system for primary control reserve and\nenergy arbitrage. Sustainable Energy, Grids and Networks, 6:152–165, 2016.\nG. Broneske and D. Wozabal. How do contract parameters influence the economics of vehicle-to-grid?\nManufacturing & Service Operations Management, 19(1):150–164, 2017.\nT. Chen and C. Guestrin. Xgboost: A scalable tree boosting system. In Proceedings of the 22nd acm\nsigkdd international conference on knowledge discovery and data mining, pages 785–794, 2016.\n24\nW. Cole and A. Karmakar. Cost projections for utility-scale battery storage: 2023 update. Technical\nReport NREL/TP-6A40-85332, National Renewable Energy Laboratory (NREL), 2023. URL https:\n//docs.nrel.gov/docs/fy23osti/85332.pdf.\nJ. De Boeck, B. Fortz, M. Labb´e, E´. Marcotte, P. Marcotte, and G. Savard. Bidding in day-ahead\nelectricity markets: A dynamic programming framework. Computers & Operations Research, 179:\n107024, 2025.\nI. Dimoulkas, M. Amelin, and M. R. Hesamzadeh. Forecasting balancing market prices using hidden\nmarkovmodels. In2016 13th International Conference on the European Energy Market (EEM),pages\n1–5. IEEE, 2016.\nP. H. Divshali and C. Evens. Optimum operation of battery storage system in frequency containment\nreserves markets. IEEE Transactions on Smart Grid, 11(6):4906–4915, 2020.\nEPEX SPOT SE. Epex spot annual reports, 2020-2023. URL https://www.epexspot.com/. Accessed:\n2024-06-17.\nEuropean Commission. Commission regulation (eu) 2015/1222 of 24 july 2015 establishing a guideline\non capacity allocation and congestion management. Official Journal of the European Union, L 197:\n24–72, 2015.\nE.FariaandS.-E.Fleten. Day-aheadmarketbiddingforanordichydropowerproducer: takingtheelbas\nmarket into account. Computational Management Science, 8:75–101, 2011.\nJ. Figgener, B. Tepe, F. Ru¨cker, I. Schoeneberger, C. Hecht, A. Jossen, and D. U. Sauer. The influence\nof frequency containment reserve flexibilization on the economics of electric vehicle fleet operation.\nJournal of Energy Storage, 53:105138, 2022.\nS.-E. Fleten and T. K. Kristoffersen. Short-term hydropower production planning by stochastic pro-\ngramming. Computers & Operations Research, 35(8):2656–2671, 2008.\nS. Goodarzi, H. N. Perera, and D. Bunn. The impact of renewable energy forecast errors on imbalance\nvolumes and electricity spot prices. Energy Policy, 134:110827, 2019.\nC. Graf, T. Kuppelwieser, and D. Wozabal. Frequent auctions for intraday electricity markets. The\nEnergy Journal, (45), 2024.\nJ. Gray and P. Khandelwal. Towards a realistic gas storage model. Commodities Now, 7(2):1–4, 2004.\nL.Grinsztajn,E.Oyallon,andG.Varoquaux.Whydotree-basedmodelsstilloutperformdeeplearningon\ntypicaltabulardata? InS.Koyejo,S.Mohamed,A.Agarwal,D.Belgrave,K.Cho,andA.Oh,editors,\nAdvances in Neural Information Processing Systems, volume 35, pages 507–520. Curran Associates,\nInc., 2022.\nD. R. Jiang and W. B. Powell. Optimal hour-ahead bidding in the real-time electricity market with\nbattery storage using approximate dynamic programming. INFORMS Journal on Computing, 27(3):\n525–543, 2015.\nF.KaranfilandY.Li. Theroleofcontinuousintradayelectricitymarkets: Theintegrationoflarge-share\nwind power generation in denmark. The Energy Journal, 38(2), 2017.\n25\nT. Kempitiya, S. Sierla, D. De Silva, M. Yli-Ojanper¨a, D. Alahakoon, and V. Vyatkin. An artificial\nintelligenceframeworkforbiddingoptimizationwithuncertaintyinmultiplefrequencyreservemarkets.\nApplied Energy, 280:115918, 2020.\nH. Kongelf, K. Overrein, G. Klæboe, and S.-E. Fleten. Portfolio size’s effects on gains from coordinated\nbidding in electricity markets: A case study of a norwegian hydropower producer. Energy Systems,\n10:567–591, 2019.\nE.Kraft,D.Keles,andW.Fichtner. Modelingoffrequencycontainmentreservepriceswitheconometrics\nand artificial intelligence. Journal of Forecasting, 39(8):1179–1197, 2020.\nS. Kulakov and F. Ziel. The impact of renewable energy forecasts on intraday electricity prices. arXiv\npreprint arXiv:1903.09641, 2019.\nT.KuppelwieserandD.Wozabal. Liquiditycostsonintradaypowermarkets: Continuoustradingversus\nauctions. Energy Policy, 154:112299, 2021.\nT. Kuppelwieser and D. Wozabal. Intraday power trading: toward an arms race in weather forecasting?\nOR Spectrum, 45(1):57–83, 2023.\nN. L¨ohndorf and D. Wozabal. The value of coordination in multimarket bidding of grid energy storage.\nOperations research, 71(1):1–22, 2023.\nN. L¨ohndorf, D. Wozabal, and S. Minner. Optimizing trading decisions for hydro storage systems using\napproximate dual dynamic programming. Operations Research, 61(4):810–823, 2013.\nG. Marcjasz, B. Uniejewski, and R. Weron. Beating the na¨ıve—combining lasso with na¨ıve intraday\nelectricity price forecasts. Energies, 13(7):1667, 2020.\nM.NarajewskiandF.Ziel. Econometricmodellingandforecastingofintradayelectricityprices. Journal\nof Commodity Markets, 19:100107, 2020.\nR. Shwartz-Ziv and A. Armon. Tabular data: Deep learning is not all you need. Information Fusion,\n81:84–90, 2022.\nR. Sioshansi. Welfare impacts of electricity storage and the implications of ownership structure. The\nEnergy Journal, 31(2), 2010.\nE.SortommeandM.A.El-Sharkawi. Optimalschedulingofvehicle-to-gridenergyandancillaryservices.\nIEEE Transactions on Smart Grid, 3(1):351–359, 2012. doi: 10.1109/TSG.2011.2164099.\nT. Thien, D. Schweer, D. vom Stein, A. Moser, and D. U. Sauer. Real-world operating strategy and\nsensitivity analysis of frequency containment reserve provision with battery energy storage systems in\nthe german market. Journal of energy storage, 13:143–163, 2017.\nB.Uniejewski,G.Marcjasz,andR.Weron.Understandingintradayelectricitymarkets: Variableselection\nand very short-term price forecasting using lasso. International Journal of Forecasting, 35(4):1533–\n1547, 2019.\nD. Wozabal and G. Rameseder. Optimal bidding of a virtual power plant on the spanish day-ahead and\nintraday market for electricity. European Journal of Operational Research, 280(2):639–655, 2020.\n26\nB. Xu, A. Oudalov, J. Poland, A. Ulbig, and G. Andersson. Bess control strategies for participating in\ngrid frequency regulation. IFAC Proceedings Volumes, 47(3):4024–4029, 2014.\nY. J. A. Zhang, C. Zhao, W. Tang, and S. H. Low. Profit-maximizing planning and control of battery\nenergy storage systems for primary frequency control. IEEE Transactions on Smart Grid, 9(2):712–\n723, 2016.\n27\n",
    "tables": [],
    "images": []
  }
]