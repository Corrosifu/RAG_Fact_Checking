[
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 0,
    "text": "reward models are metrics in a trench coat - preprint # # r eward m odels are m etrics in a t rench c oat * * sebastian gehrmann * * bloomberg sgehrmann8 @ bloomberg. net a bstract the emergence of reinforcement learning in post - training of large language models has sparked significant interest in reward models. reward models assess the quality of sampled model outputs to generate training signals. this task is also performed by evaluation metrics that monitor the performance of an ai model. we find that the two research areas are mostly separate, leading to redundant terminology and repeated pitfalls. common challenges include susceptibility to spurious correlations, impact on downstream reward hacking, methods to improve data quality, and approaches to meta - evaluation. our position paper argues that a closer collaboration between the fields can help overcome these issues. to that end, we show how metrics outperform reward models on specific tasks and provide an extensive survey of the two areas. grounded in this survey, we point to multiple research topics in which closer alignment can improve reward models and metrics in areas such as preference elicitation methods, avoidance of spurious correlations and reward hacking, and calibration - aware meta - evaluation. 1 i ntroduction reinforcement learning ( rl ) plays a major role in post - training, aligning, and adapting large language models ( llms ) to a broad range of tasks ( openai, 2025 ; comanici et al., 2025 ; xai, 2025 ; kimi et al., 2025 ; guo et al., 2025 ). scaling laws apply to reinforcement learning from human feedback ( rlhf, christiano et al., 2017 ) similarly as to the rest of the training stack ( bai et al., 2022a ). as such, scalable alternatives to human feedback have become popular, either in the form of verifiable rewards ( lambert et al., 2024 ) or in the form of models that assess the quality of model outputs ( li et al., 2018 ). developing robust and reliable _ reward models _ is crucial, as the downstream rl models can experience reward hacking ( amodei et al., 2016 ), optimizing for spurious correlations in the reward model rather than learning the intended behavior. to overcome these issues, reward models have experienced significant research interest. in parallel to research on reward models, _ model - based evaluation _ of generated text has similarly seen a surge in interest, enabling a switch from “ traditional ” lexical metrics like bleu ( papineni et al., 2002 ) and rouge ( lin, 2004 ) to learned models ( ma et al., 2018 ; 2019 ) and prompt - based approaches referred to as llm - as - a - judge ( zheng et al., 2023 ). the two fields present two sides of the same coin : while reward models assess output quality to directly improve models, evaluation metrics assess output quality to identify potential areas of improvement. both fields seek to develop classifiers that consume generated content as input and assign a goodness score as output. both fields strongly benefit from rigor, consideration of the sociotechnical context in which a system is deployed, and improved correlation between model - based judgments and expert human raters. the key difference between the two is that while metrics tend to be more specialized, reward models tend to assess broad capabilities spanning many tasks. due to their similarities, one might expect the fields learn from and inform each other, and that breakthroughs transfer quickly between them. our position paper argues that while this should be the case, it is not. instead, the academic literature in these fields only infrequently informs each other and the fields are actively developing and using different terminology for the same methods. while metrics are commonly used to generate training data for reward models ( malik et al., 2025 ), and are thus instrumental to reward model performance, little attention is being paid to which metrics generate that data. we demonstrate this phenomenon by analyzing the citation graphs of papers in each sub - field, showing that inter - field citations account for fewer than 10 % of total cited papers. we further support this claim by presenting results from 1 reward models are metrics in a trench coat - preprint two small experiments : one in which we apply a metric to a reward modeling benchmark and one where we apply reward modeling techniques to a factuality evaluation benchmark. the results show that reward modeling approaches lag behind dedicated metrics for these specialized tasks, providing opportunities for improvements and motivating cross - testing on their respective benchmarks. motivated by these findings, we conduct an extensive survey of the two fields and their intersection. we lay out scenarios in which we can use all the tools at our disposal and showcase how it could lead to better reward models and evaluation metrics. specifically, we argue that a closer collaboration could lead to major progress in overcoming reward hacking, in preference elicitation, and in metaevaluation"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 1,
    "text": "to which metrics generate that data. we demonstrate this phenomenon by analyzing the citation graphs of papers in each sub - field, showing that inter - field citations account for fewer than 10 % of total cited papers. we further support this claim by presenting results from 1 reward models are metrics in a trench coat - preprint two small experiments : one in which we apply a metric to a reward modeling benchmark and one where we apply reward modeling techniques to a factuality evaluation benchmark. the results show that reward modeling approaches lag behind dedicated metrics for these specialized tasks, providing opportunities for improvements and motivating cross - testing on their respective benchmarks. motivated by these findings, we conduct an extensive survey of the two fields and their intersection. we lay out scenarios in which we can use all the tools at our disposal and showcase how it could lead to better reward models and evaluation metrics. specifically, we argue that a closer collaboration could lead to major progress in overcoming reward hacking, in preference elicitation, and in metaevaluation. we also discuss areas in which the fields differ and should not interact, and how this relates to goodhart ’ s law, which states that a measure ceases to be a good measure when it becomes a target. grounded in these discussions, we make specific recommendations to researchers working on reward models and evaluation metrics on how the separation can be overcome. 2 h ow did modern r eward m odels come about? as part of the rising popularity of deep learning, rl started to be explored for tasks like structured prediction ( [UNK] et al., 2009 ; ross et al., 2011 ), image recognition ( mnih et al., 2014 ; ba et al., 2015 ) and for agents like the neural turing machine ( zaremba & sutskever, 2015 ). successfully training a model via rl hinges on being able to generate reward signals. this includes being able to derive the value of intermediate states. as sutton & barto ( 2018 ) argue, “ the most important component of almost all reinforcement learning algorithms we consider is a method for efficiently estimating values. ” commenting on this issue, yann lecun famously criticized rl for having much sparser rewards than self - supervised learning during his talk “ predictive learning ” ( lecun, 2016 ). this issue applies to generated language : generation has a combinatorially large state space with its sequential token choices from a large vocabulary, and no single objective number can represents the value of an output ( gehrmann et al., 2023 ). for that reason, generation models are typically trained via teacher - forcing, a supervised approach that shows the model a ground - truth token at each prediction step. this happens only during training, not at test - time. moreover, while models are trained with a cross - entropy objective, they are evaluated via different metrics. ranzato et al. ( 2016 ) coined the term _ exposure bias _ for this mismatch between training and test time. if there was a way to directly optimize for the metric ( s ) we care about, the exposure bias could be overcome. evaluation metrics are designed to act as a proxy for human judgments and are thus wellsuited to serve as a reward function. while some inference - time methods optimize metrics ( wiseman & rush, 2016 ; freitag et al., 2021b ), reinforcement learning is a natural fit to optimize for these metrics during training. reinforce ( williams, 1992 ) and minimum risk training ( duda & hart, 1974 ) generate metric - based reward signals using sampled token sequences, and actor - critic approaches estimate partial rewards for predicted tokens ( bahdanau et al., 2017 ). various instantiations of these approaches were used for machine translation ( ranzato et al., 2016 ; shen et al., 2016 ), image captioning ( rennie et al., 2017 ), video captioning ( pasunuru & bansal, 2017 ), and summarization ( paulus et al., 2018 ). at that time, the reward models were measuring lexical overlap between a generated sequence and a ground truth ( e. g., papineni et al., 2002 ; lin, 2004 ; vedantam et al., 2015 ). these metrics have wellunderstood drawbacks ( e. g., reiter, 2018 ; freitag et al., 2020 ), especially for rl ( choshen et al., 2020 ). among others, they lead to _ reward hacking _ where models generate non - fluent language that maximizes reward scores ( amodei et al., 2016 ). researchers worked to overcome these issues, for example by regularizing the training process by combining cross - entropy losses with rl or by handcrafting additional reward functions ( pasunuru & bansal, 2018 ; [UNK] et al., 2018 ; wu et al., 2018a ). the advent"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 2,
    "text": "and summarization ( paulus et al., 2018 ). at that time, the reward models were measuring lexical overlap between a generated sequence and a ground truth ( e. g., papineni et al., 2002 ; lin, 2004 ; vedantam et al., 2015 ). these metrics have wellunderstood drawbacks ( e. g., reiter, 2018 ; freitag et al., 2020 ), especially for rl ( choshen et al., 2020 ). among others, they lead to _ reward hacking _ where models generate non - fluent language that maximizes reward scores ( amodei et al., 2016 ). researchers worked to overcome these issues, for example by regularizing the training process by combining cross - entropy losses with rl or by handcrafting additional reward functions ( pasunuru & bansal, 2018 ; [UNK] et al., 2018 ; wu et al., 2018a ). the advent of metrics measuring semantic rather than lexical similarity led to significantly reduced reward - hacking since the new models avoided over - optimizing for the generation of relevant words without fluent context ( li et al., 2018 ; yasui et al., 2019 ; scialom et al., 2019 ). [ 1 ] these models led to a clear path whereby new metrics could be validated and then used as reward models. for 1 this is also related to generative adversarial networks ( goodfellow et al., 2014 ) for generation ( e. g., yu et al., 2017 ; wu et al., 2018b ) where a discriminator differentiates generated text from the ground truth, thus similarly generating a model - based signal for human - likeness. 2 reward models are metrics in a trench coat - preprint | p < br > evaluation metric | col2 | col3 | col4 | aper count over t | col6 | col7 | ime b | y fiel | d | col11 | col12 | col13 | col14 | col15 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | ~ ~ reward ~ ~ < br > llm as | ~ ~ model ~ ~ < br > a judge | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | figure 1 : the figure shows the number of publications per year in the three subfields according to a keyword search on google scholar. publications on evaluation metrics have slowed, even though research on reward modeling and llm - as - a - judge is quickly rising in popularity. if the fields were actively learning from one another, one could assume that mentions of ” evaluation metrics ” should be growing alongside these newly emerging fields, but they are not. example, the metric bleurt was introduced ( sellam et al., 2020 ), evaluated as part of the wmt metrics shared task ( mathur et al., 2020 ), and then assessed as reward model ( shu et al., 2021 ). in parallel to the work above, the concept of _ reinforcement learning from human feedback ( rlhf ) _ was introduced for game playing and robotics ( christiano et al., 2017 ). in an essay titled “ scalable agent alignment via reward modeling : a research direction ”, leike et al. ( 2018 ) propose capturing human preferences via dedicated _ reward models _. this research culminated in the work on rlhf for summarization ( stiennon et al., 2020 ) which popularized proximal policy optimization ( ppo, schulman et al., 2017 ) as rl approach for text generation. while stiennon et al. ( 2020 ) analyzed correlations between rouge and their human preference data, they did not use widely accepted alignment metrics, existing human preference corpora, or the semantic similarity evaluation metrics discussed above. in the followup work on instructgpt ( ouyang et al., 2022 ), there are no references to the generation rl literature and no evaluation of the reward model. subsequent work introduced the notion of ai feedback as reward models ( bai et al., 2022b ; lee et al., 2024a ) and argued that"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 3,
    "text": "an essay titled “ scalable agent alignment via reward modeling : a research direction ”, leike et al. ( 2018 ) propose capturing human preferences via dedicated _ reward models _. this research culminated in the work on rlhf for summarization ( stiennon et al., 2020 ) which popularized proximal policy optimization ( ppo, schulman et al., 2017 ) as rl approach for text generation. while stiennon et al. ( 2020 ) analyzed correlations between rouge and their human preference data, they did not use widely accepted alignment metrics, existing human preference corpora, or the semantic similarity evaluation metrics discussed above. in the followup work on instructgpt ( ouyang et al., 2022 ), there are no references to the generation rl literature and no evaluation of the reward model. subsequent work introduced the notion of ai feedback as reward models ( bai et al., 2022b ; lee et al., 2024a ) and argued that language model probabilities can be directly used to model rewards in a bradley - terry model ( rafailov et al., 2023 ; bradley & terry, 1952 ). neither draws the connection to the role that perplexity and model probabilities played in existing evaluations ( e. g., lewis et al., 2020 ; min et al., 2023 ). this separation culminated in benchmarks for reward models ( e. g., frick et al., 2025 ; lambert et al., 2025 ; liu et al., 2025c ; zhou et al., 2025 ) and for metrics ( e. g., honovich et al., 2022 ; clark et al., 2023 ; freitag et al., 2024 ) that exist in parallel without meaningful interaction. this raises the question of whether this disconnect is part of a broader trend. and if the two fields were integrated tighter, would we be in a better state today? and what should one learn from the other? 3 q uantifying the r esearch f ield s eparation figure 1 establishes the need for this investigation by showing the number of papers found on google scholar per year that contain the exact strings “ evaluation metric ”, “ reward model ”, and “ llm - asa - judge ”. we include “ llm - as - a - judge ” as an emerging field that has similarly experienced rapid growth and which also uses language models to estimate the quality of generated output. notably, despite the exponential growth of the two emerging topics, the number of papers mentioning evaluation metrics decreased in 2024, with the trend continuing into 2025. if the terminology was merely changing, one would expect the new literature to still build on the older one. for that reason, we empirically study the cause of this phenomenon by conducting a citation analysis. we select up to 300 papers per field per year ( 2021 – 2025 ) via the semantic scholar graph api, with sensitivity checks at 100 / 200 yielding similar trends ( kinney et al., 2023 ). [ 2 ] for 2 [ documented at https : / / api. semanticscholar. org / api - docs / graph. the search results ] ( https : / / api. semanticscholar. org / api - docs / graph ) in the maximum 300 papers for the first two fields and 8, 25, and 43 papers respectively for llm - as - a - judge over the past three years. more details on this analysis in appendix a. 3 reward models are metrics in a trench coat - preprint ( a ) the fraction of citations from one field to another, based on keywords in cited papers. ( b ) the fraction of citations to papers in venues associated with a research area. figure 2 : in our analysis of citation dynamics across the three fields, we find that evaluation papers tend to cite other evaluation papers across research fields, while reward model papers mostly cite each other and are highly focused on machine learning venues. llm - as - a - judge work mostly cites ml and nlp venues, but has less clear citation dynamics. each paper, we additionally retrieve its citations, yielding approximately 10, 000 citations per year for each field to analyze. as a proxy to identify whether a paper in field a cites a paper in field b, we select _ signaling terms _ for each field : ( 1 ) “ metric ( s ) ”, ( 2 ) “ reward ”, “ reinforcement ”, “ policy ”, and ( 3 ) “ judge ”. if any of those terms appears in the title or abstract of a cited paper, we count this as an inter - field or intra - field citation. the results in figure 2a show that evaluation metrics and reward models are distinct fields, with only few inter - field citations but many intra - field citations. this is especially pronounced for"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 4,
    "text": "papers across research fields, while reward model papers mostly cite each other and are highly focused on machine learning venues. llm - as - a - judge work mostly cites ml and nlp venues, but has less clear citation dynamics. each paper, we additionally retrieve its citations, yielding approximately 10, 000 citations per year for each field to analyze. as a proxy to identify whether a paper in field a cites a paper in field b, we select _ signaling terms _ for each field : ( 1 ) “ metric ( s ) ”, ( 2 ) “ reward ”, “ reinforcement ”, “ policy ”, and ( 3 ) “ judge ”. if any of those terms appears in the title or abstract of a cited paper, we count this as an inter - field or intra - field citation. the results in figure 2a show that evaluation metrics and reward models are distinct fields, with only few inter - field citations but many intra - field citations. this is especially pronounced for reward models where almost 40 % intra - field citations. the numbers for evaluation metrics trend lower at around 15 – 20 % which we attribute to the heterogeneity of the field ; for example, papers on metrics for summarization cite summarization papers rather than only evaluation papers. llm - as - a - judge is an outlier, with too few papers to draw definitive conclusions. we find more evidence for the field separation when we analyze the venues of the cited papers. for this, we categorize venues into fields ( e. g., iclr as ml venue ) and calculate the percentage of citations to papers published in the various fields. the results in figure 2b reveal that reward model research predominantly cites research in machine learning venues and not nlp and computer vision. in contrast, evaluation metric work is evenly distributed and llm - as - a - judge work focuses on ml and nlp. [ 3 ] since all observed trends are stable across years, we conclude that the three research fields are largely separate with limited interaction. 4 w hat can one learn from the other? a rebuttal to our proposition that the two fields should learn from each other is that maybe there is little to learn. we thus highlight two scenarios in which a closer cross - field interaction could have changed conclusions or yielded additional insights. 4. 1 m etrics can perform well on r eward m odel b enchmarks the recently introduced rewardbench - m ( gureja et al., 2025 ) uses a subset of the maple dataset ( zhu et al., 2024 ) to assess reward models on translation evaluation. the task requires identifying which of two translation outputs was rated higher by human evaluators. the data is split into an easy and difficult subset based on the difference of human scores of the two provided translations. while all their tested models perform nearly perfectly on the easy subset, gureja et al. ( 2025 ) remark that “ _ models that perform well on easy tasks can struggle to maintain the same level of per - _ 3 we omit fields with _ ≤ _ 5 % of citations in all years, including speech, ir, and hci. ambiguous venues like preprint servers or broad venues like aaai are excluded from this analysis. detailed list in appendix c. 4 reward models are metrics in a trench coat - preprint de _ → _ en en _ → _ de zh _ → _ en en _ → _ zh gpt - 4o * * 71. 0 * * 61. 0 * * 77. 0 * * 80. 0 aya expanse 32b 62. 0 * * 69. 0 * * 76. 0 79. 0 c omet k iwi - da ( 2022 ) 59. 0 * * 68. 0 * * 59. 0 * * 86. 0 * * table 1 : results on the hard machine translation evaluation subset of rewardbench - m. for nonenglish evaluations, a 3 year old model with 550m parameters outperforms much larger llms. _ formance on harder translations, indicating the need for more sophisticated mechanisms to handle _ _ [... ] challenging scenarios _ ”. however, no machine translation evaluation metric was assessed as a baseline. thus, to test this hypothesis, we evaluate the three - year - old metric cometkiwi ( rei et al., 2022 ) which is based on infoxlm ( chi et al., 2021 ) and has only 550m parameters. the results of cometkiwi alongside the two best - performing models on the challenging translation test set of rewardbench - m ( dang et al., 2024 ; hurst et al., 2024 ) are shown in table 1. despite its age and being significantly smaller, cometkiwi performs similarly on german and outperforms the other models on chinese, with the overall best evaluation performance for the non - english generated text, demonstrating that the “"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 5,
    "text": "year old model with 550m parameters outperforms much larger llms. _ formance on harder translations, indicating the need for more sophisticated mechanisms to handle _ _ [... ] challenging scenarios _ ”. however, no machine translation evaluation metric was assessed as a baseline. thus, to test this hypothesis, we evaluate the three - year - old metric cometkiwi ( rei et al., 2022 ) which is based on infoxlm ( chi et al., 2021 ) and has only 550m parameters. the results of cometkiwi alongside the two best - performing models on the challenging translation test set of rewardbench - m ( dang et al., 2024 ; hurst et al., 2024 ) are shown in table 1. despite its age and being significantly smaller, cometkiwi performs similarly on german and outperforms the other models on chinese, with the overall best evaluation performance for the non - english generated text, demonstrating that the “ sophisticated mechanisms ” needed in current reward models already exist. building on this observation, the metametrics approach ( anugraha et al., 2024 ) has been evaluated on the latest mt metrics shared task ( freitag et al., 2024 ) and on the rewardbench leaderboard ( lambert et al., 2025 ), scoring highly in both, although not with the same model. 4. 2 r eward m odels can underperform on m etrics b enchmarks another area in which reward model and metrics benchmarks are aligned in their goals is the assessment of how well models can assess factuality and attribution. there exist benchmarks for metrics ( honovich et al., 2022 ), model performance ( jacovi et al., 2025 ), and reward models ( malik et al., 2025 ) that assess factuality. recent work demonstrates the effectiveness of llm judge ( and reward ) models ( e. g., calderon et al., 2025 ; hashemi et al., 2024 ), some even finding that dedicated finetuned evaluation models underperform llm judges ( huang et al., 2025 ). among these benchmarks, the metrics benchmark seahorse ( clark et al., 2023 ) is the largest with over 100, 000 human judgments of summarization quality aspects across multiple languages. for this experiment, we prompt various llms with the same instructions provided to human annotators in seahorse to give a binary judgment whether a summary is attributable to an article. [ 4 ] due to a lack of data availability, we exclude the wikilingua ( ladhak et al., 2020 ) subset of seahorse and focus only on xlsum ( hasan et al., 2021 ) and mlsum ( scialom et al., 2020 ), retaining 7, 793 of the 18, 330 test examples. we report pearson correlation ( _ ρ _ ) and accuracy. the results ( table 2 ) show that llms underperform the dedicated model trained on in - domain data. this remains true even if we assess judge models with a high reasoning budget like gemini 2. 5 pro and gpt - 5. in fact, the two reasoning models have an 89 % agreement rate, higher than the inter - rater agreement of 73 % reported in the paper, indicating that the models look for similar input and outputfeatures to make their prediction. the results are fairly consistent across languages. interestingly, all models score lowest on english among the evaluated languages. overall, our findings disagree with huang et al. ( 2025 ) who show that llm judges can outperform dedicated metrics in similar setups, while agreeing with bavaresco et al. ( 2025 ) who show low llm judge correlations for summarization evaluation. multiple explanations exist for the results presented here, including annotation artifacts that cause a lower performance of the llm judge setup. however, we can conclude that for evaluating attribution for summarization, it remains unclear whether llm judges have caught up to dedicated models, a question that requires further rigorous study. this conclusion mirrors the argument by chehbouni et al. ( 2025 ) that the “ rapid and widespread adoption [ of llm judges ] may have occurred prematurely ”. moreover, as shown in table 2, the llm judge setup outperforms a strong natural language inference model ( nli ) baseline ( conneau et al., 2018 ). as such, this setup could still be useful in cases where dedicated training data for a reward model or evaluation metric is unavailable. 4 we optimized performance on the validation set to minimize the effect of the prompt format. 5 reward models are metrics in a trench coat - preprint _ ρ _ acc. % rouge - l 0. 13 mt5 xnli 0. 43 mt5 seahorse 0. 59 gpt"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 6,
    "text": "performance of the llm judge setup. however, we can conclude that for evaluating attribution for summarization, it remains unclear whether llm judges have caught up to dedicated models, a question that requires further rigorous study. this conclusion mirrors the argument by chehbouni et al. ( 2025 ) that the “ rapid and widespread adoption [ of llm judges ] may have occurred prematurely ”. moreover, as shown in table 2, the llm judge setup outperforms a strong natural language inference model ( nli ) baseline ( conneau et al., 2018 ). as such, this setup could still be useful in cases where dedicated training data for a reward model or evaluation metric is unavailable. 4 we optimized performance on the validation set to minimize the effect of the prompt format. 5 reward models are metrics in a trench coat - preprint _ ρ _ acc. % rouge - l 0. 13 mt5 xnli 0. 43 mt5 seahorse 0. 59 gpt - 4o 0. 47 73. 3 gemini 2. 0 flash 0. 42 72. 1 gemini 2. 5 flash 0. 48 73. 8 claude sonnet 4 0. 45 70. 1 _ + reasoning _ gemini 2. 5 pro 0. 50 73. 9 gpt - 5 0. 47 70. 2 table 2 : pearson _ ρ _ coefficient and binary prediction accuracy on seahorse for identifying whether a summary is * * attributable * * to a source article. the baselines are finetuned mt5 xxl models by clark et al. ( 2023 ). the llm - as - a - judge approach is outperformed by a dedicated trained metric. 5 m etrics and reward models are ( not ) the same metrics and reward models both judge quality aspects of generated content with the goal of being aligned with human preferences. yet, they are not the same : they can differ in their design, application, training, and testing. to explore these aspects, we provide a survey of the two fields and discuss themes where a closer interaction could lead to mutually helpful insights. 5. 1 d esigning r eward m odels and e valuation m etrics * * sociotechnical context matters * * evaluation metrics tend to be narrowly focused on specific quality aspects. these quality aspects should follow clear and standardized definitions so that the metrics are transferable and produce scores that are understandable across organizations. a lack of transparency in how metrics are designed and the subsequent lack of reproducibility has been subject of much past criticism ( rankel et al., 2013 ; post, 2018 ; gehrmann et al., 2023 ). in contrast, if a reward model is the provider of training signals during reinforcement learning, it must therefore be able to score a myriad of tasks and output types. as such, modeling human preferences encompasses many aspects of preference beyond output quality, including whether a model correctly refuses undesired requests or avoids producing toxic language ( bai et al., 2022b ). these judgments depend on the specific application the model is used for and the policies governing this application. reward models that measure these application - specific aspects are inherently less transferrable and tied to the specific organizations that develop them ( gehrmann et al., 2025 ). following this reasoning, these reward models are inherently not comparable to another, which calls into question the utility of non - specific reward - modeling benchmarks. * * aspect - aligned reward models * * fine - grained assessments of ( partial ) generations are areas with extensive recent work in rl that more closely align with work on evaluation metrics ( gunjal et al., 2025 ; lightman et al., 2024 ). it is of particular interest, since a diverse set of reward signals can mitigate issues that arise from single - objective optimization ( freitag et al., 2021b ; zhang et al., 2024 ; fisch et al., 2024 ). a popular approach for this is to use reward models that score rubrics instead of providing generic preferences ( gunjal et al., 2025 ). rubrics are fine - grained evaluation criteria ( arora et al., 2025 ; hashemi et al., 2024 ), similar to those traditionally assessed by dedicated metrics. rubric - based prompted scoring, alongside learned reward models, is mentioned as an instrumental ingredient for post - training of models like gemini 2. 5 ( comanici et al., 2025 ). successfully assessing rubrics requires clear definitions of the evaluation categories ( howcroft et al., 2020 ). yet, even for popular concepts like “ hallucination rate ”, definitions can vary widely ( maynez et al., 2020 ; rashkin et al., 2023 ; ji et al., 2023 ). increasing the consistency of these definitions will be crucial as"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 7,
    "text": "et al., 2024 ). a popular approach for this is to use reward models that score rubrics instead of providing generic preferences ( gunjal et al., 2025 ). rubrics are fine - grained evaluation criteria ( arora et al., 2025 ; hashemi et al., 2024 ), similar to those traditionally assessed by dedicated metrics. rubric - based prompted scoring, alongside learned reward models, is mentioned as an instrumental ingredient for post - training of models like gemini 2. 5 ( comanici et al., 2025 ). successfully assessing rubrics requires clear definitions of the evaluation categories ( howcroft et al., 2020 ). yet, even for popular concepts like “ hallucination rate ”, definitions can vary widely ( maynez et al., 2020 ; rashkin et al., 2023 ; ji et al., 2023 ). increasing the consistency of these definitions will be crucial as reward models become more specific, and thus are designed more similar to evaluation 6 reward models are metrics in a trench coat - preprint metrics where the topic of fine - grained assessments is well - studied ( e. g., eyal et al., 2019 ; wang et al., 2020 ; fabbri et al., 2021 ; scialom et al., 2021 ; lee et al., 2024b ; wei et al., 2025 ). 5. 2 t raining r eward m odels and e valuation m etrics * * data collection * * the data collection methodology for any model must be aligned with its design goals. for reward models, this means reflecting the preferences of the intended audience of the downstream model, which can be extremely broad. since many aspects of generated text cannot be objectively assessed, this necessitates collecting feedback from diverse sources ( casper et al., 2023 ; metz et al., 2025 ). the culture and lived experience of raters can lead to drastically different subjective preference judgments ( e. g., aroyo et al., 2023 ; rastogi et al., 2024 ; 2025 ). another critical question to consider is whether the selected raters have sufficient expertise, as changes in annotation quality can lead to drastically different insights ( freitag et al., 2021a ; wei et al., 2024 ). in many cases, existing metrics and reward models already outperform non - expert raters, and only the highest quality annotations can further improve the models ( cui et al., 2023 ; liu et al., 2024 ; wen et al., 2025b ). moreover, wen et al. ( 2025a ) find that rl may produce errors that are increasingly difficult for humans to detect. however, hiring raters with expertise to judge long - form generation is notoriously challenging ( zhang et al., 2023 ). * * optimization targets * * design aspects such as access to a ground truth and the output format ( pairwise preferences, categorical labels, or continuous scores ) influence how models are developed. these choices depend on the downstream use case, and can have significant impact on model efficacy. for example, reference - less evaluation has improved significantly in recent years but still underperforms reference - based metrics ( ma et al., 2019 ; freitag et al., 2024 ). similar results were found for llm - as - a - judge setups ( krumdick et al., 2025 ). these choices are reflected in benchmarking practices ; many reward models produce pairwise comparisons, and their benchmarks consequently focus on this binary setup ( frick et al., 2025 ). in contrast, metrics typically generate continuous outputs, allowing for more flexible evaluation. by focusing primarily on pairwise judgments, reward model development may be ignoring the potential benefits of continuous scoring. another shared goal is the development of lightweight models that can run efficiently alongside larger models during inference or training. advances in distillation, quantization, parallelization, and pruning are therefore highly relevant to both fields. consequently, approaches to model compression that seek to train student models to outperform their teachers can equally benefit the development of both reward models and evaluation metrics ( kim et al., 2024 ; sun et al., 2023 ). 5. 3 t esting r eward m odels and e valuation m etrics * * identifying and debugging reward hacking * * a lack of correlation between reported reward model and downstream rl model performance has been attributed to limitations of the reward model ( ivison et al., 2024 ; kim et al., 2025 ; wen et al., 2025c ). when the reward model does not robustly generalize, or focuses on spurious correlations, it can lead to _ reward hacking _. amodei et al. ( 2016"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 8,
    "text": "shared goal is the development of lightweight models that can run efficiently alongside larger models during inference or training. advances in distillation, quantization, parallelization, and pruning are therefore highly relevant to both fields. consequently, approaches to model compression that seek to train student models to outperform their teachers can equally benefit the development of both reward models and evaluation metrics ( kim et al., 2024 ; sun et al., 2023 ). 5. 3 t esting r eward m odels and e valuation m etrics * * identifying and debugging reward hacking * * a lack of correlation between reported reward model and downstream rl model performance has been attributed to limitations of the reward model ( ivison et al., 2024 ; kim et al., 2025 ; wen et al., 2025c ). when the reward model does not robustly generalize, or focuses on spurious correlations, it can lead to _ reward hacking _. amodei et al. ( 2016 ) describe reward hacking as the process of “ gaming ” flaws in the reward model to maximize the rewards without learning the intended behavior. this phenomenon was empirically observed for text ( pasunuru & bansal, 2017 ; [UNK] et al., 2018 ; wu et al., 2018a ) and non - text rl ( amodei & clark, 2016 ; krakovna et al., 2020 ; nagarajan et al., 2021 ). it is not specific to reward models, as most classification models suffer from spurious correlations ( ribeiro et al., 2016 ; mccoy et al., 2019 ) and spurious correlations were found in reward models ( liu et al., 2025b ) and metrics ( sun et al., 2019 ). among the effects, reward models may prefer more confident - sounding answers ( leng et al., 2025 ), exhibit a verbosity bias ( saito et al., 2023 ), focus more on style than content ( feuer et al., 2025 ), and results may be confounded by the order in which outputs are shown ( wang et al., 2024 ). relatedly, the problem of _ sycophancy _ has been characterized as models learning to match user beliefs over generating truthful responses ( sharma et al., 2024 ). murugadoss et al. ( 2025 ) and hu et al. ( 2024 ) further show that the detail of llmas - a - judge prompts have little influence on its performance, implying that models rely too much on their implicitly learned quality criteria definitions. these issues motivate work on diagnostic datasets ( gabriel et al., 2021 ), distractor generation ( qiu et al., 2020 ; dhole et al., 2023 ), and model interpretability ( jacovi et al., 2023 ), to become aware of and overcome spurious correlations. 7 reward models are metrics in a trench coat - preprint * * meta - evaluation frameworks * * the field of meta - evaluation is concerned with the question of how we evaluate evaluators. callison - burch et al. ( 2007 ) popularized this practice in nlp through a shared task series that performs a yearly assessment of mt metrics. meta - evaluation measures two aspects : _ segment - level _ and _ system - level _ performance. a high system - level performance means that system rankings in a leaderboard are trustworthy, while segment - level assessments look at whether individual pairs of system outputs are ranked correctly. these two measures are not always correlated ( wei & jia, 2021 ), motivating an approach that matches how a model is used. algorithms like dpo ( rafailov et al., 2023 ) use the reward score difference between a chosen and rejected model output as training signal. this directly matches the segment - level meta - evaluation. however, a known issue is that evaluation metrics are often not well - calibrated ( kocmi et al., 2024 ), which may cause issues if they are applied as reward models. moreover, reward model benchmarks like rewardbench 2 ( lambert et al., 2025 ; gureja et al., 2025 ) do not consider score calibration, instead reporting overall accuracy on the task of identifying the highest rated system output, which more closely matches a system - level assessment. as a result, calibration issues may be overlooked if one focuses only on reward model benchmark performance. this oversight of segment - level assessments could further contribute to the lack of correlation between reward model and downstream model performance. thus, future work on reward model benchmarking could benefit from reporting segment - level rather than system - level performance, including assessments of score calibration. * * meta - evaluation targets * * a complicating factor for the meta - evaluation of reward models is the breadth of tasks for which they need to assess output quality. their meta"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 9,
    "text": "that evaluation metrics are often not well - calibrated ( kocmi et al., 2024 ), which may cause issues if they are applied as reward models. moreover, reward model benchmarks like rewardbench 2 ( lambert et al., 2025 ; gureja et al., 2025 ) do not consider score calibration, instead reporting overall accuracy on the task of identifying the highest rated system output, which more closely matches a system - level assessment. as a result, calibration issues may be overlooked if one focuses only on reward model benchmark performance. this oversight of segment - level assessments could further contribute to the lack of correlation between reward model and downstream model performance. thus, future work on reward model benchmarking could benefit from reporting segment - level rather than system - level performance, including assessments of score calibration. * * meta - evaluation targets * * a complicating factor for the meta - evaluation of reward models is the breadth of tasks for which they need to assess output quality. their meta - evaluations thus need to strike a balance of breadth, validity, and relevance. ivison et al. ( 2024 ) suggest that existing reward model benchmarks are too narrow, especially considering their performance variance across tasks ( bavaresco et al., 2025 ). benchmarks like rewardbench 2 already average multiple categories, but the question of how to aggregate sub - category scores into a single ranking becomes important. to that end, frick et al. ( 2025 ) find that pessimistic reward model evaluations instead of average performance are more indicative of downstream model performance, motivating alternative leaderboard designs that focus on finding shortcomings, rather than averaging performance numbers. these issues are further exacerbated when the systems that are being evaluated by evaluation metrics and reward models improve. as these models become harder to distinguish, biases in the evaluation setup become more noticeable ( wei & jia, 2021 ) and tie handling procedures need to be introduced ( thompson et al., 2024 ; sun et al., 2025 ). 5. 4 r ecommendations while developing an unhackable reward model is likely impossible ( skalse et al., 2022 ), metrics, and more directly reward models, share a symbiotic relationship with the downstream models where improvements in one translate to improvements in the other ( gehrmann et al., 2021 ). this means, we should strive to produce the most accurate estimate of human preferences. to that end, both fields benefit from having high - quality training and meta - evaluation data. this data needs to be grounded in clear definitions in the sociotechnical context that the to - be - assessed models are deployed in. while it is unavoidable to introduce spurious correlations, in both fields it is crucial to identify and measure them and to mitigate their impact on downstream uses. modeling choices and optimization targets similarly align between the two fields, whether that is applying llm - as - a - judge, or training classification models on human - curated data. due to this overlap, newly introduced methods for modeling human preferences should be evaluated on metrics and reward model benchmarks alike to paint a more accurate and complete picture of how these methods perform. more generally, meta - evaluation and the development of leaderboards is an area in which the fields have significantly diverged. they should come together to address the poor correlation between reward model benchmark scores and downstream model performance. shared best practices on tie handling, segment - level correlation measures, conducting model calibration assessments, and collecting test datasets will benefit both fields. however, as reward modeling matures as a field, it will be important to avoid falling into traps like developing default models and benchmarks that, despite being outdated, continue to be broadly used ( bommasani & cardie, 2020 ). instead, evaluation research could adopt the practice from reward modeling of moving to new and better performing model as they become available. 8 reward models are metrics in a trench coat - preprint while reward models and evaluation metrics should be developed using the same best practices, one cannot be used to replace the other. as goodhart ’ s law states, _ when a measure becomes a target, it _ _ ceases to be a good measure _ ( goodhart, 1984 ). applying to both fields, models may perform well as a proxy for the distribution over human preferences but will diverge in the tail ( i. e., rarely seen model inputs ) and may over - generalize and focus on spurious patterns ( manheim & garrabrant, 2018 ; gao et al., 2023 ). similar arguments apply to the utility of shared tasks and leaderboards which similarly are a frequent target of criticism ( e. g., scott & moore, 2006 ; ethayarajh & jurafsky, 2020 ; thomas & uminsky, 2020 ; raji et al., 2021 ; bowman & dahl, 2021 ). our practical recommendation is thus for the fields"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 10,
    "text": "and evaluation metrics should be developed using the same best practices, one cannot be used to replace the other. as goodhart ’ s law states, _ when a measure becomes a target, it _ _ ceases to be a good measure _ ( goodhart, 1984 ). applying to both fields, models may perform well as a proxy for the distribution over human preferences but will diverge in the tail ( i. e., rarely seen model inputs ) and may over - generalize and focus on spurious patterns ( manheim & garrabrant, 2018 ; gao et al., 2023 ). similar arguments apply to the utility of shared tasks and leaderboards which similarly are a frequent target of criticism ( e. g., scott & moore, 2006 ; ethayarajh & jurafsky, 2020 ; thomas & uminsky, 2020 ; raji et al., 2021 ; bowman & dahl, 2021 ). our practical recommendation is thus for the fields to share insights into methodologies, but not to collapse into one field. a full collapse would risk creating a monoculture where only a few benchmarks dictate model optimization, rather than having many different targets ( koch & peterson, 2024 ). as singh et al. ( 2025 ) state, an “ over - reliance on a single leaderboard creates a risk that providers may overfit to the aspects of leaderboard performance, without genuinely advancing the technology in meaningful ways ”. issues with broadly adopted evaluation setups lead to overspecialization and lack of generalization beyond what a specific leaderboard measures ( liu et al., 2025a ; zouhar et al., 2024 ). being too rigid in how meta - evaluations are conducted could also exclude new methods from being investigated fairly ( perrella et al., 2024 ). furthermore, while methods for reward modeling may be informed by insights from evaluation metric development, the specific reward models may not perform well on the same benchmarks. as discussed above, reward models are often specific to a sociotechnical context, and would thus not perform well on public reward modeling benchmarks. this may cause a rift between industry and academic research where the best reward modeling approaches are not publicly disclosed because they are too entangled within this context. yet, especially for models that measure human preferences for whether a model output is considered offensive or undesirable, it is critical to develop public standards and be transparent about the underlying policies a model is trying to enact. 6 c onclusions in this work, we have argued that evaluation metrics and reward models share many similarities. their developers need to make the same choices about their inputs and outputs, their collection of training and validation data, and the resulting models suffer from the same drawbacks. while the application areas and the specific choices made during development may differ, at their core, both seek to model human preferences of model output quality. this supports our thesis that the fields should look at and learn from each other ’ s advances, rather than continuing to exist in parallel. we grounded this discussion in a citation analysis that demonstrated that the research fields are developing mostly in isolation from each other. this separation of fields can lead to missed opportunities, the rediscovery of established findings, and potentially flawed conclusions. we quantified the separation through two experiments that show that reward models may be lacking when assessed on domains for which evaluation metrics are already available. we provided an extensive survey and discussed several areas in which future work on metrics and reward models, meta - evaluations, and benchmark creation could incorporate insights from both fields. while we recommend against the development of a monoculture with too few relevant benchmarks, we encourage researchers to consider work from both fields and work on unifying both methodologies and terminologies. beyond the scope of this work, we acknowledge efforts in reinforcement learning to solve tasks with verifiable rewards, for example math problems ( ke et al., 2025 ), for which reward models play a less central role. in this domain, model - based reward modeling approaches largely perform string matching between the verified and generated answer, and thus do not require as complex approaches as those discussed here. training models for these verifiable domains can induce reasoning capabilities and has led to broader generalization ( guo et al., 2025 ; comanici et al., 2025 ). while this finding does not make reward models for non - verifiable domains obsolete, it presents a possible alternative or parallel path in which reward models do not play such a central role. moreover, we note that improvements in reward models may not always translate into downstream model improvements. the _ superficial alignment hypothesis _ by zhou et al. ( 2023 ) poses that the reinforcement learning stage primarily changes ’ how ’ a model responds, rather than contributing new world knowledge. thus, even a perfect reward model cannot overcome fundamental knowledge gaps from pre - training. 9 reward models are metrics in a trench coat - preprint r eferences"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 11,
    "text": ". in this domain, model - based reward modeling approaches largely perform string matching between the verified and generated answer, and thus do not require as complex approaches as those discussed here. training models for these verifiable domains can induce reasoning capabilities and has led to broader generalization ( guo et al., 2025 ; comanici et al., 2025 ). while this finding does not make reward models for non - verifiable domains obsolete, it presents a possible alternative or parallel path in which reward models do not play such a central role. moreover, we note that improvements in reward models may not always translate into downstream model improvements. the _ superficial alignment hypothesis _ by zhou et al. ( 2023 ) poses that the reinforcement learning stage primarily changes ’ how ’ a model responds, rather than contributing new world knowledge. thus, even a perfect reward model cannot overcome fundamental knowledge gaps from pre - training. 9 reward models are metrics in a trench coat - preprint r eferences [ dario amodei and jack clark. faulty reward functions in the wild. https : / / openai. com / ] ( https : / / openai. com / index / faulty - reward - functions / ) [ index / faulty - reward - functions /, 2016. ] ( https : / / openai. com / index / faulty - reward - functions / ) dario amodei, chris olah, jacob steinhardt, paul christiano, john schulman, and dan [UNK]. concrete problems in ai safety. _ arxiv preprint arxiv : 1606. 06565 _, 2016. david anugraha, garry kuwanto, lucky susanto, derry tanti wijaya, and genta winata. metametrics - mt : tuning meta - metrics for machine translation via human preference calibration. in barry haddow, tom kocmi, philipp koehn, and christof monz ( eds. ), _ proceedings _ _ of the ninth conference on machine translation _, pp. 459 – 469, miami, florida, usa, november 2024. association for computational linguistics. doi : 10. 18653 / v1 / 2024. wmt - 1. 32. url [ https : / / aclanthology. org / 2024. wmt - 1. 32 /. ] ( https : / / aclanthology. org / 2024. wmt - 1. 32 / ) rahul k. arora, jason wei, rebecca soskin hicks, preston bowman, joaquin [UNK] candela, foivos tsimpourlas, michael sharman, meghan shah, andrea vallone, alex beutel, johannes heidecke, and karan singhal. healthbench : evaluating large language models towards improved human health. _ corr _ [, abs / 2505. 08775, 2025. doi : 10. 48550 / arxiv. 2505. 08775. url https : ] ( https : / / doi. org / 10. 48550 / arxiv. 2505. 08775 ) [ / / doi. org / 10. 48550 / arxiv. 2505. 08775. ] ( https : / / doi. org / 10. 48550 / arxiv. 2505. 08775 ) lora aroyo, mark diaz, christopher homan, vinodkumar prabhakaran, alex taylor, and ding wang. the reasonable effectiveness of diverse evaluation data. _ arxiv preprint arxiv : 2301. 09406 _, 2023. jimmy ba, volodymyr mnih, and koray kavukcuoglu. multiple object recognition with visual attention. in yoshua bengio and yann lecun ( eds. ), _ 3rd international conference on learning _ _ representations, iclr 2015, san diego, ca, usa, may 7 - 9, 2015, conference track proceed - _ _ ings _ [, 2015. url http : / / arxiv. org / abs / 1412. 7755. ] ( http : / / arxiv. org / abs / 1412. 7755 ) dzmitry bahdanau, philemon brakel, kelvin xu, anirudh goyal, ryan lowe, joelle pineau, aaron c. courville, and yoshua bengio. an actor - critic algorithm for sequence prediction. in _ 5th _ _ international conference on learning representations, iclr 2017, toulon, france, april 24 - 26, _ _ 2017, conference track proceedings _ [. openreview. net, 2017. url https : / / openreview. ] ( https : / / openreview. net / forum? id = sjdaqqveg ) [ net / forum? id = sj"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 12,
    "text": "##lr 2015, san diego, ca, usa, may 7 - 9, 2015, conference track proceed - _ _ ings _ [, 2015. url http : / / arxiv. org / abs / 1412. 7755. ] ( http : / / arxiv. org / abs / 1412. 7755 ) dzmitry bahdanau, philemon brakel, kelvin xu, anirudh goyal, ryan lowe, joelle pineau, aaron c. courville, and yoshua bengio. an actor - critic algorithm for sequence prediction. in _ 5th _ _ international conference on learning representations, iclr 2017, toulon, france, april 24 - 26, _ _ 2017, conference track proceedings _ [. openreview. net, 2017. url https : / / openreview. ] ( https : / / openreview. net / forum? id = sjdaqqveg ) [ net / forum? id = sjdaqqveg. ] ( https : / / openreview. net / forum? id = sjdaqqveg ) yuntao bai, andy jones, kamal ndousse, amanda askell, anna chen, nova dassarma, dawn drain, stanislav fort, deep ganguli, t. j. henighan, nicholas joseph, saurav kadavath, john kernion, tom conerly, sheer el - showk, nelson elhage, zac hatfield - dodds, danny hernandez, tristan hume, scott johnston, shauna kravec, liane lovitt, neel nanda, catherine olsson, dario amodei, tom b. brown, jack clark, sam mccandlish, chris olah, benjamin mann, and jared kaplan. training a helpful and harmless assistant with reinforcement learning from human feedback. _ arxiv _ [, abs / 2204. 05862, 2022a. url https : / / api. semanticscholar. org / ] ( https : / / api. semanticscholar. org / corpusid : 248118878 ) [ corpusid : 248118878. ] ( https : / / api. semanticscholar. org / corpusid : 248118878 ) yuntao bai, saurav kadavath, sandipan kundu, amanda askell, jackson kernion, andy jones, anna chen, anna goldie, azalia mirhoseini, cameron mckinnon, carol chen, catherine olsson, christopher olah, danny hernandez, dawn drain, deep ganguli, dustin li, eli tranjohnson, ethan perez, jamie kerr, jared mueller, jeffrey ladish, joshua landau, kamal ndousse, kamile lukosiute, liane lovitt, michael sellitto, nelson elhage, nicholas schiefer, [UNK] mercado, nova dassarma, robert lasenby, robin larson, sam ringer, scott johnston, shauna kravec, sheer el showk, stanislav fort, tamera lanham, timothy telleen - lawton, tom conerly, tom henighan, tristan hume, samuel r. bowman, zac hatfield - dodds, ben mann, dario amodei, nicholas joseph, sam mccandlish, tom brown, and jared kaplan. constitutional ai : harmlessness from ai feedback. _ corr _, abs / 2212. 08073, 2022b. doi : 10. 48550 / arxiv. 2212. [ 08073. url https : / / doi. org / 10. 48550 / arxiv. 2212. 08073. ] ( https : / / doi. org / 10. 48550 / arxiv. 2212. 08073 ) anna bavaresco, raffaella bernardi, leonardo bertolazzi, desmond elliott, raquel [UNK], albert gatt, esam ghaleb, mario giulianelli, michael hanna, alexander koller, andre martins, philipp mondorf, vera neplenbroek, sandro pezzelle, barbara plank, david schlangen, alessandro suglia, aditya k surikuchi, ece takmaz, and alberto testoni. llms instead of human judges? a large scale empirical study across 20 nlp evaluation tasks. in wanxiang che, joyce 10 reward models are metrics in a trench coat - preprint nabende, ekaterina shutova, and mohammad taher pilehvar ( eds. ), _ proceedings of the 63rd an"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 13,
    "text": "https : / / doi. org / 10. 48550 / arxiv. 2212. 08073 ) anna bavaresco, raffaella bernardi, leonardo bertolazzi, desmond elliott, raquel [UNK], albert gatt, esam ghaleb, mario giulianelli, michael hanna, alexander koller, andre martins, philipp mondorf, vera neplenbroek, sandro pezzelle, barbara plank, david schlangen, alessandro suglia, aditya k surikuchi, ece takmaz, and alberto testoni. llms instead of human judges? a large scale empirical study across 20 nlp evaluation tasks. in wanxiang che, joyce 10 reward models are metrics in a trench coat - preprint nabende, ekaterina shutova, and mohammad taher pilehvar ( eds. ), _ proceedings of the 63rd an - _ _ nual meeting of the association for computational linguistics ( volume 2 : short papers ) _, pp. 238 – 255, vienna, austria, july 2025. association for computational linguistics. isbn 979 - 8 [ 89176 - 252 - 7. doi : 10. 18653 / v1 / 2025. acl - short. 20. url https : / / aclanthology. org / ] ( https : / / aclanthology. org / 2025. acl - short. 20 / ) [ 2025. acl - short. 20 /. ] ( https : / / aclanthology. org / 2025. acl - short. 20 / ) rishi bommasani and claire cardie. intrinsic evaluation of summarization datasets. in bonnie webber, trevor cohn, yulan he, and yang liu ( eds. ), _ proceedings of the 2020 conference on _ _ empirical methods in natural language processing ( emnlp ) _, pp. 8075 – 8096, online, november 2020. association for computational linguistics. doi : 10. 18653 / v1 / 2020. emnlp - main. 649. [ url https : / / aclanthology. org / 2020. emnlp - main. 649 /. ] ( https : / / aclanthology. org / 2020. emnlp - main. 649 / ) samuel r. bowman and george dahl. what will it take to fix benchmarking in natural language understanding? in kristina toutanova, anna rumshisky, luke zettlemoyer, dilek hakkani - tur, iz beltagy, steven bethard, ryan cotterell, tanmoy chakraborty, and yichao zhou ( eds. ), _ proceedings of the 2021 conference of the north american chapter of the association _ _ for computational linguistics : human language technologies _, pp. 4843 – 4855, online, june 2021. association for computational linguistics. doi : 10. 18653 / v1 / 2021. naacl - main. 385. url [ https : / / aclanthology. org / 2021. naacl - main. 385 /. ] ( https : / / aclanthology. org / 2021. naacl - main. 385 / ) ralph allan bradley and milton e terry. rank analysis of incomplete block designs : i. the method of paired comparisons. _ biometrika _, 39 ( 3 / 4 ) : 324 – 345, 1952. nitay calderon, roi reichart, and rotem dror. the alternative annotator test for llm - as - a - judge : how to statistically justify replacing human annotators with llms. in wanxiang che, joyce nabende, ekaterina shutova, and mohammad taher pilehvar ( eds. ), _ proceedings of the 63rd _ _ annual meeting of the association for computational linguistics ( volume 1 : long papers ) _, pp. 16051 – 16081, vienna, austria, july 2025. association for computational linguistics. isbn 979 [ 8 - 89176 - 251 - 0. doi : 10. 18653 / v1 / 2025. acl - long. 782. url https : / / aclanthology. org / ] ( https : / / aclanthology. org / 2025. acl - long. 782 / ) [ 2025. acl - long. 782 /. ] ( https : / / aclanthology. org / 2025. acl - long. 782 / ) chris callison - burch, cameron fordyce, philipp koehn, christof monz, and josh schroeder. ( meta ) evaluation of machine translation. in chris call"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 14,
    "text": "##ammad taher pilehvar ( eds. ), _ proceedings of the 63rd _ _ annual meeting of the association for computational linguistics ( volume 1 : long papers ) _, pp. 16051 – 16081, vienna, austria, july 2025. association for computational linguistics. isbn 979 [ 8 - 89176 - 251 - 0. doi : 10. 18653 / v1 / 2025. acl - long. 782. url https : / / aclanthology. org / ] ( https : / / aclanthology. org / 2025. acl - long. 782 / ) [ 2025. acl - long. 782 /. ] ( https : / / aclanthology. org / 2025. acl - long. 782 / ) chris callison - burch, cameron fordyce, philipp koehn, christof monz, and josh schroeder. ( meta ) evaluation of machine translation. in chris callison - burch, philipp koehn, cameron shaw fordyce, and christof monz ( eds. ), _ proceedings of the second workshop on statistical machine _ _ translation _, pp. 136 – 158, prague, czech republic, june 2007. association for computational [ linguistics. url https : / / aclanthology. org / w07 - 0718 /. ] ( https : / / aclanthology. org / w07 - 0718 / ) stephen casper, xander davies, claudia shi, thomas krendl gilbert, [UNK] scheurer, javier rando, rachel freedman, tomek korbak, david lindner, pedro freire, tony tong wang, samuel marks, charbel - raphael segerie, micah carroll, andi peng, phillip j. k. christoffersen, mehul damani, stewart slocum, usman anwar, anand siththaranjan, max nadeau, eric j michaud, jacob pfau, dmitrii krasheninnikov, xin chen, lauro langosco, peter hase, erdem biyik, anca dragan, david krueger, dorsa sadigh, and dylan hadfield - menell. open problems and fundamental limitations of reinforcement learning from human feedback. _ transactions on machine _ _ learning research _ [, 2023. issn 2835 - 8856. url https : / / openreview. net / forum? ] ( https : / / openreview. net / forum? id = bx24kpj4eb ) [ id = bx24kpj4eb. survey certification, featured certification. ] ( https : / / openreview. net / forum? id = bx24kpj4eb ) khaoula chehbouni, mohammed haddou, jackie chi kit cheung, and golnoosh farnadi. neither valid nor reliable? investigating the use of llms as judges. _ arxiv preprint arxiv : 2508. 18076 _, 2025. zewen chi, li dong, furu wei, nan yang, saksham singhal, wenhui wang, xia song, xian - ling mao, heyan huang, and ming zhou. infoxlm : an information - theoretic framework for crosslingual language model pre - training. in kristina toutanova, anna rumshisky, luke zettlemoyer, dilek hakkani - tur, iz beltagy, steven bethard, ryan cotterell, tanmoy chakraborty, and yichao zhou ( eds. ), _ proceedings of the 2021 conference of the north american chapter of the asso - _ _ ciation for computational linguistics : human language technologies _, pp. 3576 – 3588, online, june 2021. association for computational linguistics. doi : 10. 18653 / v1 / 2021. naacl - main. 280. [ url https : / / aclanthology. org / 2021. naacl - main. 280 /. ] ( https : / / aclanthology. org / 2021. naacl - main. 280 / ) leshem choshen, lior fox, zohar aizenbud, and omri abend. on the weaknesses of reinforcement learning for neural machine translation. in _ 8th international conference on learning represen - _ _ tations, iclr 2020, addis ababa, ethiopia, april 26 - 30, 2020 _. openreview. net, 2020. url [ https : / / openreview. net / forum? id = h1ecw3ekvh. ] ( https : / / openreview. net / forum? id = h1ecw3ek"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 15,
    "text": "online, june 2021. association for computational linguistics. doi : 10. 18653 / v1 / 2021. naacl - main. 280. [ url https : / / aclanthology. org / 2021. naacl - main. 280 /. ] ( https : / / aclanthology. org / 2021. naacl - main. 280 / ) leshem choshen, lior fox, zohar aizenbud, and omri abend. on the weaknesses of reinforcement learning for neural machine translation. in _ 8th international conference on learning represen - _ _ tations, iclr 2020, addis ababa, ethiopia, april 26 - 30, 2020 _. openreview. net, 2020. url [ https : / / openreview. net / forum? id = h1ecw3ekvh. ] ( https : / / openreview. net / forum? id = h1ecw3ekvh ) 11 reward models are metrics in a trench coat - preprint paul f. christiano, jan leike, tom b. brown, miljan martic, shane legg, and dario amodei. deep reinforcement learning from human preferences. in isabelle guyon, ulrike von luxburg, samy bengio, hanna m. wallach, rob fergus, s. v. n. vishwanathan, and roman garnett ( eds. ), _ advances in neural information processing systems 30 : annual conference on neu - _ _ ral information processing systems 2017, december 4 - 9, 2017, long beach, ca, usa _, pp. [ 4299 – 4307, 2017. url https : / / proceedings. neurips. cc / paper / 2017 / hash / ] ( https : / / proceedings. neurips. cc / paper / 2017 / hash / d5e2c0adad503c91f91df240d0cd4e49 - abstract. html ) [ d5e2c0adad503c91f91df240d0cd4e49 - abstract. html. ] ( https : / / proceedings. neurips. cc / paper / 2017 / hash / d5e2c0adad503c91f91df240d0cd4e49 - abstract. html ) elizabeth clark, shruti rijhwani, sebastian gehrmann, joshua maynez, roee aharoni, vitaly nikolaev, thibault sellam, aditya siddhant, dipanjan das, and ankur parikh. seahorse : a multilingual, multifaceted dataset for summarization evaluation. in houda bouamor, juan pino, and kalika bali ( eds. ), _ proceedings of the 2023 conference on empirical methods in natural lan - _ _ guage processing _, pp. 9397 – 9413, singapore, december 2023. association for computational [ linguistics. doi : 10. 18653 / v1 / 2023. emnlp - main. 584. url https : / / aclanthology. org / ] ( https : / / aclanthology. org / 2023. emnlp - main. 584 / ) [ 2023. emnlp - main. 584 /. ] ( https : / / aclanthology. org / 2023. emnlp - main. 584 / ) gheorghe comanici, eric bieber, mike schaekermann, ice pasupat, noveen sachdeva, inderjit dhillon, marcel blistein, ori ram, dan zhang, evan rosen, et al. gemini 2. 5 : pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities. _ arxiv preprint arxiv : 2507. 06261 _, 2025. alexis conneau, guillaume lample, ruty rinott, adina williams, samuel r. bowman, holger schwenk, and veselin stoyanov. xnli : evaluating cross - lingual sentence representations. in _ conference on empirical methods in natural language processing _ [, 2018. url https : / / ] ( https : / / api. semanticscholar. org / corpusid : 52271711 ) [ api. semanticscholar. org / corpusid : 52271711. ] ( https : / / api. semanticscholar. org / corpusid : 52271711 ) ganqu cui, lifan yuan, ning ding, guanming yao, bingxiang he, wei zhu, yuan ni, guotong xie, ruobing xie, yankai lin, et al. ultrafeedback : boosting"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 16,
    "text": "capabilities. _ arxiv preprint arxiv : 2507. 06261 _, 2025. alexis conneau, guillaume lample, ruty rinott, adina williams, samuel r. bowman, holger schwenk, and veselin stoyanov. xnli : evaluating cross - lingual sentence representations. in _ conference on empirical methods in natural language processing _ [, 2018. url https : / / ] ( https : / / api. semanticscholar. org / corpusid : 52271711 ) [ api. semanticscholar. org / corpusid : 52271711. ] ( https : / / api. semanticscholar. org / corpusid : 52271711 ) ganqu cui, lifan yuan, ning ding, guanming yao, bingxiang he, wei zhu, yuan ni, guotong xie, ruobing xie, yankai lin, et al. ultrafeedback : boosting language models with scaled ai feedback. _ arxiv preprint arxiv : 2310. 01377 _, 2023. john dang, shivalika singh, daniel d ’ souza, arash ahmadian, alejandro salamanca, madeline smith, aidan peppin, sungjin hong, manoj govindassamy, terrence zhao, sandra kublik, meor amer, viraat aryabumi, jon ander campos, yi - chern tan, tom kocmi, florian strub, nathan grinsztajn, yannis flet - berliac, acyr locatelli, hangyu lin, dwarak talupuru, bharat venkitesh, david cairuz, bowen yang, tim chung, wei - yin ko, sylvie shang shi, amir shukayev, sammie bae, aleksandra piktus, roman [UNK], felipe cruz - salinas, eddie kim, lucas crawhall - stein, adrien morisot, sudip roy, phil blunsom, ivan zhang, aidan gomez, nick frosst, marzieh fadaee, beyza ermis, ahmet [UNK], and sara hooker. aya ex - [ [UNK] ] [ panse : combining research breakthroughs for a new multilingual frontier, 2024. url https : ] ( https : / / arxiv. org / abs / 2412. 04261 ) [ / / arxiv. org / abs / 2412. 04261. ] ( https : / / arxiv. org / abs / 2412. 04261 ) hal [UNK], john langford, and daniel marcu. search - based structured prediction. _ machine learn - _ _ ing _ [, 75 ( 3 ) : 297 – 325, 2009. doi : 10. 1007 / s10994 - 009 - 5106 - x. url https : / / doi. org / 10. ] ( https : / / doi. org / 10. 1007 / s10994 - 009 - 5106 - x ) [ 1007 / s10994 - 009 - 5106 - x. ] ( https : / / doi. org / 10. 1007 / s10994 - 009 - 5106 - x ) kaustubh dhole, varun gangal, sebastian gehrmann, aadesh gupta, zhenhao li, saad mahamood, abinaya mahadiran, simon mille, ashish shrivastava, samson tan, tongshang wu, jascha sohldickstein, jinho choi, eduard hovy, ondˇrej duˇsek, sebastian ruder, sajant anand, nagender aneja, rabin banjade, lisa barthe, hanna behnke, ian berlot - attwell, connor boyle, caroline brun, marco antonio sobrevilla cabezudo, samuel cahyawijaya, emile chapuis, wanxiang che, mukund choudhary, christian clauss, pierre colombo, filip cornell, gautier dagan, mayukh das, tanay dixit, thomas dopierre, paul - alexis dray, suchitra dubey, tatiana ekeinhor, marco di giovanni, tanya goyal, rishabh gupta, louanes hamla, sang han, fabrice harel - canada, antoine [UNK], ishan jindal, przemysław joniak, denis kleyko, venelin kovatchev, kalpesh krishna, ashutosh kumar, stefan langer, seungja"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 17,
    "text": ", lisa barthe, hanna behnke, ian berlot - attwell, connor boyle, caroline brun, marco antonio sobrevilla cabezudo, samuel cahyawijaya, emile chapuis, wanxiang che, mukund choudhary, christian clauss, pierre colombo, filip cornell, gautier dagan, mayukh das, tanay dixit, thomas dopierre, paul - alexis dray, suchitra dubey, tatiana ekeinhor, marco di giovanni, tanya goyal, rishabh gupta, louanes hamla, sang han, fabrice harel - canada, antoine [UNK], ishan jindal, przemysław joniak, denis kleyko, venelin kovatchev, kalpesh krishna, ashutosh kumar, stefan langer, seungjae ryan lee, corey james levinson, hualou liang, kaizhao liang, zhexiong liu, andrey lukyanenko, vukosi marivate, gerard de melo, simon meoni, maxine meyer, afnan mir, nafise sadat moosavi, niklas meunnighoff, timothy sum hon mun, kenton murray, marcin namysl, maria obedkova, priti oli, nivranshu pasricha, jan pfister, richard plant, vinay prabhu, vasile pais, libo qin, shahab raji, pawan kumar rajpoot, vikas raunak, roy rinberg, nicholas roberts, juan diego rodriguez, claude roux, vasconcellos samus, ananya sai, robin schmidt, thomas scialom, 12 reward models are metrics in a trench coat - preprint tshephisho sefara, saqib shamsi, xudong shen, yiwen shi, haoyue shi, anna shvets, nick siegel, damien sileo, jamie simon, chandan singh, roman sitelew, priyank soni, taylor sorensen, william soto, aman srivastava, aditya srivatsa, tony sun, mukund varma, a tabassum, fiona tan, ryan teehan, mo tiwari, marie tolkiehn, athena wang, zijian wang, zijie wang, gloria wang, fuxuan wei, bryan wilie, genta indra winata, xinyu wu, witold wydmanski, tianbao xie, usama yaseen, michael yee, jing zhang, and yue zhang. nlaugmenter : a framework for task - sensitive natural language augmentation. _ northern euro - _ _ pean journal of language technology _, 9, 2023. doi : 10. 3384 / nejlt. 2000 - 1533. 2023. 4725. url [ https : / / aclanthology. org / 2023. nejlt - 1. 5 /. ] ( https : / / aclanthology. org / 2023. nejlt - 1. 5 / ) richard o. duda and peter e. hart. pattern classification and scene analysis. in _ a _ _ wiley - interscience publication _, 1974. [ url https : / / api. semanticscholar. org / ] ( https : / / api. semanticscholar. org / corpusid : 12946615 ) [ corpusid : 12946615. ] ( https : / / api. semanticscholar. org / corpusid : 12946615 ) kawin ethayarajh and dan jurafsky. utility is in the eye of the user : a critique of nlp leaderboards. in bonnie webber, trevor cohn, yulan he, and yang liu ( eds. ), _ proceedings of the 2020 _ _ conference on empirical methods in natural language processing ( emnlp ) _, pp. 4846 – 4853, online, november 2020. association for computational linguistics. doi : 10. 18653 / v1 / 2020. [ emnlp - main. 393. url https : / / aclanthology. org / 2020. emnlp - main. 393 /. ] ( https : / / aclanthology. org / 2020. emnlp - main. 393 / ) matan eyal, tal baumel, and michael elhadad. question answering as an automatic evaluation metric for news article summarization. in jill burstein, christy doran, and thamar solorio ( eds. )"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 18,
    "text": "eye of the user : a critique of nlp leaderboards. in bonnie webber, trevor cohn, yulan he, and yang liu ( eds. ), _ proceedings of the 2020 _ _ conference on empirical methods in natural language processing ( emnlp ) _, pp. 4846 – 4853, online, november 2020. association for computational linguistics. doi : 10. 18653 / v1 / 2020. [ emnlp - main. 393. url https : / / aclanthology. org / 2020. emnlp - main. 393 /. ] ( https : / / aclanthology. org / 2020. emnlp - main. 393 / ) matan eyal, tal baumel, and michael elhadad. question answering as an automatic evaluation metric for news article summarization. in jill burstein, christy doran, and thamar solorio ( eds. ), _ proceedings of the 2019 conference of the north american chapter of the association for com - _ _ putational linguistics : human language technologies, volume 1 ( long and short papers ) _, pp. 3938 – 3948, minneapolis, minnesota, june 2019. association for computational linguistics. doi : [ 10. 18653 / v1 / n19 - 1395. url https : / / aclanthology. org / n19 - 1395 /. ] ( https : / / aclanthology. org / n19 - 1395 / ) alexander r. fabbri, chien sheng wu, wenhao liu, and caiming xiong. qafacteval : improved qa - based factual consistency evaluation for summarization. in _ north american chapter of the _ _ association for computational linguistics _ [, 2021. url https : / / api. semanticscholar. ] ( https : / / api. semanticscholar. org / corpusid : 245218667 ) [ org / corpusid : 245218667. ] ( https : / / api. semanticscholar. org / corpusid : 245218667 ) benjamin feuer, micah goldblum, teresa datta, sanjana nambiar, raz besaleli, samuel dooley, max cembalest, and john p dickerson. style outweighs substance : failure modes of llm judges in alignment benchmarking. in _ the thirteenth international conference on learning represen - _ _ tations _ [, 2025. url https : / / openreview. net / forum? id = mzhnftnam1. ] ( https : / / openreview. net / forum? id = mzhnftnam1 ) adam fisch, jacob eisenstein, vicky zayats, alekh agarwal, ahmad beirami, chirag nagpal, pete shaw, and jonathan berant. robust preference optimization through reward model distillation. _ arxiv preprint arxiv : 2405. 19316 _, 2024. markus freitag, david grangier, and isaac caswell. bleu might be guilty but references are not innocent. in bonnie webber, trevor cohn, yulan he, and yang liu ( eds. ), _ proceedings of the _ _ 2020 conference on empirical methods in natural language processing ( emnlp ) _, pp. 61 – 71, online, november 2020. association for computational linguistics. doi : 10. 18653 / v1 / 2020. [ emnlp - main. 5. url https : / / aclanthology. org / 2020. emnlp - main. 5 /. ] ( https : / / aclanthology. org / 2020. emnlp - main. 5 / ) markus freitag, george foster, david grangier, viresh ratnakar, qijun tan, and wolfgang macherey. experts, errors, and context : a large - scale study of human evaluation for machine translation. _ transactions of the association for computational linguistics _, 9 : 1460 – 1474, 2021a. doi : 10. 1162 / tacl ~ ~ a 0 ~ ~ [ 0437. url https : / / aclanthology. org / 2021. tacl - 1. 87 /. ] ( https : / / aclanthology. org / 2021. tacl - 1. 87 / ) markus freitag, david grangier, qijun tan, and bowen liang. high quality rather than high model probability : minimum bayes risk decoding with neural metrics. _ transactions of _ _ the association for computational linguistics _, 10 : 811 – 825, 2021b. [ url https : / / api. ] ( https : / / api."
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 19,
    "text": "##er, viresh ratnakar, qijun tan, and wolfgang macherey. experts, errors, and context : a large - scale study of human evaluation for machine translation. _ transactions of the association for computational linguistics _, 9 : 1460 – 1474, 2021a. doi : 10. 1162 / tacl ~ ~ a 0 ~ ~ [ 0437. url https : / / aclanthology. org / 2021. tacl - 1. 87 /. ] ( https : / / aclanthology. org / 2021. tacl - 1. 87 / ) markus freitag, david grangier, qijun tan, and bowen liang. high quality rather than high model probability : minimum bayes risk decoding with neural metrics. _ transactions of _ _ the association for computational linguistics _, 10 : 811 – 825, 2021b. [ url https : / / api. ] ( https : / / api. semanticscholar. org / corpusid : 248392447 ) [ semanticscholar. org / corpusid : 248392447. ] ( https : / / api. semanticscholar. org / corpusid : 248392447 ) markus freitag, nitika mathur, daniel deutsch, chi - kiu lo, eleftherios avramidis, ricardo rei, brian thompson, frederic blain, tom kocmi, jiayi wang, david ifeoluwa adelani, marianna buchicchio, chrysoula zerva, and alon lavie. are llms breaking mt metrics? results of the wmt24 metrics shared task. in barry haddow, tom kocmi, philipp koehn, and christof monz ( eds. ), _ proceedings of the ninth conference on machine translation _, pp. 47 – 81, miami, 13 reward models are metrics in a trench coat - preprint florida, usa, november 2024. association for computational linguistics. doi : 10. 18653 / v1 / [ 2024. wmt - 1. 2. url https : / / aclanthology. org / 2024. wmt - 1. 2 /. ] ( https : / / aclanthology. org / 2024. wmt - 1. 2 / ) evan frick, tianle li, connor chen, wei - lin chiang, anastasios nikolas angelopoulos, jiantao jiao, banghua zhu, joseph e. gonzalez, and ion stoica. how to evaluate reward models for rlhf. in _ the thirteenth international conference on learning representations _, 2025. url [ https : / / openreview. net / forum? id = cbttlto94q. ] ( https : / / openreview. net / forum? id = cbttlto94q ) saadia gabriel, asli celikyilmaz, rahul jha, yejin choi, and jianfeng gao. go figure : a meta evaluation of factuality in summarization. in chengqing zong, fei xia, wenjie li, and roberto navigli ( eds. ), _ findings of the association for computational linguistics : acl - ijcnlp 2021 _, pp. 478 – 487, online, august 2021. association for computational linguistics. doi : 10. 18653 / [ v1 / 2021. findings - acl. 42. url https : / / aclanthology. org / 2021. findings - acl. ] ( https : / / aclanthology. org / 2021. findings - acl. 42 / ) [ 42 /. ] ( https : / / aclanthology. org / 2021. findings - acl. 42 / ) leo gao, john schulman, and jacob hilton. scaling laws for reward model overoptimization. in _ international conference on machine learning _, pp. 10835 – 10866. pmlr, 2023. sebastian gehrmann, tosin adewumi, karmanya aggarwal, pawan sasanka ammanamanchi, anuoluwapo aremu, antoine bosselut, khyathi raghavi chandu, miruna - adriana clinciu, dipanjan das, kaustubh dhole, wanyu du, esin durmus, ondˇrej duˇsek, chris chinenye emezue, varun gangal, cristina garbacea, tatsunori hashimoto, yufang hou, yacine jernite, harsh jhamtani, yangfeng ji, shailza jolly, mihir kale, dhruv kumar, faisal ladhak, aman madaan"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 20,
    "text": "jacob hilton. scaling laws for reward model overoptimization. in _ international conference on machine learning _, pp. 10835 – 10866. pmlr, 2023. sebastian gehrmann, tosin adewumi, karmanya aggarwal, pawan sasanka ammanamanchi, anuoluwapo aremu, antoine bosselut, khyathi raghavi chandu, miruna - adriana clinciu, dipanjan das, kaustubh dhole, wanyu du, esin durmus, ondˇrej duˇsek, chris chinenye emezue, varun gangal, cristina garbacea, tatsunori hashimoto, yufang hou, yacine jernite, harsh jhamtani, yangfeng ji, shailza jolly, mihir kale, dhruv kumar, faisal ladhak, aman madaan, mounica maddela, khyati mahajan, saad mahamood, bodhisattwa prasad majumder, pedro henrique martins, angelina mcmillan - major, simon mille, emiel van miltenburg, moin nadeem, shashi narayan, vitaly nikolaev, andre niyongabo rubungo, salomey osei, ankur parikh, laura perez - beltrachini, niranjan ramesh rao, vikas raunak, juan diego rodriguez, sashank santhanam, [UNK] sedoc, thibault sellam, samira shaikh, anastasia shimorina, marco antonio sobrevilla cabezudo, hendrik strobelt, nishant subramani, wei xu, diyi yang, akhila yerukola, and jiawei zhou. the gem benchmark : natural language generation, its evaluation and metrics. in antoine bosselut, esin durmus, varun prashant gangal, sebastian gehrmann, yacine jernite, laura perez - beltrachini, samira shaikh, and wei xu ( eds. ), _ proceedings of the first workshop on natural language generation, evaluation, and metrics _ _ ( gem ) _, pp. 96 – 120, online, august 2021. association for computational linguistics. doi : [ 10. 18653 / v1 / 2021. gem - 1. 10. url https : / / aclanthology. org / 2021. gem - 1. 10 /. ] ( https : / / aclanthology. org / 2021. gem - 1. 10 / ) sebastian gehrmann, elizabeth clark, and thibault sellam. repairing the cracked foundation : a survey of obstacles in evaluation practices for generated text. _ journal artificial intelligence _ _ research _ [, 77 : 103 – 166, 2023. doi : 10. 1613 / jair. 1. 13715. url https : / / doi. org / 10. ] ( https : / / doi. org / 10. 1613 / jair. 1. 13715 ) [ 1613 / jair. 1. 13715. ] ( https : / / doi. org / 10. 1613 / jair. 1. 13715 ) sebastian gehrmann, claire huang, xian teng, sergei yurovski, arjun bhorkar, naveen thomas, john doucette, david rosenberg, mark dredze, and david rabinowitz. understanding and mitigating risks of generative ai in financial services. _ proceedings of the 2025 acm _ _ conference on fairness, accountability, and transparency _, 2025. [ url https : / / api. ] ( https : / / api. semanticscholar. org / corpusid : 278170940 ) [ semanticscholar. org / corpusid : 278170940. ] ( https : / / api. semanticscholar. org / corpusid : 278170940 ) ian j. goodfellow, jean pouget - abadie, mehdi mirza, bing xu, david warde - farley, sherjil ozair, aaron courville, and yoshua bengio. generative adversarial nets. in z. ghahramani, m. welling, c. cortes, n. lawrence, and k. q. weinberger ( eds. ), _ ad - _ _ vances in neural information processing systems _, volume 27. curran associates, inc., 2014. [ url https : / / proceedings. neurips. cc / paper _ files / paper / 2014 / ] ( https : / / proceedings. neurips"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 21,
    "text": ": / / api. semanticscholar. org / corpusid : 278170940 ) [ semanticscholar. org / corpusid : 278170940. ] ( https : / / api. semanticscholar. org / corpusid : 278170940 ) ian j. goodfellow, jean pouget - abadie, mehdi mirza, bing xu, david warde - farley, sherjil ozair, aaron courville, and yoshua bengio. generative adversarial nets. in z. ghahramani, m. welling, c. cortes, n. lawrence, and k. q. weinberger ( eds. ), _ ad - _ _ vances in neural information processing systems _, volume 27. curran associates, inc., 2014. [ url https : / / proceedings. neurips. cc / paper _ files / paper / 2014 / ] ( https : / / proceedings. neurips. cc / paper _ files / paper / 2014 / file / f033ed80deb0234979a61f95710dbe25 - paper. pdf ) [ file / f033ed80deb0234979a61f95710dbe25 - paper. pdf. ] ( https : / / proceedings. neurips. cc / paper _ files / paper / 2014 / file / f033ed80deb0234979a61f95710dbe25 - paper. pdf ) charles ae goodhart. problems of monetary management : the uk experience. in _ monetary theory _ _ and practice : the uk experience _, pp. 91 – 121. springer, 1984. anisha gunjal, anthony wang, elaine lau, vaskar nath, bing liu, and sean hendryx. rubrics as rewards : reinforcement learning beyond verifiable domains. _ corr _, abs / 2507. 17746, 2025. [ doi : 10. 48550 / arxiv. 2507. 17746. url https : / / doi. org / 10. 48550 / arxiv. 2507. ] ( https : / / doi. org / 10. 48550 / arxiv. 2507. 17746 ) [ 17746. ] ( https : / / doi. org / 10. 48550 / arxiv. 2507. 17746 ) 14 reward models are metrics in a trench coat - preprint daya guo, dejian yang, haowei zhang, junxiao song, ruoyu zhang, runxin xu, qihao zhu, shirong ma, peiyi wang, xiao bi, et al. deepseek - r1 : incentivizing reasoning capability in llms via reinforcement learning. _ arxiv preprint arxiv : 2501. 12948 _, 2025. srishti gureja, lester james validad miranda, shayekh bin islam, rishabh maheshwary, drishti sharma, gusti triandi winata, nathan lambert, sebastian ruder, sara hooker, and marzieh fadaee. m - rewardbench : evaluating reward models in multilingual settings. in wanxiang che, joyce nabende, ekaterina shutova, and mohammad taher pilehvar ( eds. ), _ proceedings of the _ _ 63rd annual meeting of the association for computational linguistics ( volume 1 : long papers ) _, pp. 43 – 58, vienna, austria, july 2025. association for computational linguistics. isbn 979 [ 8 - 89176 - 251 - 0. doi : 10. 18653 / v1 / 2025. acl - long. 3. url https : / / aclanthology. org / ] ( https : / / aclanthology. org / 2025. acl - long. 3 / ) [ 2025. acl - long. 3 /. ] ( https : / / aclanthology. org / 2025. acl - long. 3 / ) tahmid hasan, abhik bhattacharjee, md. saiful islam, kazi mubasshir, yuan - fang li, yong - bin kang, m. sohel rahman, and rifat shahriyar. xl - sum : large - scale multilingual abstractive summarization for 44 languages. in chengqing zong, fei xia, wenjie li, and roberto navigli ( eds. ), _ findings of the association for computational linguistics : acl - ijcnlp 2021 _, pp. 4693 – 4703, online, august 2021. association for computational linguistics. doi : 10. 18653 / v1 / 2021. [ findings - acl. 413. url https : /"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 22,
    "text": "##5. acl - long. 3 / ) [ 2025. acl - long. 3 /. ] ( https : / / aclanthology. org / 2025. acl - long. 3 / ) tahmid hasan, abhik bhattacharjee, md. saiful islam, kazi mubasshir, yuan - fang li, yong - bin kang, m. sohel rahman, and rifat shahriyar. xl - sum : large - scale multilingual abstractive summarization for 44 languages. in chengqing zong, fei xia, wenjie li, and roberto navigli ( eds. ), _ findings of the association for computational linguistics : acl - ijcnlp 2021 _, pp. 4693 – 4703, online, august 2021. association for computational linguistics. doi : 10. 18653 / v1 / 2021. [ findings - acl. 413. url https : / / aclanthology. org / 2021. findings - acl. 413 /. ] ( https : / / aclanthology. org / 2021. findings - acl. 413 / ) helia hashemi, jason eisner, corby rosset, benjamin van durme, and chris kedzie. llm - rubric : a multidimensional, calibrated approach to automated evaluation of natural language texts. in lun - wei ku, andre martins, and vivek srikumar ( eds. ), _ proceedings of the 62nd annual meeting _ _ of the association for computational linguistics ( volume 1 : long papers ) _, pp. 13806 – 13834, bangkok, thailand, august 2024. association for computational linguistics. doi : 10. 18653 / v1 / [ 2024. acl - long. 745. url https : / / aclanthology. org / 2024. acl - long. 745 /. ] ( https : / / aclanthology. org / 2024. acl - long. 745 / ) or honovich, roee aharoni, jonathan herzig, hagai taitelbaum, doron kukliansy, vered cohen, thomas scialom, idan szpektor, avinatan hassidim, and yossi matias. true : re - evaluating factual consistency evaluation. in marine carpuat, marie - catherine de marneffe, and ivan vladimir meza ruiz ( eds. ), _ proceedings of the 2022 conference of the north american chapter of the as - _ _ sociation for computational linguistics : human language technologies _, pp. 3905 – 3920, seattle, united states, july 2022. association for computational linguistics. doi : 10. 18653 / v1 / 2022. [ naacl - main. 287. url https : / / aclanthology. org / 2022. naacl - main. 287 /. ] ( https : / / aclanthology. org / 2022. naacl - main. 287 / ) david m. howcroft, anya belz, miruna - adriana clinciu, dimitra gkatzia, sadid a. hasan, saad mahamood, simon mille, emiel van miltenburg, sashank santhanam, and verena rieser. twenty years of confusion in human evaluation : nlg needs evaluation sheets and standardised definitions. in brian davis, yvette graham, john kelleher, and yaji sripada ( eds. ), _ proceedings of the _ _ 13th international conference on natural language generation _, pp. 169 – 182, dublin, ireland, december 2020. association for computational linguistics. doi : 10. 18653 / v1 / 2020. inlg - 1. 23. [ url https : / / aclanthology. org / 2020. inlg - 1. 23 /. ] ( https : / / aclanthology. org / 2020. inlg - 1. 23 / ) xinyu hu, mingqi gao, sen hu, yang zhang, yicheng chen, teng xu, and xiaojun wan. are llm - based evaluators confusing nlg quality criteria? in lun - wei ku, andre martins, and vivek srikumar ( eds. ), _ proceedings of the 62nd annual meeting of the association for com - _ _ putational linguistics ( volume 1 : long papers ) _, pp. 9530 – 9570, bangkok, thailand, august 2024. association for computational linguistics. doi : 10. 18653 / v1 / 2024. acl - long. 516. url [ https : / / aclanthology. org / 2024. acl - long. 51"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 23,
    "text": "[ url https : / / aclanthology. org / 2020. inlg - 1. 23 /. ] ( https : / / aclanthology. org / 2020. inlg - 1. 23 / ) xinyu hu, mingqi gao, sen hu, yang zhang, yicheng chen, teng xu, and xiaojun wan. are llm - based evaluators confusing nlg quality criteria? in lun - wei ku, andre martins, and vivek srikumar ( eds. ), _ proceedings of the 62nd annual meeting of the association for com - _ _ putational linguistics ( volume 1 : long papers ) _, pp. 9530 – 9570, bangkok, thailand, august 2024. association for computational linguistics. doi : 10. 18653 / v1 / 2024. acl - long. 516. url [ https : / / aclanthology. org / 2024. acl - long. 516 /. ] ( https : / / aclanthology. org / 2024. acl - long. 516 / ) hui huang, xingyuan bu, hongli zhou, yingqi qu, jing liu, muyun yang, bing xu, and tiejun zhao. an empirical study of llm - as - a - judge for llm evaluation : fine - tuned judge model is not a general substitute for gpt - 4. in wanxiang che, joyce nabende, ekaterina shutova, and mohammad taher pilehvar ( eds. ), _ findings of the association for computational lin - _ _ guistics : acl 2025 _, pp. 5880 – 5895, vienna, austria, july 2025. association for computational linguistics. isbn 979 - 8 - 89176 - 256 - 5. doi : 10. 18653 / v1 / 2025. findings - acl. 306. url [ https : / / aclanthology. org / 2025. findings - acl. 306 /. ] ( https : / / aclanthology. org / 2025. findings - acl. 306 / ) aaron hurst, adam lerer, adam p goucher, adam perelman, aditya ramesh, aidan clark, aj ostrow, akila welihinda, alan hayes, alec radford, et al. gpt - 4o system card. _ arxiv preprint _ _ arxiv : 2410. 21276 _, 2024. 15 reward models are metrics in a trench coat - preprint hamish ivison, yizhong wang, jiacheng liu, zeqiu wu, valentina pyatkin, nathan lambert, noah a smith, yejin choi, and hanna hajishirzi. unpacking dpo and ppo : disentangling best practices for learning from preference feedback. _ advances in neural information processing sys - _ _ tems _, 37 : 36602 – 36633, 2024. alon jacovi, jasmijn bastings, sebastian gehrmann, yoav goldberg, and katja filippova. diagnosing ai explanation methods with folk concepts of behavior. _ journal of artificial intelligence _ _ research _, 78 : 459 – 489, 2023. alon jacovi, andrew wang, chris alberti, connie tao, jon lipovetz, kate olszewska, lukas haas, michelle liu, nate keating, adam bloniarz, carl saroufim, corey fry, dror marcus, doron kukliansky, gaurav singh tomar, james swirhun, jinwei xing, lily wang, madhu gurumurthy, michael aaron, moran ambar, rachana fellinger, rui wang, zizhao zhang, sasha goldshtein, and dipanjan das. the facts grounding leaderboard : benchmarking llms ’ ability to ground responses to long - form input. _ corr _, abs / 2501. 03200, 2025. doi : 10. 48550 / arxiv. 2501. 03200. [ url https : / / doi. org / 10. 48550 / arxiv. 2501. 03200. ] ( https : / / doi. org / 10. 48550 / arxiv. 2501. 03200 ) ziwei ji, nayeon lee, rita frieske, tiezheng yu, dan su, yan xu, etsuko ishii, ye jin bang, andrea madotto, and pascale fung. survey of hallucination in natural language generation. _ acm _ _ computing surveys _, 55 ( 12 ) : 1 – 38, 2023. zi"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 24,
    "text": "##inger, rui wang, zizhao zhang, sasha goldshtein, and dipanjan das. the facts grounding leaderboard : benchmarking llms ’ ability to ground responses to long - form input. _ corr _, abs / 2501. 03200, 2025. doi : 10. 48550 / arxiv. 2501. 03200. [ url https : / / doi. org / 10. 48550 / arxiv. 2501. 03200. ] ( https : / / doi. org / 10. 48550 / arxiv. 2501. 03200 ) ziwei ji, nayeon lee, rita frieske, tiezheng yu, dan su, yan xu, etsuko ishii, ye jin bang, andrea madotto, and pascale fung. survey of hallucination in natural language generation. _ acm _ _ computing surveys _, 55 ( 12 ) : 1 – 38, 2023. zixuan ke, fangkai jiao, yifei ming, xuan - phi nguyen, austin xu, do xuan long, minzhi li, chengwei qin, peifeng wang, silvio savarese, et al. a survey of frontiers in llm reasoning : inference scaling, learning to reason, and agentic systems. _ arxiv preprint arxiv : 2504. 09037 _, 2025. seungone kim, jamin shin, yejin cho, joel jang, shayne longpre, hwaran lee, sangdoo yun, seongjin shin, sungdong kim, james thorne, and minjoon seo. prometheus : inducing fine - grained evaluation capability in language models. in _ the twelfth international confer - _ _ ence on learning representations _ [, 2024. url https : / / openreview. net / forum? id = ] ( https : / / openreview. net / forum? id = 8eujatvekw ) [ 8eujatvekw. ] ( https : / / openreview. net / forum? id = 8eujatvekw ) sunghwan kim, dongjin kang, taeyoon kwon, hyungjoo chae, dongha lee, and jinyoung yeo. rethinking reward model evaluation through the lens of reward overoptimization. in wanxiang che, joyce nabende, ekaterina shutova, and mohammad taher pilehvar ( eds. ), _ pro - _ _ ceedings of the 63rd annual meeting of the association for computational linguistics ( vol - _ _ ume 1 : long papers ) _, pp. 13252 – 13280, vienna, austria, july 2025. association for computational linguistics. isbn 979 - 8 - 89176 - 251 - 0. doi : 10. 18653 / v1 / 2025. acl - long. 649. url [ https : / / aclanthology. org / 2025. acl - long. 649 /. ] ( https : / / aclanthology. org / 2025. acl - long. 649 / ) kimi, yifan bai, yiping bao, guanduo chen, jiahao chen, ningxin chen, ruijue chen, yanru chen, yuankun chen, yutian chen, et al. kimi k2 : open agentic intelligence. _ arxiv preprint _ _ arxiv : 2507. 20534 _, 2025. rodney michael kinney, chloe anastasiades, russell authur, iz beltagy, jonathan bragg, alexandra buraczynski, isabel cachola, stefan candra, yoganand chandrasekhar, arman cohan, miles crawford, doug downey, jason dunkelberger, oren etzioni, rob evans, sergey feldman, joseph gorney, david w. graham, f. q. hu, regan huff, daniel king, sebastian kohlmeier, bailey kuehl, michael langan, daniel lin, haokun liu, kyle lo, jaron lochner, kelsey macmillan, tyler c. murray, christopher newell, smita r rao, shaurya rohatgi, paul sayre, zejiang shen, amanpreet singh, luca soldaini, shivashankar subramanian, a. tanaka, alex d wade, linda m. wagner, lucy lu wang, christopher wilhelm, caroline wu, jiangjiang yang, angele zamarron, madeleine van zuylen, and daniel s. weld. the semantic scholar open data platform. _ arxiv _ [, abs / 2301. 10140,"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 25,
    "text": "oren etzioni, rob evans, sergey feldman, joseph gorney, david w. graham, f. q. hu, regan huff, daniel king, sebastian kohlmeier, bailey kuehl, michael langan, daniel lin, haokun liu, kyle lo, jaron lochner, kelsey macmillan, tyler c. murray, christopher newell, smita r rao, shaurya rohatgi, paul sayre, zejiang shen, amanpreet singh, luca soldaini, shivashankar subramanian, a. tanaka, alex d wade, linda m. wagner, lucy lu wang, christopher wilhelm, caroline wu, jiangjiang yang, angele zamarron, madeleine van zuylen, and daniel s. weld. the semantic scholar open data platform. _ arxiv _ [, abs / 2301. 10140, 2023. url https : / / api. semanticscholar. org / ] ( https : / / api. semanticscholar. org / corpusid : 256194545 ) [ corpusid : 256194545. ] ( https : / / api. semanticscholar. org / corpusid : 256194545 ) bernard j. koch and david peterson. from protoscience to epistemic monoculture : how benchmarking set the stage for the deep learning revolution. _ corr _, abs / 2404. 06647, 2024. doi : 10. [ 48550 / arxiv. 2404. 06647. url https : / / doi. org / 10. 48550 / arxiv. 2404. 06647. ] ( https : / / doi. org / 10. 48550 / arxiv. 2404. 06647 ) 16 reward models are metrics in a trench coat - preprint tom kocmi, [UNK] zouhar, christian federmann, and matt post. navigating the metrics maze : reconciling score magnitudes and accuracies. in lun - wei ku, andre martins, and vivek srikumar ( eds. ), _ proceedings of the 62nd annual meeting of the association for computational lin - _ _ guistics ( volume 1 : long papers ) _, pp. 1999 – 2014, bangkok, thailand, august 2024. association for computational linguistics. doi : 10. 18653 / v1 / 2024. acl - long. 110. [ url https : ] ( https : / / aclanthology. org / 2024. acl - long. 110 / ) [ / / aclanthology. org / 2024. acl - long. 110 /. ] ( https : / / aclanthology. org / 2024. acl - long. 110 / ) victoria krakovna, jonathan uesato, vladimir mikulik, matthew rahtz, tom everitt, ramana kumar, zac kenton, jan leike, and shane legg. specification gaming : the flip side of ai ingenuity. [ https : / / deepmind. google / discover / blog / ] ( https : / / deepmind. google / discover / blog / specification - gaming - the - flip - side - of - ai - ingenuity / ) [ specification - gaming - the - flip - side - of - ai - ingenuity /, 2020. ] ( https : / / deepmind. google / discover / blog / specification - gaming - the - flip - side - of - ai - ingenuity / ) michael krumdick, charles lovering, varshini reddy, seth ebner, and chris tanner. no free labels : limitations of llm - as - a - judge without human grounding. _ arxiv preprint arxiv : 2503. 05061 _, 2025. wojciech [UNK], romain paulus, caiming xiong, and richard socher. improving abstraction in text summarization. in ellen riloff, david chiang, julia hockenmaier, and jun ’ ichi tsujii ( eds. ), _ proceedings of the 2018 conference on empirical methods in natural language processing _, pp. 1808 – 1817, brussels, belgium, october - november 2018. association for computational lin [ guistics. doi : 10. 18653 / v1 / d18 - 1207. url https : / / aclanthology. org / d18 - 1207 /. ] ( https : / / aclanthology. org / d18 - 1207 / ) faisal ladhak, esin durmus, claire cardie, and kathleen mckeown. wikilingua : a new benchmark dataset for cross - lingual abstractive"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 26,
    "text": "##1 _, 2025. wojciech [UNK], romain paulus, caiming xiong, and richard socher. improving abstraction in text summarization. in ellen riloff, david chiang, julia hockenmaier, and jun ’ ichi tsujii ( eds. ), _ proceedings of the 2018 conference on empirical methods in natural language processing _, pp. 1808 – 1817, brussels, belgium, october - november 2018. association for computational lin [ guistics. doi : 10. 18653 / v1 / d18 - 1207. url https : / / aclanthology. org / d18 - 1207 /. ] ( https : / / aclanthology. org / d18 - 1207 / ) faisal ladhak, esin durmus, claire cardie, and kathleen mckeown. wikilingua : a new benchmark dataset for cross - lingual abstractive summarization. in trevor cohn, yulan he, and yang liu ( eds. ), _ findings of the association for computational linguistics : emnlp 2020 _, pp. 4034 – 4048, online, november 2020. association for computational linguistics. doi : 10. 18653 / v1 / 2020. findings - emnlp. 360. [ url https : / / aclanthology. org / 2020. findings - emnlp. ] ( https : / / aclanthology. org / 2020. findings - emnlp. 360 / ) [ 360 /. ] ( https : / / aclanthology. org / 2020. findings - emnlp. 360 / ) nathan lambert, jacob morrison, valentina pyatkin, shengyi huang, hamish ivison, faeze brahman, lester james v miranda, alisa liu, nouha dziri, shane lyu, et al. tulu 3 : pushing frontiers in open language model post - training. _ arxiv preprint arxiv : 2411. 15124 _, 2024. nathan lambert, valentina pyatkin, jacob morrison, lj miranda, bill yuchen lin, khyathi chandu, nouha dziri, sachin kumar, tom zick, yejin choi, noah a. smith, and hannaneh hajishirzi. rewardbench : evaluating reward models for language modeling. in luis chiruzzo, alan ritter, and lu wang ( eds. ), _ findings of the association for computational linguistics : naacl _ _ 2025 _, pp. 1755 – 1797, albuquerque, new mexico, april 2025. association for computational [ linguistics. isbn 979 - 8 - 89176 - 195 - 7. doi : 10. 18653 / v1 / 2025. findings - naacl. 96. url https : ] ( https : / / aclanthology. org / 2025. findings - naacl. 96 / ) [ / / aclanthology. org / 2025. findings - naacl. 96 /. ] ( https : / / aclanthology. org / 2025. findings - naacl. 96 / ) yann lecun. predictive learning. [ https : / / www. youtube. com / watch? v = ] ( https : / / www. youtube. com / watch? v = ount2y4qxqo & t = 1072s ) [ ount2y4qxqo & t = 1072s, 2016. ] ( https : / / www. youtube. com / watch? v = ount2y4qxqo & t = 1072s ) harrison lee, samrat phatale, hassan mansoor, thomas mesnard, johan ferret, kellie lu, colton bishop, ethan hall, victor carbune, abhinav rastogi, and sushant prakash. rlaif vs. rlhf : scaling reinforcement learning from human feedback with ai feedback. in _ forty - first interna - _ _ tional conference on machine learning, icml 2024, vienna, austria, july 21 - 27, 2024 _. open [ review. net, 2024a. url https : / / openreview. net / forum? id = uydq2w41ko. ] ( https : / / openreview. net / forum? id = uydq2w41ko ) yukyung lee, joonghoon kim, jaehee kim, hyowon cho, jaewook kang, pilsung kang, and najoung kim. checkeval : a reliable llm - as - a - judge framework for evaluating text generation"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 27,
    "text": "johan ferret, kellie lu, colton bishop, ethan hall, victor carbune, abhinav rastogi, and sushant prakash. rlaif vs. rlhf : scaling reinforcement learning from human feedback with ai feedback. in _ forty - first interna - _ _ tional conference on machine learning, icml 2024, vienna, austria, july 21 - 27, 2024 _. open [ review. net, 2024a. url https : / / openreview. net / forum? id = uydq2w41ko. ] ( https : / / openreview. net / forum? id = uydq2w41ko ) yukyung lee, joonghoon kim, jaehee kim, hyowon cho, jaewook kang, pilsung kang, and najoung kim. checkeval : a reliable llm - as - a - judge framework for evaluating text generation using checklists. _ arxiv preprint arxiv : 2403. 18771 _, 2024b. jan leike, david krueger, tom everitt, miljan martic, vishal maini, and shane legg. scalable agent alignment via reward modeling : a research direction. _ arxiv _, abs / 1811. 07871, 2018. url [ https : / / api. semanticscholar. org / corpusid : 53745764. ] ( https : / / api. semanticscholar. org / corpusid : 53745764 ) jixuan leng, chengsong huang, banghua zhu, and jiaxin huang. taming overconfidence in llms : reward calibration in rlhf. in _ the thirteenth international conference on learning represen - _ _ tations _ [, 2025. url https : / / openreview. net / forum? id = l0tg0jzsdl. ] ( https : / / openreview. net / forum? id = l0tg0jzsdl ) 17 reward models are metrics in a trench coat - preprint mike lewis, yinhan liu, naman goyal, marjan ghazvininejad, abdelrahman mohamed, omer levy, veselin stoyanov, and luke zettlemoyer. bart : denoising sequence - to - sequence pretraining for natural language generation, translation, and comprehension. in dan jurafsky, joyce chai, natalie schluter, and joel tetreault ( eds. ), _ proceedings of the 58th annual meet - _ _ ing of the association for computational linguistics _, pp. 7871 – 7880, online, july 2020. as [ sociation for computational linguistics. doi : 10. 18653 / v1 / 2020. acl - main. 703. url https : ] ( https : / / aclanthology. org / 2020. acl - main. 703 / ) [ / / aclanthology. org / 2020. acl - main. 703 /. ] ( https : / / aclanthology. org / 2020. acl - main. 703 / ) piji li, lidong bing, and wai lam. actor - critic based training framework for abstractive summarization. _ corr _ [, abs / 1803. 11070, 2018. url http : / / arxiv. org / abs / 1803. 11070. ] ( http : / / arxiv. org / abs / 1803. 11070 ) hunter lightman, vineet kosaraju, yuri burda, harrison edwards, bowen baker, teddy lee, jan leike, john schulman, ilya sutskever, and karl cobbe. let ’ s verify step by step. in _ the twelfth _ _ international conference on learning representations _ [, 2024. url https : / / openreview. ] ( https : / / openreview. net / forum? id = v8l0pn6eoi ) [ net / forum? id = v8l0pn6eoi. ] ( https : / / openreview. net / forum? id = v8l0pn6eoi ) chin - yew lin. rouge : a package for automatic evaluation of summaries. in _ text summarization _ _ branches out _, pp. 74 – 81, barcelona, spain, july 2004. association for computational linguis [ tics. url https : / / aclanthology. org / w04 - 1013 /. ] ( https : / / aclanthology. org / w04 - 1013 / ) chris yuhao liu, liang zeng, jiacai liu, rui yan, jujie he, chaojie wang, shuicheng yan"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 28,
    "text": "conference on learning representations _ [, 2024. url https : / / openreview. ] ( https : / / openreview. net / forum? id = v8l0pn6eoi ) [ net / forum? id = v8l0pn6eoi. ] ( https : / / openreview. net / forum? id = v8l0pn6eoi ) chin - yew lin. rouge : a package for automatic evaluation of summaries. in _ text summarization _ _ branches out _, pp. 74 – 81, barcelona, spain, july 2004. association for computational linguis [ tics. url https : / / aclanthology. org / w04 - 1013 /. ] ( https : / / aclanthology. org / w04 - 1013 / ) chris yuhao liu, liang zeng, jiacai liu, rui yan, jujie he, chaojie wang, shuicheng yan, yang liu, and yahui zhou. skywork - reward : bag of tricks for reward modeling in llms. _ arxiv preprint _ _ arxiv : 2410. 18451 _, 2024. siqi liu, ian gemp, luke marris, georgios piliouras, nicolas heess, and marc lanctot. reevaluating open - ended evaluation of large language models. in _ the thirteenth international con - _ _ ference on learning representations _ [, 2025a. url https : / / openreview. net / forum? ] ( https : / / openreview. net / forum? id = kboaixkwgx ) [ id = kboaixkwgx. ] ( https : / / openreview. net / forum? id = kboaixkwgx ) tianqi liu, wei xiong, jie ren, lichang chen, junru wu, rishabh joshi, yang gao, jiaming shen, zhen qin, tianhe yu, daniel sohn, anastasia makarova, jeremiah zhe liu, yuan liu, bilal piot, abe ittycheriah, aviral kumar, and mohammad saleh. rrm : robust reward model training mitigates reward hacking. in _ the thirteenth international conference on learning representations _, [ 2025b. url https : / / openreview. net / forum? id = 88as5mqnmc. ] ( https : / / openreview. net / forum? id = 88as5mqnmc ) yantao liu, zijun yao, rui min, yixin cao, lei hou, and juanzi li. rm - bench : benchmarking reward models of language models with subtlety and style. in _ the thirteenth international con - _ _ ference on learning representations, iclr 2025, singapore, april 24 - 28, 2025 _. openreview. net, [ 2025c. url https : / / openreview. net / forum? id = qehrmqpbdd. ] ( https : / / openreview. net / forum? id = qehrmqpbdd ) qingsong ma, ondˇrej bojar, and yvette graham. results of the wmt18 metrics shared task : both characters and embeddings achieve good performance. in ondˇrej bojar, rajen chatterjee, christian federmann, mark fishel, yvette graham, barry haddow, matthias huck, antonio jimeno yepes, philipp koehn, christof monz, matteo negri, [UNK] [UNK], mariana neves, matt post, lucia specia, marco turchi, and karin verspoor ( eds. ), _ proceedings of the _ _ third conference on machine translation : shared task papers _, pp. 671 – 688, belgium, brussels, october 2018. association for computational linguistics. doi : 10. 18653 / v1 / w18 - 6450. url [ https : / / aclanthology. org / w18 - 6450 /. ] ( https : / / aclanthology. org / w18 - 6450 / ) qingsong ma, johnny wei, ondˇrej bojar, and yvette graham. results of the wmt19 metrics shared task : segment - level and strong mt systems pose big challenges. in ondˇrej bojar, rajen chatterjee, christian federmann, mark fishel, yvette graham, barry haddow, matthias huck, antonio jimeno yepes, philipp koehn, [UNK] martins, christof monz, matteo negri, [UNK] [UNK], mariana neves, matt post, marco turchi, and kar"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 29,
    "text": "671 – 688, belgium, brussels, october 2018. association for computational linguistics. doi : 10. 18653 / v1 / w18 - 6450. url [ https : / / aclanthology. org / w18 - 6450 /. ] ( https : / / aclanthology. org / w18 - 6450 / ) qingsong ma, johnny wei, ondˇrej bojar, and yvette graham. results of the wmt19 metrics shared task : segment - level and strong mt systems pose big challenges. in ondˇrej bojar, rajen chatterjee, christian federmann, mark fishel, yvette graham, barry haddow, matthias huck, antonio jimeno yepes, philipp koehn, [UNK] martins, christof monz, matteo negri, [UNK] [UNK], mariana neves, matt post, marco turchi, and karin verspoor ( eds. ), _ proceedings of _ _ the fourth conference on machine translation ( volume 2 : shared task papers, day 1 ) _, pp. 62 – 90, florence, italy, august 2019. association for computational linguistics. doi : 10. 18653 / v1 / [ w19 - 5302. url https : / / aclanthology. org / w19 - 5302 /. ] ( https : / / aclanthology. org / w19 - 5302 / ) saumya malik, valentina pyatkin, sander land, jacob morrison, noah a. smith, hannaneh hajishirzi, and nathan lambert. rewardbench 2 : advancing reward model evaluation. _ corr _, [ abs / 2506. 01937, 2025. doi : 10. 48550 / arxiv. 2506. 01937. url https : / / doi. org / 10. ] ( https : / / doi. org / 10. 48550 / arxiv. 2506. 01937 ) [ 48550 / arxiv. 2506. 01937. ] ( https : / / doi. org / 10. 48550 / arxiv. 2506. 01937 ) 18 reward models are metrics in a trench coat - preprint david manheim and scott garrabrant. categorizing variants of goodhart ’ s law. _ arxiv preprint _ _ arxiv : 1803. 04585 _, 2018. nitika mathur, johnny wei, markus freitag, qingsong ma, and ondˇrej bojar. results of the wmt20 metrics shared task. in [UNK] barrault, ondˇrej bojar, fethi bougares, rajen chatterjee, marta r. costa - juss ` a, christian federmann, mark fishel, alexander fraser, yvette graham, paco guzman, barry haddow, matthias huck, antonio jimeno yepes, philipp koehn, [UNK] martins, makoto morishita, christof monz, masaaki nagata, toshiaki nakazawa, and matteo negri ( eds. ), _ proceedings of the fifth conference on machine translation _, pp. 688 – 725, online, november 2020. association for computational linguistics. [ url https : / / aclanthology. org / ] ( https : / / aclanthology. org / 2020. wmt - 1. 77 / ) [ 2020. wmt - 1. 77 /. ] ( https : / / aclanthology. org / 2020. wmt - 1. 77 / ) joshua maynez, shashi narayan, bernd bohnet, and ryan mcdonald. on faithfulness and factuality in abstractive summarization. in dan jurafsky, joyce chai, natalie schluter, and joel tetreault ( eds. ), _ proceedings of the 58th annual meeting of the association for computational linguistics _, pp. 1906 – 1919, online, july 2020. association for computational linguistics. doi : 10. 18653 / v1 / [ 2020. acl - main. 173. url https : / / aclanthology. org / 2020. acl - main. 173 /. ] ( https : / / aclanthology. org / 2020. acl - main. 173 / ) r. thomas mccoy, ellie pavlick, and tal linzen. right for the wrong reasons : diagnosing syntactic heuristics in natural language inference. in anna korhonen, david traum, and [UNK] m ` arquez ( eds. ), _ proceedings of the 57th annual meeting of the association for computational linguistics _, pp. 3428"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 30,
    "text": "##ive summarization. in dan jurafsky, joyce chai, natalie schluter, and joel tetreault ( eds. ), _ proceedings of the 58th annual meeting of the association for computational linguistics _, pp. 1906 – 1919, online, july 2020. association for computational linguistics. doi : 10. 18653 / v1 / [ 2020. acl - main. 173. url https : / / aclanthology. org / 2020. acl - main. 173 /. ] ( https : / / aclanthology. org / 2020. acl - main. 173 / ) r. thomas mccoy, ellie pavlick, and tal linzen. right for the wrong reasons : diagnosing syntactic heuristics in natural language inference. in anna korhonen, david traum, and [UNK] m ` arquez ( eds. ), _ proceedings of the 57th annual meeting of the association for computational linguistics _, pp. 3428 – 3448, florence, italy, july 2019. association for computational linguistics. doi : 10. [ 18653 / v1 / p19 - 1334. url https : / / aclanthology. org / p19 - 1334 /. ] ( https : / / aclanthology. org / p19 - 1334 / ) yannick metz, andras geiszl, [UNK] baur, and mennatallah el - assady. reward learning from multiple feedback types. in _ the thirteenth international conference on learning representa - _ _ tions _ [, 2025. url https : / / openreview. net / forum? id = 9ieq8jqnal. ] ( https : / / openreview. net / forum? id = 9ieq8jqnal ) sewon min, kalpesh krishna, xinxi lyu, mike lewis, wen - tau yih, pang koh, mohit iyyer, luke zettlemoyer, and hannaneh hajishirzi. factscore : fine - grained atomic evaluation of factual precision in long form text generation. in houda bouamor, juan pino, and kalika bali ( eds. ), _ proceedings of the 2023 conference on empirical methods in natural language pro - _ _ cessing _, pp. 12076 – 12100, singapore, december 2023. association for computational linguis [ tics. doi : 10. 18653 / v1 / 2023. emnlp - main. 741. url https : / / aclanthology. org / 2023. ] ( https : / / aclanthology. org / 2023. emnlp - main. 741 / ) [ emnlp - main. 741 /. ] ( https : / / aclanthology. org / 2023. emnlp - main. 741 / ) volodymyr mnih, nicolas heess, alex graves, and koray kavukcuoglu. recurrent models of visual attention. in zoubin ghahramani, max welling, corinna cortes, neil d. lawrence, and kilian q. weinberger ( eds. ), _ advances in neural information processing systems 27 : annual con - _ _ ference on neural information processing systems 2014, december 8 - 13 2014, montreal, que - _ _ bec, canada _ [, pp. 2204 – 2212, 2014. url https : / / proceedings. neurips. cc / paper / ] ( https : / / proceedings. neurips. cc / paper / 2014 / hash / 09c6c3783b4a70054da74f2538ed47c6 - abstract. html ) [ 2014 / hash / 09c6c3783b4a70054da74f2538ed47c6 - abstract. html. ] ( https : / / proceedings. neurips. cc / paper / 2014 / hash / 09c6c3783b4a70054da74f2538ed47c6 - abstract. html ) bhuvanashree murugadoss, christian [UNK], ian drosos, vu le, nick mckenna, carina suzana negreanu, chris parnin, and advait sarkar. evaluating the evaluator : measuring llms ’ adherence to task evaluation instructions. in toby walsh, julie shah, and zico kolter ( eds. ), _ aaai - 25, _ _ sponsored by the association for the advancement of artificial intelligence, february 25 - march _ _ 4, 2025, philadelphia, pa, usa _, pp. 19589 – 19597. aaai press, 2025. doi : 10. 1609 / aaai. [ v39i18"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 31,
    "text": "##2538ed47c6 - abstract. html. ] ( https : / / proceedings. neurips. cc / paper / 2014 / hash / 09c6c3783b4a70054da74f2538ed47c6 - abstract. html ) bhuvanashree murugadoss, christian [UNK], ian drosos, vu le, nick mckenna, carina suzana negreanu, chris parnin, and advait sarkar. evaluating the evaluator : measuring llms ’ adherence to task evaluation instructions. in toby walsh, julie shah, and zico kolter ( eds. ), _ aaai - 25, _ _ sponsored by the association for the advancement of artificial intelligence, february 25 - march _ _ 4, 2025, philadelphia, pa, usa _, pp. 19589 – 19597. aaai press, 2025. doi : 10. 1609 / aaai. [ v39i18. 34157. url https : / / doi. org / 10. 1609 / aaai. v39i18. 34157. ] ( https : / / doi. org / 10. 1609 / aaai. v39i18. 34157 ) vaishnavh nagarajan, anders andreassen, and behnam neyshabur. understanding the failure modes of out - of - distribution generalization. in _ international conference on learning repre - _ _ sentations _ [, 2021. url https : / / openreview. net / forum? id = fstd6nfiw _ b. ] ( https : / / openreview. net / forum? id = fstd6nfiw _ b ) openai. gpt - 5 system card, aug 2025. url [ https : / / cdn. openai. com / ] ( https : / / cdn. openai. com / gpt - 5 - system - card. pdf ) [ gpt - 5 - system - card. pdf. ] ( https : / / cdn. openai. com / gpt - 5 - system - card. pdf ) long ouyang, jeff wu, xu jiang, diogo almeida, carroll l. wainwright, pamela mishkin, chong zhang, sandhini agarwal, katarina slama, alex ray, john schulman, jacob hilton, fraser kelton, luke miller, maddie simens, amanda askell, peter welinder, paul christiano, jan leike, and ryan lowe. training language models to follow instructions with human feedback. in _ pro - _ _ ceedings of the 36th international conference on neural information processing systems _, nips ’ 22, red hook, ny, usa, 2022. curran associates inc. isbn 9781713871088. 19 reward models are metrics in a trench coat - preprint kishore papineni, salim roukos, todd ward, and wei - jing zhu. bleu : a method for automatic evaluation of machine translation. in pierre isabelle, eugene charniak, and dekang lin ( eds. ), _ proceedings of the 40th annual meeting of the association for computational linguistics _, pp. 311 – 318, philadelphia, pennsylvania, usa, july 2002. association for computational linguis [ tics. doi : 10. 3115 / 1073083. 1073135. url https : / / aclanthology. org / p02 - 1040 /. ] ( https : / / aclanthology. org / p02 - 1040 / ) ramakanth pasunuru and mohit bansal. reinforced video captioning with entailment rewards. in martha palmer, rebecca hwa, and sebastian riedel ( eds. ), _ proceedings of the 2017 conference _ _ on empirical methods in natural language processing _, pp. 979 – 985, copenhagen, denmark, september 2017. association for computational linguistics. doi : 10. 18653 / v1 / d17 - 1103. url [ https : / / aclanthology. org / d17 - 1103 /. ] ( https : / / aclanthology. org / d17 - 1103 / ) ramakanth pasunuru and mohit bansal. multi - reward reinforced summarization with saliency and entailment. in marilyn walker, heng ji, and amanda stent ( eds. ), _ proceedings of the 2018 con - _ _ ference of the north american chapter of the association for computational linguistics : hu - _ _ man language technologies, volume 2 ( short papers ) _, pp. 646 – 653, new orleans, louisiana, june 2018. association for computational linguistics. doi :"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 32,
    "text": "_ proceedings of the 2017 conference _ _ on empirical methods in natural language processing _, pp. 979 – 985, copenhagen, denmark, september 2017. association for computational linguistics. doi : 10. 18653 / v1 / d17 - 1103. url [ https : / / aclanthology. org / d17 - 1103 /. ] ( https : / / aclanthology. org / d17 - 1103 / ) ramakanth pasunuru and mohit bansal. multi - reward reinforced summarization with saliency and entailment. in marilyn walker, heng ji, and amanda stent ( eds. ), _ proceedings of the 2018 con - _ _ ference of the north american chapter of the association for computational linguistics : hu - _ _ man language technologies, volume 2 ( short papers ) _, pp. 646 – 653, new orleans, louisiana, june 2018. association for computational linguistics. doi : 10. 18653 / v1 / n18 - 2102. url [ https : / / aclanthology. org / n18 - 2102 /. ] ( https : / / aclanthology. org / n18 - 2102 / ) romain paulus, caiming xiong, and richard socher. a deep reinforced model for abstractive summarization. in _ international conference on learning representations _ [, 2018. url https : ] ( https : / / openreview. net / forum? id = hkaclqga - ) [ / / openreview. net / forum? id = hkaclqga -. ] ( https : / / openreview. net / forum? id = hkaclqga - ) stefano perrella, lorenzo proietti, alessandro scir ` e, edoardo barba, and roberto navigli. guardians of the machine translation meta - evaluation : sentinel metrics fall in! in lun - wei ku, andre martins, and vivek srikumar ( eds. ), _ proceedings of the 62nd annual meeting of the associ - _ _ ation for computational linguistics ( volume 1 : long papers ) _, pp. 16216 – 16244, bangkok, thailand, august 2024. association for computational linguistics. doi : 10. 18653 / v1 / 2024. acl - long. [ 856. url https : / / aclanthology. org / 2024. acl - long. 856 /. ] ( https : / / aclanthology. org / 2024. acl - long. 856 / ) matt post. a call for clarity in reporting bleu scores. in ondˇrej bojar, rajen chatterjee, christian federmann, mark fishel, yvette graham, barry haddow, matthias huck, antonio jimeno yepes, philipp koehn, christof monz, matteo negri, [UNK] [UNK], mariana neves, matt post, lucia specia, marco turchi, and karin verspoor ( eds. ), _ proceedings of the third _ _ conference on machine translation : research papers _, pp. 186 – 191, brussels, belgium, october 2018. association for computational linguistics. doi : 10. 18653 / v1 / w18 - 6319. url [ https : / / aclanthology. org / w18 - 6319 /. ] ( https : / / aclanthology. org / w18 - 6319 / ) zhaopeng qiu, xian wu, and wei fan. automatic distractor generation for multiple choice questions in standard tests. in donia scott, nuria bel, and chengqing zong ( eds. ), _ proceedings of the _ _ 28th international conference on computational linguistics _, pp. 2096 – 2106, barcelona, spain ( online ), december 2020. international committee on computational linguistics. doi : 10. 18653 / [ v1 / 2020. coling - main. 189. url https : / / aclanthology. org / 2020. coling - main. ] ( https : / / aclanthology. org / 2020. coling - main. 189 / ) [ 189 /. ] ( https : / / aclanthology. org / 2020. coling - main. 189 / ) rafael rafailov, archit sharma, eric mitchell, christopher d. manning, stefano ermon, and chelsea finn. direct preference optimization : your language model is secretly a reward model. in alice oh, tristan naumann, amir globerson, kate saenko, moritz hardt, and sergey levine ( eds. ), _ advances in neural information processing systems 36 : annual conference on"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 33,
    "text": ", barcelona, spain ( online ), december 2020. international committee on computational linguistics. doi : 10. 18653 / [ v1 / 2020. coling - main. 189. url https : / / aclanthology. org / 2020. coling - main. ] ( https : / / aclanthology. org / 2020. coling - main. 189 / ) [ 189 /. ] ( https : / / aclanthology. org / 2020. coling - main. 189 / ) rafael rafailov, archit sharma, eric mitchell, christopher d. manning, stefano ermon, and chelsea finn. direct preference optimization : your language model is secretly a reward model. in alice oh, tristan naumann, amir globerson, kate saenko, moritz hardt, and sergey levine ( eds. ), _ advances in neural information processing systems 36 : annual conference on neural _ _ information processing systems 2023, neurips 2023, new orleans, la, usa, december 10 - _ _ 16, 2023 _ [, 2023. url http : / / papers. nips. cc / paper _ files / paper / 2023 / hash / ] ( http : / / papers. nips. cc / paper _ files / paper / 2023 / hash / a85b405ed65c6477a4fe8302b5e06ce7 - abstract - conference. html ) [ a85b405ed65c6477a4fe8302b5e06ce7 - abstract - conference. html. ] ( http : / / papers. nips. cc / paper _ files / paper / 2023 / hash / a85b405ed65c6477a4fe8302b5e06ce7 - abstract - conference. html ) deborah raji, emily denton, emily m. bender, alex hanna, and amandalynne paullada. ai and the everything in the whole wide world benchmark. in j. vanschoren and s. yeung ( eds. ), _ proceedings _ _ of _ _ the _ _ neural _ _ information _ _ processing _ _ systems _ _ track _ _ on _ _ datasets _ _ and _ _ benchmarks _, volume 1, 2021. url [ https : ] ( https : / / datasets - benchmarks - proceedings. neurips. cc / paper _ files / paper / 2021 / file / 084b6fbb10729ed4da8c3d3f5a3ae7c9 - paper - round2. pdf ) [ / / datasets - benchmarks - proceedings. neurips. cc / paper _ files / paper / ] ( https : / / datasets - benchmarks - proceedings. neurips. cc / paper _ files / paper / 2021 / file / 084b6fbb10729ed4da8c3d3f5a3ae7c9 - paper - round2. pdf ) [ 2021 / file / 084b6fbb10729ed4da8c3d3f5a3ae7c9 - paper - round2. pdf. ] ( https : / / datasets - benchmarks - proceedings. neurips. cc / paper _ files / paper / 2021 / file / 084b6fbb10729ed4da8c3d3f5a3ae7c9 - paper - round2. pdf ) peter a. rankel, john m. conroy, hoa trang dang, and ani nenkova. a decade of automatic content evaluation of news summaries : reassessing the state of the art. in hinrich schuetze, 20 reward models are metrics in a trench coat - preprint pascale fung, and massimo poesio ( eds. ), _ proceedings of the 51st annual meeting of the asso - _ _ ciation for computational linguistics ( volume 2 : short papers ) _, pp. 131 – 136, sofia, bulgaria, [ august 2013. association for computational linguistics. url https : / / aclanthology. ] ( https : / / aclanthology. org / p13 - 2024 / ) [ org / p13 - 2024 /. ] ( https : / / aclanthology. org / p13 - 2024 / ) marc ’ aurelio ranzato, sumit chopra, michael auli, and wojciech zaremba. sequence level training with recurrent neural networks. in yoshua bengio and yann lecun ( eds. ), _ 4th international _ _ conference on learning representations, iclr 2016, san juan, puerto rico, may 2 - 4, 2016"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 34,
    "text": "##ale fung, and massimo poesio ( eds. ), _ proceedings of the 51st annual meeting of the asso - _ _ ciation for computational linguistics ( volume 2 : short papers ) _, pp. 131 – 136, sofia, bulgaria, [ august 2013. association for computational linguistics. url https : / / aclanthology. ] ( https : / / aclanthology. org / p13 - 2024 / ) [ org / p13 - 2024 /. ] ( https : / / aclanthology. org / p13 - 2024 / ) marc ’ aurelio ranzato, sumit chopra, michael auli, and wojciech zaremba. sequence level training with recurrent neural networks. in yoshua bengio and yann lecun ( eds. ), _ 4th international _ _ conference on learning representations, iclr 2016, san juan, puerto rico, may 2 - 4, 2016, _ _ conference track proceedings _ [, 2016. url http : / / arxiv. org / abs / 1511. 06732. ] ( http : / / arxiv. org / abs / 1511. 06732 ) hannah rashkin, vitaly nikolaev, matthew lamm, lora aroyo, michael collins, dipanjan das, slav petrov, gaurav singh tomar, iulia turc, and david reitter. measuring attribution in natural language generation models. _ computational linguistics _, 49 ( 4 ) : 777 – 840, december 2023. doi : 10. 1162 / coli a ~ ~ 0 ~ ~ [ 0486. url https : / / aclanthology. org / 2023. cl - 4. 2 /. ] ( https : / / aclanthology. org / 2023. cl - 4. 2 / ) charvi rastogi, tian huey teh, pushkar mishra, roma patel, zoe ashwood, aida mostafazadeh davani, mark diaz, michela paganini, alicia parrish, ding wang, vinodkumar prabhakaran, lora aroyo, and verena rieser. insights on disagreement patterns in multimodal safety perception across diverse rater groups. in _ neurips safe generative ai workshop 2024 _ [, 2024. url https : ] ( https : / / openreview. net / forum? id = 8ti0lurjbp ) [ / / openreview. net / forum? id = 8ti0lurjbp. ] ( https : / / openreview. net / forum? id = 8ti0lurjbp ) charvi rastogi, tian huey teh, pushkar mishra, roma patel, ding wang, mark [UNK], alicia parrish, aida mostafazadeh davani, zoe ashwood, michela paganini, et al. whose view of safety? a deep dive dataset for pluralistic alignment of text - to - image models. _ arxiv preprint arxiv : 2507. 13383 _, 2025. ricardo rei, marcos treviso, nuno m. guerreiro, chrysoula zerva, ana c farinha, christine maroti, [UNK] g. c. de souza, taisiya glushkova, duarte alves, luisa coheur, alon lavie, and [UNK] f. t. martins. cometkiwi : ist - unbabel 2022 submission for the quality estimation shared task. in philipp koehn, [UNK] barrault, ondˇrej bojar, fethi bougares, rajen chatterjee, marta r. costa - juss ` a, christian federmann, mark fishel, alexander fraser, markus freitag, yvette graham, roman grundkiewicz, paco guzman, barry haddow, matthias huck, antonio jimeno yepes, tom kocmi, [UNK] martins, makoto morishita, christof monz, masaaki nagata, toshiaki nakazawa, matteo negri, [UNK] [UNK], mariana neves, martin popel, marco turchi, and marcos zampieri ( eds. ), _ proceedings of the seventh conference on machine translation _ _ ( wmt ) _, pp. 634 – 645, abu dhabi, united arab emirates ( hybrid ), december 2022. association [ for computational linguistics. url https : / / aclanthology. org / 2022. wmt - 1. 60 /. ] ( https : / / aclanthology. org / 2022. wmt - 1. 60 /"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 35,
    "text": "markus freitag, yvette graham, roman grundkiewicz, paco guzman, barry haddow, matthias huck, antonio jimeno yepes, tom kocmi, [UNK] martins, makoto morishita, christof monz, masaaki nagata, toshiaki nakazawa, matteo negri, [UNK] [UNK], mariana neves, martin popel, marco turchi, and marcos zampieri ( eds. ), _ proceedings of the seventh conference on machine translation _ _ ( wmt ) _, pp. 634 – 645, abu dhabi, united arab emirates ( hybrid ), december 2022. association [ for computational linguistics. url https : / / aclanthology. org / 2022. wmt - 1. 60 /. ] ( https : / / aclanthology. org / 2022. wmt - 1. 60 / ) ehud reiter. a structured review of the validity of bleu. _ comput. linguistics _, 44 ( 3 ), 2018. doi : 10. 1162 / coli _ \\ _ ~ ~ a ~ ~ _ \\ _ [ 00322. url https : / / doi. org / 10. 1162 / coli _ a _ 00322. ] ( https : / / doi. org / 10. 1162 / coli _ a _ 00322 ) steven j. rennie, etienne marcheret, youssef mroueh, jerret ross, and vaibhava goel. self - critical sequence training for image captioning. in _ 2017 ieee conference on computer vision and pat - _ _ tern recognition, cvpr 2017, honolulu, hi, usa, july 21 - 26, 2017 _, pp. 1179 – 1195. ieee com [ puter society, 2017. doi : 10. 1109 / cvpr. 2017. 131. url https : / / doi. org / 10. 1109 / ] ( https : / / doi. org / 10. 1109 / cvpr. 2017. 131 ) [ cvpr. 2017. 131. ] ( https : / / doi. org / 10. 1109 / cvpr. 2017. 131 ) marco tulio ribeiro, sameer singh, and carlos guestrin. ” why should i trust you? ” explaining the predictions of any classifier. in _ proceedings of the 22nd acm sigkdd international conference _ _ on knowledge discovery and data mining _, pp. 1135 – 1144, 2016. [UNK] ross, geoffrey j. gordon, and drew bagnell. a reduction of imitation learning and structured prediction to no - regret online learning. in geoffrey j. gordon, david b. dunson, and miroslav [UNK] ( eds. ), _ proceedings of the fourteenth international conference on artificial _ _ intelligence and statistics, aistats 2011, fort lauderdale, usa, april 11 - 13, 2011 _, volume 15 of _ jmlr proceedings _ [, pp. 627 – 635. jmlr. org, 2011. url http : / / proceedings. mlr. ] ( http : / / proceedings. mlr. press / v15 / ross11a / ross11a. pdf ) [ press / v15 / ross11a / ross11a. pdf. ] ( http : / / proceedings. mlr. press / v15 / ross11a / ross11a. pdf ) keita saito, akifumi wachi, koki wataoka, and youhei akimoto. verbosity bias in preference labeling by large language models. _ corr _, abs / 2310. 10076, 2023. doi : 10. 48550 / arxiv. 2310. [ 10076. url https : / / doi. org / 10. 48550 / arxiv. 2310. 10076. ] ( https : / / doi. org / 10. 48550 / arxiv. 2310. 10076 ) 21 reward models are metrics in a trench coat - preprint john schulman, filip wolski, prafulla dhariwal, alec radford, and oleg klimov. proximal policy optimization algorithms. _ corr _ [, abs / 1707. 06347, 2017. url http : / / arxiv. org / abs / ] ( http : / / arxiv. org / abs / 1707. 06347 ) [ 1707. 06347. ] ( http : / / arxiv. org / abs / 1707. 06347 ) thomas scialom, sylvain lamprier, benjamin piwowarski, and jacopo staiano. answers unite! unsupervised metrics for reinforced summarization models. in"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 36,
    "text": "https : / / doi. org / 10. 48550 / arxiv. 2310. 10076. ] ( https : / / doi. org / 10. 48550 / arxiv. 2310. 10076 ) 21 reward models are metrics in a trench coat - preprint john schulman, filip wolski, prafulla dhariwal, alec radford, and oleg klimov. proximal policy optimization algorithms. _ corr _ [, abs / 1707. 06347, 2017. url http : / / arxiv. org / abs / ] ( http : / / arxiv. org / abs / 1707. 06347 ) [ 1707. 06347. ] ( http : / / arxiv. org / abs / 1707. 06347 ) thomas scialom, sylvain lamprier, benjamin piwowarski, and jacopo staiano. answers unite! unsupervised metrics for reinforced summarization models. in kentaro inui, jing jiang, vincent ng, and xiaojun wan ( eds. ), _ proceedings of the 2019 conference on empirical methods in natural _ _ language processing and the 9th international joint conference on natural language process - _ _ ing ( emnlp - ijcnlp ) _, pp. 3246 – 3256, hong kong, china, november 2019. association for [ computational linguistics. doi : 10. 18653 / v1 / d19 - 1320. url https : / / aclanthology. ] ( https : / / aclanthology. org / d19 - 1320 / ) [ org / d19 - 1320 /. ] ( https : / / aclanthology. org / d19 - 1320 / ) thomas scialom, paul - alexis dray, sylvain lamprier, benjamin piwowarski, and jacopo staiano. mlsum : the multilingual summarization corpus. in bonnie webber, trevor cohn, yulan he, and yang liu ( eds. ), _ proceedings of the 2020 conference on empirical methods _ _ in natural language processing ( emnlp ) _, pp. 8051 – 8067, online, november 2020. associ [ ation for computational linguistics. doi : 10. 18653 / v1 / 2020. emnlp - main. 647. url https : ] ( https : / / aclanthology. org / 2020. emnlp - main. 647 / ) [ / / aclanthology. org / 2020. emnlp - main. 647 /. ] ( https : / / aclanthology. org / 2020. emnlp - main. 647 / ) thomas scialom, paul - alexis dray, sylvain lamprier, benjamin piwowarski, jacopo staiano, alex wang, and patrick gallinari. questeval : summarization asks for fact - based evaluation. in mariefrancine moens, xuanjing huang, lucia specia, and scott wen - tau yih ( eds. ), _ proceedings of _ _ the 2021 conference on empirical methods in natural language processing _, pp. 6594 – 6604, online and punta cana, dominican republic, november 2021. association for computational [ linguistics. doi : 10. 18653 / v1 / 2021. emnlp - main. 529. url https : / / aclanthology. org / ] ( https : / / aclanthology. org / 2021. emnlp - main. 529 / ) [ 2021. emnlp - main. 529 /. ] ( https : / / aclanthology. org / 2021. emnlp - main. 529 / ) donia scott and johanna moore. an nlg evaluation competition? eight reasons to be cautious. _ proceedings of the workshop on shared tasks and comparative evaluation in natural language _ _ generation _, 2006. thibault sellam, dipanjan das, and ankur parikh. bleurt : learning robust metrics for text generation. in dan jurafsky, joyce chai, natalie schluter, and joel tetreault ( eds. ), _ proceedings _ _ of the 58th annual meeting of the association for computational linguistics _, pp. 7881 – 7892, online, july 2020. association for computational linguistics. doi : 10. 18653 / v1 / 2020. acl - main. [ 704. url https : / / aclanthology. org / 2020. acl - main. 704 /. ] ( https : / / aclanthology. org / 2020. acl - main. 704 / ) mrinank sharma, meg tong, tomasz"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 37,
    "text": "? eight reasons to be cautious. _ proceedings of the workshop on shared tasks and comparative evaluation in natural language _ _ generation _, 2006. thibault sellam, dipanjan das, and ankur parikh. bleurt : learning robust metrics for text generation. in dan jurafsky, joyce chai, natalie schluter, and joel tetreault ( eds. ), _ proceedings _ _ of the 58th annual meeting of the association for computational linguistics _, pp. 7881 – 7892, online, july 2020. association for computational linguistics. doi : 10. 18653 / v1 / 2020. acl - main. [ 704. url https : / / aclanthology. org / 2020. acl - main. 704 /. ] ( https : / / aclanthology. org / 2020. acl - main. 704 / ) mrinank sharma, meg tong, tomasz korbak, david duvenaud, amanda askell, samuel r. bowman, esin durmus, zac hatfield - dodds, scott r johnston, shauna m kravec, timothy maxwell, sam mccandlish, kamal ndousse, oliver rausch, nicholas schiefer, da yan, miranda zhang, and ethan perez. towards understanding sycophancy in language models. in _ the twelfth international conference on learning representations _, 2024. [ url https : ] ( https : / / openreview. net / forum? id = tvhaxkmkan ) [ / / openreview. net / forum? id = tvhaxkmkan. ] ( https : / / openreview. net / forum? id = tvhaxkmkan ) shiqi shen, yong cheng, zhongjun he, wei he, hua wu, maosong sun, and yang liu. minimum risk training for neural machine translation. in katrin erk and noah a. smith ( eds. ), _ proceedings _ _ of the 54th annual meeting of the association for computational linguistics ( volume 1 : long pa - _ _ pers ) _, pp. 1683 – 1692, berlin, germany, august 2016. association for computational linguistics. [ doi : 10. 18653 / v1 / p16 - 1159. url https : / / aclanthology. org / p16 - 1159 /. ] ( https : / / aclanthology. org / p16 - 1159 / ) raphael shu, kang min yoo, and jung - woo ha. reward optimization for neural machine translation with learned metrics. _ corr _ [, abs / 2104. 07541, 2021. url https : / / arxiv. org / abs / ] ( https : / / arxiv. org / abs / 2104. 07541 ) [ 2104. 07541. ] ( https : / / arxiv. org / abs / 2104. 07541 ) shivalika singh, yiyang nan, alex wang, daniel d ’ souza, sayash kapoor, ahmet [UNK], sanmi [ [UNK] ] koyejo, yuntian deng, shayne longpre, noah a smith, et al. the leaderboard illusion. _ arxiv _ _ preprint arxiv : 2504. 20879 _, 2025. joar max viktor skalse, nikolaus h. r. howe, dmitrii krasheninnikov, and david krueger. defining and characterizing reward gaming. in alice h. oh, alekh agarwal, danielle belgrave, and kyunghyun cho ( eds. ), _ advances in neural information processing systems _, 2022. url [ https : / / openreview. net / forum? id = yb3hoxo3lx2. ] ( https : / / openreview. net / forum? id = yb3hoxo3lx2 ) 22 reward models are metrics in a trench coat - preprint nisan stiennon, long ouyang, jeff wu, daniel m. ziegler, ryan lowe, chelsea voss, alec radford, dario amodei, and paul christiano. learning to summarize from human feedback. in _ proceed - _ _ ings of the 34th international conference on neural information processing systems _, nips ’ 20, red hook, ny, usa, 2020. curran associates inc. isbn 9781713829546. hao sun, yunyi shen, and jean - francois ton. rethinking reward modeling in preference - based large language model alignment. in _ the thirteenth international conference on learning repre - _ _ sentations _ [, 2025. url https : / / open"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 38,
    "text": "##3hoxo3lx2. ] ( https : / / openreview. net / forum? id = yb3hoxo3lx2 ) 22 reward models are metrics in a trench coat - preprint nisan stiennon, long ouyang, jeff wu, daniel m. ziegler, ryan lowe, chelsea voss, alec radford, dario amodei, and paul christiano. learning to summarize from human feedback. in _ proceed - _ _ ings of the 34th international conference on neural information processing systems _, nips ’ 20, red hook, ny, usa, 2020. curran associates inc. isbn 9781713829546. hao sun, yunyi shen, and jean - francois ton. rethinking reward modeling in preference - based large language model alignment. in _ the thirteenth international conference on learning repre - _ _ sentations _ [, 2025. url https : / / openreview. net / forum? id = rfdble10qm. ] ( https : / / openreview. net / forum? id = rfdble10qm ) jiao sun, thibault sellam, elizabeth clark, tu vu, timothy dozat, dan garrette, aditya siddhant, jacob eisenstein, and sebastian gehrmann. dialect - robust evaluation of generated text. in anna rogers, jordan boyd - graber, and naoaki okazaki ( eds. ), _ proceedings of the 61st annual meet - _ _ ing of the association for computational linguistics ( volume 1 : long papers ) _, pp. 6010 – 6028, toronto, canada, july 2023. association for computational linguistics. doi : 10. 18653 / v1 / 2023. [ acl - long. 331. url https : / / aclanthology. org / 2023. acl - long. 331 /. ] ( https : / / aclanthology. org / 2023. acl - long. 331 / ) simeng sun, ori shapira, ido dagan, and ani nenkova. how to compare summarizers without target length? pitfalls, solutions and re - examination of the neural summarization literature. in antoine bosselut, asli celikyilmaz, marjan ghazvininejad, srinivasan iyer, urvashi khandelwal, hannah rashkin, and thomas wolf ( eds. ), _ proceedings of the workshop on methods for _ _ optimizing and evaluating neural language generation _, pp. 21 – 29, minneapolis, minnesota, june 2019. association for computational linguistics. doi : 10. 18653 / v1 / w19 - 2303. url [ https : / / aclanthology. org / w19 - 2303 /. ] ( https : / / aclanthology. org / w19 - 2303 / ) richard s. sutton and andrew g. barto. _ reinforcement learning - an introduction, 2nd edition _. mit press, 2018. [ url http : / / www. incompleteideas. net / book / the - book - 2nd. ] ( http : / / www. incompleteideas. net / book / the - book - 2nd. html ) [ html. ] ( http : / / www. incompleteideas. net / book / the - book - 2nd. html ) rachel thomas and david uminsky. the problem with metrics is a fundamental problem for ai. _ arxiv preprint arxiv : 2002. 08512 _, 2020. brian thompson, nitika mathur, daniel deutsch, and huda khayrallah. improving statistical significance in human evaluation of automatic metrics via soft pairwise accuracy. in barry haddow, tom kocmi, philipp koehn, and christof monz ( eds. ), _ proceedings of the ninth con - _ _ ference on machine translation _, pp. 1222 – 1234, miami, florida, usa, november 2024. association for computational linguistics. doi : 10. 18653 / v1 / 2024. wmt - 1. 118. [ url https : ] ( https : / / aclanthology. org / 2024. wmt - 1. 118 / ) [ / / aclanthology. org / 2024. wmt - 1. 118 /. ] ( https : / / aclanthology. org / 2024. wmt - 1. 118 / ) ramakrishna vedantam, c. lawrence zitnick, and devi parikh. cider : consensus - based image description evaluation. in _ ieee conference on computer vision and pattern recognition, cvpr _ _ 2015, boston, ma, usa, june 7 - 12"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 39,
    "text": "##n, and christof monz ( eds. ), _ proceedings of the ninth con - _ _ ference on machine translation _, pp. 1222 – 1234, miami, florida, usa, november 2024. association for computational linguistics. doi : 10. 18653 / v1 / 2024. wmt - 1. 118. [ url https : ] ( https : / / aclanthology. org / 2024. wmt - 1. 118 / ) [ / / aclanthology. org / 2024. wmt - 1. 118 /. ] ( https : / / aclanthology. org / 2024. wmt - 1. 118 / ) ramakrishna vedantam, c. lawrence zitnick, and devi parikh. cider : consensus - based image description evaluation. in _ ieee conference on computer vision and pattern recognition, cvpr _ _ 2015, boston, ma, usa, june 7 - 12, 2015 _, pp. 4566 – 4575. ieee computer society, 2015. doi : 10. [ 1109 / cvpr. 2015. 7299087. url https : / / doi. org / 10. 1109 / cvpr. 2015. 7299087. ] ( https : / / doi. org / 10. 1109 / cvpr. 2015. 7299087 ) alex wang, kyunghyun cho, and mike lewis. asking and answering questions to evaluate the factual consistency of summaries. in dan jurafsky, joyce chai, natalie schluter, and joel tetreault ( eds. ), _ proceedings of the 58th annual meeting of the association for computational linguistics _, pp. 5008 – 5020, online, july 2020. association for computational linguistics. doi : 10. 18653 / v1 / [ 2020. acl - main. 450. url https : / / aclanthology. org / 2020. acl - main. 450 /. ] ( https : / / aclanthology. org / 2020. acl - main. 450 / ) peiyi wang, lei li, liang chen, zefan cai, dawei zhu, binghuai lin, yunbo cao, lingpeng kong, qi liu, tianyu liu, and zhifang sui. large language models are not fair evaluators. in lun - wei ku, andre martins, and vivek srikumar ( eds. ), _ proceedings of the 62nd annual meet - _ _ ing of the association for computational linguistics ( volume 1 : long papers ) _, pp. 9440 – 9450, bangkok, thailand, august 2024. association for computational linguistics. doi : 10. 18653 / v1 / [ 2024. acl - long. 511. url https : / / aclanthology. org / 2024. acl - long. 511 /. ] ( https : / / aclanthology. org / 2024. acl - long. 511 / ) jerry wei, chengrun yang, xinying song, yifeng lu, nathan hu, jie huang, dustin tran, daiyi peng, ruibo liu, da huang, cosmo du, and quoc v. le. long - form factuality in large language models. in amir globersons, lester mackey, danielle belgrave, angela fan, ulrich paquet, jakub m. tomczak, and cheng zhang ( eds. ), _ advances in _ _ neural information processing systems 38 : _ _ annual conference on neural information _ _ processing systems 2024, neurips 2024, vancouver, bc, canada, december 10 - 15, _ 23 reward models are metrics in a trench coat - preprint _ 2024 _, 2024. [ url http : / / papers. nips. cc / paper _ files / paper / 2024 / hash / ] ( http : / / papers. nips. cc / paper _ files / paper / 2024 / hash / 937ae0e83eb08d2cb8627fe1def8c751 - abstract - conference. html ) [ 937ae0e83eb08d2cb8627fe1def8c751 - abstract - conference. html. ] ( http : / / papers. nips. cc / paper _ files / paper / 2024 / hash / 937ae0e83eb08d2cb8627fe1def8c751 - abstract - conference. html ) johnny wei and robin jia. the statistical advantage of automatic nlg metrics at the system level. in chengqing zong, fei xia, wenjie li, and roberto navigli ( eds. ), _ proceedings"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 40,
    "text": "url http : / / papers. nips. cc / paper _ files / paper / 2024 / hash / ] ( http : / / papers. nips. cc / paper _ files / paper / 2024 / hash / 937ae0e83eb08d2cb8627fe1def8c751 - abstract - conference. html ) [ 937ae0e83eb08d2cb8627fe1def8c751 - abstract - conference. html. ] ( http : / / papers. nips. cc / paper _ files / paper / 2024 / hash / 937ae0e83eb08d2cb8627fe1def8c751 - abstract - conference. html ) johnny wei and robin jia. the statistical advantage of automatic nlg metrics at the system level. in chengqing zong, fei xia, wenjie li, and roberto navigli ( eds. ), _ proceedings of the 59th _ _ annual meeting of the association for computational linguistics and the 11th international joint _ _ conference on natural language processing ( volume 1 : long papers ) _, pp. 6840 – 6854, online, august 2021. association for computational linguistics. doi : 10. 18653 / v1 / 2021. acl - long. 533. [ url https : / / aclanthology. org / 2021. acl - long. 533 /. ] ( https : / / aclanthology. org / 2021. acl - long. 533 / ) tianjun wei, wei wen, ruizhi qiao, xing sun, and jianghong ma. rocketeval : efficient automated llm evaluation via grading checklist. in _ the thirteenth international conference on learning _ _ representations _ [, 2025. url https : / / openreview. net / forum? id = zjjznj6que. ] ( https : / / openreview. net / forum? id = zjjznj6que ) jiaxin wen, ruiqi zhong, akbir khan, ethan perez, jacob steinhardt, minlie huang, samuel r. bowman, he he, and shi feng. language models learn to mislead humans via rlhf. in _ the thirteenth international conference on learning representations _ [, 2025a. url https : ] ( https : / / openreview. net / forum? id = xjljipe6dg ) [ / / openreview. net / forum? id = xjljipe6dg. ] ( https : / / openreview. net / forum? id = xjljipe6dg ) xueru wen, jie lou, zichao li, yaojie lu, xingyu xingyu, yuqiu ji, guohai xu, hongyu lin, ben he, xianpei han, le sun, and debing zhang. cheems : a practical guidance for building and evaluating chinese reward models from scratch. in wanxiang che, joyce nabende, ekaterina shutova, and mohammad taher pilehvar ( eds. ), _ proceedings of the 63rd annual meeting _ _ of the association for computational linguistics ( volume 1 : long papers ) _, pp. 15187 – 15211, vienna, austria, july 2025b. association for computational linguistics. isbn 979 - 8 - 89176 [ 251 - 0. doi : 10. 18653 / v1 / 2025. acl - long. 737. url https : / / aclanthology. org / 2025. ] ( https : / / aclanthology. org / 2025. acl - long. 737 / ) [ acl - long. 737 /. ] ( https : / / aclanthology. org / 2025. acl - long. 737 / ) xueru wen, jie lou, yaojie lu, hongyu lin, xingyu, xinyu lu, ben he, xianpei han, debing zhang, and le sun. rethinking reward model evaluation : are we barking up the wrong tree? in _ the thirteenth international conference on learning representations _ [, 2025c. url https : ] ( https : / / openreview. net / forum? id = cnwz9joni5 ) [ / / openreview. net / forum? id = cnwz9joni5. ] ( https : / / openreview. net / forum? id = cnwz9joni5 ) ronald j. williams. simple statistical gradient - following algorithms for connectionist reinforcement learning. _ machine learning _ [, 8 : 229 – 256, 1992. doi : 10. 1007 / bf00992696. url https : / / ] ( https : /"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 41,
    "text": ") xueru wen, jie lou, yaojie lu, hongyu lin, xingyu, xinyu lu, ben he, xianpei han, debing zhang, and le sun. rethinking reward model evaluation : are we barking up the wrong tree? in _ the thirteenth international conference on learning representations _ [, 2025c. url https : ] ( https : / / openreview. net / forum? id = cnwz9joni5 ) [ / / openreview. net / forum? id = cnwz9joni5. ] ( https : / / openreview. net / forum? id = cnwz9joni5 ) ronald j. williams. simple statistical gradient - following algorithms for connectionist reinforcement learning. _ machine learning _ [, 8 : 229 – 256, 1992. doi : 10. 1007 / bf00992696. url https : / / ] ( https : / / doi. org / 10. 1007 / bf00992696 ) [ doi. org / 10. 1007 / bf00992696. ] ( https : / / doi. org / 10. 1007 / bf00992696 ) sam wiseman and alexander m. rush. sequence - to - sequence learning as beam - search optimization. in jian su, kevin duh, and xavier carreras ( eds. ), _ proceedings of the 2016 confer - _ _ ence on empirical methods in natural language processing _, pp. 1296 – 1306, austin, texas, november 2016. association for computational linguistics. doi : 10. 18653 / v1 / d16 - 1137. url [ https : / / aclanthology. org / d16 - 1137 /. ] ( https : / / aclanthology. org / d16 - 1137 / ) lijun wu, fei tian, tao qin, jianhuang lai, and tie - yan liu. a study of reinforcement learning for neural machine translation. in ellen riloff, david chiang, julia hockenmaier, and jun ’ ichi tsujii ( eds. ), _ proceedings of the 2018 conference on empirical methods in natural language _ _ processing _, pp. 3612 – 3621, brussels, belgium, october - november 2018a. association for com [ putational linguistics. doi : 10. 18653 / v1 / d18 - 1397. url https : / / aclanthology. org / ] ( https : / / aclanthology. org / d18 - 1397 / ) [ d18 - 1397 /. ] ( https : / / aclanthology. org / d18 - 1397 / ) lijun wu, yingce xia, fei tian, li zhao, tao qin, jianhuang lai, and tie - yan liu. adversarial neural machine translation. in jun zhu and ichiro takeuchi ( eds. ), _ proceedings of the 10th asian _ _ conference on machine learning _, volume 95 of _ proceedings of machine learning research _, pp. [ 534 – 549. pmlr, 14 – 16 nov 2018b. url https : / / proceedings. mlr. press / v95 / ] ( https : / / proceedings. mlr. press / v95 / wu18a. html ) [ wu18a. html. ] ( https : / / proceedings. mlr. press / v95 / wu18a. html ) xai. grok 4 model card, aug 2025. url [ https : / / data. x. ai / ] ( https : / / data. x. ai / 2025 - 08 - 20 - grok - 4 - model - card. pdf ) [ 2025 - 08 - 20 - grok - 4 - model - card. pdf. ] ( https : / / data. x. ai / 2025 - 08 - 20 - grok - 4 - model - card. pdf ) go yasui, yoshimasa tsuruoka, and masaaki nagata. using semantic similarity as reward for reinforcement learning in sentence generation. in fernando alva - manchego, eunsol choi, and daniel khashabi ( eds. ), _ proceedings of the 57th annual meeting of the association for computational _ 24 reward models are metrics in a trench coat - preprint _ linguistics : student research workshop _, pp. 400 – 406, florence, italy, july 2019. association for [ computational linguistics. doi : 10. 18653 / v1 / p19 - 2056. url https : / / aclanthology. ] ( https : / / aclanthology. org / p19 - 2056 / ) [ org / p19 - 2056 /. ] ("
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 42,
    "text": "pdf. ] ( https : / / data. x. ai / 2025 - 08 - 20 - grok - 4 - model - card. pdf ) go yasui, yoshimasa tsuruoka, and masaaki nagata. using semantic similarity as reward for reinforcement learning in sentence generation. in fernando alva - manchego, eunsol choi, and daniel khashabi ( eds. ), _ proceedings of the 57th annual meeting of the association for computational _ 24 reward models are metrics in a trench coat - preprint _ linguistics : student research workshop _, pp. 400 – 406, florence, italy, july 2019. association for [ computational linguistics. doi : 10. 18653 / v1 / p19 - 2056. url https : / / aclanthology. ] ( https : / / aclanthology. org / p19 - 2056 / ) [ org / p19 - 2056 /. ] ( https : / / aclanthology. org / p19 - 2056 / ) lantao yu, weinan zhang, jun wang, and yong yu. seqgan : sequence generative adversarial nets with policy gradient. in satinder singh and shaul markovitch ( eds. ), _ proceedings of the thirty - _ _ first aaai conference on artificial intelligence, february 4 - 9, 2017, san francisco, california, _ _ usa _, pp. 2852 – 2858. aaai press, 2017. doi : 10. 1609 / aaai. v31i1. 10804. [ url https : ] ( https : / / doi. org / 10. 1609 / aaai. v31i1. 10804 ) [ / / doi. org / 10. 1609 / aaai. v31i1. 10804. ] ( https : / / doi. org / 10. 1609 / aaai. v31i1. 10804 ) wojciech zaremba and ilya sutskever. reinforcement learning neural turing machines. _ corr _, [ abs / 1505. 00521, 2015. url http : / / arxiv. org / abs / 1505. 00521. ] ( http : / / arxiv. org / abs / 1505. 00521 ) lining zhang, simon mille, yufang hou, daniel deutsch, elizabeth clark, yixin liu, saad mahamood, sebastian gehrmann, miruna clinciu, khyathi raghavi chandu, and [UNK] sedoc. a needle in a haystack : an analysis of high - agreement workers on mturk for summarization. in anna rogers, jordan boyd - graber, and naoaki okazaki ( eds. ), _ proceedings of the 61st annual _ _ meeting of the association for computational linguistics ( volume 1 : long papers ) _, pp. 14944 – 14982, toronto, canada, july 2023. association for computational linguistics. doi : 10. 18653 / [ v1 / 2023. acl - long. 835. url https : / / aclanthology. org / 2023. acl - long. 835 /. ] ( https : / / aclanthology. org / 2023. acl - long. 835 / ) yinan zhang, eric tzeng, yilun du, and dmitry kislyuk. large - scale reinforcement learning for diffusion models. in _ european conference on computer vision _ [, 2024. url https : / / api. ] ( https : / / api. semanticscholar. org / corpusid : 267095304 ) [ semanticscholar. org / corpusid : 267095304. ] ( https : / / api. semanticscholar. org / corpusid : 267095304 ) lianmin zheng, wei - lin chiang, ying sheng, siyuan zhuang, zhanghao wu, yonghao zhuang, zi lin, zhuohan li, dacheng li, eric xing, et al. judging llm - as - a - judge with mt - bench and chatbot arena. _ advances in neural information processing systems _, 36 : 46595 – 46623, 2023. chunting zhou, pengfei liu, puxin xu, srini iyer, jiao sun, yuning mao, xuezhe ma, avia efrat, ping yu, lili yu, susan zhang, gargi ghosh, mike lewis, luke zettlemoyer, and omer levy. lima : less is more for alignment. in _ thirty - seventh conference on neural information process - _ _ ing systems _ [, 2023. url https : / / openreview. net / forum? id = kb"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 43,
    "text": "zheng, wei - lin chiang, ying sheng, siyuan zhuang, zhanghao wu, yonghao zhuang, zi lin, zhuohan li, dacheng li, eric xing, et al. judging llm - as - a - judge with mt - bench and chatbot arena. _ advances in neural information processing systems _, 36 : 46595 – 46623, 2023. chunting zhou, pengfei liu, puxin xu, srini iyer, jiao sun, yuning mao, xuezhe ma, avia efrat, ping yu, lili yu, susan zhang, gargi ghosh, mike lewis, luke zettlemoyer, and omer levy. lima : less is more for alignment. in _ thirty - seventh conference on neural information process - _ _ ing systems _ [, 2023. url https : / / openreview. net / forum? id = kbmokmx2he. ] ( https : / / openreview. net / forum? id = kbmokmx2he ) enyu zhou, guodong zheng, binghai wang, zhiheng xi, shihan dou, rong bao, wei shen, limao xiong, jessica fan, yurong mou, rui zheng, tao gui, qi zhang, and xuanjing huang. rmb : comprehensively benchmarking reward models in llm alignment. in _ the thirteenth in - _ _ ternational conference on learning representations, iclr 2025, singapore, april 24 - 28, 2025 _. [ openreview. net, 2025. url https : / / openreview. net / forum? id = kmgrlg9tr0. ] ( https : / / openreview. net / forum? id = kmgrlg9tr0 ) dawei zhu, sony trenous, xiaoyu shen, dietrich klakow, bill byrne, and eva hasler. a preference - driven paradigm for enhanced translation with large language models. in kevin duh, helena gomez, and steven bethard ( eds. ), _ proceedings of the 2024 conference of the north _ _ american chapter of the association for computational linguistics : human language tech - _ _ nologies ( volume 1 : long papers ) _, pp. 3385 – 3403, mexico city, mexico, june 2024. asso [ ciation for computational linguistics. doi : 10. 18653 / v1 / 2024. naacl - long. 186. url https : ] ( https : / / aclanthology. org / 2024. naacl - long. 186 / ) [ / / aclanthology. org / 2024. naacl - long. 186 /. ] ( https : / / aclanthology. org / 2024. naacl - long. 186 / ) [UNK] zouhar, shuoyang ding, anna currey, tatyana badeka, jenyuan wang, and brian thompson. fine - tuned machine translation metrics struggle in unseen domains. in lun - wei ku, andre martins, and vivek srikumar ( eds. ), _ proceedings of the 62nd annual meeting of the association _ _ for computational linguistics ( volume 2 : short papers ) _, pp. 488 – 500, bangkok, thailand, august 2024. association for computational linguistics. doi : 10. 18653 / v1 / 2024. acl - short. 45. url [ https : / / aclanthology. org / 2024. acl - short. 45 /. ] ( https : / / aclanthology. org / 2024. acl - short. 45 / ) 25 reward models are metrics in a trench coat - preprint | col1 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | col10 | col11 | col12 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | fi < br > ~ ~ evalu ~ ~ | ld < br > ~ ~ tion metric ~ ~ | | | | | | | | | | | | rewa < br > | rd model < br > | | | | | | | | | | figure 3 : we show the percentage of citations to papers that were published more than three years ago. reward model literature exhibits outlier behavior in which this percentage is"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 44,
    "text": "##4 | col5 | col6 | col7 | col8 | col9 | col10 | col11 | col12 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | fi < br > ~ ~ evalu ~ ~ | ld < br > ~ ~ tion metric ~ ~ | | | | | | | | | | | | rewa < br > | rd model < br > | | | | | | | | | | figure 3 : we show the percentage of citations to papers that were published more than three years ago. reward model literature exhibits outlier behavior in which this percentage is decreasing drastically every year. a d etailed m ethods for c itation a nalysis the results in the main text present a high - level overview of the key findings of our citation analysis. we chose to present results for the last 5 years since reward models that resemble those discussed in this paper were only popularized in this time frame. while the semantic scholar api yields results for the years prior, they are mostly irrelevant to the discussion at hand. we extended the analysis for evaluation metrics back to 2016 but find no significant difference in results. therefore, we omit them for readability. similarly, we choose to present results of an analysis of up to 300 papers per year as a result of qualitative assessment of the data. a qualitative assessment found that, beyond the first 300 papers, search results became too noisy, with irrelevant papers being retrieved. we repeated the analysis with only the top 100 and 200 papers with no significant differences in results. the specific keywords for the analysis in figure 2a were selected based on repeated trials to maximize precision at the cost of recall. for example, including “ evaluation ” as a proxy keyword for evaluation metrics would have yielded any paper that discusses their evaluation results, not necessarily discusses how to build evaluation metrics. similarly, we included generic rl - related terms like “ policy ” for reward models since the terminology was evolving and papers only fairly recently converged on this term. to not miss citations to relevant papers prior to 2020, we included them at the risk of overestimating the true citation count. as a result, the specific numerical results are a side effect of this keyword - based identification and should be interpreted with caution. while an llm - based identification process may yield more accurate results, it would require processing a significant number of tokens. since we were only interested in aggregate trend information, we found the results from keyword - based searches sufficient and stable across many variants. b r ecency b ias in citations we quantify recency bias in citations across the three fields of study. citations only to recent papers would provide an additional piece of evidence that insights from work before llms became popular are not being considered. indeed, we find that while the average age of a cited paper for evaluation metrics published in 2025 is 5. 0 years, cited papers by reward modeling and llm - as - a - judge papers are only 3. 6 and 3. 8 years old. 62. 2 % of citations in reward modeling papers are to papers published less than 2 years ago ( 68. 5 % for llm - as - a - judge ), in contrast to 46. 8 % for evaluation metrics. critically, figure 3 shows how citations to older papers have been decreasing, especially in literature on reward models. this result is an indicator that reward modeling research is evolving quickly and that benchmarks are quickly made irrelevant by new results. 26 reward models are metrics in a trench coat - preprint c a ssignments of conference to subfield for our analysis of citations to research areas in section 3, we assign academic venues to an area if the venue is clearly affiliated with it. for example, aaai ’ s scope is all of ai and we therefore do not include it in this analysis. we include a venue in this analysis if papers published there received at least 50 citations among all the 50, 000 + papers included in our analysis. we account for various misspellings, capitalization differences, and abbreviations, but only list each venue once in the following list of assignments : * * machine learning * * colt, iclr, icml, jmlr, neurips / nips, tmlr, tnnls * * natural language processing * * acl ( including findings of acl ), conll, eacl, eamt, emnlp, inlg, lrec, naacl, semeval, wmt * * robotics * * corl, icra, iros, ijrr, rss * * vision"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03231v1",
      "title": "Reward Models are Metrics in a Trench Coat",
      "authors": [
        "Sebastian Gehrmann"
      ],
      "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.",
      "published": "2025-10-03T17:59:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03231v1"
    },
    "chunk_id": 45,
    "text": "research areas in section 3, we assign academic venues to an area if the venue is clearly affiliated with it. for example, aaai ’ s scope is all of ai and we therefore do not include it in this analysis. we include a venue in this analysis if papers published there received at least 50 citations among all the 50, 000 + papers included in our analysis. we account for various misspellings, capitalization differences, and abbreviations, but only list each venue once in the following list of assignments : * * machine learning * * colt, iclr, icml, jmlr, neurips / nips, tmlr, tnnls * * natural language processing * * acl ( including findings of acl ), conll, eacl, eamt, emnlp, inlg, lrec, naacl, semeval, wmt * * robotics * * corl, icra, iros, ijrr, rss * * vision * * cvpr, eccv, iccv, ijcv, miccai, tip, tog, wacv 27"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03230v1",
      "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
      "authors": [
        "Suyuchen Wang",
        "Tianyu Zhang",
        "Ahmed Masry",
        "Christopher Pal",
        "Spandana Gella",
        "Bang Liu",
        "Perouz Taslakian"
      ],
      "summary": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.",
      "published": "2025-10-03T17:59:34Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03230v1"
    },
    "chunk_id": 0,
    "text": "# # i mproving gui g rounding with e xplicit - p osition to - c oordinate m apping * * suyuchen wang * * [ 1, 2, 3 ] * *, tianyu zhang * * [ 1, 2, 3 ] * *, ahmed masry * * [ 1, 4 ] * *, christopher pal * * [ 1, 2, 5, 7 ] * *, * * * * spandana gella * * [ 1 ] * *, bang liu * * [ 2, 3, 7 ] * *, perouz taslakian * * [ 1, 6 ] 1 servicenow 2 mila - quebec ai institute 3 [UNK] de [UNK] 4 york university 5 polytechnique [UNK] 6 mcgill university 7 cifar ai chair * * a * * * * bstract * * gui grounding, the task of mapping natural - language instructions to pixel coordinates, is crucial for autonomous agents, yet remains difficult for current vlms. the core bottleneck is reliable patch - topixel mapping, which breaks when extrapolating to high - resolution displays unseen during training. current approaches generate coordinates as text tokens directly from visual features, forcing the model to infer complex position - to - pixel mappings implicitly ; as a result, accuracy degrades and failures proliferate on new resolutions. we address this with two complementary innovations. first, * * r * * * * uler * * * * tokens * * serve as explicit coordinate markers, letting the model reference positions similar to gridlines on a map and _ adjust _ rather than generate coordinates from scratch. second, * * interleaved * * * * mrope ( i - mr * * * * o * * * * pe ) * * improves spatial encoding by ensuring that width and height dimensions are represented equally, addressing the asymmetry of standard positional schemes. experiments on screenspot, screenspot - v2, and screenspot - pro show consistent gains in grounding accuracy, with the largest improvements on high - resolution interfaces. by providing explicit spatial guidance rather than relying on implicit learning, our approach enables more reliable gui automation across diverse resolutions and platforms. * * 1 * * * * introduction * * gui grounding is the task of mapping natural language instructions to precise pixel coordinates in graphical user interfaces, enabling autonomous agents to interact with software as humans do ( zhang et al., 2025a ; wang et al., 2024a ; zheng et al., 2024 ). this capability is fundamental for computer automation : without accurate grounding, agents cannot click buttons, fill forms, or navigate interfaces reliably. although early approaches relied on structured metadata from html / dom trees or accessibility apis ( li et al., 2020 ; deng et al., 2023 ), these methods face significant limitations : they require access to the underlying ui structure, which is often unavailable in desktop applications, inconsistent across platforms, or completely absent in legacy systems. pure vision - based grounding, which operates directly on screenshots, offers universal applicability across any visual interface without requiring special access or instrumentation ( qin et al., 2025 ; wang et al., 2025b ; guo et al., 2025 ). this approach mirrors human interaction with guis and enables automation of any software visible on screen, from modern web applications to legacy desktop tools. current vision - based approaches typically formulate gui grounding as a coordinate generation task, where models output pixel positions as text tokens ( e. g., “ x = 523, y = 217 ” ). this paradigm, adopted by models such as seeclick ( cheng et al., 2024 ), cogagent ( hong et al., 2024 ), and ui - tars ( qin et al., 2025 ), treats coordinate prediction as a standard language modeling problem. however, this approach faces a fundamental challenge illustrated in figure 1 : models must learn to map from high - dimensional visual positional embeddings to precise numerical coordinates as token outputs without explicit spatial guidance. the mapping is entirely _ implicit _ : the model receives visual patches with positional embeddings and must learn to translate these abstract and similar representations into exact and distinct pixel value tokens through its language modeling head. this implicit approach leads to two critical problems. first, * * unreliable coordinate prediction * * : without explicit guidance linking positions to coordinates, models struggle to learn stable mappings, requiring extensive training data and still producing inconsistent results ( gou et al., 2025 ; wu et al., 2025a ). second, * * poor resolution generalization * * : models trained on specific resolutions generally fail when deployed on different screen sizes, as the implicit mapping function learned during training does not transfer to new coordinate ranges ( nayak et al., 2025 ; li et al., 2025b ). improving gui grounding with explicit position - to - coordinate mapping “ record the sound ”"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03230v1",
      "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
      "authors": [
        "Suyuchen Wang",
        "Tianyu Zhang",
        "Ahmed Masry",
        "Christopher Pal",
        "Spandana Gella",
        "Bang Liu",
        "Perouz Taslakian"
      ],
      "summary": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.",
      "published": "2025-10-03T17:59:34Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03230v1"
    },
    "chunk_id": 1,
    "text": "to map from high - dimensional visual positional embeddings to precise numerical coordinates as token outputs without explicit spatial guidance. the mapping is entirely _ implicit _ : the model receives visual patches with positional embeddings and must learn to translate these abstract and similar representations into exact and distinct pixel value tokens through its language modeling head. this implicit approach leads to two critical problems. first, * * unreliable coordinate prediction * * : without explicit guidance linking positions to coordinates, models struggle to learn stable mappings, requiring extensive training data and still producing inconsistent results ( gou et al., 2025 ; wu et al., 2025a ). second, * * poor resolution generalization * * : models trained on specific resolutions generally fail when deployed on different screen sizes, as the implicit mapping function learned during training does not transfer to new coordinate ranges ( nayak et al., 2025 ; li et al., 2025b ). improving gui grounding with explicit position - to - coordinate mapping “ record the sound ” figure 1 : a comparison between traditional direct positional embedding - to - pixel coordinate mapping and r uler ’ s explicit coordinate mapping. we also identify a technical limitation in the way current vlms encode spatial information. standard multidimensional rotary positional embedding ( mrope ), used in state - of - the - art models like qwen2 - vl and qwen2. 5vl ( wang et al., 2024b ; bai et al., 2025 ), assigns different frequency bands to height and width dimensions sequentially. this creates an imbalance where one dimension receives only high - frequency components while another receives only low - frequency components, leading to uneven spatial modeling capabilities across axes, a previously overlooked issue that impacts grounding precision. to address these challenges, we introduce a framework that provides explicit spatial guidance for gui grounding through two key innovations : firstly, * * r * * * * uler * * * * ( rotary position - to - pixel mapper ) tokens * * establish an explicit coordinate reference system within the model. as illustrated in figure 1, these auxiliary tokens encode pixel coordinates directly and share positional embeddings with the corresponding image patches. instead of regressing the coordinates from abstract features, the models can now refer to the nearest r uler token and perform simple bounded arithmetic to determine exact positions. this transforms an unstable regression problem into a robust reference - and - adjustment mechanism, similar to how humans might use gridlines on a map. secondly, * * interleaved mrope ( i - mr * * * * o * * * * pe ) * * addresses frequency imbalance in standard positional encodings. by interleaving rather than sequentially assigning frequency components across spatial dimensions, it distributes highand low - frequency signals uniformly across width and height. this produces balanced spatial representations and improves the model ’ s ability to distinguish positions along both axes equally. training models from scratch with our framework and finetuning existing vlms with r uler tokens, we perform extensive evaluation on screenspot ( cheng et al., 2024 ), screenspot - v2 ( wu et al., 2025b ), and screenspot - pro ( li et al., 2025b ). our approach achieves significant improvements : on the challenging screenspot pro benchmark with high - resolution displays exceeding our training resolution, we improve accuracy from 31. 1 % to 37. 2 % through finetuning alone, demonstrating strong generalization capability. these gains are achieved with minimal computational overhead, as r uler tokens add less than 1 % to the total token count even for 8k displays. our work makes three key contributions : ( 1 ) we identify and formalize the implicit mapping problem in current gui grounding approaches, showing how it leads to poor accuracy and resolution brittleness ; ( 2 ) we introduce r uler tokens, an explicit coordinate reference mechanism that transforms unstable regression into robust spatial referencing ; ( 3 ) we present i - mr o pe, a balanced positional embedding scheme that provides equal spatial modeling capacity across dimensions. together, these innovations establish a more principled approach to gui grounding that treats pixel - level precision as an explicit architectural concern rather than an emergent property. * * 2 * * * * related work * * * * positional embeddings in vision - languge models. * * rotary positional embedding ( rope ) ( su et al., 2024 ) encodes positions by rotating embedding dimension pairs with angles proportional to token indices, but suffers from a long - term decay bias in low - frequency components. hope ( li et al., 2025a ) zeros out these low - frequency terms to prevent long - range bias. for vision - language models, abundant visual tokens exhaust rope ’ s context window ; v2pe ( ge et al., 2024 ) rescales step sizes for vision tokens, while circlerope ( wang et al., 2025a ) projects image 2 improving gui grounding with explicit position - to - coordinate mapping “ how"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03230v1",
      "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
      "authors": [
        "Suyuchen Wang",
        "Tianyu Zhang",
        "Ahmed Masry",
        "Christopher Pal",
        "Spandana Gella",
        "Bang Liu",
        "Perouz Taslakian"
      ],
      "summary": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.",
      "published": "2025-10-03T17:59:34Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03230v1"
    },
    "chunk_id": 2,
    "text": "provides equal spatial modeling capacity across dimensions. together, these innovations establish a more principled approach to gui grounding that treats pixel - level precision as an explicit architectural concern rather than an emergent property. * * 2 * * * * related work * * * * positional embeddings in vision - languge models. * * rotary positional embedding ( rope ) ( su et al., 2024 ) encodes positions by rotating embedding dimension pairs with angles proportional to token indices, but suffers from a long - term decay bias in low - frequency components. hope ( li et al., 2025a ) zeros out these low - frequency terms to prevent long - range bias. for vision - language models, abundant visual tokens exhaust rope ’ s context window ; v2pe ( ge et al., 2024 ) rescales step sizes for vision tokens, while circlerope ( wang et al., 2025a ) projects image 2 improving gui grounding with explicit position - to - coordinate mapping “ how do i switch to french? ” ` ` ` ( 10, 42 ) ` ` ` | llm decoder < br > ruler tokens interleaved mrope < br > height width high - frequency low - frequency < br > “ how do i switch to french? ” reference reference rope < br > h w h w h w h w h w h w h w < br > 0 28 vector < br > ( 21, 21 ) ( 23, 23 ) < br > height dimension width dimension < br > ( 21, 25 ) ( 10, 42 ) < br > ( 21, 25 ) < br > [UNK] 0 28 56 [UNK] [UNK] | col2 | col3 | col4 | col5 | col6 | | - - - | - - - | - - - | - - - | - - - | - - - | | | | | | | | * * ( 0, 0 ) ( 1, 1 ) * * * * ( 20, 20 ) * * * * ( 21, 21 ) ( 23, 23 ) ( 25, 25 ) * * * * ( 21, 21 ) ( 21, 22 ) ( 21, 23 ) * * * * ( 23, 25 ) * * * * ( 26, 26 ) * * * * ( 27, 27 ) ( 28, 28 ) * * * * ( 38, 38 ) ( 39, 39 ) ( 40, 40 ) ( 41, 41 ) * * outputs user query system prompt * * ruler tokens * * vision tokens | col1 | col2 | col3 | adding < br > multi - dimensional < br > position ids | col5 | col6 | | - - - | - - - | - - - | - - - | - - - | - - - | | ( 0, 0 ) | ( 0, 1 ) | ( 0, 2 ) | ( 0, 3 ) | ( 0, 4 ) | ( 0, 5 ) | | ( 1, 0 ) | ( 1, 1 ) | ( 1, 2 ) | ( 1, 3 ) | ( 1, 4 ) | ( 1, 5 ) | | ( 2, 0 ) | ( 2, 1 ) | ( 2, 2 ) | ( 2, 3 ) | ( 2, 4 ) | ( 2, 5 ) | | ( 3, 0 ) | ( 3, 1 ) | ( 3, 2 ) | ( 3, 3 ) | ( 3, 4 ) | ( 3, 5 ) | figure 2 : * * model architecture. * * our framework augments vision - language models with two key innovations : ( 1 ) r uler tokens that provide explicit position - to - coordinate mappings, transforming coordinate prediction from regression to retrieval, and ( 2 ) i - mr o pe that rebalances positional embeddings by interleaving frequency components across spatial dimensions, ensuring equal representational capacity for width and height, and tokens into circular space orthogonal to text, ensuring equal cross - modal distances. for video, m - rope ( wang et al., 2024b ) separately encodes spatial - temporal dimensions but disrupts cross - modal alignment by offsetting text tokens. video rope ( liu et al., 2025 ) addresses this by rotating spatial positions while preserving text - video continuity and relative spatial information. currently, qwen2 - vl and qwen2. 5 - vl ’ s mrope ( wang et al., 2024b ; bai et al., 2025 ) is one of the most prevailing multidimensional positional embedding due to the popularity of these models. however, the implementation of mrope results in a biased partition of rope features for each spatial - temporal dimensions. our i - mr o pe provides an elegant improvement to mrope that provides a full frequency spectrum of rope features for each spatial - temporal dimension, which allows the model to perform better position perception. concurrent to our work, q"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03230v1",
      "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
      "authors": [
        "Suyuchen Wang",
        "Tianyu Zhang",
        "Ahmed Masry",
        "Christopher Pal",
        "Spandana Gella",
        "Bang Liu",
        "Perouz Taslakian"
      ],
      "summary": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.",
      "published": "2025-10-03T17:59:34Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03230v1"
    },
    "chunk_id": 3,
    "text": "orthogonal to text, ensuring equal cross - modal distances. for video, m - rope ( wang et al., 2024b ) separately encodes spatial - temporal dimensions but disrupts cross - modal alignment by offsetting text tokens. video rope ( liu et al., 2025 ) addresses this by rotating spatial positions while preserving text - video continuity and relative spatial information. currently, qwen2 - vl and qwen2. 5 - vl ’ s mrope ( wang et al., 2024b ; bai et al., 2025 ) is one of the most prevailing multidimensional positional embedding due to the popularity of these models. however, the implementation of mrope results in a biased partition of rope features for each spatial - temporal dimensions. our i - mr o pe provides an elegant improvement to mrope that provides a full frequency spectrum of rope features for each spatial - temporal dimension, which allows the model to perform better position perception. concurrent to our work, qwen3 - vl ( qwen, 2025 ) independently developed interleaved - mrope. we note that both approaches arrived at nearly identical designs through independent research paths, as confirmed through correspondence with the team members of qwen3 - vl. * * gui grounding models. * * given the limitations of general - purpose models on ui grounding tasks ( li et al., 2025b ; nayak et al., 2025 ), recent work has focused on developing task - specific models. early approaches formulated coordinate prediction ( ui grounding ) as a text generation problem. for example, j edi ( xie et al., 2025 ) and ui - t ars ( qin et al., 2025 ) finetune open - source vlms on synthetically generated data to enhance grounding capabilities. building on this, gta1 ( yang et al., 2025 ) and se - gui ( yuan et al., 2025 ) leverage reinforcement learning, specifically grpo ( shao et al., 2024 ), with rule - based rewards to self - improve grounding performance. p hi - g round ( zhang et al., 2025b ) introduces a label smoothing strategy that weights coordinate token predictions by their numerical distance from the ground truth, while emphasizing digit positions ( e. g., tens, hundreds ). in contrast, some recent approaches have moved away from text - based coordinate generation. for example, gui - a ctor ( wu et al., 2025a ) proposes coordinate - free grounding, where the model directly predicts the visual patches corresponding to the target locations. however, current methods either generate coordinates as natural language response, which requires mapping positional embeddings to number tokens, or requires large changes to the model architecture, which is not directly compatible with general tasks. our introduced r uler provides both explicit guidance for mapping position information to tokens, while keeping the model ’ s original autoregressive generation design to maximize compatibility with other model usage scenarios. * * 3 * * * * method * * we present a framework for ui grounding that addresses fundamental limitations in how current vlms handle spatial perception. our approach introduces two complementary innovations : * * ( i ) interleaved multidimensional rotary po - * * 3 improving gui grounding with explicit position - to - coordinate mapping * * sitional embedding ( i - mr * * * * o * * * * pe ) * * that provides balanced spatial representations, and * * ( ii ) r * * * * uler * * tokens that establish explicit position - to - pixel coordinate mappings. we provide an overview of our proposed method in figure 2. * * 3. 1 * * * * r * * * * uler * * * * : explicit position - to - pixel coordinate mapping * * current vlms predict pixel coordinates for gui grounding by generating coordinates as text tokens ( e. g., “ x = 523, y = 217 ” ). since the source of such coordinate - related information is only recorded by image tokens ’ positional embeddings, generating coordinate tokens requires implicit and direct mapping from high - dimensional visual features ’ positional embeddings to natural language number tokens. this approach suffers from unstable learning dynamics and poor generalization to unseen resolutions, as the learned regression functions are inherently resolution - specific ( gou et al., 2025 ; wu et al., 2025a ). to provide a more explicit guidance for the model in generating pixel coordinates, we propose r uler, which introduces auxiliary tokens that explicitly encode pixel coordinates and share positional embeddings with corresponding image patches. inspired by the induction head mechanism in pretrained transformers ( olsson et al., 2022 ), we take advantage of the model ’ s learned capability to compare position ids and to copy tokens according to their positions, and use a series of tokens with carefully designed position ids and token values as a ruler for the image. with the help of these"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03230v1",
      "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
      "authors": [
        "Suyuchen Wang",
        "Tianyu Zhang",
        "Ahmed Masry",
        "Christopher Pal",
        "Spandana Gella",
        "Bang Liu",
        "Perouz Taslakian"
      ],
      "summary": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.",
      "published": "2025-10-03T17:59:34Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03230v1"
    },
    "chunk_id": 4,
    "text": "217 ” ). since the source of such coordinate - related information is only recorded by image tokens ’ positional embeddings, generating coordinate tokens requires implicit and direct mapping from high - dimensional visual features ’ positional embeddings to natural language number tokens. this approach suffers from unstable learning dynamics and poor generalization to unseen resolutions, as the learned regression functions are inherently resolution - specific ( gou et al., 2025 ; wu et al., 2025a ). to provide a more explicit guidance for the model in generating pixel coordinates, we propose r uler, which introduces auxiliary tokens that explicitly encode pixel coordinates and share positional embeddings with corresponding image patches. inspired by the induction head mechanism in pretrained transformers ( olsson et al., 2022 ), we take advantage of the model ’ s learned capability to compare position ids and to copy tokens according to their positions, and use a series of tokens with carefully designed position ids and token values as a ruler for the image. with the help of these tokens, instead of regressing pixel values from positional embeddings, the model finds a r uler token whose positional encoding best aligns with an image patch, and copy its value as a reference coordinate value. based on the retrieved coordinate value, the model only needs to add a number bounded by a constant _ b _ internally to get the final output number, where _ b _ is irrelevant of the image resolution, reducing the generalization gap on images with higher resolutions than the trained ones. an illustrated comparison between r uler and traditional grounding methods is shown in figure 1. specifically, consider an image partitioned ( tokenized ) into _ h × w _ patches each covering _ p × p _ pixels, and let * * x * * sys denote system tokens, * * x * * vision the visual patch embeddings, and * * x * * prompt the text prompt embeddings. we augment the input sequence with a set of auxiliary coordinate tokens * * x * * r uler as follows : * * x * * input = * * x * * sys _, _ * * x * * r uler _, _ * * x * * vision _, _ * * x * * prompt _, _ ( 1 ) we construct each r uler token _ r _ _ i _ _ ∈ _ * * x * * r uler so that it shares the same spatial position id as a visual patch and has the face token value of the initial pixel coordinate of the corresponding visual patch. this construction both aligns r uler ’ s position with input visual patches and aligns its value with output coordinate tokens ; thus, bridges the position - to - coordinate mapping : pe r uler ( _ r _ _ i _ ) = * * r * * [ mrope ] θ _, t _ 0 + _ i _ ( 2 ) where * * r * * [ mrope ] is a multidimensional rope operator, and _ t _ 0 is a fixed temporal index ensuring that the height and width components match those of the vision token at spatial position _ i _. in practice, _ t _ 0 is the initial spatial position id of the image patches. note that r uler only models one of the multiple dimensions of spatial position ids, since _ t _ 0 is the same for both height and width dimensions, and each image patch covers a square part of image. thus, the mapping between height or width to the pixel coordinate values is identical. this sharing of r uler mapping on multiple spatial dimensions helps reduce the number of r uler tokens and improve efficiency. to further manage computational cost, we introduce r uler tokens at regular intervals _ s _ instead of having them for each position : _ r _ = _ { r _ _ i _ : _ i ∈ { _ 0 _, s, _ 2 _ s,..., [UNK] _ max ( _ h, w _ ) _ / s [UNK] · s } } _ ( 3 ) in this case, the arithmetic bound is _ b _ = _ s × p _. the r uler tokens are generated during the preparation of multimodal inputs. when the input sequence has multiple images, we generate a r uler token sequence before each image with position id corresponding to each image. * * 3. 2 * * * * i - mr * * * * o * * * * pe : interleaved multidimensional rotary positional embedding * * positional embeddings encode spatial information in vision transformers. multidimensional rope ( mrope ) ( wang et al., 2024b ; bai et al., 2025 ) extends standard rope to vlms by decomposing positions into multiple spatialtemporal dimensions. however, a critical limitation of mrope is that it creates a frequency imbalance between spatial dimensions. rotary positional embeddings ( rope ) encode relative positions by applying rotation matrices directly to the query and key vectors in each attention head. let _ m ∈ _ n denote the position index of a token"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03230v1",
      "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
      "authors": [
        "Suyuchen Wang",
        "Tianyu Zhang",
        "Ahmed Masry",
        "Christopher Pal",
        "Spandana Gella",
        "Bang Liu",
        "Perouz Taslakian"
      ],
      "summary": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.",
      "published": "2025-10-03T17:59:34Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03230v1"
    },
    "chunk_id": 5,
    "text": "this case, the arithmetic bound is _ b _ = _ s × p _. the r uler tokens are generated during the preparation of multimodal inputs. when the input sequence has multiple images, we generate a r uler token sequence before each image with position id corresponding to each image. * * 3. 2 * * * * i - mr * * * * o * * * * pe : interleaved multidimensional rotary positional embedding * * positional embeddings encode spatial information in vision transformers. multidimensional rope ( mrope ) ( wang et al., 2024b ; bai et al., 2025 ) extends standard rope to vlms by decomposing positions into multiple spatialtemporal dimensions. however, a critical limitation of mrope is that it creates a frequency imbalance between spatial dimensions. rotary positional embeddings ( rope ) encode relative positions by applying rotation matrices directly to the query and key vectors in each attention head. let _ m ∈ _ n denote the position index of a token and _ d _ the dimension of the attention head. for each 2 _ × _ 2 block, rope rotates a pair of dimensions by a position - dependent angle _ mθ _ _ j _. the rotation matrix * * r * * _ θ _ _ j _ _, m _ applied to the query and key vectors is thus expressed as : * * r * * _ θ _ _ j _ _, m _ = cos ( sin ( _ mθmθ _ _ jj _ ) ) _ − _ cos ( sin ( _ mθmθ _ _ j _ _ j _ ) ) _, _ _ θ _ _ j _ = _ b _ _ [ − ] _ [ 2 ] _ [ j / d ] _ _, _ ( 4 ) 4 improving gui grounding with explicit position - to - coordinate mapping where _ b _ is a hyperparameter called rope base. the frequency _ θ _ _ j _ decreases exponentially with the dimension index _ j _, producing a spectrum that ranges from high - frequency to low - frequency components as _ j _ progresses from 0 to _ d _, which is illustrated in the right part of figure 2. in standard mrope, these frequencies are partitioned and assigned consecutively to different spatial - temporal dimensions : * * r * * [ mrope ] θ _, t, h, w _ [ = ] [ diag ] [ ( ] * * [ r ] * * [ θ ] _ t _ _ [, t ] _ _ [, ] _ * * [ r ] * * [ θ ] _ h _ _ [, h ] _ _ [, ] _ * * [ r ] * * [ θ ] _ w _ _ [, w ] _ [ ) ] ( 5 ) where θ _ t _, θ _ h _, and θ _ w _ denote disjoint yet consecutive subsets of the frequency spectrum _ θ _ _ j _. this sequential allocation leads to an imbalance : the high -, mid -, and low - frequency parts of the rope vector are fully and only occupied by the temporal, height, and width dimensions, respectively. as a result, each dimension is biased towards a limited and different frequency band, constraining the representational capacity and degrading grounding performance across axes ( liu et al., 2024c ; wang et al., 2024c ). this imbalance also potentially results in different inner processing mechanisms of each spatial - temporal dimension due to the different modeling behaviors of their corresponding positional embedding. i - mr o pe addresses this imbalance by distributing the frequency spectrum uniformly across spatial dimensions through frequency interleaving. specifically, instead of assigning consecutive frequency bands to a single axis, each frequency index _ j _ is cyclically mapped. dimension assignment for frequency _ j _ : _ p _ _ j _ = _ w _ if _ j _ mod 3 = 0 _ h _ if _ j _ mod 3 = 1 ( 6 ) _ t _ if _ j _ mod 3 = 2 where _ p _ _ j _ denotes the spatial dimension ( width, height, or temporal ) assigned to frequency _ θ _ _ j _. this interleaving ensures that every dimension receives a full range of frequencies, combining high - frequency components for fine - grained localization with low - frequency components for long - range dependencies. like vanilla mrope, text tokens in the sequence have identical temporal, height, and width indices ( _ t _ = _ h _ = _ w _ = _ m _ ), and the formulation reduces exactly to standard rope : * * r * * θ [ i - mr ] _, m, m, m _ [ o ] [ pe ] [ = ] * * [ r ] * * [ rope ] θ _, m _ ( 7 ) this preserves backward compatibility with pre - trained language models while providing more balanced spatial representations for vision tasks. * * 4 * * * * experimental setup * * * *"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03230v1",
      "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
      "authors": [
        "Suyuchen Wang",
        "Tianyu Zhang",
        "Ahmed Masry",
        "Christopher Pal",
        "Spandana Gella",
        "Bang Liu",
        "Perouz Taslakian"
      ],
      "summary": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.",
      "published": "2025-10-03T17:59:34Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03230v1"
    },
    "chunk_id": 6,
    "text": "_ j _ mod 3 = 2 where _ p _ _ j _ denotes the spatial dimension ( width, height, or temporal ) assigned to frequency _ θ _ _ j _. this interleaving ensures that every dimension receives a full range of frequencies, combining high - frequency components for fine - grained localization with low - frequency components for long - range dependencies. like vanilla mrope, text tokens in the sequence have identical temporal, height, and width indices ( _ t _ = _ h _ = _ w _ = _ m _ ), and the formulation reduces exactly to standard rope : * * r * * θ [ i - mr ] _, m, m, m _ [ o ] [ pe ] [ = ] * * [ r ] * * [ rope ] θ _, m _ ( 7 ) this preserves backward compatibility with pre - trained language models while providing more balanced spatial representations for vision tasks. * * 4 * * * * experimental setup * * * * training setup. * * we conduct two sets of experiments to validate our approach : training from scratch and finetuning existing vlms. for the from - scratch experiments, we build on the llava - next framework ( liu et al., 2024b ) using siglip - so400m - 14 @ 384 ( zhai et al., 2023 ) as vision encoder and qwen2. 5 7b instruct ( qwen et al., 2024 ) as language decoder. we replace the standard 1d positional embeddings in the language decoder in llava - next with mrope or i - mr o pe, and integrate r uler tokens into the input sequence during both training and inference. following the llava - next training paradigm, we employ a two - stage training process. first, we perform visionlanguage alignment pretraining on the llava - 558k dataset ( liu et al., 2024a ), training only the mlp projection layer. second, we conduct domain - specific supervised finetuning on ui grounding tasks, training both the projection layer through full finetuning and the language model through lora ( hu et al., 2022 ) for parameter efficiency. for finetuning experiments, we adapt qwen2. 5 - vl 7b instruct ( bai et al., 2025 ) by introducing r uler tokens and focus on verifying the significance of r uler alone on grounding performance. we do not change the original model ’ s mrope to avoid dramatic changes to the learned model behaviors regarding positional embedding. we use qwen2. 5vl ’ s default system prompt and chat template for all the finetuning experiments. in all experiments, we set the r uler token ’ s default interval as _ s _ = 8 in the main experiments. for i - mr o pe, since gui grounding does not require a temporal dimension, we use 2d mrope and i - mr o pe in the from - scratch training experiments. specifically, the dimension assignment for frequency _ j _ is : _ h _ if _ j _ mod 2 = 0 dimension assignment for frequency _ j _ : _ p _ _ j _ = _ t _ if _ j _ mod 2 = 1 ( 8 ) the training process follows standard vlm objectives with ui grounding tasks. the model learns to leverage r uler tokens for coordinate prediction while i - mr o pe provides balanced spatial representations throughout the transformer layers. this combination enables precise pixel - level grounding without compromising general vision - language capabilities. more hyperparameter settings can be found in appendix a. 5 improving gui grounding with explicit position - to - coordinate mapping * * training data. * * both experimental settings are trained on the uground dataset ( gou et al., 2025 ), which provides comprehensive ui grounding annotations on websites. it contains approximately 8m element annotations across 775k screenshots, providing diverse training signals for robust grounding capabilities. to comply with qwen2. 5 - vl ’ s post - training settings regarding coordinates ( bai et al., 2025 ), we pre - process all coordinates in uground to use raw pixel values rather than normalized ones. this choice ensures consistency with our r uler token design, which requires each patch ’ s size in terms of the output coordinate to be a square, and avoids the ambiguity introduced by normalization in different aspect ratios. * * evaluation setup. * * we evaluate our models on three ui grounding benchmarks : screenspot ( cheng et al., 2024 ), screenspot - v2 ( wu et al., 2025b ), and screenspot pro ( li et al., 2025b ). each benchmark presents screenshots paired with natural language instructions that describe the target ui elements. models must predict the pixel coordinates corresponding to the described element. screenspot and screenspot - v2 contain 1, 272 instructions each"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03230v1",
      "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
      "authors": [
        "Suyuchen Wang",
        "Tianyu Zhang",
        "Ahmed Masry",
        "Christopher Pal",
        "Spandana Gella",
        "Bang Liu",
        "Perouz Taslakian"
      ],
      "summary": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.",
      "published": "2025-10-03T17:59:34Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03230v1"
    },
    "chunk_id": 7,
    "text": "robust grounding capabilities. to comply with qwen2. 5 - vl ’ s post - training settings regarding coordinates ( bai et al., 2025 ), we pre - process all coordinates in uground to use raw pixel values rather than normalized ones. this choice ensures consistency with our r uler token design, which requires each patch ’ s size in terms of the output coordinate to be a square, and avoids the ambiguity introduced by normalization in different aspect ratios. * * evaluation setup. * * we evaluate our models on three ui grounding benchmarks : screenspot ( cheng et al., 2024 ), screenspot - v2 ( wu et al., 2025b ), and screenspot pro ( li et al., 2025b ). each benchmark presents screenshots paired with natural language instructions that describe the target ui elements. models must predict the pixel coordinates corresponding to the described element. screenspot and screenspot - v2 contain 1, 272 instructions each on mobile, desktop, and web platforms, with v2 correcting the annotation errors from the original. screenspot - pro presents a more challenging scenario with 1, 581 tasks from 23 professional desktop - only applications featuring higher resolution interfaces and greater domain shift from typical training data. in particular, screenspot - pro features higher - resolution images than our training data, making it a strong test of resolution generalization. we preprocess all benchmarks to use raw pixel coordinates for evaluation, ensuring fair comparison between methods. [ 1 ] we measure performance using _ element accuracy _, which considers a prediction correct if the predicted point falls within the ground - truth bounding box of the target element. we use the evaluation setting and the code provided by wu et al. ( 2025a ). * * baselines. * * we compare against state - of - the - art ui grounding models of comparable scale. our baseline models includes qwen - 2 - vl 7b instruct ( wang et al., 2024b ), one of the most commonly used open - source vlms ; seeclick9. 6b ( cheng et al., 2024 ), an early specialized ui grounding model ; os - atlas - 7b ( wu et al., 2025b ), a model designed for operating system interactions ; aguvis - 7b ( xu et al., 2025 ), which uses visual grounding with bounding box supervision ; uground - v1 - 7b ( gou et al., 2025 ) trained on the same uground dataset ; ui - tars - 7b ( qin et al., 2025 ), a recent strong baseline ; and gui - actor - 7b ( wu et al., 2025a ) which uses attention - based grounding instead of outputting coordinates. all baseline numbers are reported from original papers or reproduced using official implementations with consistent evaluation protocols. note that our models use less training data than gui - actor. besides, our models are only trained on uground and thus have not seen data from domains other than websites, unlike ui - tars and gui - actor. * * 5 * * * * results * * * * 5. 1 * * * * gui grounding performance * * we present the comparison among the models trained from scratch with r uler and i - mr o pe, the finetuned models equipped with r uler, and the baseline models on screenspot - pro, screenspot, and screenspot - v2 in table 1, table 2, and table 3, respectively. for the from - scratch training experiments, multidimensional rope consistently outperforms the default 1d rope ( llava pe ) across all benchmarks. furthermore, our proposed i - mr o pe achieves both lower training loss and stronger grounding performance than the original mrope, demonstrating the effectiveness of balancing the spectrum across the spatial dimensions. r uler tokens further enhance performance by providing guidance on position - tocoordinate mapping, achieving the best overall results among all models trained from scratch across all datasets. noticeably, the gains from r uler are most pronounced on screenspot - pro, reflecting how its reference - then - copy mechanism and bounded pixel coordinate arithmetic across resolutions help generalization to higher resolution grounding tasks. for fine - tuning experiments, we also observe that adding r uler consistently improves performance, with the largest gains on the higher - resolution screenspot - pro benchmark. although r uler does not achieve state - of - the - art results partly due to the limited training data and domains, our experiments nevertheless demonstrate that incorporating r uler reliably enhances grounding performance under comparable training conditions. 1 for baselines trained with normalized coordinates, we apply appropriate transformations to the output to enable comparison. 6 improving gui grounding with explicit position - to - coordinate mapping table 1 : grounding element accuracy on * * screenspot - pro * *. the results of models marked with"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03230v1",
      "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
      "authors": [
        "Suyuchen Wang",
        "Tianyu Zhang",
        "Ahmed Masry",
        "Christopher Pal",
        "Spandana Gella",
        "Bang Liu",
        "Perouz Taslakian"
      ],
      "summary": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.",
      "published": "2025-10-03T17:59:34Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03230v1"
    },
    "chunk_id": 8,
    "text": "on position - tocoordinate mapping, achieving the best overall results among all models trained from scratch across all datasets. noticeably, the gains from r uler are most pronounced on screenspot - pro, reflecting how its reference - then - copy mechanism and bounded pixel coordinate arithmetic across resolutions help generalization to higher resolution grounding tasks. for fine - tuning experiments, we also observe that adding r uler consistently improves performance, with the largest gains on the higher - resolution screenspot - pro benchmark. although r uler does not achieve state - of - the - art results partly due to the limited training data and domains, our experiments nevertheless demonstrate that incorporating r uler reliably enhances grounding performance under comparable training conditions. 1 for baselines trained with normalized coordinates, we apply appropriate transformations to the output to enable comparison. 6 improving gui grounding with explicit position - to - coordinate mapping table 1 : grounding element accuracy on * * screenspot - pro * *. the results of models marked with † are adopted from wu et al. ( 2025a ). best results per column within each comparable model group are shown in * * bold * *. note that results in the first two groups are not directly comparable to ours, either because the models are closed - source ( weights / architectures unavailable ) or because their training data and underlying base models are unclear or incomparable. we nevertheless include these numbers for reference. * * model * * * * dev * * * * creative * * * * cad * * * * scientific * * * * office * * * * os * * * * avg * * gpt - 4o [ † ] 0. 7 0. 6 1. 5 1. 2 0. 9 0. 0 0. 8 claude compute [ † ] 12. 6 16. 8 11. 9 25. 8 26. 9 8. 1 17. 1 qwen2 - vl - 7b [ † ] 1. 3 0. 9 0. 4 3. 5 3. 0 0. 5 1. 6 seeclick - 9. 6b [ † ] 0. 3 0. 6 1. 9 2. 0 0. 9 1. 5 1. 1 os - atlas - 7b [ † ] 17. 7 17. 9 10. 3 24. 4 27. 4 16. 8 18. 9 aguvis - 7b [ † ] 16. 1 21. 4 13. 8 34. 6 34. 3 19. 4 22. 9 uground - v1 - 7b 28. 1 31. 7 14. 6 39. 0 49. 6 24. 5 31. 1 ui - tars - 7b 36. 1 32. 8 18. 0 50. 0 53. 5 24. 5 35. 7 gui - actor - 7b + verifier [ † ] 38. 8 40. 5 37. 2 44. 5 64. 8 43. 9 44. 2 * * 5. 2 * * * * analysis on r * * * * uler * * * * token interval * * to analyze the effect of changing the interval of the r uler token, we provide a sensitivity analysis of _ s _ in equation 3. the results are shown in figure 3. in the figure, we notice that all interval settings yield consistent improvements compared to models without r uler tokens in all datasets. however, varying the r uler token interval does not yield significant or consistent improvements on the benchmarks. based on the results, we adopt the setting of _ s _ = 8 as a good trade - off between performance and efficiency. however, it should be noted that in extremely low - resolution settings such as mobile phone screenshot grounding, an interval _ s _ = 16 may inject only a single r uler token, leading to reduced performance in the mobile - related subtasks of screenspot and screenspot - v2. * * 5. 3 * * * * efficiency analysis * * to demonstrate the efficiency of adding r uler tokens, we provide an efficiency analysis in the _ p _ = 8 setting in figure 4. in this figure, we report the ratio of r uler tokens to image tokens in common resolutions of mobile phones and computer screens under different interval settings. even in the extreme 8k screenshot scenarios and using an interval of _ s _ = 2, r uler only adds 68 additional tokens, which is merely 0. 2 % of the total number of vision tokens. for low - resolution mobile screenshots, the highest ratio of r uler to vision tokens observed is 2. 8 %, where the impact on efficiency remains negligible. these results confirm that the introduction of tokens r uler can effectively improve grounding performance while maintaining efficiency. * * 6 * * * * conclusions and limitations * * we presented a framework for gui grounding that replaces implicit position - to - pixel coordinate mapping with explicit spatial guidance. r uler tokens provide coordinate"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03230v1",
      "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
      "authors": [
        "Suyuchen Wang",
        "Tianyu Zhang",
        "Ahmed Masry",
        "Christopher Pal",
        "Spandana Gella",
        "Bang Liu",
        "Perouz Taslakian"
      ],
      "summary": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.",
      "published": "2025-10-03T17:59:34Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03230v1"
    },
    "chunk_id": 9,
    "text": "* * to demonstrate the efficiency of adding r uler tokens, we provide an efficiency analysis in the _ p _ = 8 setting in figure 4. in this figure, we report the ratio of r uler tokens to image tokens in common resolutions of mobile phones and computer screens under different interval settings. even in the extreme 8k screenshot scenarios and using an interval of _ s _ = 2, r uler only adds 68 additional tokens, which is merely 0. 2 % of the total number of vision tokens. for low - resolution mobile screenshots, the highest ratio of r uler to vision tokens observed is 2. 8 %, where the impact on efficiency remains negligible. these results confirm that the introduction of tokens r uler can effectively improve grounding performance while maintaining efficiency. * * 6 * * * * conclusions and limitations * * we presented a framework for gui grounding that replaces implicit position - to - pixel coordinate mapping with explicit spatial guidance. r uler tokens provide coordinate references that transform unstable regression into robust reference and adjustment, while i - mr o pe corrects frequency imbalances in the positional embeddings. our approach achieves consistent improvements across benchmarks, with particularly strong gains on high - resolution displays beyond train 7 improving gui grounding with explicit position - to - coordinate mapping table 2 : grounding element accuracy on * * screenspot * *. the results of models marked with † are adopted from wu et al. ( 2025a ). best results per column within each group are shown in * * bold * *. m - text m - icon d - text d - icon w - text w - icon avg gpt - 4 [ † ] 22. 6 24. 5 20. 2 11. 8 9. 2 8. 8 16. 2 gpt - 4o [ † ] 20. 2 24. 9 21. 1 23. 6 12. 2 7. 8 18. 3 claude computer use [ † ] - - - - - - 83. 0 gemini 2. 0 [ † ] - - - - - - 84. 0 qwen2 - vl - 7b [ † ] 75. 5 60. 7 76. 3 54. 3 35. 2 25. 7 55. 3 seeclick - 9. 6b [ † ] 78. 0 52. 0 72. 2 30. 0 55. 7 32. 5 53. 4 os - atlas - 7b [ † ] 93. 0 72. 9 91. 8 62. 9 90. 9 74. 3 82. 5 aguvis - 7b 95. 6 [ † ] 77. 7 93. 8 67. 1 88. 3 75. 2 84. 4 uground - v1 - 7b 93. 0 79. 9 93. 8 76. 4 90. 9 84. 0 86. 3 ui - tars - 7b 94. 5 85. 2 95. 9 85. 7 90. 0 83. 5 89. 5 gui - actor - 7b + verifier [ † ] 96. 0 83. 0 93. 8 82. 1 92. 2 87. 4 89. 7 | col1 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | 37. 237 |. 1 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | 5 < br > 7 | | | | | | | ~ ~ 34. 6 ~ ~ < br > ~ ~ 36 ~ ~ | ~ ~ 34. 6 ~ ~ < br > ~ ~ 36 ~ ~ | ~ ~. 5 ~ ~ | | | 3 < br > | ~ ~ 32. 3 ~ ~ < br > 3 | ~ ~ 32. 3 ~ ~ < br > 3 | ~ ~ 32. 3 ~ ~ < br > 3 | ~ ~ 32. 7 ~ ~ < br >. 1 < br > | ~ ~ 32. 7 ~ ~ < br >. 1 < br > | ~ ~ 32. 7 ~ ~ < br >. 1 < br > | 32. 9 < br > ~ ~ 32. 7 ~ ~ | 32. 9 < br > ~ ~ 32. 7 ~ ~ | | | | 3 < br > | 29. 2 | 29. 2 | | 29. < br > < br > 31. 9 | 29. < br > < br > 31. 9 | 4 | | | | | | 3 < br > | | | | | | | | | | | | col1 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | col10 | col11 | col12 | col13 | | - - - | - - - |"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03230v1",
      "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
      "authors": [
        "Suyuchen Wang",
        "Tianyu Zhang",
        "Ahmed Masry",
        "Christopher Pal",
        "Spandana Gella",
        "Bang Liu",
        "Perouz Taslakian"
      ],
      "summary": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.",
      "published": "2025-10-03T17:59:34Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03230v1"
    },
    "chunk_id": 10,
    "text": "~ ~ 32. 3 ~ ~ < br > 3 | ~ ~ 32. 7 ~ ~ < br >. 1 < br > | ~ ~ 32. 7 ~ ~ < br >. 1 < br > | ~ ~ 32. 7 ~ ~ < br >. 1 < br > | 32. 9 < br > ~ ~ 32. 7 ~ ~ | 32. 9 < br > ~ ~ 32. 7 ~ ~ | | | | 3 < br > | 29. 2 | 29. 2 | | 29. < br > < br > 31. 9 | 29. < br > < br > 31. 9 | 4 | | | | | | 3 < br > | | | | | | | | | | | | col1 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | col10 | col11 | col12 | col13 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | | | | | | | 88. 2 < br > 89. 2 < br > 8 | 88. 2 < br > 89. 2 < br > 8 | 88. 2 < br > 89. 2 < br > 8 | 88. 2 < br > 89. 2 < br > 8 | 9. 0 < br > ~ ~ 88. 6 ~ ~ | 9. 0 < br > ~ ~ 88. 6 ~ ~ | 9. 0 < br > ~ ~ 88. 6 ~ ~ | | | | | | | | 88. 2 < br > 89. 2 < br > 8 | 88. 2 < br > 89. 2 < br > 8 | | | | | | | 85. 5 < br > 85 | 85. 5 < br > 85 | 85. 5 < br > 85 | ~ ~ 84. 5 ~ ~ < br > 86. 1 < br >. 6 < br > 85. 4 | ~ ~ 84. 5 ~ ~ < br > 86. 1 < br >. 6 < br > 85. 4 | ~ ~ 84. 5 ~ ~ < br > 86. 1 < br >. 6 < br > 85. 4 | 86. 0 < br > 85. 7 | 86. 0 < br > 85. 7 | | | | | | | 84. 0 | 84. 0 | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | ne | ne | ne | | 1 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | col10 | col11 | col12 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | 9 | | | | | | | 87. 8 < br > 87 | 87. 8 < br > 87 | 87. 8 < br > 87 |. 7 < br > 87. 1 |. 7 < br > 87. 1 | | 5 < br > 7 | | | | ~ ~ 8 ~ ~ | ~ ~ 8 ~ ~ | ~ ~ 8 ~ ~ | 86. 8 < br > ~ ~. 5 ~ ~ < br > | 86. 8 < br > ~ ~. 5 ~ ~ < br > | | | | | 3 < br > | ~ ~ 82. 5 ~ ~ < br > 83. 7 < br > 8 | ~ ~ 82. 5 ~ ~ < br > 83. 7 < br > 8 | ~ ~ 82. 5 ~ ~ < br > 83. 7 < br > 8 | 83. 0 < br > < br > 3. 3 < br > 83. 1 | 83. 0 < br > < br > 3. 3 < br > 83. 1 | 83. 0 < br > < br > 3. 3 < br > 83. 1 | 83. 6 < br > 8 |. 1 | | | | | 3 < br > | | | | | | | | | | | | | 3 < br > | | | | | | i ~ ~ - ~ ~ < br > aini | i ~ ~ - ~ ~ < br > aini | i ~ ~ - ~ ~ < br > aini | i ~ ~ - ~ ~ < br > aini | i ~ ~ - ~ ~ < br > aini | i ~ ~ - ~ ~ < br > aini | | 3 < br >"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03230v1",
      "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
      "authors": [
        "Suyuchen Wang",
        "Tianyu Zhang",
        "Ahmed Masry",
        "Christopher Pal",
        "Spandana Gella",
        "Bang Liu",
        "Perouz Taslakian"
      ],
      "summary": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.",
      "published": "2025-10-03T17:59:34Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03230v1"
    },
    "chunk_id": 11,
    "text": "7 < br > 8 | ~ ~ 82. 5 ~ ~ < br > 83. 7 < br > 8 | 83. 0 < br > < br > 3. 3 < br > 83. 1 | 83. 0 < br > < br > 3. 3 < br > 83. 1 | 83. 0 < br > < br > 3. 3 < br > 83. 1 | 83. 6 < br > 8 |. 1 | | | | | 3 < br > | | | | | | | | | | | | | 3 < br > | | | | | | i ~ ~ - ~ ~ < br > aini | i ~ ~ - ~ ~ < br > aini | i ~ ~ - ~ ~ < br > aini | i ~ ~ - ~ ~ < br > aini | i ~ ~ - ~ ~ < br > aini | i ~ ~ - ~ ~ < br > aini | | 3 < br > | | | | | | | | | | | | figure 3 : ablation study on r uler token intervals _ s _ across different benchmarks and training settings. ing resolutions, validating its generalization capability. the minimal computational overhead ( less than 1 % of token increase ) makes deployment practical. future work could explore adaptive token placement and extension to video interfaces. the success of explicit spatial guidance over implicit learning suggests broader applications beyond gui automation for any task that requires precise visual localization. * * references * * shuai bai, keqin chen, xuejing liu, jialin wang, wenbin ge, sibo song, kai dang, peng wang, shijie wang, jun tang, humen zhong, yuanzhi zhu, mingkun yang, zhaohai li, jianqiang wan, pengfei wang, wei ding, zheren fu, yiheng xu, jiabo ye, xi zhang, tianbao xie, zesen cheng, hang zhang, zhibo yang, haiyang xu, and junyang lin. qwen2. 5 - vl technical report. _ arxiv preprint arxiv : 2502. 13923 _, 2025. 8 improving gui grounding with explicit position - to - coordinate mapping table 3 : grounding element accuracy on * * screenspot - v2 * *. the results of models marked with † are adopted from wu et al. ( 2025a ). best results per column within each group are shown in * * bold * *. m - text m - icon d - text d - icon w - text w - icon avg gpt - 4o + omniparser - v2 [ † ] 95. 5 74. 6 92. 3 60. 9 88. 0 59. 6 80. 7 seeclick - 9. 6b [ † ] 78. 4 50. 7 70. 1 29. 3 55. 2 32. 5 55. 1 os - atlas - 7b [ † ] 95. 2 75. 8 90. 7 63. 6 90. 6 77. 3 84. 1 aguvis - 7b [ † ] 95. 5 77. 3 95. 4 77. 9 91. 0 72. 4 86. 0 uground - v1 - 7b 95. 0 83. 3 95. 0 77. 8 92. 1 77. 2 87. 6 ui - tars - 7b 96. 9 89. 1 95. 4 85. 0 93. 6 85. 2 91. 6 gui - actor - 7b + verifier [ † ] 97. 2 84. 8 94. 3 85. 0 94. 0 85. 2 90. 9 | ( % < br > tokens < br > 2. 5 < br > 2. 0 image < br > 1. 5 < br > # < br > / < br > tokens < br > 1. 0 < br > 0. 5 ruler < br > 0. 0 | 2. | 8 % | col4 | col5 | col6 | col7 | col8 | col9 | col10 | col11 | col12 | col13 | col14 | col15 | col16 | col17 | l 4 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | 0. 0 < br > 0. 5 < br > 1. 0 < br > 1. 5 < br > 2. 0 < br > 2. 5 < br > ruler tokens / # image tokens ( % | 2. | % | | | | | | | | | | | | | rule < br > |"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03230v1",
      "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
      "authors": [
        "Suyuchen Wang",
        "Tianyu Zhang",
        "Ahmed Masry",
        "Christopher Pal",
        "Spandana Gella",
        "Bang Liu",
        "Perouz Taslakian"
      ],
      "summary": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.",
      "published": "2025-10-03T17:59:34Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03230v1"
    },
    "chunk_id": 12,
    "text": "< br > 0. 0 | 2. | 8 % | col4 | col5 | col6 | col7 | col8 | col9 | col10 | col11 | col12 | col13 | col14 | col15 | col16 | col17 | l 4 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | 0. 0 < br > 0. 5 < br > 1. 0 < br > 1. 5 < br > 2. 0 < br > 2. 5 < br > ruler tokens / # image tokens ( % | 2. | % | | | | | | | | | | | | | rule < br > | interv < br > | l 4 < br > | | 0. 0 < br > 0. 5 < br > 1. 0 < br > 1. 5 < br > 2. 0 < br > 2. 5 < br > ruler tokens / # image tokens ( % | ~ ~ 1. ~ ~ | ~ ~ % ~ ~ | | | | | | | | | | | | | ~ ~ rule ~ ~ < br > rule | ~ ~ interv ~ ~ < br > r interva | ~ ~ l 8 ~ ~ < br > l 16 | | 0. 0 < br > 0. 5 < br > 1. 0 < br > 1. 5 < br > 2. 0 < br > 2. 5 < br > ruler tokens / # image tokens ( % | | 1. < br > | % | | | | | | | | | | | | | | | | 0. 0 < br > 0. 5 < br > 1. 0 < br > 1. 5 < br > 2. 0 < br > 2. 5 < br > ruler tokens / # image tokens ( % | 0. | 9 % | ~ ~ 1. ~ ~ < br > | ~ ~ 3 % ~ ~ < br > 1. | 0 % | 0. | 9 % < br > | | | | | | | | | | | | 0. 0 < br > 0. 5 < br > 1. 0 < br > 1. 5 < br > 2. 0 < br > 2. 5 < br > ruler tokens / # image tokens ( % | | 0. < br > < br > 0. | 7 % < br > 0. < br > 5 % < br > ~ ~ 0. ~ ~ | 6 % < br > 0. < br > ~ ~ 3 % ~ ~ < br > ~ ~ 0. ~ ~ | 0. < br > 5 % < br > ~ ~ 0. ~ ~ < br > ~ ~ 3 % ~ ~ < br > 0. | 7 % < br > < br > ~ ~ 4 % ~ ~ < br > 0. < br > % < br > ~ ~ 0. ~ ~ | ~ ~ 0. ~ ~ < br > 5 % < br > 0. < br > ~ ~ 3 % ~ ~ < br > 0. | ~ ~ 8 % ~ ~ < br > 0. < br > 4 % < br > ~ ~ 0. ~ ~ < br > 2 % < br > 0. | 7 % < br > 0 < br > ~ ~ 3 % ~ ~ < br > ~ ~ 0 ~ ~ < br > % < br > 0 |. 5 % < br > 0. < br > ~ ~. 3 % ~ ~ < br > 0. < br > 1 % < br > 0. | 4 % < br > ~ ~ 0. ~ ~ < br > 2 % < br > 0. < br > % < br > 0. | ~ ~ 4 % ~ ~ < br > 0. < br > 2 % < br > ~ ~ 0. ~ ~ < br > % < br > 0. | 5 % < br > ~ ~ 0. ~ ~ < br > ~ ~ 3 % ~ ~ < br > 0. < br > % < br > | 5 % < br > ~ ~ 0. ~ ~ < br > ~ ~ 3 % ~ ~ < br > 0. < br > % < br > | ~ ~ 3 % ~ ~ < br > ~ ~ 0. ~ ~ < br > 2 % < br > 0. < br > < br > | ~ ~ 2 % ~ ~ < br > 0. 2 < br > % < br > < br > < br > | % < br > < br > | | 0. 0 < br > 0. 5 < br"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03230v1",
      "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
      "authors": [
        "Suyuchen Wang",
        "Tianyu Zhang",
        "Ahmed Masry",
        "Christopher Pal",
        "Spandana Gella",
        "Bang Liu",
        "Perouz Taslakian"
      ],
      "summary": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.",
      "published": "2025-10-03T17:59:34Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03230v1"
    },
    "chunk_id": 13,
    "text": "~ < br > 2 % < br > 0. < br > % < br > 0. | ~ ~ 4 % ~ ~ < br > 0. < br > 2 % < br > ~ ~ 0. ~ ~ < br > % < br > 0. | 5 % < br > ~ ~ 0. ~ ~ < br > ~ ~ 3 % ~ ~ < br > 0. < br > % < br > | 5 % < br > ~ ~ 0. ~ ~ < br > ~ ~ 3 % ~ ~ < br > 0. < br > % < br > | ~ ~ 3 % ~ ~ < br > ~ ~ 0. ~ ~ < br > 2 % < br > 0. < br > < br > | ~ ~ 2 % ~ ~ < br > 0. 2 < br > % < br > < br > < br > | % < br > < br > | | 0. 0 < br > 0. 5 < br > 1. 0 < br > 1. 5 < br > 2. 0 < br > 2. 5 < br > ruler tokens / # image tokens ( % | | | | | | | | | | | | | 0. | 0. | 1 % < br > 0. | 0. < br > % < br > 0. 0 | % < br > % | figure 4 : analysis of the ratio of the number of r uler tokens to the number of image tokens under common mobile phone and computer screen resolutions for different r uler intervals. all numbers are in percentages ( % ). kanzhi cheng, qiushi sun, yougang chu, fangzhi xu, li yantao, jianbing zhang, and zhiyong wu. seeclick : harnessing gui grounding for advanced visual gui agents. in _ proceedings of the 62nd annual meeting of _ _ the association for computational linguistics ( volume 1 : long papers ) _, pp. 9313 – 9332, bangkok, thailand, [ august 2024. association for computational linguistics. doi : 10. 18653 / v1 / 2024. acl - long. 505. url https : ] ( https : / / aclanthology. org / 2024. acl - long. 505 / ) [ / / aclanthology. org / 2024. acl - long. 505 /. ] ( https : / / aclanthology. org / 2024. acl - long. 505 / ) xiang deng, yu gu, boyuan zheng, shijie chen, samuel stevens, boshi wang, huan sun, and yu su. mind2web : towards a generalist agent for the web. in _ thirty - seventh conference on neural information processing systems _ _ datasets and benchmarks track _ [, 2023. url https : / / openreview. net / forum? id = kiyqbo3wqw. ] ( https : / / openreview. net / forum? id = kiyqbo3wqw ) junqi ge, ziyi chen, jintao lin, jinguo zhu, xihui liu, jifeng dai, and xizhou zhu. v2pe : improving multimodal long - context capability of vision - language models with variable visual position encoding. _ arxiv preprint _ _ arxiv : 2412. 09616 _, 2024. boyu gou, ruohan wang, boyuan zheng, yanan xie, cheng chang, yiheng shu, huan sun, and yu su. navigating the digital world as humans do : universal visual grounding for gui agents. in _ the thirteenth international con - _ _ ference on learning representations _ [, 2025. url https : / / openreview. net / forum? id = kxnoqaisct. ] ( https : / / openreview. net / forum? id = kxnoqaisct ) 9 improving gui grounding with explicit position - to - coordinate mapping dong guo, faming wu, feida zhu, fuxing leng, guang shi, haobin chen, haoqi fan, jian wang, jianyu jiang, jiawei wang, jingji chen, jingjia huang, kang lei, liping yuan, lishu luo, pengfei liu, qinghao ye, rui qian, shen yan, shixiong zhao, shuai peng, shuangye li, sihang yuan, sijin wu, tianheng cheng, weiwei liu, wenqian wang, xianhan zeng, xiao liu, xiaobo qin, xiaohan ding, xiaojun xiao, xiaoying zhang, xuanwei zhang, xuehan xiong, yanghua peng, yangrui chen, yanwei li, yanxu hu, yi lin, yiyuan hu, yiyuan zhang,"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03230v1",
      "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
      "authors": [
        "Suyuchen Wang",
        "Tianyu Zhang",
        "Ahmed Masry",
        "Christopher Pal",
        "Spandana Gella",
        "Bang Liu",
        "Perouz Taslakian"
      ],
      "summary": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.",
      "published": "2025-10-03T17:59:34Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03230v1"
    },
    "chunk_id": 14,
    "text": "/ forum? id = kxnoqaisct ) 9 improving gui grounding with explicit position - to - coordinate mapping dong guo, faming wu, feida zhu, fuxing leng, guang shi, haobin chen, haoqi fan, jian wang, jianyu jiang, jiawei wang, jingji chen, jingjia huang, kang lei, liping yuan, lishu luo, pengfei liu, qinghao ye, rui qian, shen yan, shixiong zhao, shuai peng, shuangye li, sihang yuan, sijin wu, tianheng cheng, weiwei liu, wenqian wang, xianhan zeng, xiao liu, xiaobo qin, xiaohan ding, xiaojun xiao, xiaoying zhang, xuanwei zhang, xuehan xiong, yanghua peng, yangrui chen, yanwei li, yanxu hu, yi lin, yiyuan hu, yiyuan zhang, youbin wu, yu li, yudong liu, yue ling, yujia qin, zanbo wang, zhiwu he, aoxue zhang, bairen yi, bencheng liao, can huang, can zhang, chaorui deng, chaoyi deng, cheng lin, cheng yuan, chenggang li, chenhui gou, chenwei lou, chengzhi wei, chundian liu, chunyuan li, deyao zhu, donghong zhong, feng li, feng zhang, gang wu, guodong li, guohong xiao, haibin lin, haihua yang, haoming wang, heng ji, hongxiang hao, hui shen, huixia li, jiahao li, jialong wu, jianhua zhu, jianpeng jiao, jiashi feng, jiaze chen, jianhui duan, jihao liu, jin zeng, jingqun tang, jingyu sun, joya chen, jun long, junda feng, junfeng zhan, junjie fang, junting lu, kai hua, kai liu, kai shen, kaiyuan zhang, ke shen, ke wang, keyu pan, kun zhang, kunchang li, lanxin li, lei li, lei shi, li han, liang xiang, liangqiang chen, lin chen, lin li, lin yan, liying chi, longxiang liu, mengfei du, mingxuan wang, ningxin pan, peibin chen, pengfei chen, pengfei wu, qingqing yuan, qingyao shuai, qiuyan tao, renjie zheng, renrui zhang, ru zhang, rui wang, rui yang, rui zhao, shaoqiang xu, shihao liang, shipeng yan, shu zhong, shuaishuai cao, shuangzhi wu, shufan liu, shuhan chang, songhua cai, tenglong ao, tianhao yang, tingting zhang, wanjun zhong, wei jia, wei weng, weihao yu, wenhao huang, wenjia zhu, wenli yang, wenzhi wang, xiang long, xiangrui yin, xiao li, xiaolei zhu, xiaoying jia, xijin zhang, xin liu, xinchen zhang, xinyu yang, xiongcai luo, xiuli chen, xuantong zhong, xuefeng xiao, xujing li, yan wu, yawei wen, yifan du, yihao zhang, yining ye, yonghui wu, yu liu, yu yue, yufeng zhou, yufeng yuan, yuhang xu, yuhong yang, yun zhang, yunhao fang, yuntao li, yurui ren, yuwen xiong, zehua hong, zehua wang, zewei sun, zeyu wang, zhao cai, zhaoyue zha, zhecheng an, zhehui zhao, zhengzhuo xu, zhipeng chen, zhiyong wu, zhuofan zheng, zihao wang, zilong huang, ziyu zhu, and zuquan song. seed1. 5 - vl technical report, 2025. url [ https : / / arxiv. org / abs / 2505. 07062. ] ( https : / / arxiv. org / abs / 2505. 07062 ) wenyi hong, weihan wang, qingsong lv, jiazheng xu, wenmeng yu, junhui ji, yan wang, zihan wang, yuxiao dong, ming ding, and jie tang. cogagent : a visual language model for gui agents. in _ proceedings of the _ _ ieee / cvf conference on computer vision and pattern recognition ( cvpr ) _, pp."
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03230v1",
      "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
      "authors": [
        "Suyuchen Wang",
        "Tianyu Zhang",
        "Ahmed Masry",
        "Christopher Pal",
        "Spandana Gella",
        "Bang Liu",
        "Perouz Taslakian"
      ],
      "summary": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.",
      "published": "2025-10-03T17:59:34Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03230v1"
    },
    "chunk_id": 15,
    "text": "zewei sun, zeyu wang, zhao cai, zhaoyue zha, zhecheng an, zhehui zhao, zhengzhuo xu, zhipeng chen, zhiyong wu, zhuofan zheng, zihao wang, zilong huang, ziyu zhu, and zuquan song. seed1. 5 - vl technical report, 2025. url [ https : / / arxiv. org / abs / 2505. 07062. ] ( https : / / arxiv. org / abs / 2505. 07062 ) wenyi hong, weihan wang, qingsong lv, jiazheng xu, wenmeng yu, junhui ji, yan wang, zihan wang, yuxiao dong, ming ding, and jie tang. cogagent : a visual language model for gui agents. in _ proceedings of the _ _ ieee / cvf conference on computer vision and pattern recognition ( cvpr ) _, pp. 14281 – 14290, june 2024. edward j hu, yelong shen, phillip wallis, zeyuan allen - zhu, yuanzhi li, shean wang, lu wang, and weizhu chen. lora : low - rank adaptation of large language models. in _ international conference on learning representations _, [ 2022. url https : / / openreview. net / forum? id = nzevkeefyf9. ] ( https : / / openreview. net / forum? id = nzevkeefyf9 ) haoran li, yingjie qin, baoyuan ou, lai xu, and ruiwen xu. hope : hybrid of position embedding for length generalization in vision - language models. _ arxiv preprint arxiv : 2505. 20444 _, 2025a. kaixin li, ziyang meng, hongzhan lin, ziyang luo, yuchen tian, jing ma, zhiyong huang, and tat - seng chua. screenspot - pro : gui grounding for professional high - resolution computer use. _ arxiv preprint arxiv : 2504. 07981 _, 2025b. yang li, jiacong he, xin zhou, yuan zhang, and jason baldridge. mapping natural language instructions to mobile [ ui action sequences, 2020. url https : / / arxiv. org / abs / 2005. 03776. ] ( https : / / arxiv. org / abs / 2005. 03776 ) haogeng liu, quanzeng you, xiaotian han, yongfei liu, huaibo huang, ran he, and hongxia yang. visual anchors are strong information aggregators for multimodal large language model. in _ ad - _ _ vances in neural information processing systems _, volume 37, pp. 17696 – 17718. curran associates, inc., 2024a. url [ https : / / proceedings. neurips. cc / paper _ files / paper / 2024 / file / ] ( https : / / proceedings. neurips. cc / paper _ files / paper / 2024 / file / 1f84412e84da6440ca355d87184cb1b3 - paper - conference. pdf ) [ 1f84412e84da6440ca355d87184cb1b3 - paper - conference. pdf. ] ( https : / / proceedings. neurips. cc / paper _ files / paper / 2024 / file / 1f84412e84da6440ca355d87184cb1b3 - paper - conference. pdf ) haotian liu, chunyuan li, qingyang wu, and yong jae lee. visual instruction tuning. in _ thirty - seventh con - _ _ ference on neural information processing systems _ [, 2023. url https : / / openreview. net / forum? id = ] ( https : / / openreview. net / forum? id = w0h2xghlkw ) [ w0h2xghlkw. ] ( https : / / openreview. net / forum? id = w0h2xghlkw ) haotian liu, chunyuan li, yuheng li, bo li, yuanhan zhang, sheng shen, and yong jae lee. llava - next : im [ proved reasoning, ocr, and world knowledge, january 2024b. url https : / / llava - vl. github. io / blog / ] ( https : / / llava - vl. github. io / blog / 2024 - 01 - 30 - llava - next / ) [ 2024 - 01 - 30 - llava - next /. ] ( https : / / llava - vl. github. io /"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03230v1",
      "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
      "authors": [
        "Suyuchen Wang",
        "Tianyu Zhang",
        "Ahmed Masry",
        "Christopher Pal",
        "Spandana Gella",
        "Bang Liu",
        "Perouz Taslakian"
      ],
      "summary": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.",
      "published": "2025-10-03T17:59:34Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03230v1"
    },
    "chunk_id": 16,
    "text": "##review. net / forum? id = ] ( https : / / openreview. net / forum? id = w0h2xghlkw ) [ w0h2xghlkw. ] ( https : / / openreview. net / forum? id = w0h2xghlkw ) haotian liu, chunyuan li, yuheng li, bo li, yuanhan zhang, sheng shen, and yong jae lee. llava - next : im [ proved reasoning, ocr, and world knowledge, january 2024b. url https : / / llava - vl. github. io / blog / ] ( https : / / llava - vl. github. io / blog / 2024 - 01 - 30 - llava - next / ) [ 2024 - 01 - 30 - llava - next /. ] ( https : / / llava - vl. github. io / blog / 2024 - 01 - 30 - llava - next / ) xiaoran liu, hang yan, chenxin an, xipeng qiu, and dahua lin. scaling laws of rope - based extrapolation. in _ the _ _ twelfth international conference on learning representations _ [, 2024c. url https : / / openreview. net / ] ( https : / / openreview. net / forum? id = jo7k0sj5v6 ) [ forum? id = jo7k0sj5v6. ] ( https : / / openreview. net / forum? id = jo7k0sj5v6 ) zikang liu, longteng guo, yepeng tang, tongtian yue, junxian cai, kai ma, qingbin liu, xi chen, and jing liu. vrope : rotary position embedding for video large language models. _ arxiv preprint arxiv : 2502. 11664 _, 2025. shravan nayak, xiangru jian, kevin qinghong lin, juan a. rodriguez, montek kalsi, rabiul awal, nicolas chapados, m. tamer ozsu, aishwarya agrawal, david vazquez, christopher pal, perouz taslakian, spandana gella, [ [UNK] ] 10 improving gui grounding with explicit position - to - coordinate mapping and sai rajeswar. ui - vision : a desktop - centric gui benchmark for visual perception and interaction, 2025. url [ https : / / arxiv. org / abs / 2503. 15661. ] ( https : / / arxiv. org / abs / 2503. 15661 ) catherine olsson, nelson elhage, neel nanda, nicholas joseph, nova dassarma, tom henighan, ben mann, amanda askell, yuntao bai, anna chen, tom conerly, dawn drain, deep ganguli, zac hatfield - dodds, danny hernandez, scott johnston, andy jones, jackson kernion, liane lovitt, kamal ndousse, dario amodei, tom brown, jack clark, jared kaplan, sam mccandlish, and chris olah. in - context learning and induction heads. _ arxiv preprint _ _ arxiv : 2209. 11895 _, 2022. yujia qin, yining ye, junjie fang, haoming wang, shihao liang, shizuo tian, junda zhang, jiahao li, yunxin li, shijue huang, et al. ui - tars : pioneering automated gui interaction with native agents. _ arxiv preprint _ _ arxiv : 2501. 12326 _, 2025. qwen. qwen3 - vl : sharper vision, deeper thought, broader action. [ https : / / qwen. ] ( https : / / qwen. ai / blog? id = 99f0335c4ad9ff6153e517418d48535ab6d8afef & from = research. latest - advancements - list ) [ ai / blog? id = 99f0335c4ad9ff6153e517418d48535ab6d8afef & from = research. ] ( https : / / qwen. ai / blog? id = 99f0335c4ad9ff6153e517418d48535ab6d8afef & from = research. latest - advancements - list ) [ latest - advancements - list, 2025. [ accessed 01 - 10 - 2025 ]. ] ( https : / / qwen. ai / blog? id = 99f0335c4ad9ff6153e517418"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03230v1",
      "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
      "authors": [
        "Suyuchen Wang",
        "Tianyu Zhang",
        "Ahmed Masry",
        "Christopher Pal",
        "Spandana Gella",
        "Bang Liu",
        "Perouz Taslakian"
      ],
      "summary": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.",
      "published": "2025-10-03T17:59:34Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03230v1"
    },
    "chunk_id": 17,
    "text": "[ https : / / qwen. ] ( https : / / qwen. ai / blog? id = 99f0335c4ad9ff6153e517418d48535ab6d8afef & from = research. latest - advancements - list ) [ ai / blog? id = 99f0335c4ad9ff6153e517418d48535ab6d8afef & from = research. ] ( https : / / qwen. ai / blog? id = 99f0335c4ad9ff6153e517418d48535ab6d8afef & from = research. latest - advancements - list ) [ latest - advancements - list, 2025. [ accessed 01 - 10 - 2025 ]. ] ( https : / / qwen. ai / blog? id = 99f0335c4ad9ff6153e517418d48535ab6d8afef & from = research. latest - advancements - list ) qwen, :, an yang, baosong yang, beichen zhang, binyuan hui, bo zheng, bowen yu, chengyuan li, dayiheng liu, fei huang, haoran wei, huan lin, jian yang, jianhong tu, jianwei zhang, jianxin yang, jiaxi yang, jingren zhou, junyang lin, kai dang, keming lu, keqin bao, kexin yang, le yu, mei li, mingfeng xue, pei zhang, qin zhu, rui men, runji lin, tianhao li, tianyi tang, tingyu xia, xingzhang ren, xuancheng ren, yang fan, yang su, yichang zhang, yu wan, yuqiong liu, zeyu cui, zhenru zhang, and zihan qiu. qwen2. 5 technical report. _ arxiv _ _ preprint arxiv : 2412. 15115 _, 2024. samyam rajbhandari, jeff rasley, olatunji ruwase, and yuxiong he. zero : memory optimizations toward training trillion parameter models. _ arxiv preprint arxiv : 1910. 02054 _, 2019. jie ren, samyam rajbhandari, reza yazdani aminabadi, olatunji ruwase, shuangyan yang, minjia zhang, dong li, and yuxiong he. zero - offload : democratizing billion - scale model training. _ arxiv preprint arxiv : 2101. 06840 _, 2021. zhihong shao, peiyi wang, qihao zhu, runxin xu, junxiao song, xiao bi, haowei zhang, mingchuan zhang, y. k. li, y. wu, and daya guo. deepseekmath : pushing the limits of mathematical reasoning in open language models, [ 2024. url https : / / arxiv. org / abs / 2402. 03300. ] ( https : / / arxiv. org / abs / 2402. 03300 ) jianlin su, murtadha ahmed, yu lu, shengfeng pan, wen bo, and yunfeng liu. roformer : enhanced transformer with rotary position embedding. _ neurocomput. _, 568 ( c ), february 2024. issn 0925 - 2312. doi : 10. 1016 / j. neucom. [ 2023. 127063. url https : / / doi. org / 10. 1016 / j. neucom. 2023. 127063. ] ( https : / / doi. org / 10. 1016 / j. neucom. 2023. 127063 ) chengcheng wang, jianyuan guo, hongguang li, yuchuan tian, ying nie, chang xu, and kai han. circlerope : cone - like decoupled rotary positional embedding for large vision - language models. _ arxiv preprint _ _ arxiv : 2505. 16416 _, 2025a. junyang wang, haiyang xu, jiabo ye, ming yan, weizhou shen, ji zhang, fei huang, and jitao sang. mobile - agent : autonomous multi - modal mobile device agent with visual perception. _ arxiv preprint arxiv : 2401. 16158 _, 2024a. peng wang, shuai bai, sinan tan, shijie wang, zhihao fan, jinze bai, keqin chen, xuejing liu, jialin wang, wenbin ge, yang fan, kai dang, mengfei du, xuancheng ren, rui men, dayiheng liu, chang zhou,"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03230v1",
      "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
      "authors": [
        "Suyuchen Wang",
        "Tianyu Zhang",
        "Ahmed Masry",
        "Christopher Pal",
        "Spandana Gella",
        "Bang Liu",
        "Perouz Taslakian"
      ],
      "summary": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.",
      "published": "2025-10-03T17:59:34Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03230v1"
    },
    "chunk_id": 18,
    "text": "wang, jianyuan guo, hongguang li, yuchuan tian, ying nie, chang xu, and kai han. circlerope : cone - like decoupled rotary positional embedding for large vision - language models. _ arxiv preprint _ _ arxiv : 2505. 16416 _, 2025a. junyang wang, haiyang xu, jiabo ye, ming yan, weizhou shen, ji zhang, fei huang, and jitao sang. mobile - agent : autonomous multi - modal mobile device agent with visual perception. _ arxiv preprint arxiv : 2401. 16158 _, 2024a. peng wang, shuai bai, sinan tan, shijie wang, zhihao fan, jinze bai, keqin chen, xuejing liu, jialin wang, wenbin ge, yang fan, kai dang, mengfei du, xuancheng ren, rui men, dayiheng liu, chang zhou, jingren zhou, and junyang lin. qwen2 - vl : enhancing vision - language model ’ s perception of the world at any resolution. _ arxiv _ _ preprint arxiv : 2409. 12191 _, 2024b. suyuchen wang, ivan kobyzev, peng lu, mehdi rezagholizadeh, and bang liu. resonance rope : improving context length generalization of large language models. in lun - wei ku, andre martins, and vivek srikumar ( eds. ), _ findings of the association for computational linguistics : acl 2024 _, pp. 586 – 598, bangkok, thailand, august 2024c. association for computational linguistics. doi : 10. 18653 / v1 / 2024. findings - acl. 32. url [ https : / / aclanthology. org / 2024. findings - acl. 32 /. ] ( https : / / aclanthology. org / 2024. findings - acl. 32 / ) xinyuan wang, bowen wang, dunjie lu, junlin yang, tianbao xie, junli wang, jiaqi deng, xiaole guo, yiheng xu, chen henry wu, zhennan shen, zhuokai li, ryan li, xiaochuan li, junda chen, boyuan zheng, peihang li, fangyu lei, ruisheng cao, yeqiao fu, dongchan shin, martin shin, jiarui hu, yuyan wang, jixuan chen, yuxiao ye, danyang zhang, dikang du, hao hu, huarong chen, zaida zhou, haotian yao, ziwei chen, qizheng gu, yipu wang, heng wang, diyi yang, victor zhong, flood sung, y. charles, zhilin yang, and tao yu. opencua : open [ foundations for computer - use agents, 2025b. url https : / / arxiv. org / abs / 2508. 09123. ] ( https : / / arxiv. org / abs / 2508. 09123 ) qianhui wu, kanzhi cheng, rui yang, chaoyun zhang, jianwei yang, huiqiang jiang, jian mu, baolin peng, bo qiao, reuben tan, et al. gui - actor : coordinate - free visual grounding for gui agents. _ arxiv preprint _ _ arxiv : 2506. 03143 _, 2025a. 11 improving gui grounding with explicit position - to - coordinate mapping zhiyong wu, zhenyu wu, fangzhi xu, yian wang, qiushi sun, chengyou jia, kanzhi cheng, zichen ding, liheng chen, paul pu liang, and yu qiao. os - atlas : foundation action model for generalist gui agents. in _ the _ _ thirteenth international conference on learning representations _ [, 2025b. url https : / / openreview. net / ] ( https : / / openreview. net / forum? id = n9pdafni8t ) [ forum? id = n9pdafni8t. ] ( https : / / openreview. net / forum? id = n9pdafni8t ) tianbao xie, jiaqi deng, xiaochuan li, junlin yang, haoyuan wu, jixuan chen, wenjing hu, xinyuan wang, yuhui xu, zekun wang, et al. scaling computer - use grounding via user interface decomposition and synthesis. _ arxiv _ _ preprint arxiv : 2505. 13227 _, 2025. yiheng xu, zekun wang, junli wang, dunjie lu, tianbao xie, amrita saha, doyen sah"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03230v1",
      "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
      "authors": [
        "Suyuchen Wang",
        "Tianyu Zhang",
        "Ahmed Masry",
        "Christopher Pal",
        "Spandana Gella",
        "Bang Liu",
        "Perouz Taslakian"
      ],
      "summary": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.",
      "published": "2025-10-03T17:59:34Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03230v1"
    },
    "chunk_id": 19,
    "text": "_ the _ _ thirteenth international conference on learning representations _ [, 2025b. url https : / / openreview. net / ] ( https : / / openreview. net / forum? id = n9pdafni8t ) [ forum? id = n9pdafni8t. ] ( https : / / openreview. net / forum? id = n9pdafni8t ) tianbao xie, jiaqi deng, xiaochuan li, junlin yang, haoyuan wu, jixuan chen, wenjing hu, xinyuan wang, yuhui xu, zekun wang, et al. scaling computer - use grounding via user interface decomposition and synthesis. _ arxiv _ _ preprint arxiv : 2505. 13227 _, 2025. yiheng xu, zekun wang, junli wang, dunjie lu, tianbao xie, amrita saha, doyen sahoo, tao yu, and caiming xiong. aguvis : unified pure vision agents for autonomous gui interaction. in _ forty - second international confer - _ _ ence on machine learning _ [, 2025. url https : / / openreview. net / forum? id = plihowfx4r. ] ( https : / / openreview. net / forum? id = plihowfx4r ) yan yang, dongxu li, yutong dai, yuhao yang, ziyang luo, zirui zhao, zhiyuan hu, junzhe huang, amrita saha, zeyuan chen, et al. gta1 : gui test - time scaling agent. _ arxiv preprint arxiv : 2507. 05791 _, 2025. xinbin yuan, jian zhang, kaixin li, zhuoxuan cai, lujian yao, jie chen, enguang wang, qibin hou, jinwei chen, peng - tao jiang, et al. enhancing visual grounding for gui agents via self - evolutionary reinforcement learning. _ arxiv _ _ preprint arxiv : 2505. 12370 _, 2025. xiaohua zhai, basil mustafa, alexander kolesnikov, and lucas beyer. sigmoid loss for language image pre - training. _ ieee international conference on computer vision _, 2023. doi : 10. 1109 / iccv51070. 2023. 01100. chaoyun zhang, liqun li, shilin he, xu zhang, bo qiao, si qin, minghua ma, yu kang, qingwei lin, saravan rajmohan, et al. ufo : a ui - focused agent for windows os interaction. in _ proceedings of the 2025 conference of the _ _ nations of the americas chapter of the association for computational linguistics : human language technologies _ _ ( volume 1 : long papers ) _, pp. 597 – 622, 2025a. miaosen zhang, ziqiang xu, jialiang zhu, qi dai, kai qiu, yifan yang, chong luo, tianyi chen, justin wagle, tim franklin, et al. phi - ground tech report : advancing perception in gui grounding. _ arxiv preprint arxiv : 2507. 23779 _, 2025b. boyuan zheng, boyu gou, jihyung kil, huan sun, and yu su. gpt - 4v ( ision ) is a generalist web agent, if grounded. in _ icml _ [, 2024. url https : / / openreview. net / forum? id = pieckj2dlb. ] ( https : / / openreview. net / forum? id = pieckj2dlb ) * * a * * * * implementation details * * we provide detailed training configurations for our experiments in the following. all experiments are performed on 8 nvidia h100 gpus. * * a. 1 * * * * training from scratch * * * * stage 1 : vision - language alignment pretraining. * * we follow the llava - next training paradigm. the model uses siglip - so400m - 14 @ 384 ( zhai et al., 2023 ) as the vision encoder and qwen2. 5 7b instruct ( qwen et al., 2024 ) as the language model. during pretraining, we train only the mlp projection layer while keeping both vision and language models frozen. training is performed on the llava - 558k dataset ( liu et al., 2023 ) for 1 epoch with a learning rate of 1 _ × _ 10 _ [ − ] _ [ 3 ] using cosine scheduling and 3 % warmup ratio. we use a per - device batch size of 4 with gradient accumulation steps of 2, resulting in an effective batch size of 64"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03230v1",
      "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
      "authors": [
        "Suyuchen Wang",
        "Tianyu Zhang",
        "Ahmed Masry",
        "Christopher Pal",
        "Spandana Gella",
        "Bang Liu",
        "Perouz Taslakian"
      ],
      "summary": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.",
      "published": "2025-10-03T17:59:34Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03230v1"
    },
    "chunk_id": 20,
    "text": "experiments are performed on 8 nvidia h100 gpus. * * a. 1 * * * * training from scratch * * * * stage 1 : vision - language alignment pretraining. * * we follow the llava - next training paradigm. the model uses siglip - so400m - 14 @ 384 ( zhai et al., 2023 ) as the vision encoder and qwen2. 5 7b instruct ( qwen et al., 2024 ) as the language model. during pretraining, we train only the mlp projection layer while keeping both vision and language models frozen. training is performed on the llava - 558k dataset ( liu et al., 2023 ) for 1 epoch with a learning rate of 1 _ × _ 10 _ [ − ] _ [ 3 ] using cosine scheduling and 3 % warmup ratio. we use a per - device batch size of 4 with gradient accumulation steps of 2, resulting in an effective batch size of 64 across 8 gpus. the maximum sequence length is set to 8, 192 tokens. images are processed using the anyres configuration with a maximum of 9 patches and grid pinpoints ranging from ( 1 _ × _ 1 ) to ( 12 _ × _ 6 ) to accommodate high - resolution images during inference. we employ deepspeed zero - 2 with cpu offload ( ren et al., 2021 ) and mixed precision training ( bf16 ) for memory efficiency. for models using ruler, we set the token interval to _ s _ = 8, while positional embedding configurations ( default llava pe, mrope, or i - mrope ) are specified throughout the pretraining and finetuning process. * * stage 2 : domain - specific finetuning. * * using the pretrained projection layer from stage 1, we finetune on the uground dataset ( gou et al., 2025 ) with coordinates converted to raw pixel values to match our ruler token design. in this stage, we train the projection layer with full parameter finetuning and the language model using lora ( hu et al., 2022 ) with rank 16 for parameter efficiency. the base learning rate is set to 1 _ × _ 10 _ [ − ] _ [ 5 ] for the projection layer and lora parameters. we use a per - device batch size of 1 with gradient accumulation steps of 4, yielding an effective batch size of 32. the maximum sequence length is extended to 16, 384 tokens to accommodate higherresolution images. training runs for 1 epoch with cosine learning rate scheduling and 3 % warmup. we continue using deepspeed zero - 2 with cpu offload and bf16 mixed precision. 12 improving gui grounding with explicit position - to - coordinate mapping * * a. 2 * * * * finetuning qwen2. 5 - vl * * for adapting the pretrained qwen2. 5 - vl 7b instruct model ( bai et al., 2025 ), we use a conservative finetuning approach to preserve the existing capabilities of the model while adding ruler tokens. we maintain the model ’ s original mrope configuration to avoid disrupting learned position - aware behaviors. the model is finetuned with a low learning rate of 1 _ × _ 10 _ [ − ] _ [ 5 ] using cosine scheduling with 3 % warmup to ensure stable adaptation. we use a perdevice batch size of 4 with gradient accumulation steps of 4, resulting in an effective batch size of 128. the maximum sequence length remains at 16, 384 tokens, and we utilize qwen2. 5 - vl ’ s dynamic resolution capability with pixel counts ranging from 784 to 50, 176. training runs for 1 epoch on the uground dataset with all components ( vision encoder, mlp projector, and language model ) being trainable. we employ deepspeed zero - 3 ( rajbhandari et al., 2019 ) for distributed training and bf16 mixed precision. ruler tokens are integrated into the input sequence with interval _ s _ = 8 when specified, and we use qwen2. 5 - vl ’ s native chat template and system prompts for consistency with the pretrained model ’ s behavior. * * a. 3 * * * * evaluation protocol * * all models are evaluated using greedy decoding ( temperature = 0 ) with the same maximum sequence length as training. for screenspot benchmarks, we preprocess all coordinates to raw pixel values and use the evaluation code from wu et al. ( 2025a ). element accuracy is computed by checking if the predicted coordinate falls within the ground - truth bounding box. we ensure consistent pre - processing across all baselines for fair comparison. 13"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03230v1",
      "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
      "authors": [
        "Suyuchen Wang",
        "Tianyu Zhang",
        "Ahmed Masry",
        "Christopher Pal",
        "Spandana Gella",
        "Bang Liu",
        "Perouz Taslakian"
      ],
      "summary": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.",
      "published": "2025-10-03T17:59:34Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03230v1"
    },
    "chunk_id": 21,
    "text": "training and bf16 mixed precision. ruler tokens are integrated into the input sequence with interval _ s _ = 8 when specified, and we use qwen2. 5 - vl ’ s native chat template and system prompts for consistency with the pretrained model ’ s behavior. * * a. 3 * * * * evaluation protocol * * all models are evaluated using greedy decoding ( temperature = 0 ) with the same maximum sequence length as training. for screenspot benchmarks, we preprocess all coordinates to raw pixel values and use the evaluation code from wu et al. ( 2025a ). element accuracy is computed by checking if the predicted coordinate falls within the ground - truth bounding box. we ensure consistent pre - processing across all baselines for fair comparison. 13"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 0,
    "text": "# # * * mixer : mixed hyperspherical random embedding neural network for * * * * texture recognition * * * * ricardo t. fares * * [ 1 ] * * lucas c. ribas * * [ 1 ] * * abstract * * randomized neural networks for representation learning have consistently achieved prominent results in texture recognition tasks, effectively combining the advantages of both traditional techniques and learning - based approaches. however, existing approaches have so far focused mainly on improving cross - information prediction, without introducing significant advancements to the overall randomized network architecture. in this paper, we propose m ixer, a novel randomized neural network for texture representation learning. at its core, the method leverages hyperspherical random embeddings coupled with a dual - branch learning module to capture both intra - and inter - channel relationships, further enhanced by a newly formulated optimization problem for building rich texture representations. experimental results have shown the interesting results of the proposed approach across several pure texture benchmarks, each with distinct characteristics and challenges. the source code will be available upon publication. * * 1. introduction * * texture is a widely studied visual feature in both research fields of computer vision ( haralick et al., 1973 ) and neuroscience ( julesz, 1981 ). its study has not only enabled a deeper understanding of human texture perception but also allowed computers to efficiently represent them in their own language for later use in _ downstream tasks _, such as material recognition ( sharan et al., 2013 ; chen et al., 2021 ), land classification ( akiva et al., 2022 ), and biological image analysis ( oiticica et al., 2025 ). to tackle these tasks, many texture representation approaches have been proposed in the literature, which currently can be broadly classified in three groups : _ handcrafted _ ( haralick et al., 1973 ; manjunath & ma, 1996 ; leung & malik, 2001 ; ojala et al., 2002b ), _ learning - based _ ( cimpoi et al., 2015 ; zhang et al., 2017 ; zhai et al., 2020 ), and _ hybrid _ techniques ( junior & backes, 2016 ; scabini et al., 2023 ; su 1 [UNK] institute of biosciences, humanities and exact sciences, sao paulo state university, sao jos [UNK] e do rio preto, brazil. correspon - [UNK] dence to : lucas c. ribas _ < _ lucas. ribas @ unesp. br _ > _. et al., 2023 ). the first ones are characterized by approaches manually designed from scratch, which provide greater explainability but generally have limited descriptive power. on the other hand, the second group is characterized by the use of neural networks to automatically extract the essential attributes. although they offer greater descriptive power, these methods are generally less interpretable and demand substantial amounts of data and energy. in this context, the third group of approaches seeks to leverage the advantages of the previous ones while simultaneously addressing their inherent limitations. in this group, approaches are characterized by those that either combine traditional descriptors with neural networks as in su et al. ( 2023 ) or those as in junior & backes ( 2016 ) ; scabini et al. ( 2023 ) that use neural networks while maintaining inherent characteristics of some _ handcrafted _ descriptors, such as the absence of a dataset to work properly as for instance in lbp ( ojala et al., 2002b ), i. e., given an image a lbp representation is promptly returned without the need of a pre - defined training and test split. therefore, thinking in a venn diagram, _ hybrid _ approaches can be seen as the intersection of the _ handcrafted _ and _ learning - based _ approaches, such that some of the mentioned _ learning - based _ techniques may be considered _ hybrid _ ones. currently, interesting hybrid texture recognition approaches are those based on shallow and fast neural networks. in particular, to the best of our knowledge, junior & backes ( 2016 ) proposed the first texture representation learning technique using a randomized neural network ( rnn ). this is a shallow 1 - hidden - layer neural network, where the hidden layer is randomly initialized and the output layer weights are computed using a closed - form solution. this leads to a rapid training procedure, and the resulting weights are subsequently used to compose the image representation. this technique has been successfully applied in representation learning tasks, such as in color - texture ( ribas et al., 2024 ), and shape representation ( junior et al., 2018 ; fujiwara & hashimoto, 2020 ; ribas & bruno, 2024 ). however, most of these representation learning techniques have focused primarily on constructing improved input and output feature matrices to enhance the learning of weights through better cross - information prediction, that is, guiding the network"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 1,
    "text": "interesting hybrid texture recognition approaches are those based on shallow and fast neural networks. in particular, to the best of our knowledge, junior & backes ( 2016 ) proposed the first texture representation learning technique using a randomized neural network ( rnn ). this is a shallow 1 - hidden - layer neural network, where the hidden layer is randomly initialized and the output layer weights are computed using a closed - form solution. this leads to a rapid training procedure, and the resulting weights are subsequently used to compose the image representation. this technique has been successfully applied in representation learning tasks, such as in color - texture ( ribas et al., 2024 ), and shape representation ( junior et al., 2018 ; fujiwara & hashimoto, 2020 ; ribas & bruno, 2024 ). however, most of these representation learning techniques have focused primarily on constructing improved input and output feature matrices to enhance the learning of weights through better cross - information prediction, that is, guiding the network to learn more effective weights by forcing it to predict more complex relationships between input and output content. in contrast, little to no research in texture representation learning has simultaneously explored archi 1 * * mixer : mixed hyperspherical random embedding neural network for texture recognition * * tectural improvements, such as enhancements to the random projector or the underlying optimization problem. in this work, we introduce m ixer, a novel texture representation learning random neural network. it is composed of four core modules. for any given image, the first module, called the _ local pattern extractor _, is responsible for densely extracting small patches from each image channel independently, aiming to capture raw local texture information. next, the second module, called the _ hyperspherical _ _ random projector _, encodes the extracted patches into random embeddings and constrains them to lie on the surface of a hypersphere through embedding normalization. the third module, referred to as the _ learning _ module, consists of two branches that capture intra - and inter - channel intensity relationships. the first branch employs a purely randomized autoencoder, while the second addresses this learning through a novel optimization problem. finally, the last module, called _ compression _ module, compresses ( summarizes ) the decoders ’ learned weights into a useful color - texture representation for recognition tasks. * * contributions of this paper * *. our contributions are summarized as follows : - we introduced a novel hyperspherical multi - head random projector that : ( i ) distinctly encodes the local patches of different image channels, thereby implicitly introducing channel ownership information ; and ( ii ) constrains the random embeddings to lie on the surface of a hypersphere, retaining only their directional information. - we proposed a novel learning module composed of the d i rect and m ixed learning branches. the former captures intra - channel intensity relationships, whereas the latter focuses on inter - channel relationships, achieved through a new optimization problem applied to an intermediate fused representation. - experimental results demonstrated that our color - texture representation consistently outperformed the existing approaches, being the only among the compared approaches to surpass the 97 % barrier of outex, and the 99 % barrier of the average accuracy. * * structure of the paper * *. section 2 presents the notation and the required background. section 3 introduces the method of our novel texture representation. section 4 exhibits the experimental setup. section 5 shows the results and presents the discussion. to conclude, section 6 terminates the work with the conclusions and future works. * * 2. background and notation * * * * notation * *. throughout the paper, we adopt the following notation conventions for readability. let the lowercase let ters _ a ∈ _ r be scalars, and the boldface lowercase letters * * a * * _ ∈ _ r _ [ n ] _ be _ n _ - dimensional vectors, where _ a _ _ k _ _ ∈ _ r is its _ k _ - th component. we define the boldface uppercase letters * * a * * _ ∈ _ r _ [ m ] [ × ] [ n ] _ as a real matrix of size _ m × n _, where _ a _ _ ij _ _ ∈ _ r is its ( _ i, j _ ) - entry. further, let calligraphic uppercase letters _ a _ denote a set of elements, with the following exceptions that r _ [ n ] _ is the set of all _ n _ - dimensional real vectors, r _ [ m ] [ × ] [ n ] _ is the set of all real matrices of size _ m × n _, and n is the set of natural numbers. * * 2. 1. texture recognition * * * * classical texture recognition * *. the early days of texture recognition relied heavily on _ classical _ or _ handcrafted _ feature extractors, which were manually designed by specialists and typically based on predefined steps. to begin with, the pioneering work"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 2,
    "text": "boldface uppercase letters * * a * * _ ∈ _ r _ [ m ] [ × ] [ n ] _ as a real matrix of size _ m × n _, where _ a _ _ ij _ _ ∈ _ r is its ( _ i, j _ ) - entry. further, let calligraphic uppercase letters _ a _ denote a set of elements, with the following exceptions that r _ [ n ] _ is the set of all _ n _ - dimensional real vectors, r _ [ m ] [ × ] [ n ] _ is the set of all real matrices of size _ m × n _, and n is the set of natural numbers. * * 2. 1. texture recognition * * * * classical texture recognition * *. the early days of texture recognition relied heavily on _ classical _ or _ handcrafted _ feature extractors, which were manually designed by specialists and typically based on predefined steps. to begin with, the pioneering work by haralick et al. ( 1973 ) not only proposed a feature extraction technique based on measures such as angular second moment, contrast, and correlation derived from gray - level co - occurrence matrices, but also introduced the notion of texture as the spatial distribution of gray - level tones, although no formal and universally accepted definition exists to this day. later, studies on the visual information processing system ( daugman, 1985 ; jones & palmer, 1987 ) discussed the receptive fields of simple cells in the visual cortex, showing that they can be expressed in terms of gabor filters. this inspired researchers in proposing texture feature extractors using these filters or wavelets ( bovik et al., 1990 ; manjunath & ma, 1996 ). in general, these approaches consist of generating a filter bank with filters of distinct orientations and frequencies, and then convolving the image with each filter. subsequently, measures such as the mean and standard deviation can be computed from the filter responses to serve as features of the input image. following this, ojala et al. ( 1996 ) proposed the local binary pattern ( lbp ). at its core, a local neighborhood scans the entire image with overlap, and the values within each neighborhood are thresholded relative to the central pixel value. the numbers resulting from the binary patterns of each neighborhood are aggregated into a histogram, which serves as the texture representation. in addition, many improved and robuster versions and similar techniques to lbp were proposed, such as ojala et al. ( 2002b ) that introduced the widely known rotation invariant version of the former approach, ojansivu & heikkila [UNK] ( 2008 ) proposed the local phase quantization ( lpq ) technique, a texture descriptor robust to blurring, and guo et al. ( 2010 ) presented the complete lbp ( clbp ). around the early 2000s, techniques such as bag of textons ( bot ) ( leung & malik, 2001 ) and bag of visual words ( bovw ) ( csurka et al., 2004 ) emerged, representing an image as a histogram over a learned or predefined code 2 * * mixer : mixed hyperspherical random embedding neural network for texture recognition * * book ( liu et al., 2019 ). generally, given a training set, these methods select and describe local patches from the images and then build a codebook by applying a vector quantization algorithm, such as _ k _ - means, over the set of local patch descriptors. later, this codebook is used to generate the histogram from a test image, which serves as its feature vector. in addition, with the rise of the deep - learning models, the phase of local patch description turned to use deep - learned features, such as in fv - cnn ( cimpoi et al., 2015 ), deepten ( zhang et al., 2017 ) and boff ( florindo & laureano, 2023 ). * * deep - learning - based texture recognition * *. since the rapid emergence of deep learning methods in the last decade, the research community has seen a variety of approaches adopting convolutional neural networks ( cnns ) and, more recently, vision transformers ( vits ) for texture recognition. this is largely attributed to their ability to automatically learn and extract key features from images, in contrast to the manually designed descriptors discussed earlier. these approaches can be divided into two categories : feature extraction and end - to - end learning. the former is characterized by the use of the extracted features from a off - the - shelf pre - trained backbone followed by the use of a classic classifier, such as knn and svm. the latter involves training a complete architecture from scratch or fine - tuning a pretrained model. remarkable examples of feature extraction approaches are : fv - cnn ( cimpoi et al., 2015 ) which uses the fisher vector ( fv ) to pool the local features from a convolutional layer of a cnn backbone, ignoring the spatial information, thus creating an order"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 3,
    "text": ". since the rapid emergence of deep learning methods in the last decade, the research community has seen a variety of approaches adopting convolutional neural networks ( cnns ) and, more recently, vision transformers ( vits ) for texture recognition. this is largely attributed to their ability to automatically learn and extract key features from images, in contrast to the manually designed descriptors discussed earlier. these approaches can be divided into two categories : feature extraction and end - to - end learning. the former is characterized by the use of the extracted features from a off - the - shelf pre - trained backbone followed by the use of a classic classifier, such as knn and svm. the latter involves training a complete architecture from scratch or fine - tuning a pretrained model. remarkable examples of feature extraction approaches are : fv - cnn ( cimpoi et al., 2015 ) which uses the fisher vector ( fv ) to pool the local features from a convolutional layer of a cnn backbone, ignoring the spatial information, thus creating an orderless representation ; and radam ( scabini et al., 2023 ) that randomly encodes multi - depth aggregated features from cnn backbones to later compose the texture representation. conversely, in the end - to - end learning category, notable techniques are : deepten ( zhang et al., 2017 ) where the authors proposed a single network that performs the feature extraction, the codebook ( or dictionary ) learning ( in a supervised manner ) and the encoding of the representation ; depnet ( xue et al., 2018 ) where authors discussed that the textures in surfaces preserve some spatial information. thus, guided by this starting point, the authors proposed the texture encoding branch and the global average pooling branch. the former addresses the orderless representation of the image, while the latter captures local spatial cues. later, dsrnet ( zhai et al., 2020 ) is a texture recognition network that learns the spatial dependency between texture primitives. this was motivated by the fact that multiple texture primitives appear differently in their spatial context ; however, they present an inherent spatial dependency. following, chen et al. ( 2024 ) proposed the dtp ( deep tracing pattern ) module. this module is responsible for leverag ing simultaneously shallow and deep layer features, thus obtaining rich cross - layer features for texture recognition. to this end, the dtp module perform a cross - layer feature aggregation, and inspired by lbp, it densely samples 3d patches of the grouped tensor to capture spatial and crosslayer information. after, a spatial pyramid histogram is used to comprise the feature vector. * * 2. 2. randomized neural network * * * * general background * *. randomized neural networks proposed in ( huang et al., 2006 ; pao & takefuji, 1992 ; pao et al., 1994 ; schmidt et al., 1992 ) are continuously being used by the research community for pattern recognition tasks. in particular, canonical application areas are _ classifi - _ _ cation _ and _ regression _. however, as previously mentioned, in the last decade novel approaches employing randomized neural networks have been proposed for representation learning. these methods have been applied primarily to textures, dynamic textures, and shape representations, diverging from their more common applications. in general, the large adoption of the community is due to three essential aspects that attracted interest in randomized neural networks. in the first place, the simplicity, since the most common cases are architectures composed by a single fully - connected hidden layer with randomly generated weights, and whose responsibility is to perform a non - linear random projection of the input data. another important aspect is its speed and low computational cost, which result from computing the output layer weights through a closedform solution. this enables fast training without the need for backpropagation. finally, these models also exhibit good generalization capabilities for certain types of problems. commonly, there are two widely utilized randomized neural networks in the literature : randomized vector functional link ( rvfl ), and the extreme learning machine ( elm ). both architectures share the common aspect of non - linearly random project the input data into another dimensional space, and the characteristic of a fast - training phase conducted via a closed - form solution by using the ( regularized ) least - squares solution. nevertheless, their main difference lies in how the output nodes are connected. the rvfl architecture has the output nodes connected both with the hidden nodes and the input ones, while in the elm architecture, the output nodes are only connected with the hidden ones. although its strengths and weaknesses have been extensively discussed, particularly regarding how the output layer should be connected. in this work, the output layer is connected only with the hidden nodes, following the previous literature in texture representation learning using randomized neural networks. * * formalism * *. in this part, we present a mathematical back 3 * * mixer : mixed hyperspherical random embedding neural network for texture recognition * * ground of the randomized neural network. let _ d _ = _ { _ ( * * x *"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 4,
    "text": "both architectures share the common aspect of non - linearly random project the input data into another dimensional space, and the characteristic of a fast - training phase conducted via a closed - form solution by using the ( regularized ) least - squares solution. nevertheless, their main difference lies in how the output nodes are connected. the rvfl architecture has the output nodes connected both with the hidden nodes and the input ones, while in the elm architecture, the output nodes are only connected with the hidden ones. although its strengths and weaknesses have been extensively discussed, particularly regarding how the output layer should be connected. in this work, the output layer is connected only with the hidden nodes, following the previous literature in texture representation learning using randomized neural networks. * * formalism * *. in this part, we present a mathematical back 3 * * mixer : mixed hyperspherical random embedding neural network for texture recognition * * ground of the randomized neural network. let _ d _ = _ { _ ( * * x * * _ i _ _, _ * * y * * _ i _ ) _ } _ _ [ n ] _ _ i _ = 1 _ [ ⊂x ×y ] _ [ be the dataset consisting of ] _ n _ samples, where * * x * * _ i _ _ ∈x _ is a _ p _ - dimensional input feature vector, and * * y * * _ i _ _ ∈y _ is a _ r _ - dimensional output feature vector. from _ d _ it is assembled the input and output feature matrices represented by * * x * * = hconcat ( * * x * * 1 _, _ * * x * * 2 _,..., _ * * x * * _ n _ ) _ ∈ _ r _ [ p ] [ × ] [ n ] _, and * * y * * = hconcat ( * * y * * 1 _, _ * * y * * 2 _,..., _ * * y * * _ n _ ) _ ∈ _ r _ [ r ] [ × ] [ n ] _, respectively, where hconcat ( _ · _ ) is the horizontal concatenation operation. following this, the network non - linearly projects these input feature vectors into another dimensional space. to this end, a matrix _ * * ψ * * _ _ ∈ _ r _ [ ω ] [ × ] [ p ] _ is randomly generated by some strategy, such as sampling each matrix ’ s entry from some distribution, e. g., _ * * ψ * * _ _ ij _ _ ∼n _ ( _ [UNK], σ _ [ 2 ] ), or using some pseudorandom number generator procedure. further, defining this matrix is a fundamental step, because the number of neurons in the hidden layer ( _ ω _ ), more specifically the dimension of the space where the features are projected into, shall be specified. in this context, upon the specification of the random weight matrix _ * * ψ * * _, the hidden or projected feature matrix is given by : * * z * * = _ α _ ( _ * * ψ * * _ * * x * * ) _ ∈ _ [ 0 _, _ 1 ] _ [ ω ] [ × ] [ n ] _ _, _ ( 1 ) where _ α _ ( _ x _ ) : = 1 _ / _ ( 1 + _ e _ _ [ − ] [ x ] _ ) is the sigmoid function applied element - wise. in general, one can choose another non - linear function, such as hyperbolic tangent. accordingly, from equation ( 1 ), the projected matrix consists of all real vectors * * z * * _ i _ = _ α _ ( _ * * ψ * * _ * * x * * _ i _ ) _ ∈ _ r _ [ ω ] _, which represent the _ ω _ - dimensional internal representation of the input feature vector * * x * * _ i _ _ ∈ _ r _ [ p ] _. subsequently, the learning phase to obtain the trained weights of the output layer shall be conducted. in this sense, the main objective of a randomized neural network is to seek for a matrix _ * * φ * * _ _ ∈ _ r _ [ r ] [ × ] [ ω ] _ of a linear transformation _ t _ : r _ [ ω ] _ _ → _ r _ [ r ] _, that takes the image of * * z * * _ i _, being * * z * * _ i _ the internal representation of * * x * * _ i _, as close as possible to * * y * * _ i _ under the squared _ [UNK] _ 2 norm. more precisely, this involves solving the following minimization problem : * * optimization 1 * * ( least - squares ) * *. * * let * * x * * _ ∈ _ r _ [ p ] [ × ] ["
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 5,
    "text": "* * _ i _ _ ∈ _ r _ [ p ] _. subsequently, the learning phase to obtain the trained weights of the output layer shall be conducted. in this sense, the main objective of a randomized neural network is to seek for a matrix _ * * φ * * _ _ ∈ _ r _ [ r ] [ × ] [ ω ] _ of a linear transformation _ t _ : r _ [ ω ] _ _ → _ r _ [ r ] _, that takes the image of * * z * * _ i _, being * * z * * _ i _ the internal representation of * * x * * _ i _, as close as possible to * * y * * _ i _ under the squared _ [UNK] _ 2 norm. more precisely, this involves solving the following minimization problem : * * optimization 1 * * ( least - squares ) * *. * * let * * x * * _ ∈ _ r _ [ p ] [ × ] [ n ] _, * * y * * _ ∈ _ r _ [ r ] [ × ] [ n ] _ and * * z * * _ ∈ _ r _ [ ω ] [ × ] [ n ] _ be the previously defined input, output, and projected feature matrices. we seek for a matrix _ * * φ * * _ _ [ ∗ ] _ _ ∈ _ r _ [ r ] [ × ] [ ω ] _ that solves the following minimization problem : min _ ∥ _ * * y * * _ − _ _ * * φ * * _ * * z * * _ ∥ _ _ f _ [ 2 ] [ + ] _ [ γ ] _ [ ω ( ] _ * * [ φ ] * * _ [ ) ] _ [, ] _ ( 2 ) _ * * φ * * _ where _ ∥ · ∥ _ _ f _ is the frobenius norm, ω ( _ · _ ) is the regularization term, and _ γ > _ 0 is the regularization parameter. in particular, when the regularization term is set to * * ω * * ( _ * * φ * * _ ) = 0, i. e., no regularization is applied. the solution for the minimization problem in equation ( 2 ) is given by the leastsquares solution : _ * * φ * * _ _ [ ∗ ] _ = * * yz * * _ [ † ] _, where * * z * * _ [ † ] _ = * * z * * _ [ t ] _ ( * * zz * * _ [ t ] _ ) _ [ − ] _ [ 1 ] is the moore - penrose pseudoinverse ( penrose, 1955 ). alternatively, a regularization term may be introduced for two main reasons. first, the regularization contributes in balancing the model complexity by adjusting the model ’ s biasvariance trade - off. second, inverting the matrix * * zz * * _ [ t ] _ may be challenging when it is ill - conditioned. under these circumstances, one may utilize the tikhonov ’ s regularization ( calvetti et al., 2000 ) without losing the closed - form aspect. to this end, the regularization term is set to ω ( _ * * φ * * _ ) = _ ∥ _ _ * * φ * * _ _ ∥ _ [ 2 ] _ f _ [. ] in this case, the solution of problem ( 2 ) is given by the regularized least - squares solution : _ * * φ * * _ _ [ ∗ ] _ = * * yz * * _ [ t ] _ ( * * zz * * _ [ t ] _ + _ γ _ * * id * * ) _ [ − ] _ [ 1 ] _, _ ( 3 ) where * * id * * is the identity matrix of size _ ω × ω _. * * 3. method * * in this section, we introduce m ixer, our novel approach for texture representation learning. as illustrated in figure 1, m ixer consists of four core modules : 1 ) local pattern extractor ( lpe ) module ; 2 ) hyperspherical random projector ( hrp ) module ; 3 ) learning module ; and 4 ) compression module. thus, the remainder of this section is dedicated to presenting the internal mechanisms of these modules. * * local pattern extractor module * *. given an image * * i * * _ ∈ _ r _ [ c ] [ × ] [ h ] [ × ] [ w ] _. this module, depicted in figure 1 ( b ), is responsible for extracting local intensity patterns from the image by densely sampling multiple small patches. its purpose is to capture variations and implicit spatial relationships among pixel intensities, thereby inherently representing raw texture information to be subsequently used as input for the remainder of the network. to this end, the module extracts multiple _ j × j _ patches centered at every pixel from each image channel"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 6,
    "text": "our novel approach for texture representation learning. as illustrated in figure 1, m ixer consists of four core modules : 1 ) local pattern extractor ( lpe ) module ; 2 ) hyperspherical random projector ( hrp ) module ; 3 ) learning module ; and 4 ) compression module. thus, the remainder of this section is dedicated to presenting the internal mechanisms of these modules. * * local pattern extractor module * *. given an image * * i * * _ ∈ _ r _ [ c ] [ × ] [ h ] [ × ] [ w ] _. this module, depicted in figure 1 ( b ), is responsible for extracting local intensity patterns from the image by densely sampling multiple small patches. its purpose is to capture variations and implicit spatial relationships among pixel intensities, thereby inherently representing raw texture information to be subsequently used as input for the remainder of the network. to this end, the module extracts multiple _ j × j _ patches centered at every pixel from each image channel of * * i * *, thus with overlapping. however, centering a pixel at or near the image border is not feasible because the patch size would overflow the image bounds. therefore, the image is padded before patch extraction. assuming that _ j _ is an odd natural number, the padding size applied in all image channel sides is _ [ j ] [ − ] _ [ 1 ] 2 [, and the utilized padding mode is replication. in ] general, this module is expressed by : pad _ j _ ( * * i * * ) _ ∈ _ r _ [ c ] [ × ] _ [ ( ] _ [ h ] _ [ + ] _ [ j ] [ − ] _ [ 1 ) ] _ [ × ] _ [ ( ] _ [ w ] _ [ + ] _ [ j ] [ − ] _ [ 1 ) ] ( 4 ) lpe ( pad _ j _ ( * * i * * ) ) _ ∈ _ r _ [ c ] [ × ] [ h ] [ × ] [ w ] [ × ] [ j ] [ × ] [ j ] _ _. _ ( 5 ) therefore, the output of equation ( 5 ) is a 5 - dimensional tensor that, basically, stores every _ j _ _ ×j _ image patches centered at every pixel of the image channel of dimension _ h × _ _ w _ for every image channel among the _ c _ available. finally, this module generalizes the widely used patch - based extraction technique, extending it to images with an arbitrary number of channels, as commonly employed in rnn - based texture representation learning approaches ( junior & backes, 2016 ; 4 * * mixer : mixed hyperspherical random embedding neural network for texture recognition * * _ figure 1. _ overview of the m ixer pipeline. the input image * * i * * _ ∈ _ r _ [ c ] [ × ] [ h ] [ × ] [ w ] _ is fed to the local pattern extractor ( lpe ) module, which pads the image and subsequently performs the extraction of tiny patches to record the raw texture information. thereafter, these patches are fed to the hyperspherical random projector ( hrp ) module that maps these patches in hyperspherical random embeddings composing the random projected matrices * * z * * _ [ ′ ′ ] _ _ i _ _ [ ∈ ] _ [ r ] [ ( ] _ [ ω ] _ [ + 1 ) ] _ [ × ] [ hw ] _ [. the projected matrices are fed to both d ] [ irect ] [ and m ] [ ixed ] [ branches responsible for ] learning the intra - and inter - channel local intensity relationships, respectively. the linear decoder ’ s learned weights from both modules are fed to the compression module, which is responsible for vertically concatenating them, resulting in the aggregated learned weight matrix, and is responsible for applying selected compression functions to compress the weight matrix into a useful color - texture representation. ribas & bruno, 2024 ). we refer the reader to section a of the supplementary materials for further details about this module. * * hyperspherical random projector module * *. this module, illustrated in figure 1 ( c ), encodes the raw pixel intensities of the extracted patches into internal representations, referred to as hyperspherical random embeddings. these embeddings are subsequently used during the training phase of the proposed learning modules. in this context, to obtain these internal representations, the module performs nonlinear random projections of the patch intensities, encoding them into a generally higher _ ω _ - dimensional space. these projections are then constrained to lie on the surface of a unit hypersphere through embedding normalization. this normalization step helps computational and training stability ( zhang et al., 2023 ; wang & isola, 2020 ), and here it does by adjusting potential column - norm distortions in the projected ( hidden ) matrix and by enhancing the conditioning of the matrix during the"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 7,
    "text": "- texture representation. ribas & bruno, 2024 ). we refer the reader to section a of the supplementary materials for further details about this module. * * hyperspherical random projector module * *. this module, illustrated in figure 1 ( c ), encodes the raw pixel intensities of the extracted patches into internal representations, referred to as hyperspherical random embeddings. these embeddings are subsequently used during the training phase of the proposed learning modules. in this context, to obtain these internal representations, the module performs nonlinear random projections of the patch intensities, encoding them into a generally higher _ ω _ - dimensional space. these projections are then constrained to lie on the surface of a unit hypersphere through embedding normalization. this normalization step helps computational and training stability ( zhang et al., 2023 ; wang & isola, 2020 ), and here it does by adjusting potential column - norm distortions in the projected ( hidden ) matrix and by enhancing the conditioning of the matrix during the inversion step. to accomplish this, let * * l * * = lpe ( pad _ j _ ( * * i * * ) ) be the 5 dimensional tensor output of the previous layer, which contains the pixel intensities of the extracted patches for every channel of the image. we reshape this tensor by independently merging the image spatial dimensions and the patch size dimensions. following this, we interchange these last two reshaped dimensions. we express these steps by : * * x * * = reshape ( * * l * * ) _ ∈ _ r _ [ c ] [ × ] [ j ] _ [ 2 ] _ [ × ] [ hw ] _ _. _ ( 6 ) hence, after the reshaping process, we obtain * * x * * 1 _, _ * * x * * 2 _,..., _ * * x * * _ c _, where each * * x * * _ k _ _ ∈ _ r _ [ j ] _ [ 2 ] _ [ × ] [ hw ] _ is a matrix containing the flattened, densely extracted patches over the spatial dimensions of the _ k _ - th image channel. subsequently, each of these matrices is used during the random projection phase to obtain the internal representation of each flattened patch. to this end, we perform : * * z * * _ k _ = _ α _ ( _ * * ψ * * _ _ k _ * * x * * _ [ ′ ′ ] _ _ k _ [ ) ] _ [ ∈ ] _ [ [ 0 ] _ [, ] _ [ 1 ] ] _ [ ω ] [ × ] [ hw ] _ _ [, ] _ ( 7 ) where _ * * ψ * * _ _ k _ _ ∈ _ r _ [ ω ] [ ∈ ] _ [ ( ] _ [ j ] _ [ 2 ] [ + 1 ) ] is the random weight matrix [ 1 ] used only to project the _ k _ - th pre - processed input feature matrix : * * x * * _ [ ′ ′ ] _ _ k _ [ = ] [ vconcat ] [ ( ] _ [ { − ] _ * * [ 1 ] * * _ [ hw ] _ _ [, ] _ * * [ x ] * * _ [ ′ ] _ _ k _ _ [ } ] _ [ ) ] _ [ ∈ ] _ [ r ] [ ( ] _ [ j ] _ [ 2 ] [ + 1 ) ] _ [ × ] [ hw ] _ _ [, ] _ ( 8 ) where vconcat ( _ · _ ) is the vertical concatenation operation, * * 1 * * _ hw _ _ ∈ _ r [ 1 ] _ [ × ] [ hw ] _ is a row matrix with all entries set to one, representing the bias terms, and * * x * * _ [ ′ ] _ _ k _ [ is the unit normal scaled ] input feature matrix defined by : [ * * x * * _ [ ′ ] _ _ k _ [ ] ] _ [ ij ] _ [ = ] [ * * x * * _ k _ ] _ ij _ _ − _ [ * * x * * _ k _ ] _ i, _ : _, _ _ k ∈ { _ 1 _, _ 2 _,..., c }, _ ( 9 ) _ s _ _ k, i _ + _ [UNK] _ where [ * * x * * _ k _ ] _ i, _ : = _ hw _ 1 _ hwj _ = 1 [ [ ] * * [ x ] * * _ [ k ] _ [ ] ] _ [ ij ] _ [ is the sample mean of ] the _ i _ - th row of the _ k _ - th input feature matrix * * x * * _ k _, _ s _ [ 2 ] _ k, i _ [ = ] _ hw _ 1 _ −"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 8,
    "text": "defined by : [ * * x * * _ [ ′ ] _ _ k _ [ ] ] _ [ ij ] _ [ = ] [ * * x * * _ k _ ] _ ij _ _ − _ [ * * x * * _ k _ ] _ i, _ : _, _ _ k ∈ { _ 1 _, _ 2 _,..., c }, _ ( 9 ) _ s _ _ k, i _ + _ [UNK] _ where [ * * x * * _ k _ ] _ i, _ : = _ hw _ 1 _ hwj _ = 1 [ [ ] * * [ x ] * * _ [ k ] _ [ ] ] _ [ ij ] _ [ is the sample mean of ] the _ i _ - th row of the _ k _ - th input feature matrix * * x * * _ k _, _ s _ [ 2 ] _ k, i _ [ = ] _ hw _ 1 _ − _ 1 _ hwj _ = 1 [ ( [ ] * * [ x ] * * _ [ k ] _ [ ] ] _ [ ij ] _ _ [ − ] _ [ [ ] * * [ x ] * * _ [ k ] _ [ ] ] _ i, _ : [ ) ] [ 2 ] [ is the sample variance, ] 1 we refer the reader to the section b of the supplementary material for the random weight matrix generation process. 5 * * mixer : mixed hyperspherical random embedding neural network for texture recognition * * and _ [UNK] _ = 10 _ [ − ] _ [ 10 ] is a small positive number to prevent division by zero. in this context, we have that * * z * * _ k _ consists of all the _ ω _ dimensional random embedded patch intensities. following this, before entering the learning modules, these projected feature matrices * * z * * 1 _, _ * * z * * 2 _,..., _ * * z * * _ c _ have their column vectors projected onto the unit hypersphere s _ [ ω ] [ − ] _ [ 1 ] = _ { _ * * v * * _ ∈ _ r _ [ ω ] _ _ | ∥ _ * * v * * _ ∥ _ 2 = 1 _ } _. this process is expressed by : [ * * z * * _ k _ ] _ ij _ [ * * z * * _ [ ′ ] _ _ k _ [ ] ] _ [ ij ] _ [ = ] _ k ∈ { _ 1 _, _ 2 _,..., c }, _ ( 10 ) max ( _ ∥ _ [ * * z * * _ k _ ] : _, j _ _ ∥ _ 2 _, [UNK] _ ) _ [, ] _ where _ ∥ · ∥ _ 2 is the euclidean norm, and [ * * z * * _ k _ ] : _, j _ is the _ j _ - th column of * * z * * _ k _. finally, as done for the input feature matrix, we also add a bias weight by vertically concatenating a row matrix filled with _ − _ 1, such that the output of this module is : * * z * * _ [ ′ ′ ] _ _ k _ [ = ] [ vconcat ] [ ( ] _ [ { − ] _ * * [ 1 ] * * _ [ hw ] _ _ [, ] _ * * [ z ] * * _ [ ′ ] _ _ k _ _ [ } ] _ [ ) ] _ [ ∈ ] _ [ r ] [ ( ] _ [ ω ] _ [ + 1 ) ] _ [ × ] [ hw ] _ _ [. ] _ ( 11 ) to simplify the notation, we denote * * z * * _ [ ′ ′ ] _ _ k _ [, the output of this ] module for a input feature matrix * * x * * _ k _, as _ f _ _ * * ψ * * _ _ k _ ( * * x * * _ k _ ), where _ f _ _ * * ψ * * _ _ k _ ( _ · _ ) is designated as the _ k _ - th random encoder whose random weight matrix is given by _ * * ψ * * _ _ k _ _ ∈ _ r _ [ ω ] [ × ] _ [ ( ] _ [ j ] _ [ 2 ] [ + 1 ) ]. * * learning module * *. this module represents one of the main components of our novel approach, and is shown in figure 1 ( d ). this is partitioned into two learning branches called the d irect and m ixed branches. these are responsible for learning multiple linear decoder networks, where their learned layer weights ( scalars ) are used later by the compression ( summarization ) module to assemble a useful color - texture representation. - * * d * * *"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 9,
    "text": "* _ k _, as _ f _ _ * * ψ * * _ _ k _ ( * * x * * _ k _ ), where _ f _ _ * * ψ * * _ _ k _ ( _ · _ ) is designated as the _ k _ - th random encoder whose random weight matrix is given by _ * * ψ * * _ _ k _ _ ∈ _ r _ [ ω ] [ × ] _ [ ( ] _ [ j ] _ [ 2 ] [ + 1 ) ]. * * learning module * *. this module represents one of the main components of our novel approach, and is shown in figure 1 ( d ). this is partitioned into two learning branches called the d irect and m ixed branches. these are responsible for learning multiple linear decoder networks, where their learned layer weights ( scalars ) are used later by the compression ( summarization ) module to assemble a useful color - texture representation. - * * d * * * * irect * * : this branch is responsible for learning a mapping that reconstructs the local intensity patterns of the extracted _ j × j _ patches from the hyperspherical random embeddings, with the intent to induce the network to learn the relationship between the hidden ( projected ) space and the intensities ( input ) space, from the point of view of the raw spatial texture present in the input matrix * * x * *. to this end, this branch learns the mapping through the following optimization problem. * * optimization 2 * * ( direct branch ) * *. * * let _ g _ _ * * θ * * _ ( * * z * * ) = _ * * θ * * _ * * z * * be a linear decoder network with parameters _ * * θ * * _. we seek to learn the parameters _ * * θ * * _ _ [ ∗ ] _ _ k _ _ [ ∈ ] _ [ r ] _ [ j ] _ [ 2 ] _ [ × ] _ [ ( ] _ [ ω ] _ [ + 1 ) ] [ for each image ] channel by solving the following minimization problem : min _ * * θ * * _ _ k _ _ [ ∥ ] _ * * [ x ] * * _ [ k ] _ _ [ − ] _ _ [ g ] _ _ * * [ θ ] * * _ _ [ k ] _ [ ( ] _ [ f ] _ _ * * [ ψ ] * * _ _ [ k ] _ [ ( ] * * [ x ] * * _ [ k ] _ [ ) ) ] _ [ ∥ ] _ _ f _ [ 2 ] [ + ] _ [ γ ] _ _ [ d ] _ _ [ ∥ ] _ _ * * [ θ ] * * _ _ [ k ] _ _ [ ∥ ] _ [ 2 ] _ f _ _ [, ] _ ( 12 ) where _ γ _ _ d _ _ > _ 0 is the regularization parameter of the direct branch. this optimization problem acts as a pure randomized autoencoder, where we force the network to learn how to reconstruct the original patches intensities from a non - linear random projection of themselves. consequently, from equation ( 15 ), we have that the shared internal representation * * s * * _ k _ of some patch _ k _, emerge as the average of the internal representations of the same the optimization problem presented in equation ( 12 ) has a closed - form solution given by the following regularized least - squares solution : _ * * θ * * _ _ [ ∗ ] _ _ k _ [ = ] * * [ x ] * * _ [ k ] _ * * [ z ] * * _ [ ′ ′ ] _ _ k _ _ t _ ( * * z * * _ ′ ′ k _ * * [ z ] * * _ [ ′ ′ ] _ _ k _ _ t _ + _ γ _ _ d _ * * id * * ) _ − _ 1 _. _ ( 13 ) finally, the subscript is emphasized because a linear decoder network is found for each channel of the input image. thus, a set of linear decoders that learned the spatial texture relationships of each channel independently is obtained. in this sense, this branch outputs the set _ s _ _ d _ = _ { _ _ * * θ * * _ _ [ ∗ ] _ 1 _ [, ] _ _ * * [ θ ] * * _ _ [ ∗ ] _ 2 _ [,..., ] _ _ * * [ θ ] * * _ _ [ ∗ ] _ _ c _ _ [ } ] _ [ that characterizes the local inten - ] sity relationships present in the input image channels. - * * m * * * * ixed * * : unlike the d irect branch that uses its own patch internal representation to reconstruct itself. this branch aims to reconstruct each patch not only from its own random embedding but also from the"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 10,
    "text": "− _ 1 _. _ ( 13 ) finally, the subscript is emphasized because a linear decoder network is found for each channel of the input image. thus, a set of linear decoders that learned the spatial texture relationships of each channel independently is obtained. in this sense, this branch outputs the set _ s _ _ d _ = _ { _ _ * * θ * * _ _ [ ∗ ] _ 1 _ [, ] _ _ * * [ θ ] * * _ _ [ ∗ ] _ 2 _ [,..., ] _ _ * * [ θ ] * * _ _ [ ∗ ] _ _ c _ _ [ } ] _ [ that characterizes the local inten - ] sity relationships present in the input image channels. - * * m * * * * ixed * * : unlike the d irect branch that uses its own patch internal representation to reconstruct itself. this branch aims to reconstruct each patch not only from its own random embedding but also from the random embeddings of the corresponding patch across all image channels. in this context, this branch first constructs a shared representation by combining the internal representations, serving as an intermediate fusion phase. following this, the result of the mixing process is used as input to the decoder network, whose main role is to reconstruct the original patch intensities. therefore, the network is guided to reconstruct the original patch information of a specific image channel by leveraging all available information from the corresponding patch across all channels, thereby learning inter - channel relationships. to achieve this, this branch learns the reconstruction through the following optimization problem : * * optimization 3 * * ( mixed branch ) * *. * * let _ g _ _ * * [UNK] * * _ ( * * z * * ) = _ * * [UNK] * * _ * * z * * be a linear decoder network with parameters _ * * [UNK] * * _. we seek to learn the parameters _ * * [UNK] * * _ _ [ ∗ ] _ _ k _ _ [ ∈ ] _ [ r ] _ [ j ] _ [ 2 ] _ [ × ] _ [ ( ] _ [ ω ] _ [ + 1 ) ] [ for each image ] channel by solving the following minimization problem : min _ * * [UNK] * * _ _ k _ _ ∥ _ * * x * * _ k _ _ − _ _ g _ _ * * [UNK] * * _ _ k _ ( * * s * * ) _ ∥ _ _ f _ [ 2 ] [ + ] _ [ γ ] _ _ [ m ] _ _ [ ∥ ] _ _ * * [ [UNK] ] * * _ _ k _ _ [ ∥ ] _ _ f _ [ 2 ] _ [, ] _ ( 14 ) where _ γ _ _ m _ _ > _ 0 is the regularization parameter of the mixed branch, and * * s * * _ ∈ _ r [ ( ] _ [ ω ] _ [ + 1 ) ] _ [ × ] [ n ] _ is the mixed random embedding built by averaging all internal random embeddings obtained for each image channel. that is, * * s * * = [ 1 ] _ c _ _ c _ _ f _ _ * * ψ * * _ _ j _ ( * * x * * _ j _ ) _. _ ( 15 ) _ j _ = 1 6 * * mixer : mixed hyperspherical random embedding neural network for texture recognition * * patch for all image channels. next, similarly to the preceding optimization problem, the closed - form solution for the equation ( 14 ) is given by the following regularized least - squares solution : _ * * [UNK] * * _ _ [ ∗ ] _ _ k _ [ = ] * * [ x ] * * _ [ k ] _ * * [ s ] * * _ [ t ] _ [ ( ] * * [ ss ] * * _ [ t ] _ [ + ] _ [ γ ] _ _ [ m ] _ * * [ id ] * * [ ) ] _ [ − ] _ [ 1 ] _ [. ] _ ( 16 ) finally, as in the direct branch, the output of this branch is a set of linear decoders _ s _ _ m _ = _ { _ _ * * [UNK] * * _ _ [ ∗ ] _ 1 _ [, ] _ _ * * [ [UNK] ] * * _ _ [ ∗ ] _ 2 _ [,..., ] _ _ * * [ [UNK] ] * * _ _ [ ∗ ] _ _ c _ _ [ } ] _ [ trained ] to reconstruct the local intensity patterns of each image channel from a common mixed representation. * * compression module * *. given an image * * i * * _ ∈ _ r _ [ c ] [ × ] [ h ] [ × ] [ w ] _ its image representation should be defined by a _ n _ - dimensional real vector that carries useful information about * * i * * to be used in"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 11,
    "text": "] * * [ ) ] _ [ − ] _ [ 1 ] _ [. ] _ ( 16 ) finally, as in the direct branch, the output of this branch is a set of linear decoders _ s _ _ m _ = _ { _ _ * * [UNK] * * _ _ [ ∗ ] _ 1 _ [, ] _ _ * * [ [UNK] ] * * _ _ [ ∗ ] _ 2 _ [,..., ] _ _ * * [ [UNK] ] * * _ _ [ ∗ ] _ _ c _ _ [ } ] _ [ trained ] to reconstruct the local intensity patterns of each image channel from a common mixed representation. * * compression module * *. given an image * * i * * _ ∈ _ r _ [ c ] [ × ] [ h ] [ × ] [ w ] _ its image representation should be defined by a _ n _ - dimensional real vector that carries useful information about * * i * * to be used in downstream tasks. nevertheless, as was observed, a set _ s _ = _ s _ _ d _ _ ∪s _ _ m _ _ ⊂ _ r _ [ j ] _ [ 2 ] _ [ × ] _ [ ( ] _ [ ω ] _ [ + 1 ) ] containing the learned linear decoders ’ weights is obtained as output of the learning module ( i. e., previous module ). in this context, the role of this module, illustrated in figure 1 ( e ), is to compress ( summarize ) the learned weights of these linear decoders, represented by real matrices, in real vectors to serve as a useful color - texture representation. to this end, we begin by defining a compression function : * * definition 3. 1 * * ( compression function ) * *. * * every scalarvalued function _ h _ : _ a ⊂ _ r _ [ n ] _ _ → _ r that maps a _ n _ dimensional real vector * * x * * _ ∈ _ _ a _ to a scalar _ h _ ( * * x * * ) _ ∈ _ r, where _ h _ ( * * x * * ) embeds some structural or semantic information about * * x * * is called a compression ( summarization ) function. by defining the compression function, also called the summarization function, we express that _ h _ must extract some useful knowledge ( simple or complex ) about the input vector. in this sense, a function that receives any real vector and simply returns a random number cannot be considered a compression function, since it does not embed any information. in this context, let * * f * * = vconcat ( _ s _ ) _ ∈ _ r _ [ | s | ] [ j ] _ [ 2 ] _ [ × ] _ [ ( ] _ [ ω ] _ [ + 1 ) ] be the real matrix resulting from the vertical concatenation of every matrix in _ s _, where _ | s | _ = 2 _ c _, since _ c _ decoders are learned in each branch. as a result, the matrix * * f * * contains the weights of the all decoders learned in both proposed branches. since these weights contain valuable content about the texture information of the input image, a set of summarization functions _ h _ are applied to compress the matrix * * f * * in a real vector serving as representation of the texture image * * i * *. therefore, this compression process is represented by : * * s * * _ h _ = ( _ h _ ( * * f * * 1 ) _, h _ ( * * f * * 2 ) _,..., h _ ( * * f * * _ ω _ + 1 ) ) _ ∈ _ r _ [ ω ] _ [ + 1 ] ( 17 ) * * ω * * _ ω _ ( * * i * * ) = hconcat ( _ { _ * * s * * _ h _ _ | h ∈h } _ ) _ ∈ _ r _ [ | h | ] _ [ ( ] _ [ ω ] _ [ + 1 ) ] _, _ ( 18 ) where * * f * * _ k _ _ ∈ _ r _ [ | s | ] [ j ] _ [ 2 ] is the _ k _ - th column of * * f * *, * * s * * _ h _ is the real vector representing the compressed matrix * * f * * under _ h ∈h _, and * * ω * * _ ω _ ( * * i * * ) is the texture representation of the image * * i * * using _ ω _ - dimensional random embeddings. in the present work, the set of compression functions employed is composed by four statistical measures _ h _ _ [UNK] _, _ h _ _ σ _, _ h _ _ γ _ and _ h _ _ κ _ which corresponds to the mean,"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 12,
    "text": "s * * _ h _ _ | h ∈h } _ ) _ ∈ _ r _ [ | h | ] _ [ ( ] _ [ ω ] _ [ + 1 ) ] _, _ ( 18 ) where * * f * * _ k _ _ ∈ _ r _ [ | s | ] [ j ] _ [ 2 ] is the _ k _ - th column of * * f * *, * * s * * _ h _ is the real vector representing the compressed matrix * * f * * under _ h ∈h _, and * * ω * * _ ω _ ( * * i * * ) is the texture representation of the image * * i * * using _ ω _ - dimensional random embeddings. in the present work, the set of compression functions employed is composed by four statistical measures _ h _ _ [UNK] _, _ h _ _ σ _, _ h _ _ γ _ and _ h _ _ κ _ which corresponds to the mean, standard deviation, skewness, and excess kurtosis, respectively. thus, the dimensionality of the texture representation in equation ( 18 ) is given by 4 ( _ ω _ + 1 ). for more information about the employed statistical measures, such as their formulas, we refer the reader to section c of the supplementary material. finally, we assemble a new texture representation by late fusing the learned representations from distinct _ ω _ 1 _, ω _ 2 _,..., ω _ _ n _ random embeddings sizes. this is a common utilized approach in previous rnn - based techniques, such as ( junior & backes, 2016 ; ribas et al., 2020 ), which shown to improve the performance of the texture recognition task. thus, we define this late fused color - texture representation as : * * υ * * _ w _ ( * * i * * ) = hconcat ( _ { _ * * ω * * _ ω _ ( * * i * * ) _ | ω ∈w } _ ) _ ∈ _ r _ [ m ] _ _, _ ( 19 ) where _ w _ = _ { ω _ 1 _, ω _ 2 _,..., ω _ _ n _ _ } ⊂ _ n is the set containing the random embeddings sizes used to compose the late fused representation, and _ m _ = 4 _ · _ [ ] _ ω∈w _ [ ( ] _ [ ω ] _ [ + 1 ) ] [ is the dimen - ] sionality of the proposed color - texture representation. * * 4. experiments * * in this section, we present the server infrastructure used to conduct the experiments, along with the versions of the main libraries employed to develop the proposed approach. we then describe the benchmark datasets used to evaluate the technique, highlighting their main characteristics. finally, we detail the cross - validation strategy, the evaluation metrics, and the classifier. * * setup * *. the experiments were conducted on a server running ubuntu 22. 04. 03 lts operating system equipped with a intel i9 - 14900k processor, 128 gb of ram, and a single graphic card nvidia rtx 4090. specifically, the approach runs on the specified graphic card. furthermore, the proposed technique is implemented using p y t orch v2. 6. 0, and the evaluation process used the scikit - learn v1. 6. 1 package. * * benchmarks * *. we evaluated our approach using four wellknown texture datasets exhibiting distinct textural challenges, attributes, and characteristics. in this context, this enabled us to analyze the novel approach over a broad range of scenarios and how well the proposed approach generalized in the texture recognition task. next, we briefly detail the peculiarities of each employed texture dataset : - * * outextc13 * * ( ojala et al., 2002a ) : this is the thirteenth 7 * * mixer : mixed hyperspherical random embedding neural network for texture recognition * * texture classification suite proposed from the outex surfaces and is widely used in both grayscale and colored versions. this dataset has proven to be hard to categorize due to the need for an efficient micro - textural characterization. thus, as done in ( backes et al., 2013 ), the employed dataset configuration is composed by 1360 color - texture images obtained by cropping 20 non - overlapping windows of size 128 _ × _ 128 pixels from 68 color - texture source images of size 538 _ × _ 746 pixels. - * * curet * * ( dana et al., 1999 ) : it stands for columbiautrecht reflectance and texture dataset. this dataset was proposed to study the appearances of the textured surfaces under distinct illuminations and viewing angles, therefore, tackling conditions that most datasets would not. in this sense, the presence of real - world surface textures ( e. g., aluminum, leather, cord"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 13,
    "text": "network for texture recognition * * texture classification suite proposed from the outex surfaces and is widely used in both grayscale and colored versions. this dataset has proven to be hard to categorize due to the need for an efficient micro - textural characterization. thus, as done in ( backes et al., 2013 ), the employed dataset configuration is composed by 1360 color - texture images obtained by cropping 20 non - overlapping windows of size 128 _ × _ 128 pixels from 68 color - texture source images of size 538 _ × _ 746 pixels. - * * curet * * ( dana et al., 1999 ) : it stands for columbiautrecht reflectance and texture dataset. this dataset was proposed to study the appearances of the textured surfaces under distinct illuminations and viewing angles, therefore, tackling conditions that most datasets would not. in this sense, the presence of real - world surface textures ( e. g., aluminum, leather, corduroy, paper etc. ) under multiple light conditions and viewing angles makes the texture recognition task harder, thereby resulting in a suitable dataset for evaluation. the utilized dataset setup consists of 5612 color - texture images resulting from 61 existing classes with each 92 samples with dimensions 200 _ × _ 200 pixels. this is the same setup performed in ( scabini et al., 2020 ). - * * usptex * * ( backes et al., 2012 ) : this natural image dataset, built by the university of sao paulo focused on obtaining [UNK] samples found day - to - day ( e. g., rice, vegetation, walls, bricks etc. ). the intent was to obtain a dataset with a higher degree of texture samples that exhibit irregular, random, or non - periodic patterns. the utilized configuration is composed by 2292 color - texture images divided in 191 classes, each containing 12 samples of dimensions 128 _ × _ 128 pixels. - * * mbt * * ( abdelmounaime & dong - chen, 2013 ) : the multiband texture ( mbt ) dataset was proposed for the analysis of textural approaches focusing in samples with intra - and inter - band spatial variations. the colors present in these samples of mbt are due to the distinct textural content that comprises each color channel. in this context, this is an interesting dataset to evaluate how well our novel approach simultaneously describes these intra - and interband spatial variations. as done in ( scabini et al., 2020 ), we employed the dataset configuration that comprises 2464 samples with dimension 160 _ × _ 160 pixels by cropping 16 non - overlapping windows from each of the 154 original images of size 640 _ × _ 640 pixels. * * cross - validation, metrics and classifier * *. to evaluate the performance of the novel approach we utilized the linear discriminant analysis ( lda ) classifier with the leave - oneout ( loo ) cross - validation strategy using the accuracy as performance metric. this metric was used since all utilized benchmark datasets are balanced, and is a well - known | m ( ) 10 | 5 < br > 4 < br > 3 < br > 2 < br > 1 < br > 0 < br > 1 < br > 2 < br > 3 < br > 4 < br > 5 | col3 | | - - - | - - - | - - - | | log | log | log | | log | log | ~ ~ 2 ~ ~ < br > ~ ~ 1 0 ~ ~ < br > ~ ~ 1 ~ ~ < br > ~ ~ 2 ~ ~ < br > ~ ~ 3 ~ ~ < br > ~ ~ 4 ~ ~ < br > ~ ~ 5 ~ ~ < br > log10 ( < br > d ) | | m ( ) 10 | 5 < br > 4 < br > 3 < br > 2 < br > 1 < br > 0 < br > 1 < br > 2 < br > 3 < br > 4 < br > 5 | col3 | | - - - | - - - | - - - | | log | log | log | | log | log | ~ ~ 2 ~ ~ < br > ~ ~ 1 0 ~ ~ < br > ~ ~ 1 ~ ~ < br > ~ ~ 2 ~ ~ < br > ~ ~ 3 ~ ~ < br > ~ ~ 4 ~ ~ < br > ~ ~ 5 ~ ~ < br > log10 ( < br > d ) | _ figure 2. _ accuracy ( % ) behavior of the color - texture representation * * ω * * 59 ( * * i * * ) for all the benchmark datasets as the regularization of the d irect and m ixed branches varies. performance proxy used for evaluation of texture recognition methods. in addition, we adopted this linear decision boundary classifier owing to its simplicity, and we used the default hyperparameter configuration provided by the scikit - learn v1. 6."
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 14,
    "text": "br > 3 < br > 4 < br > 5 | col3 | | - - - | - - - | - - - | | log | log | log | | log | log | ~ ~ 2 ~ ~ < br > ~ ~ 1 0 ~ ~ < br > ~ ~ 1 ~ ~ < br > ~ ~ 2 ~ ~ < br > ~ ~ 3 ~ ~ < br > ~ ~ 4 ~ ~ < br > ~ ~ 5 ~ ~ < br > log10 ( < br > d ) | _ figure 2. _ accuracy ( % ) behavior of the color - texture representation * * ω * * 59 ( * * i * * ) for all the benchmark datasets as the regularization of the d irect and m ixed branches varies. performance proxy used for evaluation of texture recognition methods. in addition, we adopted this linear decision boundary classifier owing to its simplicity, and we used the default hyperparameter configuration provided by the scikit - learn v1. 6. 1 package, which uses the singular value decomposition ( svd ) as solver. for more information about the setting, we refer the reader to the supplementary material. * * 5. results and discussions * * * * regularization analysis * *. to understand the effect of the regularization on the decoder ’ s learned weights, and consequently, in the color - texture representation. we analyzed the behavior of the obtained accuracies of the texture representation * * ω * * 59 ( * * i * * ) across all benchmark datasets, as the regularization hyperparameters _ γ _ _ d _ and _ γ _ _ m _ for the direct and mixed branches, respectively, varies over the region _ r × r _, where _ r _ = _ { _ 10 _ [ k ] _ _ | k ∈ _ z _ ∧− _ 5 _ ≤ _ _ k ≤ _ 5 _ } _. figure 2 exhibits a greater performance of the proposed color - texture representation in outex and curet as the regularization values for both branches increased. this is observed by warmer colors, representing greater accuracy, present on the upper right region, which is determined by high regularization on both branches. in that region, accuracies of up to 96. 9 % were achieved in outex, and up to 98. 0 % in curet, thus indicating a good performance of the texture representation in this condition. in addition, another common aspect in these datasets was the relatively low performance identified by the presence of cooler colors in the remaining region, corresponding to the cases in which either one of the branches exhibited low regularization or both branches did. 8 * * mixer : mixed hyperspherical random embedding neural network for texture recognition * * _ figure 3. _ accuracy ( % ) behavior of the color - texture representation * * ω * * 59 ( * * i * * ) for the outex & curet and usptex & mbt dataset pairs as the regularization of the d irect and m ixed branches varies. the behavior is the average of the accuracies obtained by the datasets in each configuration. the inset plot in each figure refers to the region near to the highest average accuracy. * * note * * : the color bar of the inset plot was adjusted to help the visualization of the highest average accuracy. these findings suggest that outex and curet favor from the use of both branches, and while these are operating in conjunction, they had a stronger preference towards higher regularization to obtain good performances. this may be attributed to the fact that stronger regularization induces the decoders to reduce the fitting of the original patches intensities as well as possible noise, thus forcing the decoder to focus on the general discriminative information about the texture on the image, instead of the small peculiarities potentially present in it. following, usptex shown a common aspect with the last two evaluated benchmarks, wherein all three presented a low performance in the upper left region, corresponding to low regularization on the d irect branch and high on the m ixed one. however, the fact that the proposed representation in usptex shown a moderate performance when both regularization values were low, and this performance weakened as only the m ixed branch regularization increased indicates that this branch played a key role in the generalizability of the usptex benchmark, and might be attributed to the fact that the increased regularization resulted in underfit, and consequently the decoder did not properly learn the textural content of the image under the mixing optimization problem, thus weakening the overall representation. in addition, unlike outex and curet, usptex has achieved the highest accuracy of 99. 5 % with moderate values for regularization in both branches. subsequently, the performance behavior for the mbt dataset was basically the opposite of that observed in outex and curet. the higher accuracies occurred outside the high regularization region, whereas the lower accuracies were obtained there. this denotes that both branches may be suffering from underfit when strongly regularized, as in the case of usptex for the m ixed branch. never"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 15,
    "text": ", the fact that the proposed representation in usptex shown a moderate performance when both regularization values were low, and this performance weakened as only the m ixed branch regularization increased indicates that this branch played a key role in the generalizability of the usptex benchmark, and might be attributed to the fact that the increased regularization resulted in underfit, and consequently the decoder did not properly learn the textural content of the image under the mixing optimization problem, thus weakening the overall representation. in addition, unlike outex and curet, usptex has achieved the highest accuracy of 99. 5 % with moderate values for regularization in both branches. subsequently, the performance behavior for the mbt dataset was basically the opposite of that observed in outex and curet. the higher accuracies occurred outside the high regularization region, whereas the lower accuracies were obtained there. this denotes that both branches may be suffering from underfit when strongly regularized, as in the case of usptex for the m ixed branch. neverthe less, unlike the last three benchmarks, the mbt exhibited good performance on a broad range of regularization values, particularly those characterized by low to moderate levels. among these regularization levels, the representation achieved the maximum accuracy of 99. 5 %. in addition to the preceding analysis, figure 2 shows two pairs of datasets that exhibit similar suitable regularization values. the first pair comprises outex and curet, while the second consists of usptex and mbt. thus, to ensure fair hyperparameter selection within each pair, we adopt the same regularization values across the datasets. we analyzed their average accuracies through a joint evaluation as the regularization values varied within the same parameter space. figure 3 presents the joint analysis for both pairs of datasets. for outex and curet, the inset plot highlighting the region with the highest accuracy clearly shows that _ γ _ _ d _ = 10 [ 4 ] and _ γ _ _ m _ = 10 [ 5 ] yield the best average configuration. similarly, for usptex and mbt, the plot reveals that _ γ _ _ d _ = 10 [ 0 ], and _ γ _ _ m _ = 10 [ 0 ] are the optimal configurations on average as well. therefore, these configurations will be used for each pair for the remainder of the paper. * * ablation analysis * *. figure 4 presents the results for the ablation analysis of the proposed texture representation * * ω * * _ ω _ ( * * i * * ). in outex and curet, it can be observed that the representation obtained using both branches increased the performance, being more notable for outex. furthermore, although the m ixed branch achieved the lowest accuracies on these datasets, the final representations were strengthened when both learning branches were combined. in other words, accuracy improved when both branches were used, suggesting that the features learned in each branch complemented one another. in usptex and mbt, it was observed that using only a single branch was sufficient to achieve the highest performance. this indicates that one of the learning branches is already capable of extracting the meaningful features from the tex 9 * * mixer : mixed hyperspherical random embedding neural network for texture recognition * * | both < br > direct | col2 | col3 | | - - - | - - - | - - - | | | ~ ~ m ~ ~ | ~ ~ xed ~ ~ | | both < br > direct | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | col10 | col11 | col12 | col13 | col14 | col15 | col16 | col17 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | | | | | | | | | | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | | | | | | | | | | ~ ~ mixed ~ ~ | ~ ~ mixed ~ ~ | ~ ~ mixed ~ ~ | ~"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 16,
    "text": "| both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | | | | | | | | | | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | both < br > direct < br > | | | | | | | | | | ~ ~ mixed ~ ~ | ~ ~ mixed ~ ~ | ~ ~ mixed ~ ~ | ~ ~ mixed ~ ~ | ~ ~ mixed ~ ~ | ~ ~ mixed ~ ~ | ~ ~ mixed ~ ~ | ~ ~ mixed ~ ~ | ~ ~ mixed ~ ~ | | | | | | | | | | ~ ~ mixed ~ ~ | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | _ figure 4. _ average accuracy ( % ) behavior of the proposed texture representation * * ω * * _ ω _ ( * * i * * ) when either one of the branches are being used or both of them are. ture image. interestingly, while usptex shows the m ixed branch achieving the highest accuracy, mbt exhibits the best performance with the d irect branch. therefore, this brief analysis demonstrates the beneficial impact of employing both learning branches, particularly in the outex and curet datasets, as well as the usefulness of having both branches available. this design highlights the adaptability of the approach to extract features from diverse textural patterns, as illustrated by the usptex and mbt datasets, where a single branch was sufficient. however, the remainder of the paper uses the color - texture representation obtained when both learning branches are activated. * * embedding size analysis * *. we evaluated how the accuracy of the proposed texture representation * * ω * * _ ω _ ( * * i * * ) behaves as its unique parameter _ ω ∈ _ n, representing the random embedding size, varies. to this end, the parameter space where _ ω _ varied over was defined as _ o _ = _ { _ 9 _, _ 19 _,..., _ 109 _ } _, and is broader than those presented in previous studies ( junior & backes, 2016 ; ribas et al., 2020 ). we also presented the obtained accuracies for all benchmark datasets, thereby providing a thorough analysis of the parameter impact. figure 5 presents the performance for all datasets. in particular, outex generally exhibited an increase in accuracy as the embedding size grew. however, performance drops were observed in the intervals [ 29 _, _ 39 ] n and [ 59 _, _ 89 ] n. the former showed a more pronounced drop, while the latter exhibited only a subtle decrease. conversely, curet, usptex, and mbt, unlike outex, displayed a sharp increase in performance at the initial values, followed by relative stability across the remaining parameter space. this suggests that the embedding size had a beneficial impact on the overall performance of the proposed representation. this is largely motivated by the increasing number of learned features which depends on _ ω _, and which are discriminative enough to almost saturate the curet, usptex and mbt simultaneously, and surpass the 97 % barrier, and almost the 98 % one, performance of the outex dataset, where to the best of our knowledge is the unique rnn - based approach to achieve this as shall be discussed later. in addition, following previous studies ( junior & backes, 2016 ; ribas et al., 2020 ), we also investigated the performance of the novel approach * * υ * * _ w _ ( * * i * * ) when more random embedding sizes are incorporated. we performed this analysis because previous studies have shown that combining features learned from lower - dimensional embeddings generally yields representations with higher performance, even when the total number of features remains the same. in particular, our study considered only two random embedding sizes to avoid generating excessively large feature vectors, with the selected pair of embedding sizes satisfying : ( _ ω _ 1 _, ω _ 2 ) _ ∈ { _ ( _ ω _ 1 _"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 17,
    "text": "##ate the curet, usptex and mbt simultaneously, and surpass the 97 % barrier, and almost the 98 % one, performance of the outex dataset, where to the best of our knowledge is the unique rnn - based approach to achieve this as shall be discussed later. in addition, following previous studies ( junior & backes, 2016 ; ribas et al., 2020 ), we also investigated the performance of the novel approach * * υ * * _ w _ ( * * i * * ) when more random embedding sizes are incorporated. we performed this analysis because previous studies have shown that combining features learned from lower - dimensional embeddings generally yields representations with higher performance, even when the total number of features remains the same. in particular, our study considered only two random embedding sizes to avoid generating excessively large feature vectors, with the selected pair of embedding sizes satisfying : ( _ ω _ 1 _, ω _ 2 ) _ ∈ { _ ( _ ω _ 1 _, ω _ 2 ) _ ∈o × o | ω _ 1 _ < ω _ 2 _ }. _ ( 20 ) table 1 shows the performance of the approach for all benchmark datasets over the combined embeddings. although there were a performance improvement of * * υ * * _ w _ ( * * i * * ) over * * ω * * _ ω _ ( * * i * * ), the increase was modest. particularly, the greater improvement occurred in curet with 99. 7 % ( * * υ * * 99 _, _ 109 ( * * i * * ) ) _ vs. _ 99. 0 % ( * * ω * * 109 ( * * i * * ) ), followed by outex 97. 9 % ( * * υ * * 39 _, _ 79 ( * * i * * ) ) _ vs. _ 97. 7 % ( * * ω * * 109 ( * * i * * ) ), and mbt 99. 8 % ( * * υ * * 69 _, _ 79 ( * * i * * ) ) _ vs. _ 99. 6 % ( * * ω * * 109 ( * * i * * ) ). there was no performance gain in usptex. this suggests that our simpler approach * * ω * * _ ω _ ( * * i * * ) with only one embedding already contains enough discriminative features for classification. nevertheless, our experiments are consistent with previous findings indicating that combining lower - dimensional embeddings can yield better performance while maintaining the same number of features. for instance, in outex, the representation * * υ * * 29 _, _ 59 ( * * i * * ) achieved 97. 4 % with 360 descriptors, where the representation * * ω * * 89 ( * * i * * ) achieved 96. 7 % with the same amount of descriptors. we end this section by selecting the texture representation that achieved the highest average accuracy, for a fairness comparison with the literature methods. this representation was * * υ * * 39 _, _ 109 ( * * i * * ) and achieved the average accuracy of 99. 2 % with 600 descriptors. * * literature comparison * *. we compared our novel approach with two types of texture recognition methods : the _ hand - _ _ crafted _ ones, and those based on _ randomized neural net - _ _ works _. included among the handcrafted are the opponentgabor ( jain & healey, 1998 ), composed by opponent features from gabor - filter outputs ; the ones based in local patterns, such as lpq ( ojansivu & heikkila [UNK], 2008 ) and clbp ( guo et al., 2010 ) ; and those that models the texture as complex networks, building the representation upon network ’ s topological measures, such as mcnd ( scabini et al., 10 * * mixer : mixed hyperspherical random embedding neural network for texture recognition * * | col1 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | col10 | col11 | col12 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | ~ ~ o ~ ~ | ~ ~ ute ~ ~ | | | col1 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | col10 | col11 | col12 | | - - - | - - - | - - - | - - - | - - - | - - - | - -"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 18,
    "text": "| col1 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | col10 | col11 | col12 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | ~ ~ o ~ ~ | ~ ~ ute ~ ~ | | | col1 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | col10 | col11 | col12 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | ~ ~ cu ~ ~ | ~ ~ re ~ ~ | | _ figure 5. _ accuracy ( % ) behavior of the proposed texture representation * * ω * * _ ω _ ( * * i * * ) as the random embedding size _ ω _ varies in the defined parameter space. this behavior analysis is presented for all benchmark datasets. | col1 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | col10 | col11 | col12 | col13 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | ~ ~ us ~ ~ | ~ ~ pte ~ ~ | ~ ~ x ~ ~ | | | | | | | | | | | | | | | | col1 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | col10 | col11 | col12 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | ~ ~ b ~ ~ | | | | | | | | | | | | | | | 2019 ), and ssn ( scabini et al., 2020 ). following this, among the rnn - based approaches, the main ones to be compared, include : ssr ( ribas et al., 2024 ), which combines complex network theory with the randomized neural network, the sst ( fares & ribas, 2024 ) that performs a spatio - spectral texture learning by cross - channel predicting, and the vctex ( fares & ribas, 2025 ) that uses volumetric ( 3d ) color cubes for simultaneous color - texture encoding, thereby requiring only a single neural network for learning the raw texture representation, differing from the last two approaches that require more. table 2 presents the accuracy comparison among the literature methods. in outex, our novel approach attained the highest accuracy of 97. 8 %, being 1. 0 % greater than ssn, the second - best technique, and being the unique approach to surpass the 97 % barrier, and almost the 98 %. similarly to outex, in curet, our approach also achieved the highest accuracy of 99. 5 %, being 0. 9 % greater than the two runnerup approaches, which were ssn and ssr, achieving 98. 6 %. thus, in both discussed datasets, the better performances indicate increases of approximately 13, and 50 images correctly classified, respectively, with all this achieved using a smaller number of descriptors. in usptex and mbt, our proposed technique achieved the highest accuracy on the former and the second - best performance on the latter. the increase and the respective decrease were minimal, a difference of only 0. 1 % in both datasets. thus,"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 19,
    "text": "require more. table 2 presents the accuracy comparison among the literature methods. in outex, our novel approach attained the highest accuracy of 97. 8 %, being 1. 0 % greater than ssn, the second - best technique, and being the unique approach to surpass the 97 % barrier, and almost the 98 %. similarly to outex, in curet, our approach also achieved the highest accuracy of 99. 5 %, being 0. 9 % greater than the two runnerup approaches, which were ssn and ssr, achieving 98. 6 %. thus, in both discussed datasets, the better performances indicate increases of approximately 13, and 50 images correctly classified, respectively, with all this achieved using a smaller number of descriptors. in usptex and mbt, our proposed technique achieved the highest accuracy on the former and the second - best performance on the latter. the increase and the respective decrease were minimal, a difference of only 0. 1 % in both datasets. thus, taking into account implementation and hardware variability, it is reasonable to state that no significant improvements or declines were observed. however, it should be noted that our approach achieved the best accuracy in the last benchmarks with a smaller number of features, indicating that it provides a more efficient descriptor. finally, our approach presented the highest average accu racy of 99. 2 % among the compared methods, representing an increase of 0. 7 % over the second - best accuracy of 98. 5 % achieved by ssn, and being the only technique to surpass the 99 %. therefore, this emphasizes its greater discriminative power and its adaptability to diverse textural patterns and conditions present in the tackled benchmarks. * * 6. conclusions and future works * * in this work, we introduced m ixer, a texture representation learning approach that learns by decoding the encoded texture information from hyperspherical random embeddings. by leveraging two learning branches, called d irect and m ixed branches, trained by distinct optimization objectives, and using as representation the weights of the learned linear decoder networks, our approach was able to learn a robust and efficient texture descriptor, achieving the highest average accuracy in the texture benchmarks. to achieve this, we first densely extract local patches from the image to capture the raw texture information. following, these patches are randomly encoded and restricted to lie on the surface of a unit hypersphere, emphasizing the directional information. next, the d irect module learns to reconstruct the original patch information just by looking at its own representation. conversely, the m ixed module learns to reconstruct the original patch of a specific channel by mixing the internal representation of the same patch in all image channels, thus performing a simultaneous crosschannel reconstruction by means of an intermediate fused representation. * * future works * *. there are two interesting points for future works. first, we believe that there might be better ways to create the input and output matrices by leveraging distinct texture modeling techniques, such as those using _ complex _ _ networks _. further, modeling these matrices differently im 11 * * mixer : mixed hyperspherical random embedding neural network for texture recognition * * accuracy ( _ ↑ _ ) ( _ ω _ 1 _, ω _ 2 ) outex13 curet usptex mbt avg. _ line left for adjustment _ ( 9, 19 ) 95. 4 95. 4 98. 8 98. 8 97. 1 ( 9, 29 ) 96. 2 96. 2 99. 2 98. 9 97. 6 ( 9, 39 ) 95. 5 97. 4 99. 2 99. 4 97. 9 ( 9, 49 ) 96. 5 98. 0 99. 3 99. 2 98. 3 ( 9, 59 ) 96. 8 98. 4 99. 5 99. 5 98. 6 ( 9, 69 ) 96. 5 98. 6 99. 5 99. 6 98. 6 ( 9, 79 ) 96. 8 98. 7 99. 4 99. 5 98. 6 ( 9, 89 ) 96. 9 99. 1 99. 6 99. 4 98. 8 ( 9, 99 ) 97. 4 99. 1 99. 5 99. 4 98. 9 ( 9, 109 ) 97. 5 99. 3 99. 7 99. 6 99. 0 ( 19, 29 ) 96. 4 97. 6 99. 3 99. 2 98. 1 ( 19, 39 ) 96. 4 98. 2 99. 2 99. 4 98. 3 ( 19, 49 ) 96. 5 98. 3 99. 3 99. 3 98. 4 ( 19, 59 ) 97. 1 98. 6 99. 6 99. 5 98. 7 ( 19, 69 ) 97. 2 98. 8 99. 5 99. 4 98. 7 ( 19, 79 ) 97. 3 99. 0 99. 6 99. 5 98. 9 ( 19, 89 ) 97. 1 99. 2 99. 6 99. 5 98"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 20,
    "text": ". 6 ( 9, 89 ) 96. 9 99. 1 99. 6 99. 4 98. 8 ( 9, 99 ) 97. 4 99. 1 99. 5 99. 4 98. 9 ( 9, 109 ) 97. 5 99. 3 99. 7 99. 6 99. 0 ( 19, 29 ) 96. 4 97. 6 99. 3 99. 2 98. 1 ( 19, 39 ) 96. 4 98. 2 99. 2 99. 4 98. 3 ( 19, 49 ) 96. 5 98. 3 99. 3 99. 3 98. 4 ( 19, 59 ) 97. 1 98. 6 99. 6 99. 5 98. 7 ( 19, 69 ) 97. 2 98. 8 99. 5 99. 4 98. 7 ( 19, 79 ) 97. 3 99. 0 99. 6 99. 5 98. 9 ( 19, 89 ) 97. 1 99. 2 99. 6 99. 5 98. 9 ( 19, 99 ) 97. 4 99. 3 99. 5 99. 6 99. 0 ( 19, 109 ) 97. 5 99. 2 99. 7 99. 7 99. 0 ( 29, 39 ) 96. 6 98. 4 99. 6 99. 4 98. 5 ( 29, 49 ) 96. 8 98. 5 99. 5 99. 3 98. 5 ( 29, 59 ) 97. 4 98. 9 99. 6 99. 3 98. 8 ( 29, 69 ) 97. 3 98. 9 99. 6 99. 6 98. 9 ( 29, 79 ) 97. 6 99. 1 99. 5 99. 5 98. 9 ( 29, 89 ) 97. 3 99. 3 99. 7 99. 4 98. 9 ( 29, 99 ) 97. 1 99. 3 99. 7 99. 4 98. 9 ( 29, 109 ) 97. 8 99. 4 99. 6 99. 5 99. 1 accuracy ( _ ↑ _ ) ( _ ω _ 1 _, ω _ 2 ) outex13 curet usptex mbt avg. ( 39, 49 ) 97. 1 98. 8 99. 6 99. 5 98. 8 ( 39, 59 ) 97. 6 99. 1 99. 6 99. 7 99. 0 ( 39, 69 ) 97. 6 99. 1 99. 6 99. 7 99. 0 ( 39, 79 ) 97. 9 99. 2 99. 5 99. 6 99. 1 ( 39, 89 ) 97. 1 99. 3 99. 7 99. 5 98. 9 ( 39, 99 ) 97. 4 99. 4 99. 5 99. 6 99. 0 ( 39, 109 ) 97. 8 99. 5 99. 7 99. 7 99. 2 ( 49, 59 ) 97. 4 99. 1 99. 7 99. 5 98. 9 ( 49, 69 ) 97. 1 99. 1 99. 6 99. 6 98. 9 ( 49, 79 ) 97. 5 99. 2 99. 5 99. 6 99. 0 ( 49, 89 ) 97. 1 99. 3 99. 5 99. 4 98. 8 ( 49, 99 ) 97. 6 99. 4 99. 7 99. 6 99. 1 ( 49, 109 ) 97. 6 99. 4 99. 5 99. 6 99. 0 ( 59, 69 ) 97. 6 99. 2 99. 7 99. 6 99. 0 ( 59, 79 ) 97. 6 99. 5 99. 6 99. 6 99. 1 ( 59, 89 ) 97. 4 99. 5 99. 6 99. 6 99. 0 ( 59, 99 ) 97. 6 99. 5 99. 5 99. 6 99. 1 ( 59, 109 ) 97. 4 99. 6 99. 6 99. 7 99. 1 ( 69, 79 ) 97. 8 99. 3 99. 5 99. 8 99. 1 ( 69, 89 ) 97. 4 99. 4 99. 7 99. 6 99. 0 ( 69, 99 ) 97. 2 99. 5 99. 6 99. 5 99. 0 ( 69, 109 ) 97. 7 99. 6 99. 6 99. 7 99. 2 ( 79, 89 ) 97. 7 99. 5 99. 7 99. 6 99. 1 ( 79, 99 ) 97. 3 99. 6 99. 6 99. 5 99. 0 ( 79, 109 ) 97. 5 99. 6 99. 7 99. 6 99. 1 ( 89, 99 ) 97. 3 99. 6 99. 6 99. 6 99. 0 ( 89, 109 ) 97. 4 99. 6 99. 7 99. 7 99. 1 ( 99, 109 ) 97. 4 99. 7 99. 7 99. 7 99. 1 _ table 1. _ accuracy ( % ) of"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 21,
    "text": "3 99. 5 99. 8 99. 1 ( 69, 89 ) 97. 4 99. 4 99. 7 99. 6 99. 0 ( 69, 99 ) 97. 2 99. 5 99. 6 99. 5 99. 0 ( 69, 109 ) 97. 7 99. 6 99. 6 99. 7 99. 2 ( 79, 89 ) 97. 7 99. 5 99. 7 99. 6 99. 1 ( 79, 99 ) 97. 3 99. 6 99. 6 99. 5 99. 0 ( 79, 109 ) 97. 5 99. 6 99. 7 99. 6 99. 1 ( 89, 99 ) 97. 3 99. 6 99. 6 99. 6 99. 0 ( 89, 109 ) 97. 4 99. 6 99. 7 99. 7 99. 1 ( 99, 109 ) 97. 4 99. 7 99. 7 99. 7 99. 1 _ table 1. _ accuracy ( % ) of the proposed texture representation * * υ * * _ ω _ 1 _, ω _ 2 ( * * i * * ) for all the benchmark datasets. the left table presents the accuracies for the random embedding sizes combinations where _ ω _ 1 _ ∈ { _ 9 _, _ 19 _, _ 29 _ } _. the right table exhibits the accuracies for the remaining of the combinations of the previously defined space for ( _ ω _ 1 _, ω _ 2 ). poses the network to cross this information, which might produce better representations. second, we suggest that directly adjusting the optimization problem accounting for a multi - objective least squares, maintaining the closed - form expressiveness, might produce interesting representations depending on how each objective is specified. * * acknowledgements * * r. t. fares acknowledges support from fapesp ( grant # 2024 / 01744 - 8 ), l. c. ribas acknowledges support from fapesp ( grants # 2023 / 04583 - 2 and 2018 / 22214 - 6 ). * * references * * abdelmounaime, s. and dong - chen, h. new brodatz - based image databases for grayscale color and multiband texture analysis. _ international scholarly research notices _, 2013 ( 1 ) : 876386, 2013. akiva, p., purri, m., and leotta, m. self - supervised material and texture representation learning for remote sensing tasks. in _ proceedings of the ieee / cvf conference _ _ on computer vision and pattern recognition _, pp. 8203 – 8215, 2022. backes, a. r., casanova, d., and bruno, o. m. color texture analysis based on fractal descriptors. _ pattern _ _ recognition _, 45 ( 5 ) : 1984 – 1992, 2012. backes, a. r., casanova, d., and bruno, o. m. texture analysis and classification : a complex network - based approach. _ information sciences _, 219 : 168 – 180, 2013. bovik, a., clark, m., and geisler, w. multichannel texture analysis using localized spatial filters. _ ieee transactions _ _ on pattern analysis and machine intelligence _, 12 ( 1 ) : 55 – 73, 1990. 12 * * mixer : mixed hyperspherical random embedding neural network for texture recognition * * method outex13 curet usptex mbt acc # opponent - gabor ~ ~ _ [ † ] _ ~ ~ 93. 5 95. 8 99. 1 97. 6 96. 5 _ − _ lpq _ [ † ] [, i ] _ 80. 1 91. 7 90. 4 95. 7 89. 5 _ − _ clbp _ [ † ] [, i ] _ 89. 6 91. 8 97. 4 98. 2 94. 3 _ − _ cntd _ [ † ] [, i ] _ 92. 3 91. 9 97. 9 98. 5 95. 2 _ − _ mcnd _ [ † ] _ 95. 4 97. 0 99. 0 97. 1 97. 1 _ − _ ssn 96. 8 98. 6 99. 5 99. 0 98. 5 648 ssr 96. 7 98. 6 99. 3 98. 2 98. 2 630 sst 96. 8 95. 6 _ [ ∗ ] _ 99. 1 99. 8 97. 8 756 vctex 96. 0 96. 0 _ [ ∗ ] _ 99. 6 99. 1 97. 7 648 * * mixer ( ours ) * * * * 97. 8 * * * * 99. 5 * * * * 99. 7 * * 99. 7 * * 99. 2 * * 600 _ table 2. _ accuracy comparison with literature methods. approaches with a _ † _ symbol were sourced from ( scabini"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 22,
    "text": "† ] [, i ] _ 92. 3 91. 9 97. 9 98. 5 95. 2 _ − _ mcnd _ [ † ] _ 95. 4 97. 0 99. 0 97. 1 97. 1 _ − _ ssn 96. 8 98. 6 99. 5 99. 0 98. 5 648 ssr 96. 7 98. 6 99. 3 98. 2 98. 2 630 sst 96. 8 95. 6 _ [ ∗ ] _ 99. 1 99. 8 97. 8 756 vctex 96. 0 96. 0 _ [ ∗ ] _ 99. 6 99. 1 97. 7 648 * * mixer ( ours ) * * * * 97. 8 * * * * 99. 5 * * * * 99. 7 * * 99. 7 * * 99. 2 * * 600 _ table 2. _ accuracy comparison with literature methods. approaches with a _ † _ symbol were sourced from ( scabini et al., 2020 ), and those with symbol _ [ i ] _ indicate an integrative approach. the results with the symbol _ ∗ _ were calculated. the remaining approaches ’ results were obtained from their original papers. acc refers to the average accuracy among the benchmark datasets. calvetti, d., morigi, s., reichel, l., and sgallari, f. tikhonov regularization and the l - curve for large discrete ill - posed problems. _ journal of computational and _ _ applied mathematics _, 123 ( 1 - 2 ) : 423 – 446, 2000. chen, z., li, f., quan, y., xu, y., and ji, h. deep texture recognition via exploiting cross - layer statistical selfsimilarity. in _ proceedings of the ieee / cvf conference _ _ on computer vision and pattern recognition _, pp. 5231 – 5240, 2021. chen, z., quan, y., xu, r., jin, l., and xu, y. enhancing texture representation with deep tracing pattern encoding. _ pattern recognition _, 146 : 109959, 2024. cimpoi, m., maji, s., and vedaldi, a. deep filter banks for texture recognition and segmentation. in _ proceedings of _ _ the ieee conference on computer vision and pattern _ _ recognition _, pp. 3828 – 3836, 2015. csurka, g., dance, c., fan, l., willamowski, j., and bray, c. visual categorization with bags of keypoints. in _ workshop on statistical learning in computer vision, _ _ eccv _, volume 1, pp. 1 – 2. prague, 2004. dana, k. j., van ginneken, b., nayar, s. k., and koenderink, j. j. reflectance and texture of real - world surfaces. _ acm transactions on graphics ( tog ) _, 18 ( 1 ) : 1 – 34, 1999. daugman, j. g. uncertainty relation for resolution in space, spatial frequency, and orientation optimized by two - dimensional visual cortical filters. _ journal of the _ _ optical society of america a _, 2 ( 7 ) : 1160 – 1169, 1985. fares, r. t. and ribas, l. c. a new approach to learn spatiospectral texture representation with randomized networks : application to brazilian plant species identification. in _ international conference on engineering applications of _ _ neural networks _, pp. 435 – 449. springer, 2024. fares, r. t. and ribas, l. c. volumetric color - texture representation for colorectal polyp classification in histopathology images. in _ 20th international conference on com - _ _ puter vision theory and applications _, pp. 210 – 221, 2025. florindo, j. b. and laureano, e. e. boff : a bag of fuzzy deep features for texture recognition. _ expert systems with _ _ applications _, 219 : 119627, 2023. fujiwara, k. and hashimoto, t. neural implicit embedding for point cloud analysis. in _ proceedings of the ieee / cvf _ _ conference on computer vision and pattern recognition _, pp. 11734 – 11743, 2020. guo, z., zhang, l., and zhang, d. a completed modeling of local binary pattern operator for texture classification. _ ieee transactions on image processing _, 19 ( 6 ) : 1657 – 1663, 2010. haralick, r. m., shanmugam, k., and dinstein, i. textural features for image classification. _ ieee transactions _ _ on systems, man, and cybernetics _, smc"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 23,
    "text": ". 210 – 221, 2025. florindo, j. b. and laureano, e. e. boff : a bag of fuzzy deep features for texture recognition. _ expert systems with _ _ applications _, 219 : 119627, 2023. fujiwara, k. and hashimoto, t. neural implicit embedding for point cloud analysis. in _ proceedings of the ieee / cvf _ _ conference on computer vision and pattern recognition _, pp. 11734 – 11743, 2020. guo, z., zhang, l., and zhang, d. a completed modeling of local binary pattern operator for texture classification. _ ieee transactions on image processing _, 19 ( 6 ) : 1657 – 1663, 2010. haralick, r. m., shanmugam, k., and dinstein, i. textural features for image classification. _ ieee transactions _ _ on systems, man, and cybernetics _, smc - 3 ( 6 ) : 610 – 621, 1973. huang, g. - b., zhu, q. - y., and siew, c. - k. extreme learning machine : theory and applications. _ neurocomputing _, 70 ( 1 - 3 ) : 489 – 501, 2006. jain, a. and healey, g. a multiscale representation including opponent color features for texture recognition. _ ieee _ _ transactions on image processing _, 7 ( 1 ) : 124 – 128, 1998. joanes, d. n. and gill, c. a. comparing measures of sample skewness and kurtosis. _ journal of the royal statisti - _ _ cal society : series d ( the statistician ) _, 47 ( 1 ) : 183 – 189, 1998. jones, j. p. and palmer, l. a. an evaluation of the twodimensional gabor filter model of simple receptive fields in cat striate cortex. _ journal of neurophysiology _, 58 ( 6 ) : 1233 – 1258, 1987. julesz, b. textons, the elements of texture perception, and their interactions. _ nature _, 290 ( 5802 ) : 91 – 97, 1981. junior, j. j. d. m. s. and backes, a. r. elm based signature for texture classification. _ pattern recognition _, 51 : 395 – 401, 2016. 13 * * mixer : mixed hyperspherical random embedding neural network for texture recognition * * junior, j. j. d. m. s., backes, a. r., and bruno, o. m. randomized neural network based descriptors for shape classification. _ neurocomputing _, 312 : 201 – 209, 2018. leung, t. and malik, j. representing and recognizing the visual appearance of materials using three - dimensional textons. _ international journal of computer vision _, 43 ( 1 ) : 29 – 44, 2001. liu, l., chen, j., fieguth, p., zhao, g., chellappa, r., and pietikainen, m. from bow to cnn : two decades of texture [UNK] representation for texture classification. _ international _ _ journal of computer vision _, 127 ( 1 ) : 74 – 109, 2019. manjunath, b. and ma, w. texture features for browsing and retrieval of image data. _ ieee transactions on pattern _ _ analysis and machine intelligence _, 18 ( 8 ) : 837 – 842, 1996. oiticica, p. r., angelim, m. k., soares, j. c., soares, a. c., proen [UNK] a - modena, j. l., bruno, o. m., and oliveira jr, [UNK] o. n. using machine learning and optical microscopy image analysis of immunosensors made on plasmonic substrates : application to detect the sars - cov - 2 virus. _ acs sensors _, 10 ( 2 ) : 1407 – 1418, 2025. ojala, t., pietikainen, m., and harwood, d. a comparative [UNK] study of texture measures with classification based on featured distributions. _ pattern recognition _, 29 ( 1 ) : 51 – 59, 1996. ojala, t., maenpaa, t., pietikainen, m., viertola, j., kyllonen, j., and huovinen, s. outex - new framework for empirical evaluation of texture analysis algorithms. in _ in - _ _ ternational conference on pattern recognition _, volume 1, pp. 701 – 706. ieee, 2002a. ojala, t., pietikainen, m., and maenpaa, t. multiresolution gray -"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 24,
    "text": "of immunosensors made on plasmonic substrates : application to detect the sars - cov - 2 virus. _ acs sensors _, 10 ( 2 ) : 1407 – 1418, 2025. ojala, t., pietikainen, m., and harwood, d. a comparative [UNK] study of texture measures with classification based on featured distributions. _ pattern recognition _, 29 ( 1 ) : 51 – 59, 1996. ojala, t., maenpaa, t., pietikainen, m., viertola, j., kyllonen, j., and huovinen, s. outex - new framework for empirical evaluation of texture analysis algorithms. in _ in - _ _ ternational conference on pattern recognition _, volume 1, pp. 701 – 706. ieee, 2002a. ojala, t., pietikainen, m., and maenpaa, t. multiresolution gray - scale and rotation invariant texture classification with local binary patterns. _ ieee transactions on pat - _ _ tern analysis and machine intelligence _, 24 ( 7 ) : 971 – 987, 2002b. ojansivu, v. and heikkila, j. blur insensitive texture classi - [UNK] fication using local phase quantization. in _ international _ _ conference on image and signal processing _, pp. 236 – 243. springer, 2008. pao, y. - h. and takefuji, y. functional - link net computing : theory, system architecture, and functionalities. _ com - _ _ puter _, 25 ( 5 ) : 76 – 79, 1992. doi : 10. 1109 / 2. 144401. pao, y. - h., park, g. - h., and sobajic, d. j. learning and generalization characteristics of the random vector functional link net. _ neurocomputing _, 6 ( 2 ) : 163 – 180, 1994. penrose, r. a generalized inverse for matrices. _ mathemati - _ _ cal proceedings of the cambridge philosophical society _, 51 ( 3 ) : 406 – 413, 1955. ribas, l. c. and bruno, o. m. learning a complex network representation for shape classification. _ pattern recogni - _ _ tion _, 154 : 110566, 2024. ribas, l. c., junior, j. j. d. m. s., scabini, l. f., and bruno, o. m. fusion of complex networks and randomized neural networks for texture analysis. _ pattern recognition _, 103 : 107189, 2020. ribas, l. c., scabini, l. f., condori, r. h., and bruno, o. m. color - texture classification based on spatio - spectral complex network representations. _ physica a : statistical me - _ _ chanics and its applications _, 635 : 129518, 2024. scabini, l., zielinski, k. m., ribas, l. c., gon [UNK] alves, w. n., de baets, b., and bruno, o. m. radam : texture recognition through randomized aggregated encoding of deep activation maps. _ pattern recognition _, 143 : 109802, 2023. scabini, l. f., condori, r. h., gon [UNK] alves, w. n., and bruno, o. m. multilayer complex network descriptors for color – texture characterization. _ information sciences _, 491 : 30 – 47, 2019. scabini, l. f., ribas, l. c., and bruno, o. m. spatiospectral networks for color - texture analysis. _ information _ _ sciences _, 515 : 64 – 79, 2020. schmidt, w. f., kraaijveld, m. a., duin, r. p., et al. feed forward neural networks with random weights. in _ in - _ _ ternational conference on pattern recognition _, pp. 1 – 4. ieee computer society press, 1992. sharan, l., liu, c., rosenholtz, r., and adelson, e. h. recognizing materials using perceptually inspired features. _ international journal of computer vision _, 103 ( 3 ) : 348 – 371, 2013. su, z., zhang, j., wang, l., zhang, h., liu, z., pietikainen, [UNK] m., and liu, l. lightweight pixel difference networks for efficient visual representation learning. _ ieee trans - _ _ actions on pattern analysis and machine intelligence _, 45 ( 12 ) :"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 25,
    "text": "_ sciences _, 515 : 64 – 79, 2020. schmidt, w. f., kraaijveld, m. a., duin, r. p., et al. feed forward neural networks with random weights. in _ in - _ _ ternational conference on pattern recognition _, pp. 1 – 4. ieee computer society press, 1992. sharan, l., liu, c., rosenholtz, r., and adelson, e. h. recognizing materials using perceptually inspired features. _ international journal of computer vision _, 103 ( 3 ) : 348 – 371, 2013. su, z., zhang, j., wang, l., zhang, h., liu, z., pietikainen, [UNK] m., and liu, l. lightweight pixel difference networks for efficient visual representation learning. _ ieee trans - _ _ actions on pattern analysis and machine intelligence _, 45 ( 12 ) : 14956 – 14974, 2023. wang, t. and isola, p. understanding contrastive representation learning through alignment and uniformity on the hypersphere. in _ international conference on machine _ _ learning _, pp. 9929 – 9939. pmlr, 2020. xue, j., zhang, h., and dana, k. deep texture manifold for ground terrain recognition. in _ proceedings of the ieee _ _ conference on computer vision and pattern recognition _, pp. 558 – 567, 2018. zhai, w., cao, y., zha, z. - j., xie, h., and wu, f. deep structure - revealed network for texture recognition. in _ proceedings of the ieee / cvf conference on computer _ _ vision and pattern recognition _, pp. 11010 – 11019, 2020. 14 * * mixer : mixed hyperspherical random embedding neural network for texture recognition * * zhang, h., xue, j., and dana, k. deep ten : texture encoding network. in _ proceedings of the ieee conference on _ _ computer vision and pattern recognition _, pp. 708 – 717, 2017. zhang, j., zhang, h., vasudevan, r., and johnson - roberson, m. hyperspherical embedding for point cloud completion. in _ proceedings of the ieee / cvf conference on com - _ _ puter vision and pattern recognition _, pp. 5323 – 5332, 2023. 15 * * supplementary material for mixer : mixed hyperspherical random embedding neural network for texture recognition * * * * a. local pattern extractor module * * in this section, we explore in greater depth some nuances of the proposed local pattern extractor ( lpe ) module, whose responsibility is to extract the local intensity patterns present in each input image channel, and subsequently use this valuable information as input to the remaining of the network. * * padding * *. to begin with, as expressed in the main text, this process starts by centralizing _ j × j _ patches at every pixel position for a given channel of dimensions _ h × w _ of the input image. nevertheless, as can be observed if no action were taken in relation to the channel ’ s original dimensions, it would not be possible to center the patches next to or at the image margin. in this regard, to enable us to centralize the patches at every pixel position of the image channel, a padding process is performed. thus, if the patch side is _ j _, being _ j _ an odd number, then a padding size of _ [ j ] [ − ] _ 2 [ 1 ] is applied at every channel side. this process is depicted in figure a. 1. as a result, after the padding process the original image channel dimensions _ h × w _ change to ( _ h _ + _ j − _ 1 ) _ × _ ( _ w _ + _ j − _ 1 ). _ figure a. 1. _ illustration of the padding process of an arbitrary matrix. in this present study, this arbitrary matrix stores the pixel intensity values of an image channel. particularly, the padding is performed employing the replication mode, where the channel ’ s edge values are replicated. this process of replication is depicted in figure a. 2. furthermore, as expected, since in the concrete image example _ h _ = _ w _ = 3, and the patch side size is _ j _ = 3, the dimension after the padding process is ( _ h _ + _ j − _ 1 ) = ( 3 + 3 _ − _ 1 ) = 5 ( which is equal for the width dimension ), matching the dimensions of the matrix of the right side of figure a. 2. therefore, mathematically, the exhibited process in figure a. 2 clearly represents the input and output of"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 26,
    "text": "_ j − _ 1 ) _ × _ ( _ w _ + _ j − _ 1 ). _ figure a. 1. _ illustration of the padding process of an arbitrary matrix. in this present study, this arbitrary matrix stores the pixel intensity values of an image channel. particularly, the padding is performed employing the replication mode, where the channel ’ s edge values are replicated. this process of replication is depicted in figure a. 2. furthermore, as expected, since in the concrete image example _ h _ = _ w _ = 3, and the patch side size is _ j _ = 3, the dimension after the padding process is ( _ h _ + _ j − _ 1 ) = ( 3 + 3 _ − _ 1 ) = 5 ( which is equal for the width dimension ), matching the dimensions of the matrix of the right side of figure a. 2. therefore, mathematically, the exhibited process in figure a. 2 clearly represents the input and output of the function pad _ j _ : r _ [ c ] [ × ] [ h ] [ × ] [ w ] _ _ → _ r _ [ c ] [ × ] _ [ ( ] _ [ h ] _ [ + ] _ [ j ] [ − ] _ [ 1 ) ] _ [ × ] _ [ ( ] _ [ w ] _ [ + ] _ [ j ] [ − ] _ [ 1 ) ] _. _ ( a. 1 ) in the presented case, the input image dimension is * * i * * _ ∈ _ r [ 1 ] _ [ × ] _ [ 3 ] _ [ × ] _ [ 3 ], and the output padded image dimension is | col1 | col2 | col3 | | - - - | - - - | - - - | | | | | | | | | _ figure a. 2. _ concrete example of the padding process using the replication mode of a 3 _ × _ 3 image, and assuming a patch side size of _ j _ = 3. after the padding the dimension is 5 _ × _ 5. pad _ j _ ( * * i * * ) _ ∈ _ r [ 1 ] _ [ × ] _ [ 5 ] _ [ × ] _ [ 5 ]. thus, it should be noted that in the exemplified process the image consists of only one channel. however, for an arbitrary channel - sized image, this process is performed for each channel independently. finally, for more information on the replication mode we refer the reader to the pytorch v2. 6. 0 official documentation [ 2 ]. * * patch - based extraction * *. after the image padding, multiple _ j × j _ patches are centered at every pixel of the padded image pad _ j _ ( * * i * * ), which corresponds to all pixels of the original image * * i * *. this is mathematically expressed by : lpe ( pad _ j _ ( * * i * * ) ) _ ∈ _ r _ [ c ] [ × ] [ h ] [ × ] [ w ] [ × ] [ j ] [ × ] [ j ] _ _. _ ( a. 2 ) as expressed in the main text, this 5 - dimensional output tensor stores all of these _ j × j _ patches centered at every position for each image channel. in this sense, with the intent to provide a concrete example of this process. let * * i * * be the same image as the concrete example represented in figure a. 2, and let _ j _ = 3. hence, the figure a. 3 shows the all nine possible patches of size 3 _ × _ 3. each of these patches represents the content of the last two dimensions of the 5 - dimensional tensor. nevertheless, one may visualize the overall figure as a matrix of matrices, which represents the last four dimensions of that tensor. therefore, it can be clearly visualized how the lpe module captures the essential information of the raw pixels intensities information present in the input image. * * b. hyperspherical random projector module * * * * reshaping * *. we show with a concrete example the result of the reshaping process of the output of the previous module. let the content in figure a. 3 be the 5 - dimensional tensor * * l * * _ ∈ _ r [ 1 ] _ [ × ] _ [ 3 ] _ [ × ] _ [ 3 ] _ [ × ] _ [ 3 ] _ [ × ] _ [ 3 ] containing the extracted 3 _ × _ 3 patches centered in every pixel of the image ’ s spatial dimension. note that the unitary dimension refers to the number of channels. for the sake of clarity, although our concrete example deals 2 https : / / docs. pytorch. org / docs / 2. 6 / generated / torch. nn. functional. pad. html 16 *"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 27,
    "text": "the lpe module captures the essential information of the raw pixels intensities information present in the input image. * * b. hyperspherical random projector module * * * * reshaping * *. we show with a concrete example the result of the reshaping process of the output of the previous module. let the content in figure a. 3 be the 5 - dimensional tensor * * l * * _ ∈ _ r [ 1 ] _ [ × ] _ [ 3 ] _ [ × ] _ [ 3 ] _ [ × ] _ [ 3 ] _ [ × ] _ [ 3 ] containing the extracted 3 _ × _ 3 patches centered in every pixel of the image ’ s spatial dimension. note that the unitary dimension refers to the number of channels. for the sake of clarity, although our concrete example deals 2 https : / / docs. pytorch. org / docs / 2. 6 / generated / torch. nn. functional. pad. html 16 * * supplementary material for mixer : mixed hyperspherical random embedding neural network for texture recognition * * ( 0, 0 ) ( 0, 1 ) ( 0, 2 ) ( 1, 0 ) ( 1, 1 ) ( 1, 2 ) ( 2, 0 ) ( 2, 1 ) ( 2, 2 ) _ figure a. 3. _ concrete example of the information captured by the output of the lpe module represented by lpe ( pad ( * * i * * ) ). each of the matrix represents a 3 _ × _ 3 patch obtained by centering it at the blue colored pixel, while also represents the content of the last two dimensions of the tensor. in addition, the overall figure can be seen as a matrix of matrices, representing the last four dimensions. with only one channel, this is done for each channel independently. thus, the matrix * * x * * = reshape ( * * l * * ) _ ∈ _ r _ [ c ] [ × ] [ j ] _ [ 2 ] _ [ × ] [ hw ] _ resulting from the reshaping process of the 5 - dimensional tensor * * l * * is illustrated in figure b. 4. from this matrix, it can be observed that the intensities of each patch are along the column of the matrix * * x * *, while the rows refers to the intensities of a specific position inside each patch. it shall be noted that although most of the pixels are padding pixels, those colored in red, this is attributed to the fact that our initial image has a spatial dimension of 3 _ × _ 3. in general, for larger texture images such 128 _ × _ 128 most of the columns would be similar to the fifth column, i. e., without any padding pixels. to conclude, this matrix is used in the remaining of the random projector module. * * random weight matrix generation * *. in this part, it is presented how the random weight matrix used in the process of projecting the input data into another dimensional space is built. although in our proposed approach we need a set of these random weight matrices, i. e., one for each image channel, which would correspond to a 3 - dimensional tensor, we will present the steps and an algorithm for generating a _ figure b. 4. _ concrete example of the matrix * * x * * = reshape ( * * l * * ) _ ∈ _ r [ 1 ] _ [ × ] _ [ 9 ] _ [ × ] _ [ 9 ] obtained after the reshaping process of the 5 - dimensional tensor * * l * * _ ∈ _ r [ 1 ] _ [ × ] _ [ 3 ] _ [ × ] _ [ 3 ] _ [ × ] _ [ 3 ] _ [ × ] _ [ 3 ] represented in figure a. 3. random _ n _ - dimensional tensor * * t * * _ ∈ _ r _ [ n ] _ [ 1 ] _ [ × ] [ n ] _ [ 2 ] _ [ × · · · × ] [ n ] _ _ [ n ] _. let * * v * * _ ∈ _ r _ [ l ] _, where _ l _ = [ ] _ [ n ] _ _ i _ = 1 _ [ n ] _ _ [ i ] _ [, with ] _ [ n ] _ _ [ i ] _ [ being the size ] of the _ i _ - th dimension of * * t * *. this vector will be filled using the same procedure and configuration as in junior & backes ( 2016 ). in particular, the authors used a linear congruential generator ( lcg ) for generating pseudorandom numbers. specifically, utilizing this approach, the elements of the vector * * v * * satisfies the following recurrence relation : * * v * * _ k _ + 1 : = ( _ a _ * * v * * _ k _ + _ b _"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 28,
    "text": "1 ] _ [ × ] [ n ] _ [ 2 ] _ [ × · · · × ] [ n ] _ _ [ n ] _. let * * v * * _ ∈ _ r _ [ l ] _, where _ l _ = [ ] _ [ n ] _ _ i _ = 1 _ [ n ] _ _ [ i ] _ [, with ] _ [ n ] _ _ [ i ] _ [ being the size ] of the _ i _ - th dimension of * * t * *. this vector will be filled using the same procedure and configuration as in junior & backes ( 2016 ). in particular, the authors used a linear congruential generator ( lcg ) for generating pseudorandom numbers. specifically, utilizing this approach, the elements of the vector * * v * * satisfies the following recurrence relation : * * v * * _ k _ + 1 : = ( _ a _ * * v * * _ k _ + _ b _ ) mod _ c, _ _ k ∈ { _ 0 _, _ 1 _,..., l− _ 2 _ } _ ( b. 3 ) where the parameters are initialized as * * v * * 0 = _ l _ + 1 _, a _ = _ l _ + 2 _, b _ = _ l _ + 3, and _ c _ = _ l _ [ 2 ] following junior & backes ( 2016 ). after filling the entire vector, a standardization process is applied upon * * v * *, i. e., * * v * * _ k _ = * * [ v ] * * _ [ k ] _ _ [ − ] _ ~ ~ * * [ v ] * * ~ ~ _, _ _ k ∈ { _ 0 _, _ 1 _,..., l − _ 1 _ } _ ( b. 4 ) _ s _ * * v * * where ~ ~ * * v * * ~ ~ = _ l _ 1 _ lk _ = 0 _ − _ 1 * * [ v ] * * _ [ k ] _ [, is the sample mean of ] * * [ v ] * * [, and ] 1 _ l− _ 1 _ s _ [ 2 ] * * v * * [ = ] _ l− _ 1 _ k _ = 0 [ ( ] * * [ v ] * * _ [ k ] _ _ [ − ] _ ~ ~ * * [ v ] * * ~ ~ [ ) ] [ 2 ] [ is the sample variance of ] * * [ v ] * * [. ] in this context, to obtain the tensor * * t * *, the vector * * v * * is reshaped to present _ n _ dimensions, where the _ i _ - th dimension has _ n _ _ i _ elements. following, we present in algorithm 1 a pytorch - like pseudocode for the previous taken steps. in this context, if we let lcg ( _ n _ 1 _, n _ 2 _,..., n _ _ n _ ) be the _ n _ dimensional tensor representing the output of the pseudocode, then for any input texture image * * i * * _ ∈ _ r _ [ c ] [ × ] [ h ] [ × ] [ w ] _, the random weight matrices used in the random projector module is given by lcg ( _ c, ω, j _ [ 2 ] + 1 ) _ ∈ _ r _ [ c ] [ × ] [ ω ] [ × ] _ [ ( ] _ [ j ] _ [ 2 ] [ + 1 ) ]. 17 * * supplementary material for mixer : mixed hyperspherical random embedding neural network for texture recognition * * * * algorithm 1 * * random weight matrix generator * * input : * * each dimension size _ n _ 1 _, n _ 2 _,..., n _ _ n _ * * output : * * random tensor * * t * * _ ∈ _ r _ [ n ] _ [ 1 ] _ [ × ] [ n ] _ [ 2 ] _ [ × · · · × ] [ n ] _ _ [ n ] _ * * v * * _ ← _ torch. zeros ( [ ] _ [ n ] _ _ i _ = 1 _ [ n ] _ _ [ i ] _ [ ) ] * * v * * 0 _ ← _ _ l _ + 1 _ a ← _ _ l _ + 2 _ b ← _ _ l _ + 3 _ c ← _ _ l _ [ 2 ] * * for * * _ k ← _ 0 * * to * * _ l − _ 2 * * do * * * * v * * _ k _ + 1 _ ← _ ( _ a _ * * v * * _ k _ + _ b _ ) mod _ c _ * * end"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 29,
    "text": "n _ _ n _ * * output : * * random tensor * * t * * _ ∈ _ r _ [ n ] _ [ 1 ] _ [ × ] [ n ] _ [ 2 ] _ [ × · · · × ] [ n ] _ _ [ n ] _ * * v * * _ ← _ torch. zeros ( [ ] _ [ n ] _ _ i _ = 1 _ [ n ] _ _ [ i ] _ [ ) ] * * v * * 0 _ ← _ _ l _ + 1 _ a ← _ _ l _ + 2 _ b ← _ _ l _ + 3 _ c ← _ _ l _ [ 2 ] * * for * * _ k ← _ 0 * * to * * _ l − _ 2 * * do * * * * v * * _ k _ + 1 _ ← _ ( _ a _ * * v * * _ k _ + _ b _ ) mod _ c _ * * end for * * * * v * * _ ← _ ( * * v * * _ − _ torch. mean ( * * v * * ) ) _ / _ torch. std ( * * v * * ) * * return * * torch. reshape ( * * v * * _, _ ( _ n _ 1 _, n _ 2 _,..., n _ _ n _ ) ) * * c. compression module * * in this section, we present the set _ h _ of compression functions used to summarize the weights of the learned decoders to assemble the texture representation. specifically, this set consists mostly of statistical measure functions _ h _ 1 _, h _ 2 _,..., h _ _ | h | _ used to compress the column vectors of the resulting matrix * * f * * _ ∈ _ r _ [ | s | ] [ j ] _ [ 2 ] _ [ × ] [ hw ] _ from the vertical concatenation of the learned decoders ’ weights present in the set _ s _ = _ s _ _ d _ _ ∪s _ _ m _, where _ s _ _ d _ and _ s _ _ m _ are the sets containing the learned decoders ’ s weights from the d irect and m ixed branches, respectively. _ figure c. 5. _ illustration of a compression function _ h _ : _ a ⊂ _ r _ [ n ] _ _ → _ r. the compression function is responsible for compressing ( or summarizing ) a _ n _ - dimensional real vector * * x * * _ ∈ _ _ a _ in a real number _ h _ ( * * x * * ). the complete definition is presented in the main text. in this context, as presented in the main text, four statistical measures are employed : mean, standard deviation, skewness, and excess kurtosis. the mean gives a central tendency of the sample, while the standard deviation is a dispersion measure. following this, the skewness and kurtosis are measures about the shape of the distribution. in this sense, these measures complement each other, and are used to create a more robust texture representation. next, their formulas are presented. let _ m _ _ r _ ( * * x * * ) be the _ n _ - th sample central moment, which following ( joanes & gill, 1998 ), is defined by : _ m _ _ r _ ( * * x * * ) : = [ 1 ] _ n _ _ n _ ( _ x _ _ k _ _ − _ ~ ~ * * x * * ~ ~ ) _ [ r ] _ _, _ ( c. 5 ) _ k _ = 1 1 _ n _ where ~ ~ * * x * * ~ ~ = _ n _ _ k _ = 1 _ [ x ] _ _ [ k ] _ [ is the sample mean of the ] _ [ n ] _ [ - ] dimensional real vector * * x * *. thus, the utilized statistical measures ’ formulas are given by : _ h _ _ [UNK] _ ( * * x * * ) : = ~ ~ * * x * * ~ ~ ( c. 6 ) _ h _ _ σ _ ( * * x * * ) : = ( _ m _ 2 ( * * x * * ) ) [ 1 ] _ [ / ] _ [ 2 ] ( c. 7 ) _ m _ 3 ( * * x * * ) _ h _ _ γ _ ( * * x * * ) : = ( c. 8 ) ( _ m _ 2 ( * * x * * ) ) [ 3 ] _ [ / ] _ [ 2 ] _ m _ 4 ( * * x * * ) _ h _ _ κ _ ( * * x * * ) : = ( _ m _ 2 ( * * x * * ) ) [ 2 ] _ [ − ] _ [ 3 ]"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03228v1",
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "authors": [
        "Ricardo T. Fares",
        "Lucas C. Ribas"
      ],
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "published": "2025-10-03T17:58:04Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03228v1"
    },
    "chunk_id": 30,
    "text": "] dimensional real vector * * x * *. thus, the utilized statistical measures ’ formulas are given by : _ h _ _ [UNK] _ ( * * x * * ) : = ~ ~ * * x * * ~ ~ ( c. 6 ) _ h _ _ σ _ ( * * x * * ) : = ( _ m _ 2 ( * * x * * ) ) [ 1 ] _ [ / ] _ [ 2 ] ( c. 7 ) _ m _ 3 ( * * x * * ) _ h _ _ γ _ ( * * x * * ) : = ( c. 8 ) ( _ m _ 2 ( * * x * * ) ) [ 3 ] _ [ / ] _ [ 2 ] _ m _ 4 ( * * x * * ) _ h _ _ κ _ ( * * x * * ) : = ( _ m _ 2 ( * * x * * ) ) [ 2 ] _ [ − ] _ [ 3 ] ( c. 9 ) it can be noted that the utilized statistical measures formulas of standard deviation and kurtosis are not unbiased esti mators. nevertheless, it is not necessary to have the most accurate estimator, the objective here is solely a mechanism to compress ( summarize ) an information present in a real vector to a real number. 18"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 0,
    "text": "# * * a fast non - reversible sampler for bayesian * * * * finite mixture models * * # # # # filippo ascolani [ ∗ ] and giacomo zanella [ † ] october 6, 2025 * * abstract * * finite mixtures are a cornerstone of bayesian modelling, and it is well - known that sampling from the resulting posterior distribution can be a hard task. in particular, popular reversible markov chain monte carlo schemes are often slow to converge when the number of observations _ n _ is large. in this paper we introduce a novel and simple non - reversible sampling scheme for bayesian finite mixture models, which is shown to drastically outperform classical samplers in many scenarios of interest, especially during convergence phase and when components in the mixture have non - negligible overlap. at the theoretical level, we show that the performance of the proposed non - reversible scheme cannot be worse than the standard one, in terms of asymptotic variance, by more than a factor of four ; and we provide a scaling limit analysis suggesting that the non - reversible sampler can reduce the convergence time from _ o _ ( _ n _ [ 2 ] ) to _ o _ ( _ n _ ). we also discuss why the statistical features of mixture models make them an ideal case for the use of non - reversible discrete samplers. ∗ duke university, department of statistical science, durham, nc, united states ( filippo. ascolani @ duke. edu ) - bocconi university, department of decision sciences and bidsa, milan, italy ( giacomo. zanella @ unibocconi. it ) gz acknowledges support from the european research council ( erc ), through stg “ prsc - hdbayle ” grant id 101076564. # # # * * 1 introduction * * # # # # * * 1. 1 bayesian finite mixture models * * let _ k ∈ _ n and consider a finite mixture model ( marin et al., 2005 ; [UNK], 2006 ; mclachlan et al., 2019 ) defined as _ y _ _ i _ _ | _ _ * * θ * * _ _, _ _ * * w * * _ [ i. i. d. ] _ ∼ _ _ k _ _ w _ _ k _ _ f _ _ θ _ _ k _ ( _ · _ ) _ i _ = 1 _,..., n _ _ k _ = 1 ( 1 ) i. i. d. _ θ _ _ k _ _ ∼ _ _ p _ 0 _ k _ = 1 _,..., k _ _ * * w * * _ _ ∼ _ dir ( _ * * α * * _ ) _, _ where _ * * θ * * _ = ( _ θ _ 1 _,..., θ _ _ k _ ), _ * * w * * _ = ( _ w _ 1 _,..., w _ _ k _ ), _ * * α * * _ = ( _ α _ 1 _,..., α _ _ k _ ) and dir ( _ * * α * * _ ) denotes the dirichlet distribution on the ( _ k _ _ − _ 1 ) - dimensional simplex ∆ _ k− _ 1 _ ⊂ _ r _ [ k ] _ with parameters _ * * α * * _. here _ f _ _ θ _ is a probability density on a space _ y _ depending on a parameter _ θ ∈ _ θ _ ⊂ _ r _ [ d ] _, to which a prior distribution with density _ p _ 0 is assigned. for example, one could have _ y _ = θ = r _ [ d ] _ and _ f _ _ θ _ ( _ y _ ) = _ n _ ( _ y | θ, _ σ ) for some fixed σ, where _ n _ ( _ y | θ, _ σ ) denotes the density of the multivariate normal with mean vector _ θ _ and covariance matrix σ at a point _ y _. a popular strategy to perform posterior computations with model ( 1 ) ( also for maximum likelihood estimation, as originally noted in dempster et al. ( 1977 ) ) consists in augmenting the model as follows i. i. d. ( 2 ) _ y _ _ i _ _ | c, _ _ * * θ * * _ _, _ _ * * w * * _ [ i. i. d. ] _ ∼ _ _ f _ _ θ _ _ ci _ ( _ y _ ) _, _ _ c _ _ i _ _ | _ _ * * θ * * _ _, _ _ * * w * * _ [ i. i. d. ] _ ∼ _ cat ( _ * * w * * _ ) _, _ _ * * w * * _ _ ∼ _ dir ( _ * * α * * _"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 1,
    "text": "denotes the density of the multivariate normal with mean vector _ θ _ and covariance matrix σ at a point _ y _. a popular strategy to perform posterior computations with model ( 1 ) ( also for maximum likelihood estimation, as originally noted in dempster et al. ( 1977 ) ) consists in augmenting the model as follows i. i. d. ( 2 ) _ y _ _ i _ _ | c, _ _ * * θ * * _ _, _ _ * * w * * _ [ i. i. d. ] _ ∼ _ _ f _ _ θ _ _ ci _ ( _ y _ ) _, _ _ c _ _ i _ _ | _ _ * * θ * * _ _, _ _ * * w * * _ [ i. i. d. ] _ ∼ _ cat ( _ * * w * * _ ) _, _ _ * * w * * _ _ ∼ _ dir ( _ * * α * * _ ) _, _ _ θ _ _ k _ _ ∼ _ _ p _ 0 _, _ where _ c _ = ( _ c _ 1 _,..., c _ _ n _ ) _ ∈ _ [ _ k _ ] _ [ n ] _, with [ _ k _ ] = _ { _ 1 _,..., k } _, is the set of allocation variables and cat ( _ * * w * * _ ) denotes the categorical distribution with probability weights _ * * w * * _. given a sample _ y _ = ( _ y _ 1 _,..., y _ _ n _ ), the joint posterior distribution of ( _ c, _ _ * * θ * * _ _, _ _ * * w * * _ ) then reads dir ( _ * * w * * _ _ | _ _ * * α * * _ ) _ k _ _ p _ 0 ( _ θ _ _ k _ ) _ k _ = 1 _ n _ _ i _ = 1 _ k _ _ w _ _ [ n ] _ _ [ k ] _ [ ( ] _ [ c ] _ [ ) + ] _ [ α ] _ _ [ k ] _ _ [ − ] _ [ 1 ] _ k _ _ k _ = 1 _ k _ _ k _ = 1 _ w _ _ c _ _ i _ _ f _ _ θ _ _ ci _ ( _ y _ _ i _ ) _ i _ = 1 ( 3 ) _ π _ ( _ c, _ _ * * θ * * _ _, _ _ * * w * * _ ) _ ∝ _ _ ∝ _ _ k _ _ k _ = 1 _ f _ _ θ _ _ k _ ( _ y _ _ i _ ) _ p _ 0 ( _ θ _ _ k _ ) _, _ _ i _ : _ c _ _ i _ = _ k _ where _ n _ _ k _ ( _ c _ ) = [ ] _ [ n ] _ _ i _ = 1 [ 1 ] [ ( ] _ [ c ] _ _ [ i ] _ [ = ] _ [ k ] _ [ ) and ] [ 1 ] [ denotes the indicator function. in particular, it is ] possible to integrate out ( _ * * θ * * _ _, _ _ * * w * * _ ) from ( 3 ) to obtain the marginal posterior distribution of _ c _ given by _ k _ _ k _ = 1 _ f _ _ θ _ _ k _ ( _ y _ _ i _ ) _ p _ 0 ( _ θ _ _ k _ ) d _ θ _ _ k _ _, _ _ i _ : _ c _ _ i _ = _ k _ ( 4 ) _ π _ ( _ c _ ) _ ∝ _ _ k _ _ k _ = 1 γ ( _ α _ _ k _ + _ n _ _ k _ ( _ c _ ) ) _ k _ = 1 _ k _ = 1 θ 2 from which we deduce the so - called full - conditional distribution of _ c _ _ i _ ( 5 ) _ π _ ( _ c _ _ i _ = _ k | c _ _ −i _ ) _ ∝ _ [ _ α _ _ k _ + _ n _ _ k _ ( _ c _ _ −i _ ) ] _ p _ ( _ y _ _ i _ _ | y _ _ −i _ _, c _ _ −i _ _, c _ _ i _ = _ k _ ) _ k ∈ _ [ _ k _ ] where _ c _ _ −i _ = ( _ c _ 1 _,..., c _ _ i− _ 1 _, c _ _ i _ + 1 _,..., c _ _ n _ ), _ y _ _ −i _ = ( _ y _ 1 _,.."
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 2,
    "text": "_ c _ ) ) _ k _ = 1 _ k _ = 1 θ 2 from which we deduce the so - called full - conditional distribution of _ c _ _ i _ ( 5 ) _ π _ ( _ c _ _ i _ = _ k | c _ _ −i _ ) _ ∝ _ [ _ α _ _ k _ + _ n _ _ k _ ( _ c _ _ −i _ ) ] _ p _ ( _ y _ _ i _ _ | y _ _ −i _ _, c _ _ −i _ _, c _ _ i _ = _ k _ ) _ k ∈ _ [ _ k _ ] where _ c _ _ −i _ = ( _ c _ 1 _,..., c _ _ i− _ 1 _, c _ _ i _ + 1 _,..., c _ _ n _ ), _ y _ _ −i _ = ( _ y _ 1 _,..., y _ _ i− _ 1 _, y _ _ i _ + 1 _,..., y _ _ n _ ) and _ _ _ _ _ _ _ _ _ p _ ( _ y _ _ i _ _ | y _ _ −i _ _, c _ _ −i _ _, c _ _ i _ = _ k _ ) = _ f _ _ θ _ ( _ y _ _ i _ ) θ _ _ _ _ _ j _ = _ _ _ i _ : _ c _ _ j _ = _ k _ _ [ f ] _ _ [ θ ] _ [ ( ] _ [ y ] _ _ [ j ] _ [ ) ] _ [ p ] _ [ 0 ] [ ( ] _ [ θ ] _ [ ) ] [ d ] _ [ θ ] _ ~ ~ ~ ~ θ ~ ~ ~ ~ _ j _ = _ _ _ i _ : _ c _ _ j _ = _ k _ _ [ f ] _ _ [ θ ] _ _ [ ′ ] _ [ ( ] _ [ y ] _ _ [ j ] _ [ ) ] _ [ p ] _ [ 0 ] [ ( ] _ [ θ ] _ _ [ ′ ] _ [ ) d ] _ [ θ ] _ _ [ ′ ] _ _ _ _ _ _ _ is the predictive distribution of observation _ y _ _ i _ given _ y _ _ −i _ and the allocation variables. if _ p _ 0 is conjugate with respect to the density _ f _ _ θ _, then _ p _ ( _ y _ _ i _ _ | y _ _ −i _ _, c _ _ −i _ _, c _ _ i _ = _ k _ ) and thus _ π _ ( _ c _ _ i _ = _ k | c _ _ −i _ ) are available in closed form. for example, if _ f _ _ θ _ ( _ y _ ) = _ n _ ( _ y | θ, _ σ ) and _ p _ 0 ( _ θ _ ) = _ n _ ( _ θ | θ _ 0 _, _ σ 0 ) it holds that _ p _ ( _ y _ _ i _ _ | y _ _ −i _ _, c _ _ −i _ _, c _ _ i _ = _ k _ ) = _ n _ ( _ y _ _ i _ _ | _ [UNK] _ [UNK], _ σ ), where [ [UNK] ] [UNK] [UNK] = σ + σ _ [ − ] _ 0 [ 1 ] + _ n _ _ k _ ( _ c _ _ −i _ ) σ _ [ − ] _ [ 1 ] [ ] _ [ − ] _ [ 1 ] _, _ _ [UNK] _ = σ _ [ − ] _ 0 [ 1 ] + _ n _ _ k _ ( _ c _ _ −i _ ) σ _ [ − ] _ [ 1 ] [ ] _ [ − ] _ [ 1 ] [ ] σ _ [ − ] _ 0 [ 1 ] _ [ θ ] _ [ 0 ] [ + ] _ [ n ] _ _ [ k ] _ [ ( ] _ [ c ] _ _ [ − ] [ i ] _ [ ) σ ] _ [ − ] _ [ 1 ] [ [UNK] ] _ [ y ] _ _ [ k, ] [ − ] [ i ] _ and _ y _ [ [UNK] ] _ k, −i _ = _ n _ _ [ − ] _ _ k _ [ 1 ] [ ( ] _ [ c ] _ _ [ − ] [ i ] _ [ ) ] [ ] _ j _ = _ _ _ i _ : _ c _ _ j _ = _ k _ _ [ y ] _ _ [ j ] _ [. analogous expressions are available for likelihoods ] in the exponential family, see e. g. robert ( 2007, sec. 3. 3 ) for details."
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 3,
    "text": "[ − ] _ [ 1 ] [ ] σ _ [ − ] _ 0 [ 1 ] _ [ θ ] _ [ 0 ] [ + ] _ [ n ] _ _ [ k ] _ [ ( ] _ [ c ] _ _ [ − ] [ i ] _ [ ) σ ] _ [ − ] _ [ 1 ] [ [UNK] ] _ [ y ] _ _ [ k, ] [ − ] [ i ] _ and _ y _ [ [UNK] ] _ k, −i _ = _ n _ _ [ − ] _ _ k _ [ 1 ] [ ( ] _ [ c ] _ _ [ − ] [ i ] _ [ ) ] [ ] _ j _ = _ _ _ i _ : _ c _ _ j _ = _ k _ _ [ y ] _ _ [ j ] _ [. analogous expressions are available for likelihoods ] in the exponential family, see e. g. robert ( 2007, sec. 3. 3 ) for details. # # # # * * 1. 2 the marginal gibbs ( mg ) sampler * * most popular algorithms for finite mixture models are based on the augmentation in ( 2 ), see e. g. diebolt and robert ( 1994 ). here we consider the random - scan [ 1 ] gibbs sampler which iterates updates from _ π _ ( _ c _ _ i _ _ | c _ _ −i _ ) for randomly chosen _ i ∈ _ [ _ n _ ]. its markov kernel _ p _ mg is defined as _ _ _ _ _ _ _ p _ mg ( _ c, c _ _ [ ′ ] _ ) = [ 1 ] _ n _ _ _ _ _ _ _ _ n _ _ p _ mg _, i _ ( _ c, c _ _ [ ′ ] _ ) _, _ _ c, c _ _ [ ′ ] _ _ ∈ _ [ _ k _ _ [ n ] _ ] _ i _ = 1 _ _ _ _ _ _ with _ p _ mg _, i _ ( _ c, c _ _ [ ′ ] _ ) = _ δ _ _ c _ _ −i _ ( _ c _ _ [ ′ ] _ _ −i _ [ ) ] _ [ π ] _ [ ( ] _ [ c ] _ _ [ i ] _ _ [ | ] [ c ] _ _ [ − ] [ i ] _ [ ). the associated pseudocode is given in algo - ] rithm 1. we refer to _ p _ mg as _ marginal _ sampler, since it targets the marginal posterior distribution of _ c _ defined in ( 4 ). once a sample from _ π _ ( _ c _ ) is available, draws from _ π _ ( _ c, _ _ * * θ * * _ _, _ _ * * w * * _ ) can be obtained by sampling from _ π _ ( _ * * θ * * _ _, _ _ * * w * * _ _ | c _ ), so that algorithm 1 can be used to perform full posterior inference on _ π _ ( _ c, _ _ * * θ * * _ _, _ _ * * w * * _ ). being an irreducible and aperiodic markov kernel on a finite space, _ p _ mg is uniformly ergodic for every fixed _ n _, see e. g. levin and peres ( 2017, theorem 4. 9 ) and roberts and rosenthal ( 2004, sec. 3. 3 ) for discussion about uniform ergodicity. however, as we will see later on, its rate of convergence tends to deteriorate quickly as _ n _ increases. 1 here we consider the random - scan strategy since it simplifies some of the proofs and comparisons below. we expect the behaviour of _ p _ mg _ [ n ] _ [, where ] _ [ p ] _ _ [ k ] _ [ = ] _ [ p... p ] _ [ denotes the ] _ [ k ] _ [ - th power of a markov kernel ] _ [ p ] _ [, to be ] roughly comparable to the one of the deterministic - scan version ( which updates _ c _ _ i _ for _ i _ = 1 _,..., n _ sequentially at each iteration ) in most cases of interest, and thus stick to the random - scan for simplicity. 3 * * algorithm 1 * * ( marginal sampler _ p _ mg ) initialize _ c _ [ ( 0 ) ] _ ∈ _ [ _ k _ ] _ [ n ] _. * * for * * _ t ≥ _ 1 * * do * * sample _ i ∼ _ unif ( _ { _ 1 _,..., n } _ ), where unif denotes the uniform distribution. sample _ c _ [ ( ] _ i _ _ [ t ] _ [ ) ] _ ∼ _ _ π _ ( _ c _ _ i _ _ |"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 4,
    "text": "denotes the ] _ [ k ] _ [ - th power of a markov kernel ] _ [ p ] _ [, to be ] roughly comparable to the one of the deterministic - scan version ( which updates _ c _ _ i _ for _ i _ = 1 _,..., n _ sequentially at each iteration ) in most cases of interest, and thus stick to the random - scan for simplicity. 3 * * algorithm 1 * * ( marginal sampler _ p _ mg ) initialize _ c _ [ ( 0 ) ] _ ∈ _ [ _ k _ ] _ [ n ] _. * * for * * _ t ≥ _ 1 * * do * * sample _ i ∼ _ unif ( _ { _ 1 _,..., n } _ ), where unif denotes the uniform distribution. sample _ c _ [ ( ] _ i _ _ [ t ] _ [ ) ] _ ∼ _ _ π _ ( _ c _ _ i _ _ | c _ [ ( ] _ − _ _ [ t ] [ − ] _ _ i _ [ 1 ) ] ), with _ π _ ( _ c _ _ i _ = _ k | c _ _ −i _ ) as in ( 5 ), and set _ c _ [ ( ] _ − _ _ [ t ] _ [ ) ] _ i _ [ = ] _ [ c ] _ _ − _ [ ( ] _ [ t ] [ − ] _ _ i _ [ 1 ) ]. * * end for * * a popular alternative to the marginal sampler is the so - called _ conditional _ sampler introduced in diebolt and robert ( 1994 ), which directly targets _ π _ ( _ c, _ _ * * θ * * _ _, _ _ * * w * * _ ) defined in ( 3 ) alternating updates of ( _ * * θ * * _ _, _ _ * * w * * _ ) _ | c _ and _ c | _ ( _ * * θ * * _ _, _ _ * * w * * _ ). we postpone the discussion of this algorithm to section 3. 2, since the latter is always dominated by _ p _ mg in terms of mixing speed ( see e. g. proposition 3. 3 ). # # # # * * 1. 3 illustrative example * * it is well - known that _ p _ mg can be slow to converge when _ n _ is large ( celeux et al., 2000 ; lee et al., 2009 ). as a first illustrative example, we take model ( 1 ) with _ k _ = 2, _ f _ _ θ _ ( _ y _ ) = _ n _ ( _ y | θ, _ 1 ), _ p _ 0 ( _ θ _ ) = _ n _ ( _ θ | _ 0 _, _ 1 ), _ * * α * * _ = ( 0 _. _ 5 _, _ 0 _. _ 5 ), and we consider the posterior distribution given ( _ y _ 1 _,..., y _ _ n _ ) generated as i. i. d. ( 6 ) _ y _ _ i _ _ ∼ _ 0 _. _ 9 _ n _ ( 0 _. _ 9 _, _ 1 ) + 0 _. _ 1 _ n _ ( _ − _ 0 _. _ 9 _, _ 1 ) _, _ _ i _ = 1 _,..., n _ with _ n _ = 2000. this is a relatively simple one - dimensional problem, with data generated from two components with a reasonable degree of separation between them ( the two means are almost two standard deviations away from each other ). we use _ p _ mg to sample from the resulting posterior _ π _ ( _ c _ ), leading to a markov chain _ { c _ [ ( ] _ [ t ] _ [ ) ] _ } _ _ t _ = 0 _, _ 1 _, _ 2 _,... _ on [ _ k _ ] _ [ n ] _. the left panel of figure 1 displays 100 independent traceplots of the size of the largest cluster in _ { c _ [ ( ] _ [ t ] _ [ ) ] _ } _ _ t _, with all chains independently initialized by sampling _ c _ [ ( 0 ) ] uniformly from [ _ k _ ] _ [ n ] _. most runs are still far from 0 _. _ 9 ( value around which we expect the posterior to concentrate ) after 150 _ ×n _ iterations. indeed trajectories exhibit a typical random - walk behaviour, with slow convergence to stationarity. the center panel instead shows the traceplots generated by the same number of runs and iterations of _ p _ nr, the non - reversible scheme we propose in section 2. 2 ( see algorithm 6 therein for pseudocode and full details ). the chain"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 5,
    "text": "_ _ t _ = 0 _, _ 1 _, _ 2 _,... _ on [ _ k _ ] _ [ n ] _. the left panel of figure 1 displays 100 independent traceplots of the size of the largest cluster in _ { c _ [ ( ] _ [ t ] _ [ ) ] _ } _ _ t _, with all chains independently initialized by sampling _ c _ [ ( 0 ) ] uniformly from [ _ k _ ] _ [ n ] _. most runs are still far from 0 _. _ 9 ( value around which we expect the posterior to concentrate ) after 150 _ ×n _ iterations. indeed trajectories exhibit a typical random - walk behaviour, with slow convergence to stationarity. the center panel instead shows the traceplots generated by the same number of runs and iterations of _ p _ nr, the non - reversible scheme we propose in section 2. 2 ( see algorithm 6 therein for pseudocode and full details ). the chain appears to reach the high - probability region and forget the starting configuration much faster. this is also clear from the right panel, which displays empirical estimates of the marginal distributions of the markov chains induced by _ p _ mg and _ p _ nr over time. 4 * * marginal * * 0 50 100 150 * * non reversible * * 0 50 100 150 * * marginal distribution of the chains * * 1 20 40 60 80 100 120 140 figure 1 : left and center : traceplots of 100 independent runs of the size of the largest cluster for 150 iterations ( after a thinning of size _ n _, i. e. after 150 _ × n _ total updates ) of _ p _ mg ( left ) and _ p _ nr ( center ) in algorithm 6. right : empirical estimates of the marginal distribution at every 10 _ × n _ iterations for _ p _ mg ( gray ) and _ p _ nr ( black ). the model is the one in ( 1 ) with _ k _ = 2, _ f _ _ θ _ ( _ y _ ) = _ n _ ( _ y | θ, _ 1 ), _ p _ 0 ( _ θ _ ) = _ n _ ( _ θ | _ 0 _, _ 1 ) and _ * * α * * _ = ( 0 _. _ 5 _, _ 0 _. _ 5 ), while the data are generated as in ( 6 ). initial configurations _ c _ [ ( 0 ) ] are sampled uniformly from [ _ k _ ] _ [ n ] _. # # # # * * 1. 4 lifted samplers for discrete spaces * * our proposed sampler is inspired by classical non - reversible mcmc constructions ( diaconis et al., 2000 ; fearnhead et al., 2018 ), which loosely speaking force the algorithm to persistently move in one direction as much as possible. to illustrate the idea, consider an arbitrary probability distribution _ π _ on a countable space _ c _ and an augmented distribution _ π _ [UNK] ( _ c, v _ ) = _ [ π ] _ [ ( ] _ [ c ] _ [ ) ] _ c ∈c, v ∈ { − _ 1 _, _ + 1 _ }, _ 2 _ [, ] _ on the space _ x _ = _ c × { − _ 1 _, _ + 1 _ } _, so that _ π _ is the marginal distribution of [UNK] _ π _ over _ c _. given two markov kernels _ { q _ + 1 ( _ c, · _ ) _ } _ _ c∈c _ and _ { q _ _ − _ 1 ( _ c, · _ ) _ } _ _ c∈c _ on _ c _, let _ p _ lift be the nonreversible [UNK] _ π _ - invariant markov kernel defined in algorithm 2. the kernels are usually * * algorithm 2 * * generating a sample ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) _ ∼ _ _ p _ lift ( ( _ c, v _ ) _, · _ ) generate [UNK] _ c ∼ _ _ q _ _ v _ ( _ c, · _ ). set ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) = ( [UNK] _ c, v _ ) with probability min 1 _, _ _ [ π ] _ [ ( ] _ [ c ] _ [ [UNK] ] [ ) ] _ [ q ] _ _ [ − ] [ v ] _ [ ( ] _ [ c ] _ [ [UNK] ] _ [, ] [ c ] _ [ ) ] _ π _ ( _ c _ ) _ q _ _ v _ ( _ c, _ [UNK] _ c _ ) _. _ otherwise set ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) = ( _ c, −v _ )"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 6,
    "text": "′ ] _ _, v _ _ [ ′ ] _ ) _ ∼ _ _ p _ lift ( ( _ c, v _ ) _, · _ ) generate [UNK] _ c ∼ _ _ q _ _ v _ ( _ c, · _ ). set ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) = ( [UNK] _ c, v _ ) with probability min 1 _, _ _ [ π ] _ [ ( ] _ [ c ] _ [ [UNK] ] [ ) ] _ [ q ] _ _ [ − ] [ v ] _ [ ( ] _ [ c ] _ [ [UNK] ] _ [, ] [ c ] _ [ ) ] _ π _ ( _ c _ ) _ q _ _ v _ ( _ c, _ [UNK] _ c _ ) _. _ otherwise set ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) = ( _ c, −v _ ). chosen so that _ q _ _ v _ ( _ c, · _ ) and _ q _ _ −v _ ( _ c, · _ ) have disjoint support and the variable _ v ∈ { − _ 1 _, _ + 1 _ } _ encodes a direction ( or velocity ) along which the chain is exploring the space : such direction is reversed only when a proposal is rejected ( see algorithm 2 ). as a simple 5 example, take _ c _ = n and _ q _ _ v _ ( _ c, · _ ) = _ δ _ _ c _ + _ v _ ( _ · _ ), so that _ v _ = + 1 implies that the chain is moving towards increasing values and viceversa with _ v _ = _ − _ 1. within this perspective _ v _ can be seen as a “ memory bank ” which keeps track of the past history of the chain and introduces momentum. the kernel _ p _ lift is often referred to as a _ lifted _ version of the ( reversible ) metropolis - hastings kernel with proposal distribution _ q _ = 0 _. _ 5 _ q _ + 1 + 0 _. _ 5 _ q _ _ − _ 1 and target distribution _ π _. lifted kernels can mix significantly faster than their reversible counterparts ( diaconis et al., 2000 ) and are in general at least as efficient as the original method under mild assumptions ( bierkens, 2016 ; andrieu and livingstone, 2021 ; gagnon and maire, 2024b ). however, whether or not lifting techniques achieve a notable speed - up depends on the features of _ π _ and the choice of _ q _ _ v _. for example, if proposed moves are often rejected, then the direction _ v _ will be reversed frequently and the chain will exhibit an almost reversible behaviour ; while if the sampler manages to make long ‘ excursions ’ ( i. e. consecutive moves without flipping direction ) one expects to observe significant gains obtained by lifting. * * non - reversible samplers for mixture models * * general techniques to construct non - reversible samplers for discrete spaces have been proposed in the literature, see e. g. gagnon and maire ( 2024a, sec. 3 ) for constructions on partially - ordered discrete spaces and power and goldman ( 2019 ) for discrete spaces with algebraic structures. we are, however, not aware of successful applications of these methodologies to mixture models. part of the reason could be that, in order to build a lifted counter - part of _ p _ mg for mixture models, one would need to define some notion of direction or partial ordering on [ _ k _ ] _ [ n ] _, or more generally on the space of partitions and it is not obvious how to do so in a way that is computationally efficient and results in long excursions with persistence in direction ( thus leading to substantial speed - ups ). for example, one could directly rely on the cartesian product structure of [ _ k _ ] _ [ n ] _ and attach a velocity component to each coordinate, applying for example the discrete hamiltonian monte carlo algorithm of nishimura et al. ( 2020 ) : this however would not pair well with the geometry of posterior distributions _ π _ ( _ c _ ) arising in mixture models and likely result in short excursions and little speed - up. to tackle this issue, we take a different perspective on [ _ k _ ] _ [ n ] _, moving from the kernel _ p _ mg, which is a mixture over data - points ( i. e. over _ i ∈ _ [ _ n _ ] ), to a kernel _ p _ r which is a mixture over pairs of clusters ( see section 2. 1 for definition ). this allows us to derive an effective non - reversible sampler _ p _ nr targeting _ π _ ( _ c _ ), built"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 7,
    "text": "##s ). for example, one could directly rely on the cartesian product structure of [ _ k _ ] _ [ n ] _ and attach a velocity component to each coordinate, applying for example the discrete hamiltonian monte carlo algorithm of nishimura et al. ( 2020 ) : this however would not pair well with the geometry of posterior distributions _ π _ ( _ c _ ) arising in mixture models and likely result in short excursions and little speed - up. to tackle this issue, we take a different perspective on [ _ k _ ] _ [ n ] _, moving from the kernel _ p _ mg, which is a mixture over data - points ( i. e. over _ i ∈ _ [ _ n _ ] ), to a kernel _ p _ r which is a mixture over pairs of clusters ( see section 2. 1 for definition ). this allows us to derive an effective non - reversible sampler _ p _ nr targeting _ π _ ( _ c _ ), built as a mixture of lifted samplers associated to pairs of clusters ( see section 2. 2 for definition ). note that, while we designed our sampler to be effective for posterior distributions of mixture models, the proposed scheme can in principle be used with any distribution _ π _ on [ _ k _ ] _ [ n ] _. # # # # * * 1. 5 related literature * * * * bayesian mixture models * * bayesian finite mixture models are a classical topic which has received a lot of attention in the last decades, see marin et al. ( 2005 ) ; 6 [UNK] - schnatter ( 2006 ) for some reviews. the challenges related to sampling from the resulting posterior distribution have been also discussed extensively, see e. g. early examples in ( diebolt and robert, 1994 ; celeux et al., 2000 ; stephens, 2000 ; lee et al., 2009 ; hobert et al., 2011 ), and the marginal and conditional samplers we compare with are arguably the most popular schemes that are routinely used to accomplish such tasks ( marin et al., 2005, section 1. 4 ). * * lifted mcmc for statistical models with discrete parameters * * nonreversible mcmc samplers have been previously designed for and applied to bayesian statistical models with discrete parameters, such as variable selection, permutationbased and graphical models ; see e. g. power and goldman ( 2019 ) ; gagnon and maire ( 2024a ) ; schauer and [UNK] ( 2024 ) and references therein. however, posterior distributions arising from such models are usually strongly concentrated and highly non - smooth, limiting the length of excursions and speed - ups obtained with lifted chains. as a result, one often ends up observing large gains ( e. g. hundred - fold ) when targeting uniform or prior distributions ( which are usually quite flat ) and more modest gains ( e. g. two - fold ) when targeting actual posterior distributions used in practice ; see e. g. schauer and [UNK] ( 2024, figures 1 and 3 ), power and goldman ( 2019, table 1 ) or gagnon and maire ( 2024a, figure 1 ) [ 2 ]. instead, a key feature of our proposed sampler is that, in many cases of interest, the speed - up relative to its reversible counter - part remains large even in the presence of observed data ( i. e. for the actual posterior ). we argue that this is due to statistical features of mixture models that make them wellsuited to appropriately designed non - reversible samplers ( such as _ p _ nr ) ; see section 2. 2. 1 for more details. # # # # * * 1. 6 structure of the paper * * in section 2 we introduce our proposed non - reversible markov kernel _ p _ nr, which targets _ π _ ( _ c _ ) in ( 4 ). in section 3 we first show that, after accounting for computational cost, _ p _ nr cannot perform worse than _ p _ mg, in terms of asymptotic variance, by more than a factor of four. this is done by combining some variations of classical results on asymptotic variances of lifted samplers with a peskun comparison between _ p _ mg and an auxiliary reversible kernel _ p _ r. we then provide analogous results for the conditional sampler by showing that it is dominated by the marginal one ( section 3. 2 ). in section 4 we continue the comparison between _ p _ mg and _ p _ nr, showing that in the prior case the latter improves on the former by an order of magnitude, i. e. reducing the convergence time from _ o _ ( _ n _ [ 2 ] ) to _ o _ ( _ n _ ). this is done through a scaling limit analysis, which 2 this is in contrast with applications of lifting techniques to discrete models arising in statistical physics ( see e. g"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 8,
    "text": "first show that, after accounting for computational cost, _ p _ nr cannot perform worse than _ p _ mg, in terms of asymptotic variance, by more than a factor of four. this is done by combining some variations of classical results on asymptotic variances of lifted samplers with a peskun comparison between _ p _ mg and an auxiliary reversible kernel _ p _ r. we then provide analogous results for the conditional sampler by showing that it is dominated by the marginal one ( section 3. 2 ). in section 4 we continue the comparison between _ p _ mg and _ p _ nr, showing that in the prior case the latter improves on the former by an order of magnitude, i. e. reducing the convergence time from _ o _ ( _ n _ [ 2 ] ) to _ o _ ( _ n _ ). this is done through a scaling limit analysis, which 2 this is in contrast with applications of lifting techniques to discrete models arising in statistical physics ( see e. g. vucelja, 2016 ), which often feature a higher degree of symmetry and smoothness, thus making non - reversible mcmc methods more effective ; see e. g. power and goldman ( 2019, table 1 ) for numerical examples and faulkner and livingstone ( 2024 ) for a recent review. 7 proves that, after rescaling time by a factor of _ n _ [ 2 ], the evolution of the frequencies _ n _ _ k _ ( _ c _ ) evolving according to _ p _ mg converges to a wright - fisher process ( ethier, 1976 ), which is a diffusion on the probability simplex. in contrast, when the chain evolves according to _ p _ nr, we obtain convergence to a non - singular piecewise deterministic markov process ( davis, 1984 ) after rescaling time by only a factor of _ n _. section 5 discusses a variant of _ p _ nr and, finally, section 6 provides various numerical simulations, where _ p _ nr is shown to significantly outperform _ p _ mg in sampling from mixture models posterior distributions, both in low and high - dimensional cases. the supplementary material contains additional simulation studies, together with the proofs of all the theoretical results. r code to replicate all the numerical experiments can be found at ` [ https : / / github. com / gzanella / nonreversible _ finitemixtures ] ( https : / / github. com / gzanella / nonreversible _ finitemixtures ) `. # # # * * 2 a non - reversible marginal sampler * * # # # # * * 2. 1 a reversible sampler that operates over pairs of clus - * * * * ters * * let _ π _ ( _ c _ ) be an arbitrary probability distribution on [ _ k _ ] _ [ n ] _, such as ( 4 ) in the context of finite mixtures, and denote the set of ordered pairs in [ _ k _ ], with cardinality _ k _ ( _ k _ _ − _ 1 ) _ / _ 2, as ( 7 ) _ k _ = ( _ k, k _ _ [ ′ ] _ ) _ ∈ _ [ _ k _ ] [ 2 ] : _ k < k _ _ [ ′ ] _ [ ] _. _ as an intermediate step towards defining _ p _ nr, we first consider a _ π _ - reversible markov kernel on [ _ k _ ] _ [ n ] _ defined as ( 8 ) _ p _ r ( _ c, c _ _ [ ′ ] _ ) = _ p _ _ c _ ( _ k, k _ _ [ ′ ] _ ) _ p _ _ k, k _ _ ′ _ ( _ c, c _ _ [ ′ ] _ ) _ c, c _ _ [ ′ ] _ _ ∈ _ [ _ k _ ] _ [ n ] _ _, _ ( _ k, k _ _ [ ′ ] _ ) _ ∈k _ where ( 9 ) _ p _ _ c _ ( _ k, k _ _ [ ′ ] _ ) = _ [ n ] _ _ [ k ] _ [ ( ] _ [ c ] _ [ ) ] [ + ] _ [ n ] _ _ [ k ] _ _ [ ′ ] _ [ ( ] _ [ c ] _ [ ) ] _, _ ( _ k, k _ _ [ ′ ] _ ) _ ∈k _ ( _ k − _ 1 ) _ n _ is a probability distribution on _ k _ for each _ c ∈ _ [ _ k _ ] _ [ n ] _, i. e. [ ] ( _ k, k _ _ [ ′ ] _ ) _ ∈k _ _ [ p ] _ _ [ c ] _ [ ( ] _ [ k, k ] _ _ [ ′ ] _ [ ) = 1, and ] _ p _ _ k, k _ _ ′ _ is"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 9,
    "text": "] _ ) _ ∈k _ where ( 9 ) _ p _ _ c _ ( _ k, k _ _ [ ′ ] _ ) = _ [ n ] _ _ [ k ] _ [ ( ] _ [ c ] _ [ ) ] [ + ] _ [ n ] _ _ [ k ] _ _ [ ′ ] _ [ ( ] _ [ c ] _ [ ) ] _, _ ( _ k, k _ _ [ ′ ] _ ) _ ∈k _ ( _ k − _ 1 ) _ n _ is a probability distribution on _ k _ for each _ c ∈ _ [ _ k _ ] _ [ n ] _, i. e. [ ] ( _ k, k _ _ [ ′ ] _ ) _ ∈k _ _ [ p ] _ _ [ c ] _ [ ( ] _ [ k, k ] _ _ [ ′ ] _ [ ) = 1, and ] _ p _ _ k, k _ _ ′ _ is the _ π _ - reversible metropolis - hastings ( mh ) kernel that proposes to move a uniformly drawn point from cluster _ k _ to cluster _ k _ _ [ ′ ] _ or viceversa with probability 1 _ / _ 2. the resulting kernel _ p _ r is defined in algorithm 3 where, for ease of notation, for every _ c ∈ _ [ _ k _ ] _ [ n ] _, _ i ∈ _ [ _ n _ ] and _ k ∈ _ [ _ k _ ] we write ( _ c _ _ −i _ _, k _ ) _ ∈ _ [ _ k _ ] _ [ n ] _ for the vector _ c _ with the _ i _ - th entry _ c _ _ i _ replaced by _ k _. despite the fact that _ p _ r is a mixture with weights _ p _ _ c _ depending on the current state _ c _, invariance with respect to _ π _ is preserved, as proven in the next lemma. the 8 * * algorithm 3 * * generating a sample _ c _ _ [ ′ ] _ _ ∼ _ _ p _ r ( _ c, · _ ) sample ( _ k, k _ _ [ ′ ] _ ) _ ∼ _ _ p _ _ c _ as in algorithm 4. set ( _ k _ _ − _ _, k _ + ) = ( _ k, k _ _ [ ′ ] _ ) with probability 1 _ / _ 2 and ( _ k _ _ − _ _, k _ + ) = ( _ k _ _ [ ′ ] _ _, k _ ) otherwise if _ n _ _ k _ _ − _ ( _ c _ ) = 0 set _ c _ _ [ ′ ] _ = _ c _. if _ n _ _ k _ _ − _ ( _ c _ ) _ > _ 0 sample _ i ∼ _ unif ( _ { i _ _ [ ′ ] _ _ ∈ _ [ _ n _ ] : _ c _ _ i _ _ ′ _ = _ k _ _ − _ _ } _ ) and set _ c _ _ [ ′ ] _ = ( _ c _ _ −i _ _, k _ + ) with probability min _ { _ 1 _, r _ ( _ c, i, k _ _ − _ _, k _ + ) _ } _ and _ c _ _ [ ′ ] _ = _ c _ otherwise, where _ n _ _ k _ _ − _ ( _ c _ ) ( 10 ) _ r _ ( _ c, i, k _ _ − _ _, k _ + ) = _ n _ _ k _ + ( _ c _ ) + 1 _ π _ ( _ c _ _ i _ = _ k _ + _ | c _ _ −i _ ) _ π _ ( _ c _ _ i _ = _ k _ _ − _ _ | c _ _ −i _ ) _ [, ] _ key point is that _ p _ _ c _ ( _ k, k _ _ [ ′ ] _ ) only depends on _ n _ _ k _ ( _ c _ ) + _ n _ _ k _ _ ′ _ ( _ c _ ) and _ p _ _ k, k _ _ ′ _ leaves the latter quantity unchanged. * * lemma 2. 1. * * _ the markov kernel p _ r _ defined in algorithm 3 is π - reversible. moreover, _ _ if π _ ( _ c _ ) _ > _ 0 _ for every c ∈ _ [ _ k _ ] _ [ n ] _ _ it is also irreducible, aperiodic and uniformly ergodic. _ sampling from _ p _ _ c _ can be performed efficiently using algorithm 4, where one cluster is selected with probability proportional to its size and the other uniformly at random from the remaining ones. validity is proved in the next lemma. * * lemma 2. 2. * *"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 10,
    "text": "[, ] _ key point is that _ p _ _ c _ ( _ k, k _ _ [ ′ ] _ ) only depends on _ n _ _ k _ ( _ c _ ) + _ n _ _ k _ _ ′ _ ( _ c _ ) and _ p _ _ k, k _ _ ′ _ leaves the latter quantity unchanged. * * lemma 2. 1. * * _ the markov kernel p _ r _ defined in algorithm 3 is π - reversible. moreover, _ _ if π _ ( _ c _ ) _ > _ 0 _ for every c ∈ _ [ _ k _ ] _ [ n ] _ _ it is also irreducible, aperiodic and uniformly ergodic. _ sampling from _ p _ _ c _ can be performed efficiently using algorithm 4, where one cluster is selected with probability proportional to its size and the other uniformly at random from the remaining ones. validity is proved in the next lemma. * * lemma 2. 2. * * _ for each c ∈ _ [ _ k _ ] _ [ n ] _ _, algorithm 4 produces a sample _ ( _ k, k _ _ [ ′ ] _ ) _ from the _ _ probability distribution p _ _ c _ _ defined in _ ( 9 ) _. _ * * algorithm 4 * * sampling ( _ k, k _ _ [ ′ ] _ ) _ ∼ _ _ p _ _ c _ defined in ( 9 ) sample _ k _ 1 from _ { _ 1 _,..., k } _ with probabilities ( _ n _ 1 ( _ c _ ) _ / n,..., n _ _ k _ ( _ c _ ) _ / n _ ) sample _ k _ 2 uniformly at random from _ { _ 1 _,..., k } \\ { k _ 1 _ } _ set _ k _ = min _ { k _ 1 _, k _ 2 _ } _ and _ k _ _ [ ′ ] _ = max _ { k _ 1 _, k _ 2 _ } _ * * comparison between * * _ p _ mg * * and * * _ p _ r both _ p _ mg and _ p _ r can be interpreted as reversible metropolis - hastings schemes that propose single - point moves. specifically, _ p _ mg and _ p _ r propose moving datapoint _ i _ to cluster _ k _ with, respectively, probabilities _ [ | ] [ c ] _ _ [ − ] [ i ] _ [ ) ] _ a _ mg ( _ i, k _ ) = _ [ π ] _ [ ( ] _ [ c ] _ _ [ i ] _ [ = ] _ [ k ] _ _ [ k ] _ _ [ | ] [ c ] _ _ [ − ] [ i ] _ [ ) ] and _ a _ r ( _ i, k _ ) = _ [ n ] _ _ [ c ] _ _ [ i ] _ [ ( ] _ [ c ] _ [ ) ] [ + ] _ [ n ] _ _ [ k ] _ [ ( ] _ [ c ] _ [ ) ] _ n _ _ n _ _ c _ [ ) ] [ + ] _ [ n ] _ _ [ k ] _ [ ( ] _ [ c ] _ [ ) ] 1 ( _ c _ _ i _ _ _ = _ k _ ) _ n _ _ c _ _ i _ ( _ c _ ) 2 ( _ k − _ 1 ) _ n _ _ [, ] _ for ( _ i, k _ ) _ ∈ _ [ _ n _ ] _ × _ [ _ k _ ]. for _ p _ mg the metropolis - hastings acceptance probability is always one, while for _ p _ r it is not. it is interesting to note that 1 1 _ a _ r ( _ i, k _ ) _ ≥ _ 2 ( _ k − _ 1 ) _ n _ _ [ ≥ ] _ 2 ( _ k − _ 1 ) _ [ a ] _ [ mg ] [ ( ] _ [ i, k ] _ [ ) ] _ [, ] _ 9 meaning that the proposal probabilities of _ p _ r can be at most 2 ( _ k − _ 1 ) times smaller than the ones of _ p _ mg. this connection will help providing formal comparison results between _ p _ r and _ p _ mg in section 3 ( see theorem 3. 1 and remark 3. 2 for more details ). we postpone details on these comparisons to section 3 and now focus on how to leverage the mixture representation of _ p _ r in ( 8 ) to build effective non - reversible algorithms targeting _ π _ ( _ c _ ). * * cost per iteration of * * _ p _ mg * * and * * _ p _ r for both _ p _ mg and _ p _ r the cost per iteration is usually dominated by"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 11,
    "text": ") _ n _ _ [ ≥ ] _ 2 ( _ k − _ 1 ) _ [ a ] _ [ mg ] [ ( ] _ [ i, k ] _ [ ) ] _ [, ] _ 9 meaning that the proposal probabilities of _ p _ r can be at most 2 ( _ k − _ 1 ) times smaller than the ones of _ p _ mg. this connection will help providing formal comparison results between _ p _ r and _ p _ mg in section 3 ( see theorem 3. 1 and remark 3. 2 for more details ). we postpone details on these comparisons to section 3 and now focus on how to leverage the mixture representation of _ p _ r in ( 8 ) to build effective non - reversible algorithms targeting _ π _ ( _ c _ ). * * cost per iteration of * * _ p _ mg * * and * * _ p _ r for both _ p _ mg and _ p _ r the cost per iteration is usually dominated by the computation of the conditional distribution _ π _ ( _ c _ _ i _ = _ k | c _ _ −i _ ) in ( 5 ), which will depend on the specific combination of kernel _ f _ _ θ _ and prior _ p _ 0. indeed, algorithm 1 requires in addition only to sample from a uniform distribution on a discrete set ( which has a fixed cost ). similar considerations hold for algorithm 3, since sampling from _ p _ _ c _ with algorithm 4 entails again only sampling from two uniform distributions. thus, we measure cost per iteration of these samplers in terms of the number of conditional distribution evaluations, which is _ k _ for _ p _ mg and 2 for _ p _ r : therefore the ratio of costs of _ p _ mg versus _ p _ r is _ k / _ 2. the same will hold for _ p _ nr in algorithm 6 below, which requires essentially the same computations of algorithm 3. # # # # * * 2. 2 the proposed non - reversible sampler * * consider the extended target distribution _ k _ ( _ k− _ 1 ) _ / _ 2 [UNK] 1 ( 11 ) _ π _ ( _ c, v _ ) : = _ π _ ( _ c _ ) _ c ∈ _ [ _ k _ ] _ [ n ] _ _, v _ = ( _ v _ _ k, k _ _ ′ _ ) ( _ k, k _ _ ′ _ ) _ ∈k _ _ ∈ { − _ 1 _, _ + 1 _ } _ _ [ k ] _ [ ( ] _ [ k ] [ − ] _ [ 1 ) ] _ [ / ] _ [ 2 ] 2 _ π _ [UNK] ( _ c, v _ ) : = _ π _ ( _ c _ ) 1 2 2 and the [UNK] _ π _ - invariant markov kernel _ p _ nr defined as ( 12 ) _ p _ nr ( ( _ c, v _ ) _, _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) ) = _ p _ _ c _ ( _ k, k _ _ [ ′ ] _ ) _ p _ [ [UNK] ] _ k, k _ _ ′ _ ( ( _ c, v _ ) _, _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) ) _, _ ( _ k, k _ _ [ ′ ] _ ) _ ∈k _ with _ p _ _ c _ defined as in ( 9 ) and _ p _ [ [UNK] ] _ k, k _ _ ′ _ being the [UNK] _ π _ - invariant kernel defined in algorithm 5. the kernel _ p _ [ [UNK] ] _ k, k _ _ ′ _ operates on the _ k _ - th and _ k _ _ [ ′ ] _ - th clusters, and it is a lifted counter - part of _ p _ _ k, k _ _ ′ _, with associated velocity component _ v _ _ k, k _ _ ′ _. in this construction, the velocity vector _ v _ is _ k _ ( _ k − _ 1 ) _ / _ 2 dimensional and only one of its component is actively used to move _ c _ at each iteration. the pseudo - code associated to _ p _ nr is given in algorithm 6. the algorithm depends on a parameter _ ξ ≥ _ 0, which can be interpreted as the refresh rate at which directions are flipped. while useful to take _ ξ > _ 0 for technical reasons ( i. e. to ensure aperiodicity ), we do not expect the value of _ ξ _ to have significant impacts in practice provided it is set to a small value, and in the simulations we always set _ ξ _ = 1 _ / _ 2. the next lemma shows that _ p _ nr is a valid [UNK] _ π _ - invariant kernel. 10 * * algorithm 5"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 12,
    "text": "_ _ ′ _, with associated velocity component _ v _ _ k, k _ _ ′ _. in this construction, the velocity vector _ v _ is _ k _ ( _ k − _ 1 ) _ / _ 2 dimensional and only one of its component is actively used to move _ c _ at each iteration. the pseudo - code associated to _ p _ nr is given in algorithm 6. the algorithm depends on a parameter _ ξ ≥ _ 0, which can be interpreted as the refresh rate at which directions are flipped. while useful to take _ ξ > _ 0 for technical reasons ( i. e. to ensure aperiodicity ), we do not expect the value of _ ξ _ to have significant impacts in practice provided it is set to a small value, and in the simulations we always set _ ξ _ = 1 _ / _ 2. the next lemma shows that _ p _ nr is a valid [UNK] _ π _ - invariant kernel. 10 * * algorithm 5 * * generating a sample ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) _ ∼ _ _ p _ [ [UNK] ] _ k, k _ _ ′ _ ( ( _ c, v _ ) _, · _ ) with probability _ ξ / n _ flip _ v _ _ k, k _ _ ′ _ to _ −v _ _ k, k _ _ ′ _ set ( _ k _ _ − _ _, k _ + ) = ( _ k, k _ _ [ ′ ] _ ) if _ v _ _ k, k _ _ ′ _ = + 1, and ( _ k _ _ − _ _, k _ + ) = ( _ k _ _ [ ′ ] _ _, k _ ) if _ v _ _ k, k _ _ ′ _ = _ − _ 1 if _ n _ _ k _ _ − _ ( _ c _ ) = 0, set ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) = ( _ c, v _ [ ( ] _ [ flip ] _ [ ) ] ), with _ v _ [ ( ] _ [ flip ] _ [ ) ] = ( _ v _ _ − _ ( _ k, k _ _ ′ _ ) _, −v _ _ k, k _ _ ′ _ ) if _ n _ _ k _ _ − _ ( _ c _ ) _ > _ 0, sample _ i ∼ _ unif ( _ { i _ _ [ ′ ] _ _ ∈ _ [ _ n _ ] _ | c _ _ i _ _ ′ _ = _ k _ _ − _ _ } _ ) and set ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) = ( ( _ c _ _ −i _ _, k _ + ) _, v _ ) with probability min _ { _ 1 _, r _ ( _ c, i, k _ _ − _ _, k _ + ) _ } _ and otherwise ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) = ( _ c, v _ [ ( ] _ [ flip ] _ [ ) ] ), with _ r _ ( _ c, i, k _ _ − _ _, k _ + ) _ } _ defined in ( 10 ) with probability _ ξ / n _ flip _ v _ _ k, k _ _ [ ′ ] _ _ [ ′ ] _ [ to ] _ [ − ] [ v ] _ _ k, k _ _ [ ′ ] _ _ [ ′ ] _ * * algorithm 6 * * one step of the non - reversible kernel ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) _ ∼ _ _ p _ nr ( ( _ c, v _ ) _, · _ ) sample ( _ k, k _ _ [ ′ ] _ ) _ ∼ _ _ p _ _ c _ as in algorithm 4. sample ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) _ ∼ _ _ p _ [ [UNK] ] _ k, k _ _ ′ _ ( ( _ c, v _ ) _, · _ ) as in algorithm 5. * * lemma 2. 3. * * _ for any probability distribution π on _ [ _ k _ ] _ [ n ] _ _, the markov kernel p _ nr _ defined _ _ in algorithm 6 is _ [UNK] _ π - invariant, with _ [UNK] _ π as in _ ( 11 ) _. moreover, if ξ > _ 0 _ and π _ ( _ c _ ) _ > _ 0 _ for _ _ every c ∈ _ [ _ k _ ] _ [ n ] _ _, then p _ nr _ is irreducible, aperiodic and uniformly ergodic. _ * * 2. 2"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 13,
    "text": "_ _ [ ′ ] _ ) _ ∼ _ _ p _ _ c _ as in algorithm 4. sample ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) _ ∼ _ _ p _ [ [UNK] ] _ k, k _ _ ′ _ ( ( _ c, v _ ) _, · _ ) as in algorithm 5. * * lemma 2. 3. * * _ for any probability distribution π on _ [ _ k _ ] _ [ n ] _ _, the markov kernel p _ nr _ defined _ _ in algorithm 6 is _ [UNK] _ π - invariant, with _ [UNK] _ π as in _ ( 11 ) _. moreover, if ξ > _ 0 _ and π _ ( _ c _ ) _ > _ 0 _ for _ _ every c ∈ _ [ _ k _ ] _ [ n ] _ _, then p _ nr _ is irreducible, aperiodic and uniformly ergodic. _ * * 2. 2. 1 * * * * specificities of mixture models that make * * _ p _ nr * * work well * * we now discuss at an informal level some of the specificities of the posterior distribution _ π _ ( _ c _ ) arising from mixture models that make _ p _ nr work well. * * lack of identifiability and concentration * * an important statistical feature of mixture models is that cluster labels are in general not identifiable as _ n →∞ _, meaning that even when _ n _ is large there is non - vanishing uncertainty on the value of _ c _ _ i _. in other words, while the posterior distribution of _ * * w * * _ and _ * * θ * * _ concentrates as _ n →∞ _, the one of _ c _ does not ( not even at the level of marginals, meaning that, for every fixed _ i _, _ π _ ( _ c _ _ i _ ) does not converge to a point mass as _ n →∞ _ ) ; see e. g. nguyen ( 2013 ) ; guha et al. ( 2021 ) and references therein for asymptotic results for mixture model posteriors. intuitively, lack of concentration occurs because the information about each individual _ c _ _ i _ does not grow with _ n _ ( since each _ c _ _ i _ is associated to a single datapoint ). this also tends to make posteriors flatter, i. e. moving one observation from one cluster to another usually leads to a small change in the target distribution. by contrast, many models with discrete parameters lead to posteriors that become increasingly more concentrated and rough as _ n →∞ _, which has a major impacts on the convergence properties of mcmc algorithms targeting them, including making standard mcmc converge faster ( see e. g. yang et al., 2016 ; zhou et al., 2022 ; zhou and chang, 2023 ) and lifting techniques less effective ( as already discussed in section 1. 5 ). 11 * * cancellations in the acceptance ratio * * for _ π _ ( _ c _ ) as in ( 4 ), the mh ratio _ r _ ( _ c, i, k _ _ − _ _, k _ + ) reads _ α _ _ k _ + + _ n _ _ k _ + ( _ c _ ) ( 13 ) _ r _ ( _ c, i, k _ _ − _ _, k _ + ) = _ n _ _ k _ + ( _ c _ ) + 1 _ n _ _ k _ _ − _ ( _ c _ ) _ α _ _ k _ _ − _ + _ n _ _ k _ _ − _ ( _ c _ ) _ − _ 1 _ p _ ( _ y _ _ i _ _ | y _ _ −i _ _, c _ _ −i _ _, c _ _ i _ = _ k _ + ) _ p _ ( _ y _ _ i _ _ | y _ _ −i _ _, c _ _ −i _ _, c _ _ i _ = _ k _ _ − _ ) _ [. ] _ interestingly, the proposal probability almost matches the term _ α _ _ k _ + _ n _ _ k _ ( _ c _ ) arising from the prior. in particular, by writing _ α _ _ k _ + + _ n _ _ k _ + ( _ c _ ) _ n _ _ k _ + ( _ c _ ) + 1 _ n _ _ k _ _ − _ ( _ c _ ) _ α _ _ k _ _ − _ + _ n _ _ k _ _ − _ ( _ c _ ) _ − _ 1 = 1 + _ α _ _ k _ + _ − _ 1 _ n _ _ k _ + ( _ c _ ) + 1 1 + _ [ α ] _ _ [ k ] _ _ [ − ] _ _ ["
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 14,
    "text": "_ _ i _ _ | y _ _ −i _ _, c _ _ −i _ _, c _ _ i _ = _ k _ _ − _ ) _ [. ] _ interestingly, the proposal probability almost matches the term _ α _ _ k _ + _ n _ _ k _ ( _ c _ ) arising from the prior. in particular, by writing _ α _ _ k _ + + _ n _ _ k _ + ( _ c _ ) _ n _ _ k _ + ( _ c _ ) + 1 _ n _ _ k _ _ − _ ( _ c _ ) _ α _ _ k _ _ − _ + _ n _ _ k _ _ − _ ( _ c _ ) _ − _ 1 = 1 + _ α _ _ k _ + _ − _ 1 _ n _ _ k _ + ( _ c _ ) + 1 1 + _ [ α ] _ _ [ k ] _ _ [ − ] _ _ [ − ] _ [ 1 ] _ n _ _ k _ _ − _ ( _ c _ ) _ − _ 1 _, _ we see that the first part of ( 13 ) goes to 1 as _ n _ _ k _ + ( _ c _ ) and _ n _ _ k _ _ − _ ( _ c _ ) increase, for every fixed value of _ * * α * * _. notice that with _ α _ _ k _ = 1 for every _ k _ this ratio is always equal to 1. this cancellation contributes to make ( 13 ) closer to 1 and thus to make excursions of _ p _ nr longer. * * flatness in the tails and behavior out of stationarity * * interestingly, also the ratio of predictive distributions in ( 13 ) tends to get close to 1 for partitions that do not correspond to well - identified and separate clusters, meaning that mixture model posteriors _ π _ ( _ c _ ) become increasingly flatter in the tails. to illustrate this, consider the com i. i. d. mon situation when labels are initialized uniformly at random, i. e. _ c _ [ ( 0 ) ] _ i _ _ ∼ _ unif ( [ _ k _ ] ). in this situations, by construction, clusters are similar to each other under _ c _ [ ( 0 ) ], resulting in ratios of predictive distributions that are close to 1 ( and converge to 1 as _ n →∞ _ ). as a consequence, the non - reversible chain will proceed almost deterministically without flipping directions until clusters start to differentiate significantly. this is indeed the behavior observed in the middle panel of figure 1, as well as in section 6. 2 and b of the supplementary material with different values of _ k _ and likelihood kernels. more generally, in mixture model contexts, non - reversibility is particularly helpful during the transient phase, where the algorithm has not yet reached the high - probability region under _ π _ and has to explore large flat regions of the state space [ 3 ]. * * overlapping components and the overfitted case * * another situation that makes ratios of predictive distributions close to 1 is when the actual clusters in the data have a considerable overlap. an extreme case of this situation is when the true number of components _ k _ _ [ ∗ ] _ ( assuming data were actually generated by a well - specified mixture model ) is strictly smaller than _ k _, which amounts to assuming that a plausible upper bound on _ k _ _ [ ∗ ] _ is known and _ k _ is set to such value ( instead of the less plausible scenario where _ k _ _ [ ∗ ] _ itself is known ). this is often called the overfitted case, see e. g. rousseau 3 this is, again, in contrast with typical bayesian discrete models that lead to posteriors with large “ discrete gradients ” in the tails providing strong enough signal for reversible schemes to converge fast in the first part of the transient phase ( yang et al., 2016 ; zhou et al., 2022 ; zhou and chang, 2023 ). 12 and mengersen ( 2011 ) for a theoretical exploration of its asymptotic properties, and it is a common situation since in many context ( e. g. density estimation ) it is preferable to overshoot rather than undershoot the value of _ k _ and thus practitioners often set _ k _ to some conservative, moderately large value. see section 6. 4 for more discussion on the overfitted case and empirical evidence that in this setting the improvement of _ p _ nr over the latter is particularly apparent. # # # * * 3 asymptotic variance comparison results * * in this section we compare the various kernels discussed above in terms of asymptotic variances. among other results we show that, after accounting for computational cost, _ p _ nr cannot be worse than _ p _ mg by more than a factor of 4. given a markov chain _ {"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 15,
    "text": "the first part of the transient phase ( yang et al., 2016 ; zhou et al., 2022 ; zhou and chang, 2023 ). 12 and mengersen ( 2011 ) for a theoretical exploration of its asymptotic properties, and it is a common situation since in many context ( e. g. density estimation ) it is preferable to overshoot rather than undershoot the value of _ k _ and thus practitioners often set _ k _ to some conservative, moderately large value. see section 6. 4 for more discussion on the overfitted case and empirical evidence that in this setting the improvement of _ p _ nr over the latter is particularly apparent. # # # * * 3 asymptotic variance comparison results * * in this section we compare the various kernels discussed above in terms of asymptotic variances. among other results we show that, after accounting for computational cost, _ p _ nr cannot be worse than _ p _ mg by more than a factor of 4. given a markov chain _ { x _ _ t _ _ } _ _ t _ with a _ π _ - invariant markov kernel _ p _ started in stationarity, the asymptotic variance of the associated mcmc estimator is given by = var _ π _ ( _ g _ ) + 2 _ ∞ _ cov ( _ g _ ( _ x _ 0 ) _, g _ ( _ x _ _ t _ ) ) _, _ _ t _ = 1 var ( _ g, p _ ) = lim _ t _ _ →∞ _ _ [ t ] _ [ var ] 1 _ t _ _ t _ _ g _ ( _ x _ _ t _ ) _ t _ = 1 for every function _ g _ such that var _ π _ ( _ g _ ) is well - defined. # # # # * * 3. 1 ordering of reversible and non - reversible schemes * * the next theorem provides ordering results for the asymptotic variances of _ p _ mg, _ p _ r and _ p _ nr. technically speaking these kernels are not directly comparable, since _ p _ mg and _ p _ r are defined on [ _ k _ ] _ [ n ] _ while _ p _ nr is defined on [ _ k _ ] _ [ n ] _ _ × { − _ 1 _, _ + 1 _ } _ _ [ k ] _ [ ( ] _ [ k ] [ − ] _ [ 1 ) ] _ [ / ] _ [ 2 ]. nonetheless, we are only interested in estimating expectations of test functions that depend on _ c _ alone, so that we can restrict attention to those, as usually done in non - reversible mcmc literature ( andrieu and livingstone, 2021 ; gagnon and maire, 2024b ). given a test function _ g _ : [ _ k _ ] _ [ n ] _ _ → _ r, with a slight abuse of notation, we also use _ g _ in var ( _ g, p _ nr ) to denote the function defined as _ g _ ( _ c, v _ ) = _ g _ ( _ c _ ) for all ( _ c, v _ ) _ ∈ _ [ _ k _ ] _ [ n ] _ _ × { − _ 1 _, _ + 1 _ } _ _ [ k ] _ [ ( ] _ [ k ] [ − ] _ [ 1 ) ] _ [ / ] _ [ 2 ]. * * theorem 3. 1. * * _ let π be a probability distribution on _ [ _ k _ ] _ [ n ] _ _ and g _ : [ _ k _ ] _ [ n ] _ _ → _ r _. then _ ( 14 ) _ var _ ( _ g, p _ nr ) _ ≤ _ _ var _ ( _ g, p _ r ) _ ≤ _ _ c _ ( _ k _ ) _ var _ ( _ g, p _ mg ) + [ _ c _ ( _ k _ ) _ − _ 1 ] _ var _ _ π _ ( _ g _ ) _, _ _ where c _ ( _ k _ ) = 2 ( _ k − _ 1 ) _ and var _ _ π _ ( _ g _ ) _ denotes var _ ( _ g _ ( _ x _ 0 ) ) _ for x _ 0 _ ∼ _ _ π. _ since in most realistic applications var ( _ g, p _ mg ) is much larger than var _ π _ ( _ g _ ), the inequality in ( 14 ) implies that _ p _ nr can be worse than _ p _ mg, in terms of variance of the associated estimators, only by a factor of 2 ( _ k − _ 1 ). moreover, since the cost per iteration of _ p _ mg is _ k / _ 2 times the one of _ p _ nr ( see section 2. 1 ) the overall worsening is at most by a factor of 4. 13 * * remark 3"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 16,
    "text": "_ ) _ − _ 1 ] _ var _ _ π _ ( _ g _ ) _, _ _ where c _ ( _ k _ ) = 2 ( _ k − _ 1 ) _ and var _ _ π _ ( _ g _ ) _ denotes var _ ( _ g _ ( _ x _ 0 ) ) _ for x _ 0 _ ∼ _ _ π. _ since in most realistic applications var ( _ g, p _ mg ) is much larger than var _ π _ ( _ g _ ), the inequality in ( 14 ) implies that _ p _ nr can be worse than _ p _ mg, in terms of variance of the associated estimators, only by a factor of 2 ( _ k − _ 1 ). moreover, since the cost per iteration of _ p _ mg is _ k / _ 2 times the one of _ p _ nr ( see section 2. 1 ) the overall worsening is at most by a factor of 4. 13 * * remark 3. 2. * * the proof of the second inequality in ( 14 ) relies on showing that _ p _ r ( _ c, c _ _ [ ′ ] _ ) _ ≥ _ _ c _ _ [ − ] _ [ 1 ] ( _ k _ ) _ p _ mg ( _ c, c _ _ [ ′ ] _ ) for every _ c _ = _ c _ _ [ ′ ] _, which means that the probability of changing state according to _ p _ r is not too low compared to the one of _ p _ mg. interestingly, the converse is not true, in the sense that there is no _ d > _ 0 independent from _ n _ such that _ p _ mg ( _ c, c _ _ [ ′ ] _ ) _ ≥ _ _ dp _ r ( _ c, c _ _ [ ′ ] _ ). indeed, let _ π _ be as in ( 4 ) with _ k _ = 3, _ * * α * * _ = ( 1 _, _ 1 _, _ 1 ) and _ f _ _ θ _ = _ f _. then if _ c _ = ( 1 _,..., _ 1 _, _ 2 _, _ 3 ) and _ c _ _ [ ′ ] _ = ( 1 _,..., _ 1 _, _ 2 _, _ 2 ) it is easy to see that 2 _ p _ mg ( _ c, c _ _ [ ′ ] _ ) = and _ p _ r ( _ c, c _ _ [ ′ ] _ ) = [ 1 ] _ n _ ( 3 + _ n − _ 1 ) 6 _ n _ _ [. ] _ the first inequality in ( 14 ) instead relies on extending classical asymptotic variance comparison results for lifted kernels to the case of state - dependent mixtures such as in _ p _ nr, as shown in section c. 1. 1 of the supplement. we stress that the results of theorem 3. 1 hold uniformly, in the sense that no assumptions on _ π _ are needed. thus using _ p _ nr is guaranteed to provide performances which never get significantly worse than the ones of _ p _ mg in terms of asymptotic variances. in the next sections, we will see that on the contrary _ p _ nr can lead to significant improvements ( e. g. by a factor of _ n _ ) relative to _ p _ mg. # # # # * * 3. 2 comparison with conditional sampler * * we now define the _ conditional _ sampler targeting _ π _ ( _ c, _ _ * * θ * * _ _, _ _ * * w * * _ ) mentioned in section 1. 2. the pseudocode is given in algorithm 7 and we denote with _ p _ cd the associated markov kernel on [ _ k _ ] _ [ n ] _ _ × _ θ _ [ k ] _ _ × _ ∆ _ k− _ 1. also here we consider the random - scan case, which allows for an easier comparison with _ p _ mg and _ p _ nr. we expect the main take - away messages to remain valid for the arguably more popular deterministic - scan scheme, even if theoretical results there are less neat ( see e. g. roberts and rosenthal ( 2015 ) ; he et al. ( 2016 ) ; gaitonde and mossel ( 2024 ) ; ascolani et al. ( 2024 ) and references therein ). the next proposition, whose proof is inspired by the one of ( liu, 1994, thm. 1 ), shows that _ p _ mg always yields a smaller asymptotic variance than _ p _ cd. again with an abuse of notation we use _ g _ to denote both _ g _ : [ _ k _ ] _ [ n ] _ _ → _ r and _ g _ : [ _ k _ ] _ [ n ] _ _ × _ θ _ [ k ] _ _"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 17,
    "text": "here we consider the random - scan case, which allows for an easier comparison with _ p _ mg and _ p _ nr. we expect the main take - away messages to remain valid for the arguably more popular deterministic - scan scheme, even if theoretical results there are less neat ( see e. g. roberts and rosenthal ( 2015 ) ; he et al. ( 2016 ) ; gaitonde and mossel ( 2024 ) ; ascolani et al. ( 2024 ) and references therein ). the next proposition, whose proof is inspired by the one of ( liu, 1994, thm. 1 ), shows that _ p _ mg always yields a smaller asymptotic variance than _ p _ cd. again with an abuse of notation we use _ g _ to denote both _ g _ : [ _ k _ ] _ [ n ] _ _ → _ r and _ g _ : [ _ k _ ] _ [ n ] _ _ × _ θ _ [ k ] _ _ × _ ∆ _ k− _ 1 _ → _ r function of the first argument alone. * * proposition 3. 3. * * _ let π be as in _ ( 3 ) _ and g _ : [ _ k _ ] _ [ n ] _ _ → _ r _. then for every f _ _ θ _ _, n, y we _ _ have that var _ ( _ g, p _ mg ) _ ≤ _ _ var _ ( _ g, p _ cd ) _. _ combined with theorem 3. 1, the above result implies that var ( _ g, p _ nr ) _ ≤ _ _ c _ ( _ k _ ) var ( _ g, p _ cd ) + [ _ c _ ( _ k _ ) _ − _ 1 ] var _ π _ ( _ g _ ), so that if _ p _ nr outperforms _ p _ mg then it should also be preferred to _ p _ cd. thus in the following we restrict to the comparison between _ p _ mg and _ p _ nr. 14 * * algorithm 7 * * ( conditional sampler _ p _ cd ) initialize ( _ c _ [ ( 0 ) ] _, _ _ * * θ * * _ [ ( 0 ) ] _, _ _ * * w * * _ [ ( 0 ) ] ) _ ∈ _ [ _ k _ ] _ [ n ] _ _ × _ θ _ [ k ] _ _ × _ ∆ _ k− _ 1 * * for * * _ t ≥ _ 1 * * do * * sample _ i ∼ _ unif ( _ { _ 1 _,..., n _ + 1 _ } _ ). * * if * * _ i ≤ _ _ n _ * * then * * sample _ c _ [ ( ] _ i _ _ [ t ] _ [ ) ] _ ∼ _ _ π _ ( _ c _ _ i _ _ | _ _ * * θ * * _ [ ( ] _ [ t ] [ − ] _ [ 1 ) ] _, _ _ * * w * * _ [ ( ] _ [ t ] [ − ] _ [ 1 ) ] ) with _ π _ ( _ c _ _ i _ = _ k | _ _ * * θ * * _ _, _ _ * * w * * _ ) = ~ ~ ~ ~ _ kk _ _ [ ′ ] _ _ w _ = 1 _ k _ _ f _ _ [ w ] _ _ θ _ _ [ k ] _ _ k _ _ [ ′ ] _ ( _ [ f ] _ _ y _ _ [ θ ] _ _ i _ _ k _ ) _ [ ′ ] _ [ ( ] _ [ y ] _ _ [ i ] _ [ ) ] _, _ _ k _ = 1 _,..., k. _ * * end if * * * * if * * _ i _ = _ n _ + 1 * * then * * sample _ * * w * * _ [ ( ] _ [ t ] _ [ ) ] _ ∼ _ dir _ α _ 1 + _ n _ 1 ( _ c _ [ ( ] _ [ t ] [ − ] _ [ 1 ) ] ) _,..., α _ _ k _ + _ n _ _ k _ ( _ c _ [ ( ] _ [ t ] [ − ] _ [ 1 ) ] ). sample _ θ _ _ k _ [ ( ] _ [ t ] _ [ ) ] _ [ ∼ ] _ _ [ π ] _ [ ( ] _ [ θ ] _ _ [ k ] _ _ [ | ] [ c ] _ [ ( ] _ [ t ] [ − ] _ [ 1 ) ] [ ) ] _ [ ∝ ] _ [ ] _ j _ : _ c _ [ ( ] _ j _ _ [ t ] [ − ] _ [ 1 ) ] = _ k _ _"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 18,
    "text": "* * then * * sample _ * * w * * _ [ ( ] _ [ t ] _ [ ) ] _ ∼ _ dir _ α _ 1 + _ n _ 1 ( _ c _ [ ( ] _ [ t ] [ − ] _ [ 1 ) ] ) _,..., α _ _ k _ + _ n _ _ k _ ( _ c _ [ ( ] _ [ t ] [ − ] _ [ 1 ) ] ). sample _ θ _ _ k _ [ ( ] _ [ t ] _ [ ) ] _ [ ∼ ] _ _ [ π ] _ [ ( ] _ [ θ ] _ _ [ k ] _ _ [ | ] [ c ] _ [ ( ] _ [ t ] [ − ] _ [ 1 ) ] [ ) ] _ [ ∝ ] _ [ ] _ j _ : _ c _ [ ( ] _ j _ _ [ t ] [ − ] _ [ 1 ) ] = _ k _ _ [ f ] _ _ [ θ ] _ _ [ k ] _ [ ( ] _ [ y ] _ _ [ j ] _ [ ) ] _ [ p ] _ [ 0 ] [ ( ] _ [ θ ] _ _ [ k ] _ [ ) for ] _ [ k ] _ [ = 1 ] _ [,..., k ] _ [. ] * * end if * * * * end for * * # # # * * 4 scaling limit analysis * * in this section we derive scaling limit results for _ p _ mg and _ p _ nr as _ n →∞ _. in general, given a sequence of discrete - time markov chains _ { x _ _ t _ [ ( ] _ [ n ] _ [ ) ] _ } _ _ t∈ _ n, scaling limit results ( gelman et al., 1997 ; roberts and rosenthal, 2001b ) consist in showing that a timechanged process _ { z _ _ t _ [ ( ] _ [ n ] _ [ ) ] _ } _ _ t∈ _ r defined as _ z _ _ t _ [ ( ] _ [ n ] _ [ ) ] = _ x _ _ [UNK] _ [ ( ] _ h _ _ [ n ] _ ( [ ) ] _ n _ ) _ t [UNK] _ [, with ] _ [ h ] _ [ ( ] _ [ n ] _ [ ) ] _ [ →∞ ] _ [ and ] _ [ [UNK] · [UNK] ] _ [ denoting ] the ceiling function, converges in a suitable sense to a non - degenerate process _ { z _ _ t _ _ } _ _ t∈ _ r + as _ n →∞ _. provided the limiting process is non - singular and ergodic, this is usually interpreted as suggesting that _ o _ ( _ h _ ( _ n _ ) ) iterations of the discrete - time markov chain are needed to mix. in other words, the time rescaling required to obtain a non - trivial limit is a measure of how the process speed scales as _ n _ grows. in order to derive such results we restrict to the prior case, where the likelihood is uninformative and the posterior distribution of _ c _ coincides with the prior ( 2 ). this can be formally described by setting _ f _ _ θ _ ( _ y _ ) = _ f _ ( _ y _ ), with _ f _ probability density on _ y _, so that the data do not provide any information on the labels. the joint distribution and full conditionals become _ k _ _ k _ = 1 [ γ ] [ ( ] _ [ α ] _ _ [ k ] _ [ + ] _ [ n ] _ _ [ k ] _ [ ( ] _ [ c ] _ [ ) ) ] ( 15 ) _ π _ ( _ c _ ) = _ | _ _ * * α * * _ _ | _ + _ n − _ 1 _ [, ] _ 1 [ γ ] [ ( ] _ [ α ] _ _ [ k ] _ [ + ] _ [ n ] _ _ [ k ] _ [ ( ] _ [ c ] _ [ ) ) ] _, _ _ π _ ( _ c _ _ i _ = _ k | c _ _ −i _ ) = _ [ α ] _ _ [ k ] _ [ + ] _ [ n ] _ _ [ k ] _ [ ( ] _ [ c ] _ _ [ − ] [ i ] _ [ ) ] γ ( _ | _ _ * * α * * _ _ | _ + _ n _ ) _ | _ _ * * α * * _ _ | _ + _ n − _ 1 with _ | _ _ * * α * * _ _ | _ = [ ] _ [ k ] _ _ k _ = 1 _ [ α ] _ _ [ k ] _ [. this is clearly a simplified setting, which allows an explicit math"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 19,
    "text": "_ 1 [ γ ] [ ( ] _ [ α ] _ _ [ k ] _ [ + ] _ [ n ] _ _ [ k ] _ [ ( ] _ [ c ] _ [ ) ) ] _, _ _ π _ ( _ c _ _ i _ = _ k | c _ _ −i _ ) = _ [ α ] _ _ [ k ] _ [ + ] _ [ n ] _ _ [ k ] _ [ ( ] _ [ c ] _ _ [ − ] [ i ] _ [ ) ] γ ( _ | _ _ * * α * * _ _ | _ + _ n _ ) _ | _ _ * * α * * _ _ | _ + _ n − _ 1 with _ | _ _ * * α * * _ _ | _ = [ ] _ [ k ] _ _ k _ = 1 _ [ α ] _ _ [ k ] _ [. this is clearly a simplified setting, which allows an explicit math - ] ematical treatment and it can be considered as an extreme case of un - identifiability and overlapping components ( which are indeed all the same ). extending the analysis 15 to the more realistic case of informative likelihood is an interesting direction for future research, see section 7 for more details. # # # # * * 4. 1 marginal sampler * * consider a markov chain _ { c _ [ ( ] _ [ t ] _ [ ) ] _ } _ _ t∈ _ n with kernel _ p _ mg and invariant distribution ( 15 ), where we suppress the dependence on _ n _ for simplicity. let _ x _ _ k _ ( _ c _ ) = _ [ n ] _ _ [ k ] _ [ ( ] _ [ c ] _ [ ) ] _ n _ [ ( ] _ [ c ] _ [ ) ] = [ 1 ] _ n _ _ n _ _ n _ 1 ( _ c _ _ i _ = _ k _ ) _, _ _ c ∈ _ [ _ k _ ] _ [ n ] _ _, _ _ i _ = 1 be the multiplicity of component _ k _ and ( 16 ) _ * * x * * _ _ t _ = ( _ x _ _ t, _ 1 _,..., x _ _ t, k _ ) = _ x _ 1 _ c _ [ ( ] _ [ t ] _ [ ) ] [ ] _,..., x _ _ k _ _ c _ [ ( ] _ [ t ] _ [ ) ] [ ] _. _ crucially, since _ π _ ( _ c _ _ i _ = _ k | c _ _ i _ ) defined in ( 15 ) only depends on the multiplicities, i. e. ( _ c _ 1 _,..., c _ _ n _ ) are exchangeable a priori, it follows that ( _ * * x * * _ _ t _ ) _ t _ = 0 _, _ 1 _, _ 2 _,... _ is itself a markov chain. moreover, _ { _ _ * * x * * _ _ t _ _ } _ _ t∈ _ n is de - initializing for _ { c _ [ ( ] _ [ t ] _ [ ) ] _ } _ _ t∈ _ n in the sense of roberts and rosenthal ( 2001a ), so that the convergence properties of the former are equivalent to the one of the latter ( by e. g. corollary 2 therein ). with an abuse of notation, we denote the kernel of _ { _ _ * * x * * _ _ t _ _ } _ _ t∈ _ n also as _ p _ mg. in the proof of theorem 4. 1 we show that e [ _ x _ _ t _ + 1 _, k _ _ − _ _ x _ _ k _ _ | _ _ * * x * * _ _ t _ = _ * * x * * _ ] = [ 2 ] _ n _ [ 2 ] _ α _ 2 _ k _ 2 _ [ k ] _ [ + ] _ [ o ] _ [ ( 1 ) ] _ α _ _ k _ 2 _ [ − | ] _ _ * * [ α ] * * _ _ [ | ] _ _ [ x ] _ 2 _ [ k ] _ and e ( _ x _ _ t _ + 1 _, k _ _ − _ _ x _ _ k _ ) [ 2 ] _ | _ _ * * x * * _ _ t _ = _ * * x * * _ = _ n _ [ 2 ] [ 2 ] [ [ ] _ [ x ] _ _ [ k ] _ [ ( 1 ] _ [ − ] _ _ [ x ] _ _ [ k ] _ [ ) + ] _ [ o ] _ [ ( 1 ) ] ] _ [, ] _ as _ n →∞ _"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 20,
    "text": "= _ * * x * * _ ] = [ 2 ] _ n _ [ 2 ] _ α _ 2 _ k _ 2 _ [ k ] _ [ + ] _ [ o ] _ [ ( 1 ) ] _ α _ _ k _ 2 _ [ − | ] _ _ * * [ α ] * * _ _ [ | ] _ _ [ x ] _ 2 _ [ k ] _ and e ( _ x _ _ t _ + 1 _, k _ _ − _ _ x _ _ k _ ) [ 2 ] _ | _ _ * * x * * _ _ t _ = _ * * x * * _ = _ n _ [ 2 ] [ 2 ] [ [ ] _ [ x ] _ _ [ k ] _ [ ( 1 ] _ [ − ] _ _ [ x ] _ _ [ k ] _ [ ) + ] _ [ o ] _ [ ( 1 ) ] ] _ [, ] _ as _ n →∞ _. the above suggests that a rescaling of order _ o _ ( _ n _ [ 2 ] ) is needed to have a non - trivial limit, as we will formally show below. in particular, let _ { _ _ * * z * * _ _ t _ _ } _ _ t∈ _ r + be the continuous - time process with generator _ [ ∂ ] _ _ g _ ( _ * * x * * _ ) + [ 1 ] _ ∂x _ _ k _ 2 2 _ ∂x _ _ k _ _ ∂x _ _ k _ _ ′ _ _ [ g ] _ [ ( ] _ * * [ x ] * * _ [ ) ] _ [, ] _ ( 17 ) _ ag _ ( _ * * x * * _ ) = [ 1 ] 2 _ k _ ( _ α _ _ k _ _ − | _ _ * * α * * _ _ | x _ _ k _ ) _ ∂x _ _ [ ∂ ] _ _ k _ = 1 _ ∂ _ [ 2 ] _ x _ _ k _ ( _ δ _ _ kk _ _ ′ _ _ − _ _ x _ _ k _ _ ′ _ ) _ ∂x _ _ k _ _ k, k _ _ [ ′ ] _ = 1 _ k _ for every _ g _ : ∆ _ k− _ 1 _ → _ r twice differentiable and where _ * * x * * _ = ( _ x _ 1 _,..., x _ _ k _ ). such process exists ( ethier, 1976 ) and is called wright - fisher with mutation rates given by _ * * α * * _. in particular, _ { _ _ * * z * * _ _ t _ _ } _ _ t∈ _ r + is a diffusion taking values in ∆ _ k− _ 1 whose stationary density is exactly _ π _ ( _ * * x * * _ ) = dir ( _ * * x * * _ _ | _ _ * * α * * _ ). the next theorem shows that, choosing _ h _ ( _ n _ ) = _ n _ [ 2 ] _ / _ 2, the continuous - time rescaling of _ { _ _ * * x * * _ _ t _ _ } _ _ t∈ _ n converges to _ { _ _ * * z * * _ _ t _ _ } _ _ t∈ _ r +. 16 * * theorem 4. 1. * * _ let { _ _ * * z * * _ _ t _ [ ( ] _ [ n ] _ [ ) ] _ } _ _ t∈ _ r + _ such that _ _ * * z * * _ _ t _ [ ( ] _ [ n ] _ [ ) ] = _ * * x * * _ _ [UNK] _ _ n _ 22 _ [ t ] [ [UNK] ] _ _ [, where ] [ { ] _ _ * * [ x ] * * _ _ [ t ] _ _ [ } ] _ _ [ t ] [ ∈ ] _ [ n ] _ [ is the markov ] _ _ chain in _ ( 16 ) _ with kernel p _ mg _ and invariant distribution π as in _ ( 15 ) _. let { _ _ * * z * * _ _ t _ _ } _ _ t∈ _ r + _ be a diffusion with generator as in _ ( 17 ) _. then if _ _ * * z * * _ 0 [ ( ] _ [ n ] _ [ ) ] _ → _ _ * * z * * _ 0 _ weakly as n →∞, we have _ _ that { _ _ * * z * * _ _ t _ [ ( ] _ [ n ] _ [ ) ] _ } _ _ t∈ _ r + _ → { _ _ * * z * * _ _ t _ _ } _ _ t∈ _ r + _ weakly as n →∞"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 21,
    "text": "] * * _ _ [ t ] _ _ [ } ] _ _ [ t ] [ ∈ ] _ [ n ] _ [ is the markov ] _ _ chain in _ ( 16 ) _ with kernel p _ mg _ and invariant distribution π as in _ ( 15 ) _. let { _ _ * * z * * _ _ t _ _ } _ _ t∈ _ r + _ be a diffusion with generator as in _ ( 17 ) _. then if _ _ * * z * * _ 0 [ ( ] _ [ n ] _ [ ) ] _ → _ _ * * z * * _ 0 _ weakly as n →∞, we have _ _ that { _ _ * * z * * _ _ t _ [ ( ] _ [ n ] _ [ ) ] _ } _ _ t∈ _ r + _ → { _ _ * * z * * _ _ t _ _ } _ _ t∈ _ r + _ weakly as n →∞, according to the skorokhod topology. _ * * remark 4. 2. * * the proof relies on convergence of generators, which is a standard technique when dealing with sequences of stochastic processes : we refer to ( ethier and kurtz, 1986, chapter 4 ) for details. while this approach is common in the mcmc literature ( see e. g. gelman et al. ( 1997 ) ; roberts and rosenthal ( 2001b ) and related works ), we are not aware of applications of it to mixture model contexts. on the contrary, the wright - fisher process often arises as the scaling limit of models for populations subjected to genetic drift and mutation ( ethier and kurtz, 1986 ; etheridge, 2011 ). connections between sampling schemes and diffusions in population genetics have been also explored in other context, especially for sequential monte carlo techniques ( koskela et al., 2020 ; brown et al., 2021 ). * * remark 4. 3. * * theorem 4. 1 suggests that _ o _ ( _ n _ [ 2 ] ) iterations are needed for _ p _ mg to converge. this is coherent with khare and zhou ( 2009, prop. 14. 10. 1 ) where, albeit motivated by a different problem, the authors show that, when targeting the prior distribution _ π _ ( _ c _ ) in ( 15 ), the second largest eigenvalue of _ p _ mg is _ | _ _ * * α * * _ _ | _ 1 _ − _ _ n _ ( _ n _ + _ | _ _ * * α * * _ _ | − _ 1 ) _ [. ] _ this implies that the so - called relaxation time of _ p _ mg scales as _ o _ ( _ n _ [ 2 ] ) as _ n →∞ _, which means that _ o _ ( _ n _ [ 2 ] ) iterations are required to mix ; see e. g. levin and peres ( 2017, thm. 12. 5 ) for more details on relaxation times. in order to see why an _ o _ ( _ n _ [ 2 ] ) convergence is slower than desired, consider for example the case _ k _ = 2. then _ { x _ _ t, _ 1 _ } _ _ t∈ _ n is a markov chain on _ { _ 0 _, _ 1 _ / n,..., _ 1 _ } _ and thus _ p _ mg requires _ n _ [ 2 ] iterations to sample from a distribution on a state space with cardinality _ n _. moreover, _ { x _ _ t, _ 1 _ } _ _ t∈ _ n can be seen as a random walk with transition probabilities p _ x _ _ t _ + 1 _, _ 1 = _ x _ 1 + [ 1 ] _ n _ _ [ | ] [ x ] _ _ [ t, ] _ [ 1 ] [ = ] _ [ x ] _ [ 1 ] _ α _ 1 + _ nx _ 1 = ( 1 _ − _ _ x _ 1 ) _ α _ 1 + _ α _ 2 + _ n − _ 1 _ [ ≈ ] _ _ [ x ] _ [ 1 ] [ ( 1 ] _ [ − ] _ _ [ x ] _ [ 1 ] [ ) ] and p _ x _ _ t _ + 1 _, _ 1 = _ x _ 1 _ − _ [ 1 ] _ n _ _ [ | ] [ x ] _ _ [ t, ] _ [ 1 ] [ = ] _ [ x ] _ [ 1 ] _ α _ 2 + _ n _ ( 1 _ − _ _ x _ 1 ) = _ x _ 1 _ α _ 1 + _ α _ 2 + _ n − _ 1 _ [ ≈ ] _ _ [ x ] _ [ 1 ] [ ( 1 ] _ [ − ] _ _ [ x ] _ [ 1 ] ["
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 22,
    "text": "[ x ] _ [ 1 ] _ α _ 1 + _ nx _ 1 = ( 1 _ − _ _ x _ 1 ) _ α _ 1 + _ α _ 2 + _ n − _ 1 _ [ ≈ ] _ _ [ x ] _ [ 1 ] [ ( 1 ] _ [ − ] _ _ [ x ] _ [ 1 ] [ ) ] and p _ x _ _ t _ + 1 _, _ 1 = _ x _ 1 _ − _ [ 1 ] _ n _ _ [ | ] [ x ] _ _ [ t, ] _ [ 1 ] [ = ] _ [ x ] _ [ 1 ] _ α _ 2 + _ n _ ( 1 _ − _ _ x _ 1 ) = _ x _ 1 _ α _ 1 + _ α _ 2 + _ n − _ 1 _ [ ≈ ] _ _ [ x ] _ [ 1 ] [ ( 1 ] _ [ − ] _ _ [ x ] _ [ 1 ] [ ) ] _ [, ] _ when _ n _ is large. thus the probability of going up and down is almost the same, leading to the observed random - walk behaviour. this is reminiscent of classical examples studied in the non - reversible mcmc literature ( diaconis et al., 2000 ), where a faster algorithm is devised by considering a lifted version of the standard random walk. 17 # # # # 4. 2 non - reversible sampler p nr consider now a markov chain _ { c _ [ ( ] _ [ t ] _ [ ) ] _, v _ [ ( ] _ [ t ] _ [ ) ] _ } _ _ t∈ _ n with kernel _ p _ nr and invariant distribution ( 15 ). define _ * * x * * _ _ t _ as in ( 16 ) and _ * * v * * _ _ t _ = _ v _ _ t, k, k _ _ ′ _ [ ] ( _ k, k _ _ [ ′ ] _ ) _ ∈ _ [ _ k _ ] [ 2 ] [ as ] _ _ _ _ 0 if _ k _ = _ k _ _ [ ′ ] _ _ _ _ _ _ v _ _ ′ _ = _ t, k, k _ _ _ _ _ _ _ _ _ _ v _ [ ( ] _ [ t ] _ [ ) ] if _ k < k _ _ [ ′ ] _ _ k, k _ _ [ ′ ] _ _ _ _ _ _ −v _ [ ( ] _ [ t ] _ [ ) ] if _ k > k _ _ [ ′ ] _ _. _ _ k _ _ [ ′ ] _ _, k _ _ _ _ _ this means that _ v _ _ t, k _ _ ′ _ _, k _ = + 1 implies that we are proposing from cluster _ k _ _ [ ′ ] _ to _ k _, for every pair ( _ k, k _ _ [ ′ ] _ ). this allows for a simpler statement in the theorem to follow. by exchangeability arguments as above, it is simple to see that _ { _ ( _ * * x * * _ _ t _ _, _ _ * * v * * _ _ t _ ) _ } _ _ t∈ _ n is de - initializing for _ { c _ [ ( ] _ [ t ] _ [ ) ] _, v _ [ ( ] _ [ t ] _ [ ) ] _ } _ _ t∈ _ n and thus it has the same convergence properties. in the proof of theorem 4. 4 we show that _ _ _ _ _ k − _ 1 [ + ] _ [ o ] _ [ ( 1 ) ] _ _ _ _ e [ _ x _ _ t _ + 1 _, k _ _ − _ _ x _ _ k _ _ | _ _ * * x * * _ _ t _ = _ * * x * * _ _, _ _ * * v * * _ _ t _ = _ v _ ] = [ 1 ] _ n _ _ _ _ _ _ _ _ _ _ k _ _ [ ′ ] _ : _ v _ _ k ′, k _ _ _ _ _ _ x _ _ k _ + _ x _ _ k _ _ ′ _ _ _ _ _ _ _ _ _ _, _ _ _ _ _ _ k _ _ [ ′ ] _ : _ v _ _ k ′, k _ = + 1 _ _ _ _ _ xk _ _ k _ + _ − x _ 1 _ k _ _ ′ _ _ [ − ] _ _ k _ _ [ ′ ] _ : _ v _ _ k ′, k _ = _ − _ 1 _ _ _ _ which suggest that rescaling time by _ n _ is sufficient for a non - trivial limit. a technical issue is that, when _ x _ _ t, k _ = 0 for some _ k"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 23,
    "text": ", _ _ * * v * * _ _ t _ = _ v _ ] = [ 1 ] _ n _ _ _ _ _ _ _ _ _ _ k _ _ [ ′ ] _ : _ v _ _ k ′, k _ _ _ _ _ _ x _ _ k _ + _ x _ _ k _ _ ′ _ _ _ _ _ _ _ _ _ _, _ _ _ _ _ _ k _ _ [ ′ ] _ : _ v _ _ k ′, k _ = + 1 _ _ _ _ _ xk _ _ k _ + _ − x _ 1 _ k _ _ ′ _ _ [ − ] _ _ k _ _ [ ′ ] _ : _ v _ _ k ′, k _ = _ − _ 1 _ _ _ _ which suggest that rescaling time by _ n _ is sufficient for a non - trivial limit. a technical issue is that, when _ x _ _ t, k _ = 0 for some _ k _ then one of the velocities jumps deterministically to _ v _ _ t, k _ _ ′ _ _, k _ = + 1 with _ k _ _ [ ′ ] _ = _ _ _ k _. to avoid complications related to such boundary effects, we study the scaling of the process in the set _ e _ _ m _ _ × v _ = _ * * x * * _ _ ∈ _ ∆ _ k− _ 1 _ | x _ _ k _ _ > _ [ 1 ] _ × { − _ 1 _, _ 0 _, _ + 1 _ } _ [ [ ] _ [ k ] _ [ ] ] [ 2 ] _, _ _ m _ [ for every ] _ [ k ] _ with _ m > _ 0 arbitrarily large but fixed. _ _ _ _ let _ * * z * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] _ _ _ _ _ t∈ _ r + [ be a piecewise deterministic markov process ] _ _ _ _ _ * * z * * _ [ ( ] _ [ m ] _ [ ) ] _ t∈ _ r + [ = ] 1 _, t _ _ [, ] _ _ * * [ z ] * * _ 2 [ ( ] _ [ m ] _ _, t _ [ ) ] _ _ _ _ ( davis, 1984 ) on _ e _ _ m _ _ ×v _ defined as follows. consider a inhomogeneous poisson process λ _ t _ with rate _ _ _ _ 1 ( 18 ) _ λ _ _ * * z * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] = 2 ( _ k − _ 1 ) _ _ where _ _ _ k _ = _ _ _ k _ _ [ ′ ] _ _ _ _ z _ 1 [ ( ] _ [ m ] _ _, t, k _ [ ) ] [ + ] _ [ z ] _ 1 [ ( ] _ [ m ] _ _, t, k _ [ ) ] _ [ ′ ] _ _ β _ _ z _ 1 [ ( ] _ [ m ] _ _, t, k _ [ ) ] _ [, z ] _ 1 [ ( ] _ [ m ] _ _, t, k _ [ ) ] _ [ ′ ] _ _ [, z ] _ 2 [ ( ] _ [ m ] _ _, t, k, k _ [ ) ] _ [ ′ ] _ + 2 _ ξ, _ _ _ _ _ _ _ _ β _ ( _ x _ _ k _ _, x _ _ k _ _ ′ _ _, v _ _ k _ _ ′ _ _, k _ ) = max 0 _, _ _ [ α ] _ _ [ k ] _ _ [ − ] _ _ [ − ] _ [ 1 ] _ x _ _ k _ _ − _ _ _ _ _ _ x _ _ k _ + _ _ _ _ _ [ − ] _ _ [ − ] _ [ 1 ] + [ 1 ] _ [ − ] _ _ [ α ] _ _ [ k ] _ [ + ] _ x _ _ k _ _ − _ _ x _ _ k _ _ _ _ _ _ _ _ _ with _ k _ _ − _ = _ k _ _ [ ′ ] _ and _ k _ + = _ k _ if _ v _ _ k _ _ ′ _ _, k _ = + 1 and viceversa if _ v _ _ k _ _ ′ _ _, k _ = _ − _ 1. in between events, 18 _ { _ _ * * z * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] _ } _ _ t∈ _ r + evolves deterministically as ( 19 ) d _ z _ [ ( ] _ [ m ] _ [ ) ] 1 _, t, k _ = φ _ k _"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 24,
    "text": "_ _ _ _ _ [ − ] _ _ [ − ] _ [ 1 ] + [ 1 ] _ [ − ] _ _ [ α ] _ _ [ k ] _ [ + ] _ x _ _ k _ _ − _ _ x _ _ k _ _ _ _ _ _ _ _ _ with _ k _ _ − _ = _ k _ _ [ ′ ] _ and _ k _ + = _ k _ if _ v _ _ k _ _ ′ _ _, k _ = + 1 and viceversa if _ v _ _ k _ _ ′ _ _, k _ = _ − _ 1. in between events, 18 _ { _ _ * * z * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] _ } _ _ t∈ _ r + evolves deterministically as ( 19 ) d _ z _ [ ( ] _ [ m ] _ [ ) ] 1 _, t, k _ = φ _ k _ _ * * z * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] d _ t _ _ _ 1 = _ k − _ 1 _ _ _ _ _ k _ _ [ ′ ] _ : _ z _ [ ( ] _ [ m ] _ [ ) ] 2 _ [ ′ ] _ _ _ _ z _ [ ( ] _ [ m ] _ [ ) ] 1 _, t, k _ [ + ] _ [ z ] _ 1 [ ( ] _ [ m ] _ _, t, k _ [ ) ] _ [ ′ ] _ _ _ _ k _ _ [ ′ ] _ : _ z _ [ ( ] _ [ m ] _ [ ) ] 2 _, t, k _ _ [ ′ ] _ _, k _ [ = + 1 ] _ _ _ z _ [ ( ] _ [ m ] _ [ ) ] _ − _ 1 _, t, k _ [ + ] _ [ z ] _ 1 [ ( ] _ [ m ] _ _, t, k _ [ ) ] _ [ ′ ] _ _ k _ _ [ ′ ] _ : _ z _ [ ( ] _ [ m ] _ [ ) ] 2 _, t, k _ _ [ ′ ] _ _, k _ [ = ] _ [ − ] _ [ 1 ] _ _ and d _ z _ [ ( ] _ [ m ] _ [ ) ] 2 d _, t _ _ t _ _, k _ _ [ ′ ] _ _, k _ = 0 _, _ with ( _ k _ _ [ ′ ] _ _, k _ ) _ ∈ _ [ _ k _ ] [ 2 ]. the system of differential equations in ( 19 ) admits a unique solution by linearity in its arguments. instead, at each event of λ _ t _, say at _ τ > _ 0, a pair ( _ k, k _ _ [ ′ ] _ ) _ ∈ _ [ _ k _ ] [ 2 ] is selected with probability _ _ _ z _ [ ( ] _ [ m ] _ [ ) ] _ q _ ( _ k, k _ _ [ ′ ] _ ) _ ∝ _ 1 _, t, k _ [ + ] _ [ z ] _ 1 [ ( ] _ [ m ] _ _, t, k _ [ ) ] _ [ ′ ] _ 2 ( _ k − _ 1 ) _ _ _ β _ _ z _ 1 [ ( ] _ [ m ] _ _, τ _ _ − _ [ ) ] _, k _ _ [, z ] _ 1 [ ( ] _ [ m ] _ _, τ _ _ − _ [ ) ] _, k _ _ [ ′ ] _ _ [, z ] _ 2 [ ( ] _ [ m ] _ _, τ _ _ − _ [ ) ] _, k _ _ [ ′ ] _ _, k _ + 2 _ ξ _ 1 ( _ k _ = _ k _ _ [ ′ ] _ ) _ _ and then the process jumps as follows : ( 20 ) _ z _ 2 [ ( ] _ [ m ] _ _, τ, k _ [ ) ] _ [ ′ ] _ _, k _ [ = ] _ [ − ] [ z ] _ 2 [ ( ] _ [ m ] _ _, τ _ _ − _ [ ) ] _, k _ _ [ ′ ] _ _, k _ and _ z _ 2 [ ( ] _ [ m ] _ _, τ, k, k _ [ ) ] _ [ ′ ] _ [ = ] _ [ − ] [ z ] _ 2 [ ( ] _ [ m ] _ _, τ _ _ − _ [ ) ] _, k, k _ _ [ ′ ] _ _ [, ] _ where _ τ _ _ − _ denotes the the left - limit at _ τ _. it follows that _ *"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 25,
    "text": "_ 1 ( _ k _ = _ k _ _ [ ′ ] _ ) _ _ and then the process jumps as follows : ( 20 ) _ z _ 2 [ ( ] _ [ m ] _ _, τ, k _ [ ) ] _ [ ′ ] _ _, k _ [ = ] _ [ − ] [ z ] _ 2 [ ( ] _ [ m ] _ _, τ _ _ − _ [ ) ] _, k _ _ [ ′ ] _ _, k _ and _ z _ 2 [ ( ] _ [ m ] _ _, τ, k, k _ [ ) ] _ [ ′ ] _ [ = ] _ [ − ] [ z ] _ 2 [ ( ] _ [ m ] _ _, τ _ _ − _ [ ) ] _, k, k _ _ [ ′ ] _ _ [, ] _ where _ τ _ _ − _ denotes the the left - limit at _ τ _. it follows that _ * * z * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] _ t∈ _ r + [ is a continuous - ] time process with generator ( 21 ) _ _ _ q _ ( _ k, k _ _ [ ′ ] _ ) _ g _ ( _ * * z * * _ * * ( * * _ * * k, k * * _ _ * * ′ * * _ * * ) * * ) _ − _ _ g _ ( _ * * z * * _ ) _ k _ = _ _ _ k _ _ [ ′ ] _ _ _ _ [, ] _ _ b _ [ ( ] _ [ m ] _ [ ) ] _ g _ ( _ * * z * * _ ) = 1 ( _ * * z * * _ 1 _ ∈ _ _ e _ _ m _ ) _ _ _ _ _ k _ _ _ _ ∂ _ _ k _ = 1 φ _ k _ ( _ * * z * * _ ) _ ∂z _ 1 _, k _ _ g _ ( _ * * z * * _ ) + _ λ _ ( _ * * z * * _ ) _ k _ = _ _ _ k _ _ _ for every _ g _ : _ e _ _ m _ _ × v → _ r twice continuously differentiable in the first argument, where _ * * z * * _ [ ( ] _ [ k, k ] _ _ [ ′ ] _ [ ) ] _ ∈ _ _ e _ _ m _ _ × v _ is equal to _ * * z * * _ except for _ * * z * * _ [ ( ] _ [ k, k ] _ _ [ ′ ] _ [ ) ] 2 _, k, k _ _ [ ′ ] _ [ = ] _ [ − ] _ _ * * [ z ] * * _ 2 [ ( ] _ [ k, k ] _ _, k _ _ [ ′ ] _ _, k _ _ [ ′ ] _ [ ) ] [ = ] _ [ − ] _ _ * * [ z ] * * _ [ 2 ] _ [, k, k ] _ _ [ ′ ] _ _ [. ] _ such a process exists for every _ m > _ 0 since the rates _ λ _ ( _ * * z * * _ ) are bounded ( davis, 1984 ). we can think of _ * * z * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] _ t∈ _ r + [ as a process with an absorbing boundary, which remains ] constant as soon as _ z _ [ ( ] _ [ m ] _ [ ) ] 1 _, t, k _ _ [ ≤ ] _ [ 1 ] _ [ / m ] _ [ for some ] _ [ k ] _ [. ] analogously, define _ * * x * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] _, _ _ * * v * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] _ t∈ _ n [ as a modification of ] _ [ { ] _ _ * * [ x ] * * _ _ [ t ] _ _ [, ] _ _ * * [ v ] * * _ _ [ t ] _ _ [ } ] _ _ [ t ] [ ∈ ] _ [ n ] [, which re - ] mains constant as soon as _ x _ _ t, k _ [ ( ] _ [ m ] _ [ ) ] _ ≤ _ 1 _ / m _ for some _ k _. the next theorem shows that, _ _ choosing _ h _ ( _ n _ ) = _ n _, the continuous - time rescaling of _ * * x * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] _, _ _ * * v * * _ _ t"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 26,
    "text": "_ [ ) ] _, _ _ * * v * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] _ t∈ _ n [ as a modification of ] _ [ { ] _ _ * * [ x ] * * _ _ [ t ] _ _ [, ] _ _ * * [ v ] * * _ _ [ t ] _ _ [ } ] _ _ [ t ] [ ∈ ] _ [ n ] [, which re - ] mains constant as soon as _ x _ _ t, k _ [ ( ] _ [ m ] _ [ ) ] _ ≤ _ 1 _ / m _ for some _ k _. the next theorem shows that, _ _ choosing _ h _ ( _ n _ ) = _ n _, the continuous - time rescaling of _ * * x * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] _, _ _ * * v * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] _ _ choosing _ h _ ( _ n _ ) = _ n _, the continuous - time rescaling of _ * * x * * _ _ t _ _, _ _ * * v * * _ _ t _ _ t∈ _ n [ converges to ] _ * * z * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] _ t _ r [. ] _ _ _ t∈ _ r + [. ] _ _ 19 * * theorem 4. 4. * * _ fix m > _ 0 _ and let _ _ * * z * * _ _ t _ [ ( ] _ [ m, n ] _ [ ) ] _ t∈ _ r + _ [ such that ] _ _ * * [ z ] * * _ _ t _ [ ( ] _ [ m, n ] _ [ ) ] = _ * * x * * _ _ [UNK] _ [ ( ] _ nt _ _ [ m ] _ _ [UNK] _ [ ) ] _ [, ] _ _ * * [ v ] * * _ _ [UNK] _ [ ( ] _ nt _ _ [ m ] _ _ [UNK] _ [ ) ] _, _ _ where { _ _ * * x * * _ _ t _ _, _ _ * * v * * _ _ t _ _ } _ _ t∈ _ n _ is a markov chain with operator p _ nr _ and invariant distribution _ _ as in _ ( 11 ) _, with π in _ ( 15 ) _. _ _ let _ _ * * z * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] _ t∈ _ r + _ [ be a piecewise deterministic markov ] _ _ process with generator _ ( 21 ) _. then if _ _ * * z * * _ 0 [ ( ] _ [ m, n ] _ [ ) ] _ → _ _ * * z * * _ 0 [ ( ] _ [ m ] _ [ ) ] _ weakly as n →∞, we have that _ _ * * z * * _ _ t _ [ ( ] _ [ m, n ] _ [ ) ] _ * * z * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] _ t∈ _ r + _ [ → ] _ _ t∈ _ r + _ [ weakly as ] [ n ] [ →∞ ] [, according to the skorokhod topology. ] _ * * remark 4. 5. * * looking at the process only in the interior of the simplex is inspired by other works on diffusion approximations, see e. g. barton et al. ( 2004 ) where they use a similar technique to deal with explosive behaviour in the boundary. if _ α _ _ k _ _ > _ 1 for every _ k _, we could proceed as in theorem 4 _. _ 2 therein to show that the boundary is never reached and thus the limit can be extended to the whole space. theorem 4. 4 suggests that the overall computational cost of algorithm 6 is _ o _ ( _ n _ ) and, combined with theorem 4. 1, this suggest an _ o _ ( _ n _ ) speed - up relative to _ p _ mg in the prior case. in section 6 we will show empirically that large improvements are also present in more realistic and interesting settings where the likelihood is informative. # # # 5 a variant of p nr the kernels _ p _ r and _ p _ nr sample a new pair ( _ k, k _ _ [ ′ ] _ ) at every iteration. while this is natural and allows for direct theoretical comparisons with _ p _ mg ( see theorem 3. 1 ), an alternative in the non - reversible case is to keep the same value of ( _ k, k _ _ [ ′ ] _ ) for multiple iterations. we thus define the"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 27,
    "text": "therein to show that the boundary is never reached and thus the limit can be extended to the whole space. theorem 4. 4 suggests that the overall computational cost of algorithm 6 is _ o _ ( _ n _ ) and, combined with theorem 4. 1, this suggest an _ o _ ( _ n _ ) speed - up relative to _ p _ mg in the prior case. in section 6 we will show empirically that large improvements are also present in more realistic and interesting settings where the likelihood is informative. # # # 5 a variant of p nr the kernels _ p _ r and _ p _ nr sample a new pair ( _ k, k _ _ [ ′ ] _ ) at every iteration. while this is natural and allows for direct theoretical comparisons with _ p _ mg ( see theorem 3. 1 ), an alternative in the non - reversible case is to keep the same value of ( _ k, k _ _ [ ′ ] _ ) for multiple iterations. we thus define the following, non - reversible and [UNK] _ π _ - invariant kernel _ * * z * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] _ t∈ _ r + _ [ → ] _ _ t∈ _ r + _ [ weakly as ] [ n ] [ →∞ ] [, according to the skorokhod topology. ] _ _ ∞ _ _ q _ _ m _ _ c _ ( _ k, k _ _ ′ _ ) ( _ t _ ) _ p _ [ [UNK] ] _ k, k _ _ [ t ] _ _ [ ′ ] _ _ [, ] _ _ t _ = 1 ( 22 ) _ q _ nr = ( _ k, k _ _ [ ′ ] _ ) _ ∈k _ 2 _ k _ ( _ k − _ 1 ) with _ m _ _ c _ ( _ k, k _ _ [ ′ ] _ ) = ( _ n _ _ k _ ( _ c _ ) + _ n _ _ k _ _ ′ _ ( _ c _ ) ) _ / s _ for some fixed _ s ∈ _ ( 0 _, _ 1 ) and _ q _ _ m _ ( _ t _ ) being the probability mass function of a geometric random variable with parameter 1 _ / m _. the algorithm picks a couple ( _ k, k _ _ [ ′ ] _ ) uniformly at random and then takes a random number of steps of the lifted kernel _ p _ [ [UNK] ] _ kk _ _ ′ _, with average number of steps proportional to the total number of points in the two clusters, i. e. _ n _ _ k _ ( _ c _ ) + _ n _ _ k _ _ ′ _ ( _ c _ ). the associated pseudo - code is presented in algorithm 8. reasoning as in lemma 2. 3 it is easy to see that _ q _ nr is * * algorithm 8 * * modified non - reversible sampler ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) _ ∼ _ _ q _ nr ( ( _ c, v _ ) _, · _ ) sample ( _ k, k _ _ [ ′ ] _ ) _ ∼ _ unif ( _ k _ ) sample _ t ∼ _ geom ( _ s / _ ( _ n _ _ k _ ( _ c _ ) + _ n _ _ k _ _ ′ _ ( _ c _ ) ) ) for some fixed _ s ∈ _ ( 0 _, _ 1 ) sample ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) _ ∼ _ _ p _ [ [UNK] ] _ k, k _ _ [ t ] _ _ [ ′ ] _ [ ( ( ] _ [ c, v ] _ [ ) ] _ [, ] [ · ] _ [ ) ] _ π _ [UNK] - invariant and uniformly ergodic, as stated in the next lemma. 20 * * lemma 5. 1. * * _ for any probability distribution π on _ [ _ k _ ] _ [ n ] _ _, the markov kernel q _ nr _ de - _ _ fined in algorithm 8 is _ [UNK] _ π - invariant, with _ [UNK] _ π as in _ ( 11 ) _. moreover, if π _ ( _ c _ ) _ > _ 0 _ for every _ _ c ∈ _ [ _ k _ ] _ [ n ] _ _, then q _ nr _ is irreducible, aperiodic and uniformly ergodic. _ the distinction with the main algorithm is that _ p _ nr resamples the pair ( _ k, k _ _ [ ′ ] _ ) at each iteration with probability proportional to _ n _ _ k _ ( _ c _ ) + _ n _ _ k _ _ ′ _ ( _ c _ ), while _ q _ nr keeps the same ( _ k, k _ _ [ ′ ]"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 28,
    "text": "next lemma. 20 * * lemma 5. 1. * * _ for any probability distribution π on _ [ _ k _ ] _ [ n ] _ _, the markov kernel q _ nr _ de - _ _ fined in algorithm 8 is _ [UNK] _ π - invariant, with _ [UNK] _ π as in _ ( 11 ) _. moreover, if π _ ( _ c _ ) _ > _ 0 _ for every _ _ c ∈ _ [ _ k _ ] _ [ n ] _ _, then q _ nr _ is irreducible, aperiodic and uniformly ergodic. _ the distinction with the main algorithm is that _ p _ nr resamples the pair ( _ k, k _ _ [ ′ ] _ ) at each iteration with probability proportional to _ n _ _ k _ ( _ c _ ) + _ n _ _ k _ _ ′ _ ( _ c _ ), while _ q _ nr keeps the same ( _ k, k _ _ [ ′ ] _ ) for _ o _ ( _ n _ _ k _ ( _ c _ ) + _ n _ _ k _ _ ′ _ ( _ c _ ) ) iterations and then resamples the pair ( _ k, k _ _ [ ′ ] _ ) uniformly from _ k _. indeed we expect _ p _ nr and _ q _ nr to perform similarly for fixed values of _ k _, but we empirically observe that _ q _ nr tends to yield slower mixing as _ k _ increases : see section a in the supplementary material for a simulative comparison in the prior case. this motivated us to focus on _ p _ nr as the main scheme of interest in this paper. * * remark 5. 2. * * in the prior case of section 4, where the invariant distribution is given by ( 15 ), it is possible to find a corresponding scaling limit for _ q _ nr. the proof is analogous to the case of _ p _ nr and we omit it for brevity, just limiting ourselves to identifying the candidate limit and discussing its implications. consider a markov chain _ { _ ( _ * * x * * _ _ t _ _, _ _ * * v * * _ _ t _ ) _ } _ _ t∈ _ n with kernel _ q _ nr. with similar calculations as in theorem 4. 4, the process _ * * z * * _ _ t _ [ ( ] _ [ m, n ] _ [ ) ] _ t∈ _ r + [ defined as ] _ * * [ z ] * * _ _ t _ [ ( ] _ [ m, n ] _ [ ) ] = _ * * x * * _ _ [UNK] _ [ ( ] _ nt _ _ [ m ] _ _ [UNK] _ [ ) ] _ [, ] _ _ * * [ v ] * * _ _ [UNK] _ [ ( ] _ nt _ _ [ m ] _ _ [UNK] _ [ ) ] can be shown to converge to _ { _ _ * * z * * _ _ t _ _ } _ _ t∈ _ r + with generator _ ∂ _ _ ∂ _ _ c _ [ ( ] _ [ m ] _ [ ) ] _ g _ ( _ * * z * * _ ) = 1 ( _ * * z * * _ 1 _ ∈ _ _ e _ _ m _ ) _ g _ ( _ * * z * * _ ) _ − _ _ g _ ( _ * * z * * _ ) _ ∂z _ 1 _, k _ + _ ∂z _ 1 _, k _ _ − _ _ _ + max 0 _, _ _ [ α ] _ _ [ k ] _ _ [ − ] _ _ [ − ] _ [ 1 ] _ z _ 1 _, k _ _ − _ _ _ _ z _ 1 _, k _ + _ _ _ [ k ] _ _ [ − ] _ _ [ − ] _ [ 1 ] + [ 1 ] _ [ − ] _ _ [ α ] _ _ [ k ] _ [ + ] _ z _ 1 _, k _ _ − _ _ z _ 1 _, k _ + _ _ [ _ g _ ( _ * * z * * _ 1 _, − _ _ * * z * * _ 2 ) _ − _ _ g _ ( _ * * z * * _ ) ] _ _ _ g _ _ * * z * * _ 1 _, _ _ * * z * * _ 2 [ ( ] _ [ k, k ] _ _ [ ′ ] _ [ ) ] _ − _ _ g _ ( _ * * z * * _ ) _, _ [ ] _ _ _ s _ + _ z _ 1 _, k _ _ − _ + _ z _ 2 _, k _ + _ _ _ k _ = _ _ _ k _ _ [ ′ ] _ _ z _ 1 _, k _ + _"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 29,
    "text": "[ 1 ] _ [ − ] _ _ [ α ] _ _ [ k ] _ [ + ] _ z _ 1 _, k _ _ − _ _ z _ 1 _, k _ + _ _ [ _ g _ ( _ * * z * * _ 1 _, − _ _ * * z * * _ 2 ) _ − _ _ g _ ( _ * * z * * _ ) ] _ _ _ g _ _ * * z * * _ 1 _, _ _ * * z * * _ 2 [ ( ] _ [ k, k ] _ _ [ ′ ] _ [ ) ] _ − _ _ g _ ( _ * * z * * _ ) _, _ [ ] _ _ _ s _ + _ z _ 1 _, k _ _ − _ + _ z _ 2 _, k _ + _ _ _ k _ = _ _ _ k _ _ [ ′ ] _ _ z _ 1 _, k _ + _ z _ 1 _, k _ _ ′ _ 2 ( _ k − _ 1 ) _ _ _ _ with _ k _ _ − _ = _ k _ _ [ ′ ] _ and _ k _ + = _ k _ if _ z _ 2 _, k, k _ _ ′ _ = + 1 and viceversa if _ z _ 2 _, k, k _ _ ′ _ = _ − _ 1. moreover _ * * z * * _ 2 [ ( ] _ [ k, k ] _ _ [ ′ ] _ [ ) ] is the vector with _ z _ 2 _, k, k _ _ ′ _ = _ −z _ 2 _, k _ _ ′ _ _, k _ = + 1 and zero otherwise. interestingly, _ c _ [ ( ] _ [ m ] _ [ ) ] coincides with the generator of the so - called coordinate sampler, introduced in wu and robert ( 2020 ), with target distribution dir ( _ * * α * * _ ). # # # # * * 5. 1 the random projection sampler being approximated * * the main feature of _ q _ nr is that, after sampling a pair ( _ k, k _ _ [ ′ ] _ ) _ ∈k _, the operator _ p _ [ [UNK] ] _ k, k _ _ ′ _ is applied for a random number of iterations. if _ s → _ 0 the latter diverges almost surely, meaning that after selecting the pair the sampler will behave as _ p _ [ [UNK] ] _ k, k _ _ [ t ] _ _ [ ′ ] _ [ with ] _ [ t ] [ →∞ ] _ [. by ] definition of _ p _ [ [UNK] ] _ k, k _ _ [ t ] _ _ [ ′ ] _ [ and ergodicity, this converges to the kernel π ] _ [ k, k ] _ _ [ ′ ] _ [ that updates the ] sub - partition of points in clusters _ k _ and _ k _ _ [ ′ ] _ conditional on the rest, i. e. _ _ lim _ t→∞ _ _ [ p ] _ _ k, k _ _ [ t ] _ _ [ ′ ] _ [ ( ] _ [ c, c ] _ _ [ ′ ] _ [ ) = [UNK] ] _ [ k, k ] _ _ [ ′ ] _ [ ( ] _ [ c, c ] _ _ [ ′ ] _ [ ) ] _ [ ∝ ] _ _ _ _ _ _ i _ : _ c _ _ i _ _ / ∈ { _ _ _ 1 _ c _ _ i _ = _ c _ _ [ ′ ] _ _ i _ _ i _ : _ c _ _ i _ _ / ∈ { k, k _ _ [ ′ ] _ _ } _ _ _ ( 23 ) _ t _ lim _ →∞ _ _ [ p ] _ _ k, k _ _ [ t ] _ _ [ ′ ] _ [ ( ] _ [ c, c ] _ _ [ ′ ] _ [ ) = [UNK] ] _ [ k, k ] _ _ [ ′ ] _ [ ( ] _ [ c, c ] _ _ [ ′ ] _ [ ) ] _ [ ∝ ] _ 1 _ c _ _ i _ = _ c _ _ [ ′ ] _ _ i _ _ π _ ( _ c _ _ [ ′ ] _ ) _ c, c _ _ [ ′ ] _ _ ∈ _ [ _ k _ ] _ [ n ] _ _. _ _ i _ : _ c _ _ i _ _ / ∈ { k, k _ _ [ ′ ] _ _ } _ _ _ 21 note that π _ k, k _ _ ′ _ is a projection kernel, i. e. π [ 2 ] _ k, k _ _ [ ′ ] _ [ = π ] _ [ k, k ] _ _ [ ′ ] _ [. analogously,"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 30,
    "text": "[ ′ ] _ [ ( ] _ [ c, c ] _ _ [ ′ ] _ [ ) = [UNK] ] _ [ k, k ] _ _ [ ′ ] _ [ ( ] _ [ c, c ] _ _ [ ′ ] _ [ ) ] _ [ ∝ ] _ 1 _ c _ _ i _ = _ c _ _ [ ′ ] _ _ i _ _ π _ ( _ c _ _ [ ′ ] _ ) _ c, c _ _ [ ′ ] _ _ ∈ _ [ _ k _ ] _ [ n ] _ _. _ _ i _ : _ c _ _ i _ _ / ∈ { k, k _ _ [ ′ ] _ _ } _ _ _ 21 note that π _ k, k _ _ ′ _ is a projection kernel, i. e. π [ 2 ] _ k, k _ _ [ ′ ] _ [ = π ] _ [ k, k ] _ _ [ ′ ] _ [. analogously, again as ] _ [ s ] [ → ] _ [ 0, ] _ q _ nr converges to the random projection kernel defined as 2 _ p _ rp ( _ c, c _ _ [ ′ ] _ ) = _ k _ ( _ k − _ 1 ) ( 24 ) _ p _ rp ( _ c, c _ _ [ ′ ] _ ) = _ k _ ( _ k − _ 1 ) π _ k, k _ _ ′ _ ( _ c, c _ _ [ ′ ] _ ) _ c, c _ _ [ ′ ] _ _ ∈ _ [ _ k _ ] _ [ n ] _ _, _ ( _ k, k _ _ [ ′ ] _ ) _ ∈k _ whose structure resembles the one of a random - scan gibbs sampler that updates the sub - partition of two randomly chosen pairs of clusters given the configuration of the other clusters. in this perspective, _ q _ nr can be interpreted as a metropolis - withingibbs sampler approximating _ p _ rp. * * remark 5. 3. * * in the prior case, as _ n →∞ _, we expect _ p _ rp in turn to approximate a gibbs sampler on the ( _ k − _ 1 ) - dimensional simplex, which at every iteration updates two coordinates chosen at random. in the special case of _ * * α * * _ = ( 1 _,..., _ 1 ), the latter has been studied in smith ( 2014 ) and shown to require _ o _ ( _ k _ log ( _ k _ ) ) iterations for mixing. # # # * * 6 simulations * * # # # # * * 6. 1 prior case * * first of all we consider the prior case, where _ f _ _ θ _ = _ f _ and the target distribution is given by ( 15 ). we let _ k _ = 3, _ n _ = 1000 and we run algorithms 1 and 6 for 300 independent runs, first with _ * * α * * _ = ( 1 _, _ 1 _, _ 1 ) and then with _ * * α * * _ = ( 0 _. _ 1 _, _ 0 _. _ 1 _, _ 0 _. _ 1 ). initial configurations are i. i. d. independently generated, so that _ c _ [ ( 0 ) ] _ i _ _ ∼ _ unif ( [ _ k _ ] ). for each run we store the value of the chains after _ t _ = 100 _ × n _ iterations and plot the corresponding proportion of labels of the first two components, i. e. ( _ n _ 1 ( _ c _ [ ( ] _ [ t ] _ [ ) ] ) _ / n, n _ 2 ( _ c _ [ ( ] _ [ t ] _ [ ) ] ) _ / n _ ) in figure 2. if the chains had reached convergence by then, these should be 300 independent samples approximately following a dirichlet - multinomial distribution with parameters _ * * α * * _ ( since _ n _ is large, this is visually close to drawing samples directly from a dir ( _ * * α * * _ ) distribution ). from the results in figure 2, it is clear that the non - reversible scheme ( second column ) leads to faster convergence : this is particularly manifest in the second row ( corresponding to _ * * α * * _ = ( 0 _. _ 1 _, _ 0 _. _ 1 _, _ 0 _. _ 1 ) ), where the mass should be concentrated around the borders of the simplex. indeed, both chains associated to _ p _ mg remain stuck close to the initial configuration, where the proportion within each group is close to 1 _ / _ 3. this is also clear from the last column of figure 2, which shows that the marginal distribution of _ p _ nr ( in black ) converges to the stationary one after fewer iterations. 22"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 31,
    "text": "approximately following a dirichlet - multinomial distribution with parameters _ * * α * * _ ( since _ n _ is large, this is visually close to drawing samples directly from a dir ( _ * * α * * _ ) distribution ). from the results in figure 2, it is clear that the non - reversible scheme ( second column ) leads to faster convergence : this is particularly manifest in the second row ( corresponding to _ * * α * * _ = ( 0 _. _ 1 _, _ 0 _. _ 1 _, _ 0 _. _ 1 ) ), where the mass should be concentrated around the borders of the simplex. indeed, both chains associated to _ p _ mg remain stuck close to the initial configuration, where the proportion within each group is close to 1 _ / _ 3. this is also clear from the last column of figure 2, which shows that the marginal distribution of _ p _ nr ( in black ) converges to the stationary one after fewer iterations. 22 * * marginal * * 0. 0 0. 2 0. 4 0. 6 0. 8 1. 0 * * marginal * * 0. 0 0. 2 0. 4 0. 6 0. 8 1. 0 * * non reversible * * 0. 0 0. 2 0. 4 0. 6 0. 8 1. 0 * * non reversible * * 0. 0 0. 2 0. 4 0. 6 0. 8 1. 0 * * marginal distribution of the chains * * 1 10 30 50 70 90 * * marginal distribution of the chains * * 1 10 30 50 70 90 figure 2 : left and center column : plot of the proportions of the first two components in the last of 100 iterations ( after a thinning of size _ n _ ) over 300 independent runs for _ p _ mg ( left ) and _ p _ nr ( center ). right column : plot of the marginal distribution of the proportion of the first component at every 10 iterations ( after thinning ) for _ p _ mg ( gray ) and _ p _ nr ( black ). the first and second rows refer to _ * * α * * _ = ( 1 _, _ 1 _, _ 1 ) and _ * * α * * _ = ( 0 _. _ 1 _, _ 0 _. _ 1 _, _ 0 _. _ 1 ), respectively. the target distribution is given in ( 15 ). # # # # * * 6. 2 posterior case * * we now consider model ( 1 ) with _ y _ = θ = r, _ k _ = 3, ( 25 ) _ f _ _ θ _ ( _ y _ ) = _ n _ ( _ y | θ, σ _ [ 2 ] ) _, _ _ p _ 0 ( _ θ _ ) = _ n _ ( _ θ | [UNK] _ 0 _, σ _ 0 [ 2 ] [ ) ] _ [. ] _ and hyperparameters set to _ [UNK] _ 0 = 0 and _ σ _ [ 2 ] = _ σ _ 0 [ 2 ] [ = 1. we then generate 300 indepen - ] dent data sets of size _ n _ = 1000, each generated from the model as follows : i. i. d. 1. sample _ * * w * * _ _ ∼ _ dirichlet ( _ * * α * * _ ) and _ θ _ _ k _ _ ∼ _ _ p _ 0 for _ k _ = 1 _,..., k _. i. i. d. 2. sample _ y _ _ i _ _ ∼ _ [ ] _ [ k ] _ _ k _ = 1 _ [ w ] _ _ [ k ] _ _ [ f ] _ _ [ θ ] _ _ k _ [ ( ] _ [ y ] _ [ ) for ] _ [ i ] _ [ = 1 ] _ [,..., n ] _ [. ] for each dataset we target the associated posterior using _ p _ mg and _ p _ nr. as before i. i. d. we initialize each chain uniformly, i. e. _ c _ [ ( 0 ) ] _ i _ _ ∼ _ unif ( [ _ k _ ] ), and store its value after _ t _ = 100 _ × n _ iterations. since the data are generated from the ( bayesian ) model, the resulting distribution of the proportions within each component should be close to the prior one, i. e. again a dirichlet - multinomial with parameter _ * * α * * _. this test for convergence, discussed for example in geweke ( 2004 ), relies on the fact that sampling from the _ prior _ distribution is equivalent to sampling from the _ posterior _, given data generated according to the marginal distribution induced by the model. 23 the resulting samples are displayed in figure 3, with the same structure as in figure 2. again the non - reversible scheme is much closer"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 32,
    "text": "target the associated posterior using _ p _ mg and _ p _ nr. as before i. i. d. we initialize each chain uniformly, i. e. _ c _ [ ( 0 ) ] _ i _ _ ∼ _ unif ( [ _ k _ ] ), and store its value after _ t _ = 100 _ × n _ iterations. since the data are generated from the ( bayesian ) model, the resulting distribution of the proportions within each component should be close to the prior one, i. e. again a dirichlet - multinomial with parameter _ * * α * * _. this test for convergence, discussed for example in geweke ( 2004 ), relies on the fact that sampling from the _ prior _ distribution is equivalent to sampling from the _ posterior _, given data generated according to the marginal distribution induced by the model. 23 the resulting samples are displayed in figure 3, with the same structure as in figure 2. again the non - reversible scheme is much closer to the correct distribution, while _ p _ mg remains close to the initial configuration. indeed, the results are remarkably close to the ones presented in section 6. 1 : this suggests that the behaviour observed in the prior case is informative also of the actual behaviour observed in the posterior case, at least in this setting. in section b of the supplementary material similar results are shown for the poisson kernel. * * marginal * * 0. 0 0. 2 0. 4 0. 6 0. 8 1. 0 * * marginal * * 0. 0 0. 2 0. 4 0. 6 0. 8 1. 0 * * non reversible * * 0. 0 0. 2 0. 4 0. 6 0. 8 1. 0 * * non reversible * * 0. 0 0. 2 0. 4 0. 6 0. 8 1. 0 * * marginal distribution of the chains * * 1 10 30 50 70 90 * * marginal distribution of the chains * * 1 10 30 50 70 90 figure 3 : left and center column : plot of the proportions of the first two components in the last of 100 iterations ( after a thinning of size _ n _ ) over 300 independent runs for _ p _ mg ( left ) and _ p _ nr ( center ). right column : plot of the marginal distribution of the proportion of the first component at every 10 iterations ( after thinning ) for _ p _ mg ( gray ) and _ p _ nr ( black ). the rows refer to _ α _ = 1 and _ α _ = 0 _. _ 1 and the target distribution is given by the posterior of model ( 1 ), with _ f _ _ θ _ ( _ y _ ) as in ( 25 ), _ [UNK] _ 0 = 0 and _ σ _ [ 2 ] = _ σ _ 0 [ 2 ] [ = 1. ] # # # # * * 6. 3 a high dimensional example * * we now consider a higher dimensional version of the previous setting, where ( 26 ) _ f _ _ θ _ ( _ y _ ) = _ n _ ( _ y | θ, σ _ _ p _ [ 2 ] _ [ i ] _ _ [ p ] _ [ ) ] _ [, ] _ _ p _ 0 ( _ θ _ ) = _ n _ ( _ θ | [UNK] _ 0 _, σ _ 0 [ 2 ] _ [ i ] _ _ [ p ] _ [ ) ] _ [, ] _ where now _ y ∈ _ r _ [ p ] _ and _ θ ∈ _ r _ [ p ] _ with _ p ≥ _ 1. we rescale the likelihood variance as _ σ _ _ p _ [ 2 ] [ = ] _ [ cp ] _ which guarantees that _ p _ 1 _ σ _ [ 2 ] ( _ θ _ 1 _ j _ _ − _ _ θ _ 2 _ j _ ) [ 2 ] = _ o _ ( 1 ) _. _ _ p _ _ p _ ( _ θ _ 1 _ j _ _ − _ _ θ _ 2 _ j _ ) [ 2 ] = _ o _ ( 1 ) _. _ _ j _ = 1 24 in other words, we ask that the distance across components, rescaled by the variance, does not diverge as _ p _ grows : this implies that some overlap between components is retained and that the problem is statistically non - trivial ( see e. g. chandra et al. ( 2023 ) for more discussion of bayesian mixture models with high - dimensional data ). we generate 500 independent samples of size _ n _ = 1000 from model ( 26 ) with _ p _ = 18, _ k _ = 5, _ [UNK] _ 0 = 0, _ σ _ 0 [ 2 ] [ = 0 ] _ [. ] _ [ 5, ] _ [ c ] _ [ = 2 and ] _ * * [ α ] * * _ [ = ( 4 ] _ ["
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 33,
    "text": "_ _ p _ ( _ θ _ 1 _ j _ _ − _ _ θ _ 2 _ j _ ) [ 2 ] = _ o _ ( 1 ) _. _ _ j _ = 1 24 in other words, we ask that the distance across components, rescaled by the variance, does not diverge as _ p _ grows : this implies that some overlap between components is retained and that the problem is statistically non - trivial ( see e. g. chandra et al. ( 2023 ) for more discussion of bayesian mixture models with high - dimensional data ). we generate 500 independent samples of size _ n _ = 1000 from model ( 26 ) with _ p _ = 18, _ k _ = 5, _ [UNK] _ 0 = 0, _ σ _ 0 [ 2 ] [ = 0 ] _ [. ] _ [ 5, ] _ [ c ] _ [ = 2 and ] _ * * [ α ] * * _ [ = ( 4 ] _ [, ] _ [ 1 ] _ [,..., ] _ [ 1 ). the data are generated ] as explained in the previous section and we run both _ p _ mg and _ p _ nr, retaining only the last iteration for every chain : the initialization is again uniform at random. in figure 4 we plot the histograms of the last iteration for the proportion associated to the first component of _ p _ mg and _ p _ nr for 500 independent runs. comparing the latter with the prior density, given by a dirichlet - multinomial with parameters ( 4 _, _ 4 ) ( approximately beta ( 4 _, _ 4 ) ), it is evident that the non - reversible scheme is able to forget the initialization while the reversible is not. indeed, as also clear from the right plot of figure 4, the marginal distribution of _ p _ mg significantly underestimates the size of the first cluster after _ t _ = 100 _ × n _ iterations. * * marginal * * 0. 0 0. 2 0. 4 0. 6 0. 8 1. 0 * * non reversible * * 0. 0 0. 2 0. 4 0. 6 0. 8 1. 0 * * marginal distribution of the chains * * 1 10 30 50 70 90 figure 4 : left and center column : histogram of the proportion of the first component in the last of 100 iterations ( after a thinning of size _ n _ ) over 500 independent runs for _ p _ mg ( left ) and _ p _ nr ( center ). the gray line corresponds to the density of a beta ( 4 _, _ 4 ). right column : plot of the marginal distribution of the chains at every 10 iterations ( after thinning ) for _ p _ mg ( gray ) and _ p _ nr ( black ). the target distribution is given by the posterior of model ( 1 ), with _ f _ _ θ _ ( _ y _ ) as in ( 26 ), _ p _ = 18, _ k _ = 5, _ [UNK] _ 0 = 0, _ σ _ 0 [ 2 ] [ = 0 ] _ [. ] _ [ 5, ] _ [ c ] _ [ = 2 and ] _ * * [ α ] * * _ [ = ( 4 ] _ [, ] _ [ 1 ] _ [,..., ] _ [ 1 ). ] # # # # * * 6. 4 overfitted setting * * finally, we consider an overfitted case, previously discussed in section 2. 2. 1. we take a one - dimensional gaussian kernel as in ( 25 ) and take _ α _ _ k _ = _ α _ for all _ k ∈ { _ 1 _,..., k } _. in this setting, using the notation of section 2. 2. 1, rousseau and mengersen ( 2011, thm. 1 ) implies that 1. if _ α > _ 1 _ / _ 2, then more than _ k _ _ [ ∗ ] _ atoms have non - negligible mass, i. e. multiple atoms are associated to the same “ true ” component, 25 2. if _ α ≤ _ 1 _ / _ 2, then the posterior concentrates on configurations with exactly _ k _ _ [ ∗ ] _ components, up to _ n _ _ [ − ] _ [ 1 ] _ [ / ] _ [ 2 ] posterior mass. i. i. d. we take _ k _ = 2 and _ k _ _ [ ∗ ] _ = 1, with _ y _ _ i _ _ ∼ _ _ n _ ( _ y | _ 2 _, _ 1 ) and _ n _ = 1000. the first two columns of figure 5 plot the histogram of the proportion of the first component after _ t _ = 100 _ ×n _ iterations ( and thinning of size _ n _ ) for _ α _ = 1 ( top row ) and _ α _"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 34,
    "text": "_ 2, then more than _ k _ _ [ ∗ ] _ atoms have non - negligible mass, i. e. multiple atoms are associated to the same “ true ” component, 25 2. if _ α ≤ _ 1 _ / _ 2, then the posterior concentrates on configurations with exactly _ k _ _ [ ∗ ] _ components, up to _ n _ _ [ − ] _ [ 1 ] _ [ / ] _ [ 2 ] posterior mass. i. i. d. we take _ k _ = 2 and _ k _ _ [ ∗ ] _ = 1, with _ y _ _ i _ _ ∼ _ _ n _ ( _ y | _ 2 _, _ 1 ) and _ n _ = 1000. the first two columns of figure 5 plot the histogram of the proportion of the first component after _ t _ = 100 _ ×n _ iterations ( and thinning of size _ n _ ) for _ α _ = 1 ( top row ) and _ α _ = 0 _. _ 1 ( bottom row ). the two algorithms are initialized according to the “ incorrect ” scenario, i. e. all the observations in the first component in the first row and uniformly at random in the bottom row. the figure illustrates that only _ p _ nr is able to reach the high probability region : this means that, despite its locality, the persistence of _ p _ nr allows for significantly faster traveling across the space. on the contrary, _ p _ mg remain stuck in the initial configuration ( which yields a similar likelihood ) for both the scenarios. this is also confirmed by the right column, which depicts the marginal distribution of the chains : after few iterations, the distribution associated to _ p _ nr stabilizes and yields the correct behaviour. * * marginal * * 0. 0 0. 2 0. 4 0. 6 0. 8 1. 0 * * marginal * * 0. 0 0. 2 0. 4 0. 6 0. 8 1. 0 * * non reversible * * 0. 0 0. 2 0. 4 0. 6 0. 8 1. 0 * * non reversible * * 0. 0 0. 2 0. 4 0. 6 0. 8 1. 0 * * marginal distribution of the chains * * 1 10 30 50 70 90 * * marginal distribution of the chains * * 1 10 30 50 70 90 figure 5 : left and center column : histogram of the proportion of the first component in the last of 100 iterations ( after a thinning of size _ n _ ) over 300 independent runs for _ p _ mg ( left ) and _ p _ nr ( center ). right column : plot of the marginal distribution of the proportion of the first component at every 10 iterations ( after thinning ) for _ p _ mg ( gray ) and _ p _ nr ( black ). first row : _ α _ = 3 _ / _ 2 and initialization uniformly at random. second row : _ α _ = 0 _. _ 1 and _ c _ [ ( 0 ) ] _ i _ = 1 for every _ i _. the target distribution is given by the posterior of model ( 1 ), with i. i. d. _ y _ _ i _ _ ∼ _ _ n _ ( _ y | _ 2 _, _ 1 ) and _ f _ _ θ _ ( _ y _ ) as in ( 25 ), _ [UNK] _ 0 = 0 and _ σ _ [ 2 ] = _ σ _ 0 [ 2 ] [ = 1. ] 26 # # # * * 7 discussion * * in this work we introduced a novel, simple and effective non - reversible mcmc sampler for mixture models, which enjoys three favourable features : ( i ) it is a simple modification of the original marginal scheme of algorithm 1, ( ii ) its performance cannot be worse than the reversible chain by more than a factor of four ( theorem 3. 1 ), ( iii ) it is shown to drastically speed - up convergence in various scenarios of interest. both the theory and methodology presented in this work could be extended in many interesting directions, and we now discuss some of those, starting from algorithmic and methodological ones. first, in the current formulation of algorithm 6, the pair of clusters to update and the observation to move are selected with probabilities that do not depend on the actual observations within the clusters ( except for their sizes ). a natural extension would be to consider informed proposal distributions, as in e. g. zanella ( 2020 ) ; power and goldman ( 2019 ) ; gagnon and maire ( 2024b ) : we expect this to lead to a potentially large decrease of the number of iterations needed for mixing, but with an additional cost per iteration. we leave the discussion and exploration of this tradeoff to future work. second, one could also consider schemes that adaptively modify the probabilities _ p _ _ c _ ( _ k, k _ _ [ ′ ] _ ) in ( 9"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 35,
    "text": "convergence in various scenarios of interest. both the theory and methodology presented in this work could be extended in many interesting directions, and we now discuss some of those, starting from algorithmic and methodological ones. first, in the current formulation of algorithm 6, the pair of clusters to update and the observation to move are selected with probabilities that do not depend on the actual observations within the clusters ( except for their sizes ). a natural extension would be to consider informed proposal distributions, as in e. g. zanella ( 2020 ) ; power and goldman ( 2019 ) ; gagnon and maire ( 2024b ) : we expect this to lead to a potentially large decrease of the number of iterations needed for mixing, but with an additional cost per iteration. we leave the discussion and exploration of this tradeoff to future work. second, one could also consider schemes that adaptively modify the probabilities _ p _ _ c _ ( _ k, k _ _ [ ′ ] _ ) in ( 9 ) in order to propose more often clusters with higher overlap ( or higher acceptance rates of proposed swaps ), thus reducing computational waste associated to frequently proposing swaps across clusters with little overlap. from the theoretical point of view, it would be highly valuable to extend the scaling limit analysis to the posterior case. while interesting, we expect this to require working with measure - valued processes and, more crucially, to require significant work in combining the mcmc analysis part with currently available results about posterior asymptotic behaviour of mixture models ( nguyen, 2013 ; guha et al., 2021 ). in this paper we stick to the case of a fixed number of components. a natural generalization regards the case of _ k _ random or infinite ( e. g. dirichlet process mixtures, see ferguson ( 1973 ) ; lo ( 1984 ) ). this presents additional technical difficulties that we leave to future work : for example, since no upper bound is available on the number of components, it would be more natural to define a markov chain over the full space of partitions of [ _ n _ ]. finally, mixture models are an instance of the broader framework of latent class models ( goodman, 1974 ) and it would be interesting to explore the effectiveness of the methodology developed here in such broader settings. # # # * * references * * andrieu, c. and s. livingstone ( 2021 ). peskun – tierney ordering for markovian monte carlo : beyond the reversible scenario. _ the annals of statistics 49 _ ( 4 ), 1958 – 1981. ascolani, f., h. lavenant, and g. zanella ( 2024 ). entropy contraction of the gibbs sampler under log - concavity. _ arxiv preprint arxiv : 2410. 00858 _. 27 barton, n. h., a. m. etheridge, and a. k. sturm ( 2004 ). coalescence in a random background. _ annals of applied probability 14 _ ( 3 ), 754 – 785. bierkens, j. ( 2016 ). non - reversible metropolis - hastings. _ statistics and comput - _ _ ing 26 _ ( 6 ), 1213 – 1228. brown, s., p. a. jenkins, a. m. johansen, and j. koskela ( 2021 ). simple conditions for convergence of sequential monte carlo genealogies with applications. _ electronic _ _ journla of probability 26 _, 1 – 22. celeux, g., m. hurn, and c. p. robert ( 2000 ). computational and inferential difficulties with mixture posterior distributions. _ journal of the american statistical _ _ association 95 _ ( 451 ), 957 – 970. chandra, n. k., a. canale, and d. b. dunson ( 2023 ). escaping the curse of dimensionality in bayesian model - based clustering. _ journal of machine learning re - _ _ search 24 _ ( 144 ), 1 – 42. chen, t. - l. and c. - r. hwang ( 2013 ). accelerating reversible markov chains. _ statistics _ _ & probability letters 83 _ ( 9 ), 1956 – 1962. davis, m. h. ( 1984 ). piecewise - deterministic markov processes : a general class of non - diffusion stochastic models. _ journal of the royal statistical society : series b _ _ ( methodological ) 46 _ ( 3 ), 353 – 376. dempster, a. p., n. m. laird, and d. b. rubin ( 1977 ). maximum likelihood from incomplete data via the em algorithm. _ journal of the royal statistical society : series _ _ b ( methodological ) 39 _ ( 1 ), 1 – 22. diaconis, p., s. holmes, and r"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 36,
    "text": "##se of dimensionality in bayesian model - based clustering. _ journal of machine learning re - _ _ search 24 _ ( 144 ), 1 – 42. chen, t. - l. and c. - r. hwang ( 2013 ). accelerating reversible markov chains. _ statistics _ _ & probability letters 83 _ ( 9 ), 1956 – 1962. davis, m. h. ( 1984 ). piecewise - deterministic markov processes : a general class of non - diffusion stochastic models. _ journal of the royal statistical society : series b _ _ ( methodological ) 46 _ ( 3 ), 353 – 376. dempster, a. p., n. m. laird, and d. b. rubin ( 1977 ). maximum likelihood from incomplete data via the em algorithm. _ journal of the royal statistical society : series _ _ b ( methodological ) 39 _ ( 1 ), 1 – 22. diaconis, p., s. holmes, and r. m. neal ( 2000 ). analysis of a nonreversible markov chain sampler. _ annals of applied probability _, 726 – 752. diebolt, j. and c. p. robert ( 1994 ). estimation of finite mixture distributions through bayesian sampling. _ journal of the royal statistical society : series b ( methodologi - _ _ cal ) 56 _ ( 2 ), 363 – 375. etheridge, a. ( 2011 ). _ some mathematical models from population genetics : ecole _ _ [ [UNK] ] _ _ d ’ [UNK] de [UNK] de saint - flour xxxix - 2009 _ _ [ [UNK] ] _. springer. ethier, s. n. ( 1976 ). a class of degenerate diffusion processes occurring in population genetics. _ communications on pure and applied mathematics 29 _ ( 5 ), 483 – 493. ethier, s. n. and t. g. kurtz ( 1986 ). _ markov processes : characterization and conver - _ _ gence _. john wiley & sons. faulkner, m. f. and s. livingstone ( 2024 ). sampling algorithms in statistical physics : a guide for statistics and machine learning. _ statistical science 39 _ ( 1 ), 137 – 164. fearnhead, p., j. bierkens, m. pollock, and g. o. roberts ( 2018 ). piecewise deterministic markov processes for continuous - time monte carlo. _ statistical science 33 _ ( 3 ), 386 – 412. ferguson, t. s. ( 1973 ). a bayesian analysis of some nonparametric problems. _ ann. _ _ stat. 1 _ ( 2 ), 209 – 230. [UNK] - schnatter, s. ( 2006 ). _ finite mixture and markov switching models _, volume 425. springer. 28 gagnon, p. and f. maire ( 2024a ). an asymptotic peskun ordering and its application to lifted samplers. _ bernoulli 30 _ ( 3 ), 2301 – 2325. gagnon, p. and f. maire ( 2024b ). theoretical guarantees for lifted samplers. _ arxiv _ _ preprint arxiv : 2405. 15952 _. gaitonde, j. and e. mossel ( 2024 ). comparison theorems for the mixing times of systematic and random scan dynamics. _ arxiv preprint arxiv : 2410. 11136 _. gelman, a., w. r. gilks, and g. o. roberts ( 1997 ). weak convergence and optimal scaling of random walk metropolis algorithms. _ the annals of applied probabil - _ _ ity 7 _ ( 1 ), 110 – 120. geweke, j. ( 2004 ). getting it right : joint distribution tests of posterior simulators. _ journal of the american statistical association 99 _ ( 467 ), 799 – 804. goodman, l. a. ( 1974 ). exploratory latent structure analysis using both identifiable and unidentifiable models. _ biometrika 61 _ ( 2 ), 215 – 231. guha, a., n. ho, and x. nguyen ( 2021 ). on posterior contraction of parameters and interpretability in bayesian mixture modeling. _ bernoulli 27 _ ( 4 ), 2159 – 2188. he, b. d., c. m. de sa, i. mitliagkas, and c. [UNK] ( 2016 ). scan order in gibbs sampling : models in which it matters and bounds on how much. _ advances in neural information _ _ processing systems 29 _. hobert, j. p., v. roy, and c. p. robert ( 2011 ). improving the convergence properties of the data augmentation algorithm with an application to bayesian mixture modeling. _ statistical science 26 _ ( 3 ), 332 – 351. khare"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 37,
    "text": "##man, l. a. ( 1974 ). exploratory latent structure analysis using both identifiable and unidentifiable models. _ biometrika 61 _ ( 2 ), 215 – 231. guha, a., n. ho, and x. nguyen ( 2021 ). on posterior contraction of parameters and interpretability in bayesian mixture modeling. _ bernoulli 27 _ ( 4 ), 2159 – 2188. he, b. d., c. m. de sa, i. mitliagkas, and c. [UNK] ( 2016 ). scan order in gibbs sampling : models in which it matters and bounds on how much. _ advances in neural information _ _ processing systems 29 _. hobert, j. p., v. roy, and c. p. robert ( 2011 ). improving the convergence properties of the data augmentation algorithm with an application to bayesian mixture modeling. _ statistical science 26 _ ( 3 ), 332 – 351. khare, k. and h. zhou ( 2009 ). rates of convergence of some multivariate markov chains with polynomial eigenfunctions. _ ann. app. probab. 19 _, 737 – 777. koskela, j., p. a. jenkins, a. m. johansen, and d. [UNK] ( 2020 ). asymptotic genealogies of interacting particle systems with an application to sequential monte carlo. _ the annals of statistics 1 _, 560 – 583. lee, k., j. - m. marin, k. mengersen, and c. robert ( 2009 ). bayesian inference on finite mixtures of distributions. in _ perspectives in mathematical sciences i : probability and _ _ statistics _, pp. 165 – 202. world scientific. levin, d. a. and y. peres ( 2017 ). _ markov chains and mixing times _, volume 107. american mathematical soc. liu, j. s. ( 1994 ). the collapsed gibbs sampler in bayesian computations with applications to a gene regulation problem. _ journal of the american statistical associa - _ _ tion 89 _ ( 427 ), 958 – 966. lo, a. y. ( 1984 ). on a class of bayesian nonparametric estimates : i. density estimates. _ ann. stat. 12 _ ( 1 ), 351 – 357. marin, j. - m., k. mengersen, and c. p. robert ( 2005 ). bayesian modelling and inference on mixtures of distributions. _ handbook of statistics 25 _, 459 – 507. mclachlan, g. j., s. x. lee, and s. i. rathnayake ( 2019 ). finite mixture models. _ annual review of statistics and its application 6 _ ( 1 ), 355 – 378. nguyen, x. ( 2013 ). convergence of latent mixing measures in finite and infinite mixture 29 models. _ annals of statistics 41 _ ( 1 ), 370 – 400. nishimura, a., d. b. dunson, and j. lu ( 2020 ). discontinuous hamiltonian monte carlo for discrete parameters and discontinuous likelihoods. _ biometrika 107 _ ( 2 ), 365 – 380. power, s. and j. v. goldman ( 2019 ). accelerated sampling on discrete spaces with non - reversible markov processes. _ arxiv preprint arxiv : 1912. 04681 _. robert, c. p. ( 2007 ). _ the bayesian choice : from decision - theoretic foundations to _ _ computational implementation _, volume 2. springer. roberts, g. o. and j. s. rosenthal ( 2001a ). markov chains and de - initializing processes. _ scandinavian journal of statistics 28 _ ( 3 ), 489 – 504. roberts, g. o. and j. s. rosenthal ( 2001b ). optimal scaling for various metropolishastings algorithms. _ statistical science 16 _ ( 4 ), 351 – 367. roberts, g. o. and j. s. rosenthal ( 2004 ). general state space markov chains and mcmc algorithms. _ probability surveys 1 _, 20 – 71. roberts, g. o. and j. s. rosenthal ( 2015 ). surprising convergence properties of some simple gibbs samplers under various scans. _ international journal of statistics and _ _ probability 5 _ ( 1 ), 51 – 60. rousseau, j. and k. mengersen ( 2011 ). asymptotic behaviour of the posterior distribution in overfitted mixture models. _ journal of the royal statistical society series _ _ b : statistical methodology 73 _ ( 5 ), 689 – 710. schauer, m. and m. [UNK] ( 2024 ). causal structure learning with momentum : sampling distributions over markov equivalence classes. _ proceedings of machine _ _ learning research 246 _, 382"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 38,
    "text": "##ishastings algorithms. _ statistical science 16 _ ( 4 ), 351 – 367. roberts, g. o. and j. s. rosenthal ( 2004 ). general state space markov chains and mcmc algorithms. _ probability surveys 1 _, 20 – 71. roberts, g. o. and j. s. rosenthal ( 2015 ). surprising convergence properties of some simple gibbs samplers under various scans. _ international journal of statistics and _ _ probability 5 _ ( 1 ), 51 – 60. rousseau, j. and k. mengersen ( 2011 ). asymptotic behaviour of the posterior distribution in overfitted mixture models. _ journal of the royal statistical society series _ _ b : statistical methodology 73 _ ( 5 ), 689 – 710. schauer, m. and m. [UNK] ( 2024 ). causal structure learning with momentum : sampling distributions over markov equivalence classes. _ proceedings of machine _ _ learning research 246 _, 382 – 400. smith, a. ( 2014 ). a gibbs sampler on the n - simplex. _ annals of applied probabil - _ _ ity 24 _ ( 1 ), 114 – 130. stephens, m. ( 2000 ). dealing with label switching in mixture models. _ journal of the _ _ royal statistical society : series b ( statistical methodology ) 62 _ ( 4 ), 795 – 809. tierney, l. ( 1998 ). a note on metropolis - hastings kernels for general state spaces. _ annals of applied probability _, 1 – 9. vucelja, m. ( 2016 ). lifting — a nonreversible markov chain monte carlo algorithm. _ american journal of physics 84 _ ( 12 ), 958 – 968. wu, c. and c. p. robert ( 2020 ). coordinate sampler : a non - reversible gibbs - like mcmc sampler. _ statistics and computing 30 _ ( 3 ), 721 – 730. yang, y., m. j. wainwright, and m. i. jordan ( 2016 ). on the computational complexity of high - dimensional bayesian variable selection. _ the annals of statistics 44 _ ( 6 ), 2497 – 2532. zanella, g. ( 2020 ). informed proposals for local mcmc in discrete spaces. _ journal of _ _ the american statistical association 115 _ ( 530 ), 852 – 865. zhou, q. and h. chang ( 2023 ). complexity analysis of bayesian learning of highdimensional dag models and their equivalence classes. _ the annals of statis - _ _ tics 51 _ ( 3 ), 1058 – 1085. 30 zhou, q., j. yang, d. vats, g. o. roberts, and j. s. rosenthal ( 2022 ). dimensionfree mixing for high - dimensional bayesian variable selection. _ journal of the royal _ _ statistical society : series b ( statistical methodology ) 84 _ ( 5 ), 1751 – 1784. # # # a comparison between p nr and q nr in this section we consider the same setting of section 6. 1, where the target distribution is given in ( 15 ). we run both _ p _ nr and _ q _ nr ( with _ s _ = 1 ) for 300 independent trials with initialization uniformly at random. we consider _ n _ = 1000, _ k _ = 3 _, _ 10 _, _ 20 _, _ 50 and _ * * α * * _ = ( 1 _, _ 1 _ / _ ( _ k − _ 1 ) _,..., _ 1 _ / _ ( _ k − _ 1 ), so that the marginal distribution on the proportion of the first component is a dirichlet - multinomial with parameters ( 1 _, _ 1 ) and thus close to a uniform distribution on ( 0 _, _ 1 ). figure 6 plots the corresponding empirical marginal distribution obtained by the chains ( black corresponds to _ p _ nr and gray to _ q _ nr ). even if both schemes correctly reach stationarity, it seems that _ q _ nr yields slower mixing as _ k _ increases : this is particularly evident in the case _ k _ = 50, where _ q _ nr remains close to the initial configuration. # # # * * b simulations for the poisson kernel * * here we consider model ( 1 ) with _ k _ = 3 and ( 27 ) _ f _ _ θ _ ( _ y _ ) = po ( _ y | θ _ ) _, _ _ p _ 0 ( _ θ _ ) = gamma ( _ θ | β _ 1 _, β _ 2 ) _. _ it is easy to show that the predictive distribution reads _ p _ ( _ y _ _ n _ + 1 = _ y | y _ ) = γ ( γ _ β _ ( 1 _ β _ +"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 39,
    "text": "6 plots the corresponding empirical marginal distribution obtained by the chains ( black corresponds to _ p _ nr and gray to _ q _ nr ). even if both schemes correctly reach stationarity, it seems that _ q _ nr yields slower mixing as _ k _ increases : this is particularly evident in the case _ k _ = 50, where _ q _ nr remains close to the initial configuration. # # # * * b simulations for the poisson kernel * * here we consider model ( 1 ) with _ k _ = 3 and ( 27 ) _ f _ _ θ _ ( _ y _ ) = po ( _ y | θ _ ) _, _ _ p _ 0 ( _ θ _ ) = gamma ( _ θ | β _ 1 _, β _ 2 ) _. _ it is easy to show that the predictive distribution reads _ p _ ( _ y _ _ n _ + 1 = _ y | y _ ) = γ ( γ _ β _ ( 1 _ β _ + 1 + ~ ~ [ ] ~ ~ [ ] ~ ~ _ [ n ] _ ~ ~ _ i _ = 1 _ [ n ] _ _ i _ = _ [ y ] _ 1 _ [ i ] _ [ ) γ ( ] _ [ y ] _ _ [ i ] _ [ + ] _ [ y ] _ [ + 1 ) ] _ [ y ] _ [ ) ] ( _ n _ + ( _ n β _ + 2 + 1 ) _ β _ 2 ) _ [ β ] [ β ] _ [ 1 ] [ 1 ] [ + ] [ + ] [ ] ~ ~ [ ] ~ ~ _ i _ _ [ n ] _ = 1 _ i _ ~ ~ _ [ n ] _ ~ ~ = 1 _ [ y ] [ y ] _ _ [ i ] _ _ [ i ] _ [ + ] _ [ y ] _ _ [. ] _ we consider _ β _ 1 = _ β _ 2 = 1 and we draw 300 independent samples from the model above with _ n _ = 1000, following the same procedure illustrated in section 6. 2. for each dataset we run algorithms 1 and 6, initialized uniformly at random, and we retain only the last iteration. the results of the simulations are similar to the ones of section 6. 2, as shown in figure 7 : again the non - reversible scheme is much closer to the prior distribution, while _ p _ mg remains close to the initial configuration. 31 | col1 | marginal distribution of the chains | col3 | col4 | col5 | col6 | col7 | col8 | col9 | col10 | col11 | col12 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | 1 10 15 20 25 30 35 40 45 50 | col1 | marginal distribution of the chains | col3 | col4 | col5 | col6 | col7 | col8 | col9 | col10 | col11 | col12 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | 1 10 15 20 25 30 35 40 45 50 | col1 | marginal distribution of the chains | col3 | col4 | col5 | col6 | col7 | col8 | col9 | col10 | col11 | col12 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | |"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 40,
    "text": "| | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | 1 10 15 20 25 30 35 40 45 50 | col1 | marginal distribution of the chains | col3 | col4 | col5 | col6 | col7 | col8 | col9 | col10 | col11 | col12 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | 1 10 15 20 25 30 35 40 45 50 | col1 | marginal distribution of the chains | col3 | col4 | col5 | col6 | col7 | col8 | col9 | col10 | col11 | col12 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | 1 10 15 20 25 30 35 40 45 50 figure 6 : plots of the marginal distribution of the proportion of the first component for the chains associated to _ p _ nr ( black ) and _ q _ nr ( gray ) at every. from top left to bottom right, the plots refer to _ k _ = 3 _, _ 10 _, _ 20 _, _ 50, where the target distribution is as in ( 15 ) with _ * * α * * _ = ( 1 _, _ 1 _ / _ ( _ k − _ 1 ) _,..., _ 1 _ / _ ( _ k − _ 1 ) and _ n _ = 1000. # # # * * c proofs * * # # # # * * c. 1 general results about lifting and mixtures * * in order to prove results below, especially theorem 3. 1, we first need to generalize some classical results about lifting of markov chains ( see e. g. chen and hwang, 2013 ; bierkens, 2016 ; andrieu and livingstone, 2021 ) to our mixture case, which can be seen as a way to construct ‘ multi - dimensional ’ lifted chains. we will make use of the following classical lemma, which for example follows by results in chen and hwang ( 2013 ) as detailed below. * * lemma c. 1. * * _ let [UNK] be a probability distribution on a finite space x _ _, p a [UNK] - invariant _ _ and irreducible markov transition matrix, p _ _ [ ∗ ] _ _ the [UNK] - adjoint of p and k _ = ( _ p _ + _ p _ _ [ ∗ ] _ ) _ / _ 2 _. _ 32 * * marginal * * 0. 0 0. 2 0. 4 0. 6 0. 8 1. 0 * * marginal * * 0. 0 0. 2 0. 4 0. 6 0. 8 1. 0 * * non reversible * * 0. 0 0. 2 0. 4 0. 6 0. 8 1. 0 * * non reversible * * 0. 0 0. 2 0. 4 0. 6 0. 8 1. 0 * * marginal distribution of the chains * * 1 10 30 50 70 90 * * marginal distribution of the chains * * 1 10 30 50 70 90 figure 7 : left and center column : plot of the proportions of the first two components in the last of 100 iterations ( after a thinning of size _ n _ ) over 300 independent runs for _ p _ mg ( left ) and _ p _ nr ( center ). right column : plot of the marginal distribution of the proportion of the first component at every 10 iterations ( after thinning ) for _ p _ mg ( gray ) and _"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 41,
    "text": "0. 4 0. 6 0. 8 1. 0 * * marginal * * 0. 0 0. 2 0. 4 0. 6 0. 8 1. 0 * * non reversible * * 0. 0 0. 2 0. 4 0. 6 0. 8 1. 0 * * non reversible * * 0. 0 0. 2 0. 4 0. 6 0. 8 1. 0 * * marginal distribution of the chains * * 1 10 30 50 70 90 * * marginal distribution of the chains * * 1 10 30 50 70 90 figure 7 : left and center column : plot of the proportions of the first two components in the last of 100 iterations ( after a thinning of size _ n _ ) over 300 independent runs for _ p _ mg ( left ) and _ p _ nr ( center ). right column : plot of the marginal distribution of the proportion of the first component at every 10 iterations ( after thinning ) for _ p _ mg ( gray ) and _ p _ nr ( black ). the rows refer to _ α _ = 1 and _ α _ = 0 _. _ 1 and the target distribution is given by the posterior of model ( 1 ), with _ f _ _ θ _ ( _ y _ ) as in ( 27 ) and _ β _ 1 = _ β _ 2 = 1. _ then var _ ( _ g, p _ ) _ ≤ _ _ var _ ( _ g, k _ ) _ for all g _ : _ x → _ r _. _ _ proof. _ consider the decomposition _ p _ = _ k _ + _ q _, _ q _ = [ 1 ] [ 1 ] 2 _ [ p ] [ − ] _ [ 1 ] 2 _ proof. _ consider the decomposition _ p _ = _ k _ + _ q _, _ q _ = 2 _ [ p ] [ − ] _ 2 _ [ p ] _ _ [ ∗ ] _ [. by construction, ] _ [ k ] _ is a _ [UNK] _ - reversible transition matrix. moreover, by definition of adjoint we have that _ q _ is antisymmetric with respect to _ [UNK] _, which means that _ [UNK] _ ( _ x _ ) _ q _ ( _ x, y _ ) = _ [UNK] _ ( _ y _ ) _ q _ ( _ y, x _ ) for all _ x, y ∈x _. finally, for every _ x ∈x _ we have that _ q _ ( _ x, y _ ) = [ 1 ] 2 _ y∈x _ 2 2 _ p _ ( _ x, y _ ) _ − _ [ 1 ] 2 _ y∈x _ _ p _ _ [ ∗ ] _ ( _ x, y _ ) = 0 _ y∈x _ and thus each row of _ q _ sums up to zero. therefore by lemma 2 in chen and hwang ( 2013 ) we have that var ( _ g, p _ ) = var ( _ g, k _ + _ q _ ) _ ≤ _ var ( _ g, k _ ) for all _ g _ : _ x → _ r. * * c. 1. 1 * * * * result with general notation * * let _ π _ be a probability distribution on a finite space _ c _. let _ d ∈ _ n, and ( _ k _ _ d, _ + 1 ) _ d∈ { _ 1 _,..., d } _ and ( _ k _ _ d, − _ 1 ) _ d∈ { _ 1 _,..., d } _ be markov transition kernels on _ c _ such that ( 28 ) _ π _ ( _ c _ ) _ k _ _ d, _ + ( _ c, c _ _ [ ′ ] _ ) = _ π _ ( _ c _ _ [ ′ ] _ ) _ k _ _ d, − _ ( _ c _ _ [ ′ ] _ _, c _ ) for all _ c _ = _ c _ _ [ ′ ] _ and all _ d _ = 1 _,..., d. _ 33 define the markov transition kernel on _ c _ ( 29 ) _ k _ _ r _ ( _ c, c _ _ [ ′ ] _ ) = _ d _ _ p _ _ c _ ( _ d _ ) _ k _ _ d _ _ c, c _ _ [ ′ ] _ [ ] _, _ _ d _ = 1 where _ k _ _ d _ = ( _ k _ _ d, _ + + _ k _ _ d, − _ ) _ / _ 2 and _ p _ _ c _ are weights such that [ ] _ [ d ] _ _ d _ = 1 _ [ p ] _ _ [ c ] _ [ ( ] _ [ d ] _ [ ) = 1 for all ] _ [ c ] [ ∈c ] _ and ( 30"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 42,
    "text": "] _ _, c _ ) for all _ c _ = _ c _ _ [ ′ ] _ and all _ d _ = 1 _,..., d. _ 33 define the markov transition kernel on _ c _ ( 29 ) _ k _ _ r _ ( _ c, c _ _ [ ′ ] _ ) = _ d _ _ p _ _ c _ ( _ d _ ) _ k _ _ d _ _ c, c _ _ [ ′ ] _ [ ] _, _ _ d _ = 1 where _ k _ _ d _ = ( _ k _ _ d, _ + + _ k _ _ d, − _ ) _ / _ 2 and _ p _ _ c _ are weights such that [ ] _ [ d ] _ _ d _ = 1 _ [ p ] _ _ [ c ] _ [ ( ] _ [ d ] _ [ ) = 1 for all ] _ [ c ] [ ∈c ] _ and ( 30 ) _ p _ _ c _ ( _ d _ ) = _ p _ _ c _ _ ′ _ ( _ d _ ) if _ k _ _ d _ ( _ c, c _ _ [ ′ ] _ ) _ > _ 0 _. _ define the markov transition kernel on _ c × { − _ 1 _, _ 1 _ } _ _ [ d ] _ ( 31 ) _ k _ _ nr _ ( ( _ c, v _ ) _, _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) ) = _ d _ _ p _ _ c _ ( _ d _ ) ( _ f _ _ d _ _ k _ lift _, d _ _ f _ _ d _ ) ( ( _ c, v _ ) _, _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) ) _, _ _ d _ = 1 where _ f _ _ d _ is the flipping operator defined as _ f _ _ d _ ( ( _ c, v _ ) _, _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) ) = 1 ( _ c _ = _ c _ _ [ ′ ] _ ) ( 1 _ − _ _ α _ ) 1 ( _ v _ = _ v _ _ [ ′ ] _ ) + _ α _ 1 ( _ v _ _ −d _ = _ v _ _ − _ _ [ ′ ] _ _ d _ _ [, v ] _ _ d _ _ [ ′ ] _ [ = ] _ [ − ] [ v ] _ _ [ d ] _ [ ) ] for some fixed _ α ∈ _ [ 0 _, _ 1 ] and ( 32 ) _ k _ lift _, d _ ( ( _ c, v _ ) _, _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) ) = _ k _ _ d, v _ _ d _ _ c, c _ _ [ ′ ] _ [ ] _ q _ _ d, c, c _ _ ′ _ ( _ v, v _ _ [ ′ ] _ ) with ( 33 ) _ q _ _ d, c, c _ _ ′ _ ( _ v, v _ _ [ ′ ] _ ) = 1 ( _ v _ _ −d _ = _ v _ _ − _ _ [ ′ ] _ _ d _ [ ) ] 1 ( _ c _ = _ c _ _ [ ′ ] _ ) 1 ( _ v _ _ d _ = _ v _ _ d _ _ [ ′ ] _ [ ) + ] [ 1 ] [ ( ] _ [ c ] _ [ = ] _ [ c ] _ _ [ ′ ] _ [ ) ] [ 1 ] [ ( ] _ [ v ] _ _ [ d ] _ [ = ] _ [ − ] [ v ] _ _ d _ _ [ ′ ] _ [ ) ] _. _ here _ α _ plays the role of a refresh rate. one could also think at the case _ α _ = 0 for simplicity, where _ f _ _ d _ becomes the identity operator and can thus be ignored. * * lemma c. 2. * * _ under _ ( 28 ) _ - _ ( 33 ) _, we have that _ _ ( a ) k _ _ r _ _ is π - reversible. _ _ ( b ) k _ _ nr _ _ is _ [UNK] _ π - invariant, with _ [UNK] _ π _ ( _ c, v _ ) = _ π _ ( _ c _ ) 2 _ [ − ] [ d ] _ _. _ _ ( c ) var _ ( [UNK] _ g, k _ _ nr _ ) _ ≤ _ _ var _ ( _ g, k _ _ r _ ) _ for all g _ : _ c × { −"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 43,
    "text": "] _ _ d _ _ [ ′ ] _ [ ) ] _. _ here _ α _ plays the role of a refresh rate. one could also think at the case _ α _ = 0 for simplicity, where _ f _ _ d _ becomes the identity operator and can thus be ignored. * * lemma c. 2. * * _ under _ ( 28 ) _ - _ ( 33 ) _, we have that _ _ ( a ) k _ _ r _ _ is π - reversible. _ _ ( b ) k _ _ nr _ _ is _ [UNK] _ π - invariant, with _ [UNK] _ π _ ( _ c, v _ ) = _ π _ ( _ c _ ) 2 _ [ − ] [ d ] _ _. _ _ ( c ) var _ ( [UNK] _ g, k _ _ nr _ ) _ ≤ _ _ var _ ( _ g, k _ _ r _ ) _ for all g _ : _ c × { − _ 1 _, _ + 1 _ } _ _ [ d ] _ _ → _ r _ and _ [UNK] _ g _ : _ c → _ r _ such _ _ that g _ ( _ c, v _ ) = [UNK] _ g _ ( _ c _ ) _ for all _ ( _ c, v _ ) _ ∈c × { − _ 1 _, _ + 1 _ } _ _ [ d ] _ _. _ _ proof. _ consider first part ( a ). by ( 28 ), for every _ c _ = _ c _ _ [ ′ ] _ we have 2 _ π _ ( _ c _ ) _ k _ _ d _ ( _ c, c _ _ [ ′ ] _ ) = _ π _ ( _ c _ ) _ k _ _ d, _ + ( _ c, c _ _ [ ′ ] _ ) + _ π _ ( _ c _ ) _ k _ _ d, − _ ( _ c, c _ _ [ ′ ] _ ) = _ π _ ( _ c _ _ [ ′ ] _ ) _ k _ _ d, − _ ( _ c _ _ [ ′ ] _ _, c _ ) + _ π _ ( _ c _ _ [ ′ ] _ ) _ k _ _ d, _ + ( _ c _ _ [ ′ ] _ _, c _ ) = 2 _ π _ ( _ c _ _ [ ′ ] _ ) _ k _ _ d _ ( _ c _ _ [ ′ ] _ _, c _ ) _. _ 34 and thus by ( 29 ) and ( 30 ) we have _ _ _ _ _ π _ ( _ c _ ) _ k _ _ r _ ( _ c, c _ _ [ ′ ] _ ) = = _ _ _ _ _ d _ _ p _ _ c _ ( _ d _ ) _ π _ ( _ c _ ) _ k _ _ d _ ( _ c, c _ _ [ ′ ] _ ) _ d _ = 1 _ d _ _ p _ _ c _ _ ′ _ ( _ d _ ) _ π _ ( _ c _ _ [ ′ ] _ ) _ k _ _ d _ ( _ c _ _ [ ′ ] _ _, c _ ) = _ π _ ( _ c _ _ [ ′ ] _ ) _ k _ _ d _ ( _ c _ _ [ ′ ] _ _, c _ ) _, _ _ d _ = 1 _ _ _ _ meaning that _ k _ _ r _ is _ π _ - reversible. consider now point ( b ). let ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) _ ∈c × { − _ 1 _, _ + 1 _ } _ _ [ d ] _. if _ v _ = _ v _ _ [ ′ ] _, by ( 32 ), _ q _ _ d, c, c _ _ ′ _ ( _ v, v _ _ [ ′ ] _ ) = 1 ( _ c _ = _ c _ _ [ ′ ] _ ) and ( 28 ) we have _ _ _ _ _ π _ [UNK] ( _ c, v _ ) _ k _ lift _, d _ ( ( _ c, v _ ) _, _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) ) = _ c∈c _ _ c∈c _ _ _ _ _ _ _ _ _ _ π _ ( _ c _ ) _ k _ _ d, v _ _ d _ ( _ c, c _ _ [ ′ ] _ ) _ q _ _ d, c, c _ _ ′ _ ( _ v, v _ _ [ ′ ] _ ) 2 _ [ − ] [ d ] _ _ c∈c _ _ _ _ _ = _ π _ ( _ c _ ) _ k _ _ d,"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 44,
    "text": "_ _ ′ _ ( _ v, v _ _ [ ′ ] _ ) = 1 ( _ c _ = _ c _ _ [ ′ ] _ ) and ( 28 ) we have _ _ _ _ _ π _ [UNK] ( _ c, v _ ) _ k _ lift _, d _ ( ( _ c, v _ ) _, _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) ) = _ c∈c _ _ c∈c _ _ _ _ _ _ _ _ _ _ π _ ( _ c _ ) _ k _ _ d, v _ _ d _ ( _ c, c _ _ [ ′ ] _ ) _ q _ _ d, c, c _ _ ′ _ ( _ v, v _ _ [ ′ ] _ ) 2 _ [ − ] [ d ] _ _ c∈c _ _ _ _ _ = _ π _ ( _ c _ ) _ k _ _ d, v _ _ d ′ _ [ ( ] _ [ c, c ] _ _ [ ′ ] _ [ ) 2 ] _ [ − ] [ d ] _ _ c _ = _ _ _ c _ _ [ ′ ] _ _ _ _ _ = _ π _ ( _ c _ _ [ ′ ] _ ) _ k _ _ d, −v _ _ d ′ _ [ ( ] _ [ c ] _ _ [ ′ ] _ _ [, c ] _ [ ) 2 ] _ [ − ] [ d ] _ [ = [UNK] ] _ [ π ] _ [ ( ] _ [ c ] _ _ [ ′ ] _ _ [, v ] _ _ [ ′ ] _ [ ) ] 1 _ − _ _ k _ _ d, −v _ _ d ′ _ [ ( ] _ [ c ] _ _ [ ′ ] _ _ [, c ] _ _ [ ′ ] _ [ ) ] _. _ _ c _ = _ _ _ c _ _ [ ′ ] _ _ _ _ _ similarly, if _ v _ _ −d _ = _ v _ _ − _ _ [ ′ ] _ _ d _ [ and ] _ [ v ] _ _ [ d ] _ [ = ] _ [ − ] [ v ] _ _ d _ _ [ ′ ] _ [, by ] _ [ q ] _ _ [ d, c, c ] _ _ [ ′ ] _ [ ( ] _ [ v, v ] _ _ [ ′ ] _ [ ) = ] [ 1 ] [ ( ] _ [ c ] _ [ = ] _ [ c ] _ _ [ ′ ] _ [ ) we have that ] _ _ _ _ _ π _ [UNK] ( _ c, v _ ) _ k _ lift _, d _ ( ( _ c, v _ ) _, _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) ) = _ c∈c _ _ c∈c _ _ _ _ _ _ _ _ _ _ π _ ( _ c _ ) _ k _ _ d, v _ _ d _ ( _ c, c _ _ [ ′ ] _ ) _ q _ _ d, c, c _ _ ′ _ ( _ v, v _ _ [ ′ ] _ ) 2 _ [ − ] [ d ] _ _ c∈c _ _ _ _ _ = [UNK] _ π _ ( _ c _ _ [ ′ ] _ ) _ k _ _ d, −v _ _ d ′ _ [ ( ] _ [ c ] _ _ [ ′ ] _ _ [, c ] _ _ [ ′ ] _ [ ) 2 ] _ [ − ] [ d ] _ [ = [UNK] ] _ [ π ] _ [ ( ] _ [ c ] _ _ [ ′ ] _ _ [, v ] _ _ [ ′ ] _ [ ) ] _ [ k ] _ _ [ d, ] [ − ] [ v ] _ _ d _ _ [ ′ ] _ [ ( ] _ [ c ] _ _ [ ′ ] _ _ [, c ] _ _ [ ′ ] _ [ ) ] _ [. ] _ summing the two expressions above, and using the fact that _ k _ lift _, d _ ( ( _ c, v _ ) _, _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) ) = 0 if _ v _ _ −d _ _ _ = _ v _ _ − _ _ [ ′ ] _ _ d _ [, we have ] _ π _ [UNK] ( _ c, v _ ) _ k _ lift _, d _ ( ( _ c, v _ ) _, _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) ) = [UNK] _ π _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) _"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 45,
    "text": "v ] _ _ d _ _ [ ′ ] _ [ ( ] _ [ c ] _ _ [ ′ ] _ _ [, c ] _ _ [ ′ ] _ [ ) ] _ [. ] _ summing the two expressions above, and using the fact that _ k _ lift _, d _ ( ( _ c, v _ ) _, _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) ) = 0 if _ v _ _ −d _ _ _ = _ v _ _ − _ _ [ ′ ] _ _ d _ [, we have ] _ π _ [UNK] ( _ c, v _ ) _ k _ lift _, d _ ( ( _ c, v _ ) _, _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) ) = [UNK] _ π _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) _, _ _ c, v _ which implies that _ k _ lift _, d _ is [UNK] _ π _ - invariant. since _ f _ _ d _ is also trivially [UNK] _ π _ - invariant and composition of invariant kernels remains invariant, then _ f _ _ d _ _ k _ lift _, d _ _ f _ _ d _ is [UNK] _ π _ - invariant. finally, using ( 30 ), we have _ _ _ _ _ π _ [UNK] ( _ c, v _ ) ( _ f _ _ d _ _ k _ lift _, d _ _ f _ _ d _ ) ( ( _ c, v _ ) _, _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) ) _ c, v _ _ _ _ _ _ π _ [UNK] ( _ c, v _ ) _ k _ _ nr _ ( ( _ c, v _ ) _, _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) ) = _ c, v _ = = _ _ _ _ _ d _ _ d _ = 1 _ d _ _ _ _ _ _ d _ _ _ _ _ _ p _ _ c _ _ ′ _ ( _ d _ ) [UNK] _ π _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) = [UNK] _ π _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) _, _ _ d _ = 1 _ _ _ _ _ p _ _ c _ ( _ d _ ) [UNK] _ π _ ( _ c, v _ ) ( _ f _ _ d _ _ k _ lift _, d _ _ f _ _ d _ ) ( ( _ c, v _ ) _, _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) ) _ c, v _ _ _ _ _ _ p _ _ c _ _ ′ _ ( _ d _ ) _ d _ = 1 _ c, v _ _ _ _ _ 35 and therefore _ k _ _ nr _ is [UNK] _ π _ - invariant. consider now point ( c ). let _ k _ [ [UNK] ] _ r _ = ( _ k _ _ nr _ + _ k _ _ nr _ _ [ ∗ ] _ [ ) ] _ [ / ] _ [ 2, where ] _ [ k ] _ _ nr _ _ [ ∗ ] _ [ is the [UNK] ] _ [ π ] _ [ - adjoint ] of _ k _ _ nr _. since _ f _ _ d _ _ [ ∗ ] _ [ = ] _ [ f ] _ _ [ d ] _ [, which is easy check by definition of ] _ [ f ] _ _ [ d ] _ [, we have that ] ( _ f _ _ d _ _ k _ lift _, d _ _ f _ _ d _ ) _ [ ∗ ] _ = _ f _ _ d _ _ [ ∗ ] _ _ [ k ] _ lift _ [ ∗ ] _ _, d _ _ [ f ] _ _ [ ∗ ] _ _ d _ [ = ] _ [ f ] _ _ [ d ] _ _ [ k ] _ lift _ [ ∗ ] _ _, d _ _ [ f ] _ _ [ d ] _ [, which implies ] _ k _ _ nr _ _ [ ∗ ] _ [ ( ( ] _ [ c, v ] _ [ ) ] _ [, ] _ [ ( ] _ [ c ] _ _ [ ′ ] _ _ [, v ] _ _ [ ′ ] _ [ ) ) = ] _ d _ _ p _ _ c _ ( _ d _ ) _ f _ _ d _ _ k _ lift _ [ ∗ ] _ _, d _ _ [ f ] _ _ [ d ] _ ( ( _"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 46,
    "text": "_ f _ _ d _ ) _ [ ∗ ] _ = _ f _ _ d _ _ [ ∗ ] _ _ [ k ] _ lift _ [ ∗ ] _ _, d _ _ [ f ] _ _ [ ∗ ] _ _ d _ [ = ] _ [ f ] _ _ [ d ] _ _ [ k ] _ lift _ [ ∗ ] _ _, d _ _ [ f ] _ _ [ d ] _ [, which implies ] _ k _ _ nr _ _ [ ∗ ] _ [ ( ( ] _ [ c, v ] _ [ ) ] _ [, ] _ [ ( ] _ [ c ] _ _ [ ′ ] _ _ [, v ] _ _ [ ′ ] _ [ ) ) = ] _ d _ _ p _ _ c _ ( _ d _ ) _ f _ _ d _ _ k _ lift _ [ ∗ ] _ _, d _ _ [ f ] _ _ [ d ] _ ( ( _ c, v _ ) _, _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) ) _ d _ = 1 and thus _ k _ [UNK] _ r _ ( ( _ c, v _ ) _, _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) ) = [ 1 ] 2 _ p _ _ c _ ( _ d _ ) ( _ f _ _ d _ _ k _ lift _, d _ _ f _ _ d _ ) ( ( _ c, v _ ) _, _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) ) + [ 1 ] 2 _ d _ = 1 _ d _ 2 _ d _ _ p _ _ c _ ( _ d _ ) _ f _ _ d _ _ k _ lift _ [ ∗ ] _ _, d _ _ [ f ] _ _ [ d ] _ ( ( _ c, v _ ) _, _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) ) _ d _ = 1 = _ d _ _ p _ _ c _ ( _ d _ ) _ f _ _ d _ _ k _ [ [UNK] ] _ nr, d _ _ f _ _ d _ ( ( _ c, v _ ) _, _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) ) _ d _ = 1 with _ k _ [ [UNK] ] _ nr, d _ : = 2 [ 1 ] 2 _ [ k ] _ lift _ [ ∗ ] _ _, d _ [. by ( ] [ 28 ] [ ) we have that for ] _ [ c ] _ _ [ ′ ] _ _ [ ] _ [ = ] _ [ c ] _ [ 1 ] [ 1 ] 2 _ [ k ] _ [ lift ] _ [, d ] _ [ + ] 2 _ k _ lift _ [ ∗ ] _ _, d _ [ ( ( ] _ [ c, v ] _ [ ) ] _ [, ] _ [ ( ] _ [ c ] _ _ [ ′ ] _ _ [, v ] _ _ [ ′ ] _ [ ) ) = ] _ [ π ] _ [ [UNK] ] _ π _ [UNK] [ ( ] ( _ [ c ] _ _ c, v _ _ [ ′ ] _ _ [, ] [ v ] _ _ [ ′ ] _ ) [ ) ] _ [ k ] _ [ lift ] _ [, d ] _ [ ( ( ] _ [ c ] _ _ [ ′ ] _ _ [, v ] _ _ [ ′ ] _ [ ) ] _ [, ] _ [ ( ] _ [ c, v ] _ [ ) ) ] = _ [ π ] _ _ π _ [ ( ] ( _ [ c ] _ _ c _ _ [ ′ ] _ ) [ ) ] _ [ k ] _ _ [ d, v ] _ _ d _ _ [ ′ ] _ _ c _ _ [ ′ ] _ _, c _ _ q _ _ d, c _ _ ′ _ _, c _ ( _ v _ _ [ ′ ] _ _, v _ ) = _ k _ _ d, −v _ _ d ′ _ _ c, c _ _ [ ′ ] _ [ ] _ q _ _ d, c _ _ ′ _ _, c _ ( _ v _ _ [ ′ ] _ _, v _ ) = _ k _ _ d, −v _ _ d _ _ c, c _ _ [ ′ ] _ [ ] _ q _ _ d, c, c _ _ ′ _ ( _ v, v _ _ [ ′ ] _ ) _, _ where we used the definition of _ q _ _ d, c _ _ ′ _ _, c _ ( _ v _ _"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 47,
    "text": "_ ) [ ) ] _ [ k ] _ _ [ d, v ] _ _ d _ _ [ ′ ] _ _ c _ _ [ ′ ] _ _, c _ _ q _ _ d, c _ _ ′ _ _, c _ ( _ v _ _ [ ′ ] _ _, v _ ) = _ k _ _ d, −v _ _ d ′ _ _ c, c _ _ [ ′ ] _ [ ] _ q _ _ d, c _ _ ′ _ _, c _ ( _ v _ _ [ ′ ] _ _, v _ ) = _ k _ _ d, −v _ _ d _ _ c, c _ _ [ ′ ] _ [ ] _ q _ _ d, c, c _ _ ′ _ ( _ v, v _ _ [ ′ ] _ ) _, _ where we used the definition of _ q _ _ d, c _ _ ′ _ _, c _ ( _ v _ _ [ ′ ] _ _, v _ ). for _ c _ _ [ ′ ] _ = _ c _ we have that _ k _ lift _ [ ∗ ] _ _, d _ [ ( ( ] _ [ c, v ] _ [ ) ] _ [, ] _ [ ( ] _ [ c, v ] _ _ [ ′ ] _ [ ) ) = ] _ [ k ] _ [ lift ] _ [, d ] _ [ ( ( ] _ [ c, v ] _ _ [ ′ ] _ [ ) ] _ [, ] _ [ ( ] _ [ c, v ] _ [ ) ) ] = _ k _ _ ′ _ _ d, v _ _ d _ [ ( ] _ [ c, c ] _ [ ) ] _ [ q ] _ _ [ d, c, c ] _ [ ( ] _ [ v ] _ _ [ ′ ] _ _ [, v ] _ [ ) = ] _ [ k ] _ _ [ d, ] [ − ] [ v ] _ _ [ d ] _ [ ( ] _ [ c, c ] _ [ ) ] _ [ q ] _ _ [ d, c, c ] _ _ [ ′ ] _ [ ( ] _ [ v, v ] _ _ [ ′ ] _ [ ) ] where we used that _ q _ _ d, c, c _ ( _ v _ _ [ ′ ] _ _, v _ ) _ > _ 0 implies _ v _ _ d _ _ [ ′ ] _ [ = ] _ [ − ] [ v ] _ _ [ d ] _ [. thus ] [ 1 ] _ c, c _ _ [ ′ ] _ [ ] _ q _ _ d, c, c _ _ ′ _ ( _ v, v _ _ [ ′ ] _ ) + [ 1 ] 2 _ [ k ] _ _ [ d, v ] _ _ [ d ] _ 2 _ k _ [UNK] _ nr, d _ ( ( _ c, v _ ) _, _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) ) = [ 1 ] _ c, c _ _ [ ′ ] _ [ ] _ q _ _ d, c, c _ _ ′ _ ( _ v, v _ _ [ ′ ] _ ) 2 _ [ k ] _ _ [ d, ] [ − ] [ v ] _ _ [ d ] _ 1 = 2 [ 1 ] _ c, c _ _ [ ′ ] _ [ ] _ q _ _ d, c, c _ _ ′ _ ( _ v, v _ _ [ ′ ] _ ) 2 _ [ k ] _ _ [ d, ] [ − ] _ 1 _ c, c _ _ [ ′ ] _ [ ] + [ 1 ] 2 _ [ k ] _ _ [ d, ] _ [ + ] 2 = _ k _ _ d _ ( _ c, c _ _ [ ′ ] _ ) _ q _ _ d, c, c _ _ ′ _ ( _ v, v _ _ [ ′ ] _ ) _. _ let now _ g _ : _ c × { − _ 1 _, _ + 1 _ } _ _ [ d ] _ _ → _ r and [UNK] _ g _ : _ c → _ r such that _ g _ ( _ c, v _ ) = [UNK] _ g _ ( _ c _ ). then, since _ f _ _ d _ leaves the first coordinate invariate and _ k _ _ d _ does not depend on _ v _, we have that _ f _ _ d _ _ k _ [ [UNK] ] _ nr, d _ _ f _ _ d _ _ g _ ( _ c, v _ ) = _ f _ _ d _ _ k _ [ [UNK] ] _ nr, d _ _ f _ _ d _ ( ( _ c, v _ ) _,"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 48,
    "text": "c _ _ [ ′ ] _ ) _ q _ _ d, c, c _ _ ′ _ ( _ v, v _ _ [ ′ ] _ ) _. _ let now _ g _ : _ c × { − _ 1 _, _ + 1 _ } _ _ [ d ] _ _ → _ r and [UNK] _ g _ : _ c → _ r such that _ g _ ( _ c, v _ ) = [UNK] _ g _ ( _ c _ ). then, since _ f _ _ d _ leaves the first coordinate invariate and _ k _ _ d _ does not depend on _ v _, we have that _ f _ _ d _ _ k _ [ [UNK] ] _ nr, d _ _ f _ _ d _ _ g _ ( _ c, v _ ) = _ f _ _ d _ _ k _ [ [UNK] ] _ nr, d _ _ f _ _ d _ ( ( _ c, v _ ) _, _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) ) [UNK] _ g _ ( _ c _ _ [ ′ ] _ ) _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ = _ k _ _ d _ ( _ c, c _ _ [ ′ ] _ ) [UNK] _ g _ ( _ c _ _ [ ′ ] _ ) = _ k _ _ d _ _ g _ [UNK] ( _ c _ ) _, _ _ c _ _ [ ′ ] _ 36 which implies _ k _ [UNK] _ nr _ _ g _ ( _ c, v _ ) = _ k _ [UNK] _ nr _ ( ( _ c, v _ ) _, _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) ) _ g _ ( _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ ) = _ k _ _ r _ _ g _ [UNK] ( _ c _ ) _. _ _ c _ _ [ ′ ] _ _, v _ _ [ ′ ] _ by simple induction then _ k _ [ [UNK] ] _ nr _ _ [ t ] _ _ [ g ] _ [ ( ] _ [ c, v ] _ [ ) = ] _ [ k ] _ _ r _ _ [ t ] _ _ [ g ] _ [ [UNK] ] [ ( ] _ [ c ] _ [ ) for every ] _ [ t ] _ [. ] it thus follows that var ( _ g, _ _ k _ [ [UNK] ] _ r _ ) = var ( [UNK] _ g, k _ _ r _ ). point ( c ) then follows from var ( _ g, k _ _ nr _ ) _ ≤ _ var ( _ g, _ _ k _ [ [UNK] ] _ r _ ), which is a consequence of lemma c. 1. # # # # * * c. 2 proof of lemma 2. 1 * * _ proof. _ reversibility follows by lemma c. 2 ( point ( a ) ), with _ k _ _ r _ = _ p _ r and ( _ k, k _ _ [ ′ ] _ ) _ ∈k _ in place of _ d ∈ _ [ _ d _ ]. the only delicate condition to verify is given by ( 30 ), which follows since _ p _ _ k, k _ _ ′ _ ( _ c, c _ _ [ ′ ] _ ) _ > _ 0 implies that _ n _ _ k _ ( _ c _ ) + _ n _ _ k _ _ ′ _ ( _ c _ ) = _ n _ _ k _ ( _ c _ _ [ ′ ] _ ) + _ n _ _ k _ _ ′ _ ( _ c _ _ [ ′ ] _ ) and therefore _ p _ _ c _ ( _ k, k _ _ [ ′ ] _ ) = _ p _ _ c _ _ ′ _ ( _ k, k _ _ [ ′ ] _ ). since _ π _ ( _ c _ ) _ > _ 0 for every _ c ∈ _ [ _ k _ ] _ [ n ] _, we have _ π _ ( _ c _ _ i _ = _ k | c _ _ −i _ ) _ > _ 0 for every _ c _ _ −i _ _ ∈ _ [ _ k _ ] _ [ n ] [ − ] _ [ 1 ]. combining this with the fact that _ p _ _ c _ ( _ k, k _ _ [ ′ ] _ ) _ > _ 0 for every ( _ k, k _ _ [ ′ ] _ ) _ ∈k _ such that _ n _ _ k _ ( _ c _ ) + _ n _ _ k _ _ ′ _ ( _ c _ ) _ > _ 0, we get that for every pair _ c _ = _ c _ _ ["
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 49,
    "text": "_ _ c _ _ ′ _ ( _ k, k _ _ [ ′ ] _ ). since _ π _ ( _ c _ ) _ > _ 0 for every _ c ∈ _ [ _ k _ ] _ [ n ] _, we have _ π _ ( _ c _ _ i _ = _ k | c _ _ −i _ ) _ > _ 0 for every _ c _ _ −i _ _ ∈ _ [ _ k _ ] _ [ n ] [ − ] _ [ 1 ]. combining this with the fact that _ p _ _ c _ ( _ k, k _ _ [ ′ ] _ ) _ > _ 0 for every ( _ k, k _ _ [ ′ ] _ ) _ ∈k _ such that _ n _ _ k _ ( _ c _ ) + _ n _ _ k _ _ ′ _ ( _ c _ ) _ > _ 0, we get that for every pair _ c _ = _ c _ _ [ ′ ] _ _ ∈ _ [ _ k _ ] _ [ n ] _ there exists a _ t ∈ _ n and a sequence _ c _ = _ c _ [ ( 0 ) ] _, c _ [ ( 1 ) ] _,..., c _ [ ( ] _ [ t ] _ [ ) ] = _ c _ _ [ ′ ] _ such that _ p _ r _ c _ [ ( ] _ [ t ] [ − ] _ [ 1 ) ] _, c _ [ ( ] _ [ t ] _ [ ) ] [ ] _ > _ 0 for every _ t _ = 1 _,..., t − _ 1. thus, _ p _ nr is irreducible. it is also easy to see that _ p _ r is aperiodic. uniform ergodicity then follows from levin and peres ( 2017, theorem 4. 9 ). # # # # * * c. 3 proof of lemma 2. 2 * * _ proof. _ fix ( _ k, k _ _ [ ′ ] _ ) _ ∈k _ and let ( _ k _ 1 _, k _ 2 ) be the pair sampled in the first two lines of algorithm 4. then a draw from the latter will have ( _ k, k _ _ [ ′ ] _ ) as realization if and only if ( _ k _ 1 _, k _ 2 ) = ( _ k, k _ _ [ ′ ] _ ) or ( _ k _ 1 _, k _ 2 ) = ( _ k _ _ [ ′ ] _ _, k _ ). by construction _ n _ _ k _ ( _ c _ ) _ n _ _ k _ _ ′ _ ( _ c _ ) p ( _ k _ 1 = _ k, k _ 2 = _ k _ _ [ ′ ] _ ) = p ( _ k _ 1 = _ k _ _ [ ′ ] _ _, k _ 2 = _ k _ ) = ( _ k − _ 1 ) _ n _ _ [, ] _ ( _ k − _ 1 ) _ n _ _ [, ] _ and thus _ p _ _ c _ ( _ k, k _ _ [ ′ ] _ ) = p ( _ k _ 1 = _ k, k _ 2 = _ k _ _ [ ′ ] _ ) + p ( _ k _ 1 = _ k _ _ [ ′ ] _ _, k _ 2 = _ k _ ), as desired. # # # # * * c. 4 proof of lemma 2. 3 * * _ proof. _ invariance follows by lemma c. 2 ( point ( b ) ), with _ k _ _ nr _ = _ p _ nr and ( _ k, k _ _ [ ′ ] _ ) _ ∈k _ in place of _ d ∈ _ [ _ d _ ]. the condition ( 30 ) is satisfied as shown in the proof of lemma 2. 1. consider then irreducibility. for ease of notation, we use the notation _ x _ = [ _ k _ ] _ [ n ] _ _ × k _ and _ x _ = ( _ c, v _ ) _ ∈x _. if _ π _ ( _ c _ ) _ > _ 0, this implies that _ π _ ( _ c _ _ i _ = _ k | c _ _ −i _ ) _ > _ 0 for every _ c _ _ −i _ _ ∈ _ [ _ k _ ] _ [ n ] [ − ] _ [ 1 ]. combining this with the fact that _ p _ _ c _ ( _ k, k _ _ [ ′ ] _ ) _ > _ 0 for every ( _ k, k _ _ [ ′ ] _ ) _ ∈k _ such that _ n _ _ k _ ( _ c _ ) + _ n _ _ k _ _ ′ _ ( _ c _ ) _ > _ 0"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 50,
    "text": ". consider then irreducibility. for ease of notation, we use the notation _ x _ = [ _ k _ ] _ [ n ] _ _ × k _ and _ x _ = ( _ c, v _ ) _ ∈x _. if _ π _ ( _ c _ ) _ > _ 0, this implies that _ π _ ( _ c _ _ i _ = _ k | c _ _ −i _ ) _ > _ 0 for every _ c _ _ −i _ _ ∈ _ [ _ k _ ] _ [ n ] [ − ] _ [ 1 ]. combining this with the fact that _ p _ _ c _ ( _ k, k _ _ [ ′ ] _ ) _ > _ 0 for every ( _ k, k _ _ [ ′ ] _ ) _ ∈k _ such that _ n _ _ k _ ( _ c _ ) + _ n _ _ k _ _ ′ _ ( _ c _ ) _ > _ 0, we get that for every pair _ x _ = _ x _ _ [ ′ ] _ _ ∈x _ there exists a _ t ∈ _ n and a sequence _ x _ = _ x _ [ ( 0 ) ] _, x _ [ ( 1 ) ] _,..., x _ [ ( ] _ [ t ] _ [ ) ] = _ x _ _ [ ′ ] _ such that _ p _ nr _ x _ [ ( ] _ [ t ] [ − ] _ [ 1 ) ] _, x _ [ ( ] _ [ t ] _ [ ) ] [ ] _ > _ 0 for every _ t _ = 1 _,..., t − _ 1. thus, _ p _ nr is irreducible. moreover, if _ ξ > _ 0 it is immediate to 37 deduce that _ p _ nr is aperiodic. uniform ergodicity then follows from levin and peres ( 2017, theorem 4. 9 ). # # # # * * c. 5 proof of theorem 3. 1 * * _ proof of theorem 3. 1. _ the first inequality var ( _ g, p _ nr ) _ ≤ _ var ( _ g, p _ r ) follows by point ( c ) of lemma c. 2, with _ k _ _ nr _ = _ p _ nr and _ k _ _ r _ = _ p _ r. in order to prove the other inequality in ( 14 ) it suffices to show that 1 ( 34 ) _ p _ r ( _ c, c _ _ [ ′ ] _ ) _ ≥ _ _ c _ = _ c _ _ [ ′ ] _ _ ∈ _ [ _ k _ ] _ [ n ] _ _, _ _ c _ ( _ k _ ) _ [ p ] _ [ mg ] [ ( ] _ [ c, c ] _ _ [ ′ ] _ [ ) ] _ [, ] _ by, e. g., theorem 2 in zanella ( 2020 ). in order to prove ( 34 ), fix _ c _ and _ c _ _ [ ′ ] _ such that _ c _ = ( _ c _ _ −i _ _, k _ ) and _ c _ _ [ ′ ] _ = ( _ c _ _ −i _ _, k _ _ [ ′ ] _ ) with _ i ∈ _ [ _ n _ ] and ( _ k, k _ _ [ ′ ] _ ) _ ∈k _. indeed for every other pair ( _ c, c _ _ [ ′ ] _ ) such that _ c _ = _ c _ _ [ ′ ] _ we have that _ p _ r ( _ c, c _ _ [ ′ ] _ ) = _ p _ mg ( _ c, c _ _ [ ′ ] _ ) = 0. by definition of _ p _ mg and _ p _ r we have _ p _ mg ( _ c, c _ _ [ ′ ] _ ) = [ 1 ] _ n _ _ [ π ] _ [ ( ] _ [ c ] _ _ [ i ] _ [ = ] _ [ k ] _ _ [ ′ ] _ _ [ | ] [ c ] _ _ [ − ] [ i ] _ [ ) ] _ [. ] _ and _, _ 1 _ p _ r ( _ c, c _ _ [ ′ ] _ ) = 2 _ n _ _ k _ _ n _ _ k _ + _ n _ _ k _ _ ′ _ _ n _ _ k _ _ π _ ( _ c _ _ i _ = _ k _ _ [ ′ ] _ _ | c _ _ −i _ ) 1 _, _ ( _ k − _ 1 ) _ n _ [ min ] _ n _ _ k _ _ ′ _ + 1 _ π _ ( _ c _ _ i _ = _ k | c _ _ −i _ ) where _ n _ _"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 51,
    "text": "[ ′ ] _ ) = [ 1 ] _ n _ _ [ π ] _ [ ( ] _ [ c ] _ _ [ i ] _ [ = ] _ [ k ] _ _ [ ′ ] _ _ [ | ] [ c ] _ _ [ − ] [ i ] _ [ ) ] _ [. ] _ and _, _ 1 _ p _ r ( _ c, c _ _ [ ′ ] _ ) = 2 _ n _ _ k _ _ n _ _ k _ + _ n _ _ k _ _ ′ _ _ n _ _ k _ _ π _ ( _ c _ _ i _ = _ k _ _ [ ′ ] _ _ | c _ _ −i _ ) 1 _, _ ( _ k − _ 1 ) _ n _ [ min ] _ n _ _ k _ _ ′ _ + 1 _ π _ ( _ c _ _ i _ = _ k | c _ _ −i _ ) where _ n _ _ j _ = _ n _ _ j _ ( _ c _ ) for every _ j ∈ _ [ _ k _ ] and _ n _ _ k _ _ ≥ _ 1 by definition of _ c _. thus 1 _ n _ _ k _ + _ n _ _ k _ _ ′ _ _ p _ r ( _ c, c _ _ [ ′ ] _ ) = 2 ( _ k − _ 1 ) _ n _ [ min ] _ n _ _ k _ _ [ k ] _ [ + ] _ [ n ] _ _ [ k ] _ _ [ ′ ] _ _ π _ ( _ c _ _ i _ = _ k _ _ [ ′ ] _ _ | c _ _ −i _ ) _ n _ _ k _ _ ′ _ + 1 _ π _ ( _ c _ _ i _ = _ k | c _ _ −i _ ) _ n _ _ k _ _ ′ _ _, _ _ [ n ] _ _ [ k ] _ [ + ] _ [ n ] _ _ [ k ] _ _ [ ′ ] _ _ n _ _ k _ _ n _ _ k _ _ ′ _ + 1 _ π _ ( _ c _ _ i _ = _ k | c _ _ −i _ ) 1 _ [ | ] [ c ] _ _ [ − ] [ i ] _ [ ) ] _ ≥ _ 1 _, _ _ [ π ] _ [ ( ] _ [ c ] _ _ [ i ] _ [ = ] _ [ k ] _ _ [ ′ ] _ 2 ( _ k − _ 1 ) _ n _ [ min ] _ π _ ( _ c _ _ i _ = _ k | c _ _ −i _ ) _ [ | ] [ c ] _ _ [ − ] [ i ] _ [ ) ] 1 1 = _ [ π ] _ [ ( ] _ [ c ] _ _ [ i ] _ [ = ] _ [ k ] _ _ [ ′ ] _ min 2 ( _ k − _ 1 ) _ n _ _ π _ ( _ c _ _ i _ = _ k _ _ [ ′ ] _ _ | c _ _ −i _ ) _ [, ] _ _ π _ ( _ c _ _ i _ = _ k | c _ _ −i _ ) _ [ c ] _ _ [ i ] _ [ = ] _ [ k ] _ _ [ ′ ] _ _ [ | ] [ c ] _ _ [ − ] [ i ] _ [ ) ] 1 1 min 2 ( _ k − _ 1 ) _ n _ _ π _ ( _ c _ _ i _ = _ k _ _ [ ′ ] _ _ | c _ _ −i _ ) _ [, ] _ _ π _ ( _ c _ _ i _ = _ k | c _ _ −i _ ) 1 _ π _ ( _ c _ _ i _ = _ k _ _ [ ′ ] _ _ | c _ _ −i _ ) 1 _ ≥ _ = 2 ( _ k − _ 1 ) _ n _ 2 ( _ k − _ 1 ) _ [ p ] _ [ mg ] [ ( ] _ [ c, c ] _ _ [ ′ ] _ [ ) ] _ [, ] _ which is exactly ( 34 ). # # # # * * c. 6 proof of proposition 3. 3 * * _ proof. _ let _ p _ [ [UNK] ] mg be the _ π _ ( _ c, _ _ * * w * * _ _, _ _ * * θ * * _ ) - reversible markov kernel on [ _ k _ ] _ [ n ] _ _ × _ θ _ [ k ] _ _ × _ ∆ _ k− _ 1 that, given ( _ c _ [ ( ] _ [ t ] _ [ ) ] _, _ _ * * w * * _ [ ( ] _ [ t ] _ [ )"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 52,
    "text": "_ _ | c _ _ −i _ ) 1 _ ≥ _ = 2 ( _ k − _ 1 ) _ n _ 2 ( _ k − _ 1 ) _ [ p ] _ [ mg ] [ ( ] _ [ c, c ] _ _ [ ′ ] _ [ ) ] _ [, ] _ which is exactly ( 34 ). # # # # * * c. 6 proof of proposition 3. 3 * * _ proof. _ let _ p _ [ [UNK] ] mg be the _ π _ ( _ c, _ _ * * w * * _ _, _ _ * * θ * * _ ) - reversible markov kernel on [ _ k _ ] _ [ n ] _ _ × _ θ _ [ k ] _ _ × _ ∆ _ k− _ 1 that, given ( _ c _ [ ( ] _ [ t ] _ [ ) ] _, _ _ * * w * * _ [ ( ] _ [ t ] _ [ ) ] _, _ _ * * θ * * _ [ ( ] _ [ t ] _ [ ) ] ) generates ( _ c _ [ ( ] _ [ t ] _ [ + 1 ) ] _, _ _ * * w * * _ [ ( ] _ [ t ] _ [ + 1 ) ] _, _ _ * * θ * * _ [ ( ] _ [ t ] _ [ + 1 ) ] ) by _ c _ [ ( ] _ [ t ] _ [ + 1 ) ] _ ∼ _ _ p _ mg _ c _ [ ( ] _ [ t ] _ [ ) ] _, · _ _, _ ( _ * * w * * _ [ ( ] _ [ t ] _ [ + 1 ) ] _, _ _ * * θ * * _ [ ( ] _ [ t ] _ [ + 1 ) ] ) _ ∼ _ _ π _ _ * * w * * _ _, _ _ * * θ * * _ _ | c _ = _ c _ [ ( ] _ [ t ] _ [ ) ] [ ] _. _ 38 by construction, var ( _ g, p _ mg ) = var ( _ g, _ _ p _ [ [UNK] ] mg ) for any _ g _ that is a function of _ c _ alone, because the marginal process on [ _ k _ ] _ [ n ] _ induced by _ p _ [ [UNK] ] mg is a markov chain with kernel _ p _ mg. we now compare _ p _ [ [UNK] ] mg and _ p _ cd. let _ [UNK] f, g [UNK] _ _ π _ = _ f _ ( _ x _ ) _ g _ ( _ x _ ) _ π _ ( d _ x _ ) _, _ _ x _ = [ _ k _ ] _ [ n ] _ _ × _ θ _ [ k ] _ _ × _ ∆ _ k− _ 1 _, _ _ x _ be the _ l _ [ 2 ] ( _ π _ ) inner product. then for any _ g ∈ _ _ l _ [ 2 ] ( _ π _ ) and ( _ c, _ _ * * w * * _ _, _ _ * * θ * * _ ) _ ∼ _ _ π _ we have _ [UNK] _ ( _ i − _ _ p _ cd ) _ g, g [UNK] _ _ π _ _ n _ 1 e [ var ( _ g _ ( _ c, _ _ * * w * * _ _, _ _ * * θ * * _ ) _ | c _ _ −i _ _, _ _ * * w * * _ _, _ _ * * θ * * _ ) ] + _ n _ + 1 [ e ] [ [ var ( ] _ [ g ] _ [ ( ] _ [ c, ] _ _ * * [ w ] * * _ _ [, ] _ _ * * [ θ ] * * _ [ ) ] _ [ | ] [ c ] _ [ ) ] ] _ i _ = 1 _ n _ 1 e [ var ( _ g _ ( _ c, _ _ * * w * * _ _, _ _ * * θ * * _ ) _ | c _ _ −i _ ) ] + _ n _ + 1 _ i _ = 1 _ n _ e [ var ( _ g _ ( _ c, _ _ * * w * * _ _, _ _ * * θ * * _ ) _ | c _ _ −i _ ) ] _ n _ _ i _ = 1 ( 35 ) 1 = _ n _ + 1 1 _ ≤ _ _ n _ + 1 = [ 1 ] _ n _ _ n _ e [ var ( _ g _ ( _ c, _ _ * * w * * _ _, _ _ * * θ * * _ ) _ | c _ _ −i _ ) ] = _ [UNK] _ ("
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 53,
    "text": "[ ) ] _ [ | ] [ c ] _ [ ) ] ] _ i _ = 1 _ n _ 1 e [ var ( _ g _ ( _ c, _ _ * * w * * _ _, _ _ * * θ * * _ ) _ | c _ _ −i _ ) ] + _ n _ + 1 _ i _ = 1 _ n _ e [ var ( _ g _ ( _ c, _ _ * * w * * _ _, _ _ * * θ * * _ ) _ | c _ _ −i _ ) ] _ n _ _ i _ = 1 ( 35 ) 1 = _ n _ + 1 1 _ ≤ _ _ n _ + 1 = [ 1 ] _ n _ _ n _ e [ var ( _ g _ ( _ c, _ _ * * w * * _ _, _ _ * * θ * * _ ) _ | c _ _ −i _ ) ] = _ [UNK] _ ( _ i − _ _ p _ [ [UNK] ] mg ) _ g, g [UNK] _ _ π _ _, _ _ i _ = 1 where the middle inequality follows from the fact that e [ var ( _ g _ ( _ c, _ _ * * w * * _ _, _ _ * * θ * * _ ) _ | c _ ) ] = e [ e [ var ( _ g _ ( _ c, _ _ * * w * * _ _, _ _ * * θ * * _ ) _ | c _ ) _ | c _ _ −i _ ] ] _ ≤ _ e [ var ( _ g _ ( _ c, _ _ * * w * * _ _, _ _ * * θ * * _ ) _ | c _ _ −i _ ) ] _, _ for every _ i _ = 1 _,..., n _ by the law of total variance. we thus have _ [UNK] _ ( _ i − _ _ p _ cd ) _ g, g [UNK] _ _ π _ _ ≤ _ _ [UNK] _ ( _ i − _ _ p _ [ [UNK] ] mg ) _ g, g [UNK] _ _ π _ for every _ g ∈ _ _ l _ [ 2 ] ( _ π _ ), which implies var ( _ g, _ _ p _ [ [UNK] ] mg ) _ ≤ _ var ( _ g, p _ cd ) for all _ g _ ( see e. g. the proof of tierney, 1998, theorem 4 ). we thus have var ( _ g, p _ mg ) = var ( _ g, _ _ p _ [ [UNK] ] mg ) _ ≤ _ var ( _ g, p _ cd ) for all _ g _ for functions _ g _ that depend only on _ c _. # # # # * * c. 7 proof of theorem 4. 1 * * _ proof. _ by ( 15 ) for every _ * * x * * _ _ ∈ _ ∆ _ k− _ 1 we have that, as _ n →∞ _, e [ _ x _ _ t _ + 1 _, k _ _ − _ _ x _ _ k _ _ | _ _ * * x * * _ _ t _ = _ * * x * * _ ] = [ 1 ] _ [ − ] _ _ [ x ] _ _ [ k ] _ _ [ k ] _ _ | _ _ * * α * * _ _ | − _ _ α _ _ k _ + _ n _ ( 1 _ − _ _ x _ _ k _ ) _ n _ _ * * α * * _ + _ n − _ 1 _ [ x ] _ _ [ k ] _ _ α _ _ k _ + _ nx _ _ k _ _ n _ _ | _ _ * * α * * _ _ | _ + _ n − _ 1 _ [ − ] _ _ [ x ] _ _ n _ _ [ k ] _ _ | _ _ * * α * * _ _ | _ + _ n − _ 1 _ α _ _ k _ _ − _ _ | _ _ * * α * * _ _ | x _ _ k _ = [ 2 ] _ n _ ( _ | _ _ * * α * * _ _ | _ + _ n − _ 1 ) [ = ] _ n _ [ 2 ] _ α _ 2 _ k _ 2 _ [ k ] _ [ + ] _ [ o ] _ [ ( 1 ) ] _ k _ 2 _ [ − | ] _ _ * * [ α ] * * _ _ [ | ] _ _ [ x ] _ 2 _ [ k ] _ and e ( _ x _ _ t _ + 1 _, k _ _ − _ _ x _ _ k _ ) [ 2 ] _ | _ _ * * x * * _ _ t _ = _ * * x * * _ ="
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 54,
    "text": "n _ _ [ k ] _ _ | _ _ * * α * * _ _ | _ + _ n − _ 1 _ α _ _ k _ _ − _ _ | _ _ * * α * * _ _ | x _ _ k _ = [ 2 ] _ n _ ( _ | _ _ * * α * * _ _ | _ + _ n − _ 1 ) [ = ] _ n _ [ 2 ] _ α _ 2 _ k _ 2 _ [ k ] _ [ + ] _ [ o ] _ [ ( 1 ) ] _ k _ 2 _ [ − | ] _ _ * * [ α ] * * _ _ [ | ] _ _ [ x ] _ 2 _ [ k ] _ and e ( _ x _ _ t _ + 1 _, k _ _ − _ _ x _ _ k _ ) [ 2 ] _ | _ _ * * x * * _ _ t _ = _ * * x * * _ = [ 1 ] _ [ − ] _ _ [ x ] _ _ [ k ] _ _ n _ [ 2 ] _ | _ _ * * α * * _ _ | − _ _ α _ _ k _ + _ n _ ( 1 _ − _ _ x _ _ k _ ) _ [ k ] _ _ n _ [ 2 ] _ * * α * * _ + _ n − _ 1 _ [ x ] _ _ [ k ] _ _ α _ _ k _ + _ nx _ _ k _ _ n _ [ 2 ] _ | _ _ * * α * * _ _ | _ + _ n − _ 1 [ + ] _ [ x ] _ _ n _ _ [ k ] _ [ 2 ] _ | _ _ * * α * * _ _ | _ + _ n − _ 1 = [ 2 ] [ [ ] _ [ x ] _ _ [ k ] _ [ ( 1 ] _ [ − ] _ _ [ x ] _ _ [ k ] _ [ ) + ] _ [ o ] _ [ ( 1 ) ] ] _ n _ [ 2 ] 39 and _ [ x ] _ _ [ k ] _ _ α _ _ k _ _ ′ _ + _ nx _ _ k _ _ ′ _ _ [ x ] _ _ [ k ] _ _ [ ′ ] _ _ n _ [ 2 ] _ | _ _ * * α * * _ _ | _ + _ n − _ 1 [ + ] _ n _ [ 2 ] e ( _ x _ _ t _ + 1 _, k _ _ − _ _ x _ _ k _ ) _ x _ _ t _ + 1 _, k _ _ ′ _ _ − _ _ x _ _ k _ _ ′ _ [ ] _ | _ _ * * x * * _ _ t _ = _ * * x * * _ = _ [ − ] [ x ] _ _ [ k ] _ [ 2 ] _ [ k ] _ _ [ ′ ] _ _ α _ _ k _ + _ nx _ _ k _ _ n _ [ 2 ] _ | _ _ * * α * * _ _ | _ + _ n − _ 1 = [ 2 ] [ [ ] _ [ − ] [ x ] _ _ [ k ] _ _ [ x ] _ _ [ k ] _ _ [ ′ ] _ [ + ] _ [ o ] _ [ ( 1 ) ] ] _ [, ] _ _ n _ [ 2 ] and _ n _ [ 2 ] e ( _ x _ _ t _ + 1 _, k _ _ − _ _ x _ _ k _ ) [ 3 ] _ | _ _ * * x * * _ _ t _ = _ * * x * * _ = _ o _ ( 1 ) for _ k _ = _ k _ _ [ ′ ] _ _ ∈ _ [ _ k _ ]. by a second - order taylor expansion, this means that sup _ | _ e [ _ g _ ( _ * * x * * _ _ t− _ 1 ) _ | _ _ * * x * * _ _ t _ = _ * * x * * _ ] _ − _ _ g _ ( _ * * x * * _ ) _ −ag _ ( _ * * x * * _ ) _ | → _ 0 _, _ _ * * x * * _ _ ∈ _ ∆ _ k _ + 1 as _ n →∞ _ for every _ g _ twice differentiable real - valued function. the result then follows by corollary 8 _. _ 9 in ( ethier and kurtz, 1986, chapter 4 ). # # # # * * c. 8 proof of theorem 4. 4 * * _ proof. _ fix _ * * z * * _ = ( _ * * x * * _ _, _ _ * * v * * _ ) _ ∈ _ _ e _ _ m _ _"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 55,
    "text": "that sup _ | _ e [ _ g _ ( _ * * x * * _ _ t− _ 1 ) _ | _ _ * * x * * _ _ t _ = _ * * x * * _ ] _ − _ _ g _ ( _ * * x * * _ ) _ −ag _ ( _ * * x * * _ ) _ | → _ 0 _, _ _ * * x * * _ _ ∈ _ ∆ _ k _ + 1 as _ n →∞ _ for every _ g _ twice differentiable real - valued function. the result then follows by corollary 8 _. _ 9 in ( ethier and kurtz, 1986, chapter 4 ). # # # # * * c. 8 proof of theorem 4. 4 * * _ proof. _ fix _ * * z * * _ = ( _ * * x * * _ _, _ _ * * v * * _ ) _ ∈ _ _ e _ _ m _ _ × v _. notice that e _ x _ _ t _ [ ( ] + 1 _ [ m ] _ [ ) ] _, k _ _ [ − ] _ _ [ x ] _ _ [ k ] _ _ [ | ] _ _ * * [ x ] * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] = _ * * x * * _ _, _ _ * * v * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] = _ * * v * * _ _ k − _ 1 _ [ α ] _ [ ( ] _ * * [ x ] * * _ _ [, k ] _ _ [ ′ ] _ _ [, k ] _ [ ) ] _ k _ _ [ ′ ] _ : _ v _ _ k ′, k _ _ k _ _ [ ′ ] _ : _ v _ _ k ′, k _ = + 1 = 1 _ − _ _ [ ξ ] _ _ n _ 1 _ n _ _ x _ _ k _ + _ x _ _ k _ _ ′ _ _ xk _ _ k _ + _ − x _ 1 _ k _ _ ′ _ _ [ α ] _ [ ( ] _ * * [ x ] * * _ _ [, k, k ] _ _ [ ′ ] _ [ ) ] _ [ − ] _ _ k _ _ [ ′ ] _ : _ v _ _ k ′, k _ = _ − _ 1 1 _ − _ _ [ ξ ] _ _ n _ _ n _ _ k _ _ [ ′ ] _ : _ v _ _ k ′, k _ _ x _ _ k _ + _ x _ _ k _ _ ′ _ _ k − _ 1 _ [ α ] _ [ ( ] _ * * [ x ] * * _ _ [, k, k ] _ _ [ ′ ] _ [ ) ] _ xk _ _ k _ + _ − x _ 1 _ k _ _ ′ _ _ [ α ] _ [ ( ] _ * * [ x ] * * _ _ [, k ] _ _ [ ′ ] _ _ [, k ] _ [ ) ] _ [ − ] _ _ k _ _ [ ′ ] _ : _ v _ _ k ′, k _ = + 1 _, _ where _ α _ _ k _ + _ nx _ _ k _ _ α _ ( _ * * x * * _ _, k, k _ _ [ ′ ] _ ) = min 1 _, _ _ nx _ _ k _ + 1 _ k _ _ [ ′ ] _ : _ v _ _ k ′, k _ = _ − _ 1 _ nx _ _ k _ _ ′ _ _ α _ _ k _ _ ′ _ + _ nx _ _ k _ _ ′ _ _ − _ 1 = 1 _ − _ _ [ β ] _ [ ( ] _ [ x ] _ _ [ k ] _ _ [, x ] _ _ [ k ] _ _ [ ′ ] _ _ [, v ] _ _ [ k ] _ _ [ ′ ] _ _ [, ] [ k ] _ [ ) ] _ [ k ] _ _ [ ′ ] _ _ [, v ] _ _ [ k ] _ _ [ ′ ] _ _ [, ] [ k ] _ [ ) ] 1 + _ o _ _ n _ _ n _ _ n _ _, _ from which we deduce that ( 36 ) e _ x _ _ t _ [ ( ] + 1 _ [ m ] _ [ ) ] _, k _ _ [ − ] _ _ [ x ] _ _ [ k ] _ _ [ | ] _ _ * * [ x ] * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] = _ * * x * * _ _, _ _ * * v * * _ _ t _ ["
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 56,
    "text": "_ _ [ k ] _ _ [, x ] _ _ [ k ] _ _ [ ′ ] _ _ [, v ] _ _ [ k ] _ _ [ ′ ] _ _ [, ] [ k ] _ [ ) ] _ [ k ] _ _ [ ′ ] _ _ [, v ] _ _ [ k ] _ _ [ ′ ] _ _ [, ] [ k ] _ [ ) ] 1 + _ o _ _ n _ _ n _ _ n _ _, _ from which we deduce that ( 36 ) e _ x _ _ t _ [ ( ] + 1 _ [ m ] _ [ ) ] _, k _ _ [ − ] _ _ [ x ] _ _ [ k ] _ _ [ | ] _ _ * * [ x ] * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] = _ * * x * * _ _, _ _ * * v * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] = _ * * v * * _ = [ φ ] _ [ k ] _ _ n _ [ ( ] _ * * [ z ] * * _ [ ) ] [ ( ] _ * * [ z ] * * _ [ ) ] 1 + _ o _ _ n _ _ n _ _ n _ _. _ similarly we get that 1 ( 37 ) e _ x _ _ t _ [ ( ] + 1 _ [ m ] _ [ ) ] _, k _ _ [ − ] _ _ [ x ] _ _ [ k ] _ _ x _ _ t _ [ ( ] + 1 _ [ m ] _ [ ) ] _, k _ _ [ ′ ] _ _ [ − ] _ _ [ x ] _ _ [ k ] _ _ [ ′ ] _ _ | _ _ * * x * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] = _ * * x * * _ _, _ _ * * v * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] = _ * * v * * _ = _ o _ _ n _ 40 _, _ for every ( _ k, k _ _ [ ′ ] _ ) _ ∈ _ [ _ k _ ] [ 2 ]. moreover ( 38 ) e _ g _ _ * * x * * _ _, _ _ * * v * * _ _ t _ [ ( ] + 1 _ [ m ] _ [ ) ] _ − _ _ g _ ( _ * * x * * _ _, _ _ * * v * * _ ) _ | _ _ * * x * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] = _ * * x * * _ _, _ _ * * v * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] = _ * * v * * _ _ _ _ _ _ _ 2 _ ξ _ + _ α _ ( _ * * x * * _ _, k, k _ _ [ ′ ] _ ) 1 _ − _ _ [ ξ ] _ _ n _ _ n _ _ _ _ _ _ _ 2 + _ α _ ( _ * * x * * _ _, k, k _ _ [ ′ ] _ ) 1 _ − _ _ [ ξ ] _ _ n _ _ _ _ _ _ _ _ ξ _ _ n _ _ _ _ _ _ _ 1 _ − _ _ α _ ( _ * * x * * _ _, k, k _ _ [ ′ ] _ ) [ ] 1 _ − _ _ [ ξ ] _ _ n _ _ _ _ _ _ _ = _ k _ = _ _ _ k _ _ [ ′ ] _ = _ _ _ _ _ x _ _ k _ + _ x _ _ k _ _ ′ _ _ g _ ( _ * * z * * _ * * ( * * _ * * k, k * * _ _ * * ′ * * _ * * ) * * ) _ − _ _ g _ ( _ * * z * * _ ) 2 ( _ k − _ 1 ) _ _ _ _ _ _ _ _ _ n _ _ _ _ _ _ _ _ ξ _ + 1 _ − _ _ α _ ( _ * * x * * _ _, k _ _ [ ′ ] _ _, k _ ) [ ] _ n _ _ _ _ _ _ _ 2 + _ α _ ( _ * * x * * _ _, k _ _ [ ′ ] _ _, k _ ) _ [ ξ ] _ _ n _ _ _ _ _ _ _ _ g _ ( _ * * z * * _ * * ( * * _ * * k, k * * _ _ * * ′ * * _ * * ) * * ) _ − _"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 57,
    "text": "_ * * z * * _ * * ( * * _ * * k, k * * _ _ * * ′ * * _ * * ) * * ) _ − _ _ g _ ( _ * * z * * _ ) 2 ( _ k − _ 1 ) _ _ _ _ _ _ _ _ _ n _ _ _ _ _ _ _ _ ξ _ + 1 _ − _ _ α _ ( _ * * x * * _ _, k _ _ [ ′ ] _ _, k _ ) [ ] _ n _ _ _ _ _ _ _ 2 + _ α _ ( _ * * x * * _ _, k _ _ [ ′ ] _ _, k _ ) _ [ ξ ] _ _ n _ _ _ _ _ _ _ _ g _ ( _ * * z * * _ * * ( * * _ * * k, k * * _ _ * * ′ * * _ * * ) * * ) _ − _ _ g _ ( _ * * z * * _ ) _ _ _ _ _ _ _ _ _ _ _ _ _ k _ = _ _ _ k _ _ [ ′ ] _ = _ [ λ ] _ [ ( ] _ * * [ z ] * * _ [ ) ] _ n _ _ _ _ _ _ _ 1 _ k _ = _ _ _ k _ _ [ ′ ] _ _ q _ ( _ k, k _ _ [ ′ ] _ ) _ g _ ( _ * * z * * _ * * ( * * _ * * k, k * * _ _ * * ′ * * _ * * ) * * ) _ − _ _ g _ ( _ * * z * * _ ) + _ o _ _ n _ _ _ * * ) * * ) _ − _ _ g _ ( _ * * z * * _ ) _ x _ _ k _ + _ x _ _ k _ _ ′ _ 1 _ β _ ( _ x _ _ k _ _, x _ _ k _ _ ′ _ _, v _ _ k, k _ _ ′ _ ) + 2 _ ξ _ + _ o _ _ n _ 2 ( _ k − _ 1 ) _ n _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ n _ _ _ _ _ _ _ _. _ _ _ _ _ _ _ _ _ by a taylor expansion we have that e _ g _ ( _ * * z * * _ _ t _ [ ( ] + 1 _ [ m ] _ [ ) ] _ [ | ] _ _ * * [ z ] * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] = _ * * z * * _ _ − _ _ g _ ( _ * * z * * _ ) = e _ g _ ( _ * * x * * _ _, _ _ * * v * * _ _ t _ [ ( ] + 1 _ [ m ] _ [ ) ] [ ) ] _ [ | ] _ _ * * [ z ] * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] = _ * * z * * _ _ − _ _ g _ ( _ * * z * * _ ) _ _ _ _ _ _ _ n _ _ _ _ _ _ _ + _ _ _ _ _ _ _ k _ _ _ _ _ _ _ _ ∂ _ 1 _ k _ = 1 e _ x _ _ t _ [ ( ] + 1 _ [ m ] _ [ ) ] _, k _ _ [ − ] _ _ [ x ] _ _ [ k ] _ _ | _ _ * * z * * _ _ t _ [ ( ] _ [ m ] _ [ ) ] = _ * * z * * _ _ ∂z _ 1 _, k _ _ g _ ( _ * * z * * _ ) + _ o _ _ n _ _ _ 1 _ − _ _ [ ξ ] _ _ n _ _ _ _ _ _, _ _ _ _ _ _ _ that, combined with ( 36 ), ( 37 ) and ( 38 ), implies _ _ _ _ _ _ sup _ * * z * * _ _ ∈e _ _ m _ _ × _ [ _ k _ ] [ 2 ] _ _ _ _ _ _ e _ g _ ( _ * * z * * _ _ t _ [ ( ] + 1 _ [ m ] _ [ ) ] [ ) ] _ [ | ] _ _ * * [ z ] * * _ _ [ t ] _ [ = ] _ * * [ z ] * * _ _ − _ _ g _ ( _ * * z * * _ ) _ −bg _ ( _ * * z * * _ ) _ → _ 0 _, _ _ _ _ _ _ _ as _ n →∞ _ for every _"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03226v1",
      "title": "A fast non-reversible sampler for Bayesian finite mixture models",
      "authors": [
        "Filippo Ascolani",
        "Giacomo Zanella"
      ],
      "summary": "Finite mixtures are a cornerstone of Bayesian modelling, and it is well-known\nthat sampling from the resulting posterior distribution can be a hard task. In\nparticular, popular reversible Markov chain Monte Carlo schemes are often slow\nto converge when the number of observations $n$ is large. In this paper we\nintroduce a novel and simple non-reversible sampling scheme for Bayesian finite\nmixture models, which is shown to drastically outperform classical samplers in\nmany scenarios of interest, especially during convergence phase and when\ncomponents in the mixture have non-negligible overlap. At the theoretical\nlevel, we show that the performance of the proposed non-reversible scheme\ncannot be worse than the standard one, in terms of asymptotic variance, by more\nthan a factor of four; and we provide a scaling limit analysis suggesting that\nthe non-reversible sampler can reduce the convergence time from O$(n^2)$ to\nO$(n)$. We also discuss why the statistical features of mixture models make\nthem an ideal case for the use of non-reversible discrete samplers.",
      "published": "2025-10-03T17:57:44Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03226v1"
    },
    "chunk_id": 58,
    "text": "_ o _ _ n _ _ _ 1 _ − _ _ [ ξ ] _ _ n _ _ _ _ _ _, _ _ _ _ _ _ _ that, combined with ( 36 ), ( 37 ) and ( 38 ), implies _ _ _ _ _ _ sup _ * * z * * _ _ ∈e _ _ m _ _ × _ [ _ k _ ] [ 2 ] _ _ _ _ _ _ e _ g _ ( _ * * z * * _ _ t _ [ ( ] + 1 _ [ m ] _ [ ) ] [ ) ] _ [ | ] _ _ * * [ z ] * * _ _ [ t ] _ [ = ] _ * * [ z ] * * _ _ − _ _ g _ ( _ * * z * * _ ) _ −bg _ ( _ * * z * * _ ) _ → _ 0 _, _ _ _ _ _ _ _ as _ n →∞ _ for every _ g _ : ∆ _ k− _ 1 _ × _ [ _ k _ ] [ 2 ] _ → _ r twice continuously differentiable in the first argument. the result then follows by corollary 8 _. _ 9 in ethier and kurtz ( 1986, chapter 4 ). 41"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03224v1",
      "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance\n  of Latent Ensembles",
      "authors": [
        "Dong Lao",
        "Yuxiang Zhang",
        "Haniyeh Ehsani Oskouie",
        "Yangchao Wu",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "summary": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.",
      "published": "2025-10-03T17:57:25Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03224v1"
    },
    "chunk_id": 0,
    "text": "preprint version. under review. # # - t est - t ime d efense a gainst a dversarial a t - tacks via s tochastic r esonance of l atent e n # # # # sembles * * dong lao * * * * [ 1, 2 ] * * * * yuxiang zhang * * * * [ 2 ] * * * * haniyeh ehsani oskouie * * * * [ 2 ] * * * * yangchao wu * * * * [ 2 ] * * * * alex wong * * * * [ 3 ] * * * * stefano soatto * * * * [ 2 ] * * 1 lsu vision lab 2 ucla vision lab 3 yale vision lab 1 dong. lao @ lsu. edu 2 _ { _ zhangbrandon102, haniyehehsani, wuyangchao1997, soatto _ } _ @ ucla. edu 3 alex. wong @ yale. edu a bstract we propose a test - time defense mechanism against adversarial attacks : imperceptible image perturbations that significantly alter the predictions of a model. unlike existing methods that rely on feature filtering or smoothing, which can lead to information loss, we propose to “ combat noise with noise ” by leveraging stochastic resonance to enhance robustness while minimizing information loss. our approach introduces small translational perturbations to the input image, aligns the transformed feature embeddings, and aggregates them before mapping back to the original reference image. this can be expressed in a closed - form formula, which can be deployed on diverse existing network architectures without introducing additional network modules or fine - tuning for specific attack types. the resulting method is entirely training - free, architecture - agnostic, and attack - agnostic. empirical results show state - of - the - art robustness on image classification and, for the first time, establish a generic test - time defense for dense prediction tasks, including stereo matching and optical flow, highlighting the method ’ s versatility and practicality. specifically, relative to clean ( unperturbed ) performance, our method recovers up to 68. 1 % of the accuracy loss on image classification, 71. 9 % on stereo matching, and 29. 2 % on optical flow under various types of adversarial attacks. 1 i ntroduction most deep neural networks in use today are deterministic maps from a fixed - size input to a fixedsize feature vector. in auto - regressive transformer models, that vector encodes the next element ( token ) in the input sequence. similarly, in convolutional architectures, that vector may encode the input data. in either case, the output vector is often highly sensitive to perturbations of the input, and one can intentionally choose these imperceptible perturbations _ adversarially _ so as to maximize the change in the output goodfellow et al. ( 2014 ). in some cases, the same perturbation can even be disruptive for a large number of possible inputs moosavi - dezfooli et al. ( 2017 ), exploiting the convoluted geometry of the decision boundary imposed by such trained models tram ` er et al. ( 2017 ). this spurious sensitivity could be exploited adversarially to disrupt the operation of a model. from a classical perspective of signal processing, adversarial perturbations of images appear as small high - frequency “ noise ” resembling _ aliasing _ artifacts. these are imperceptible since the human visual system easily discounts them on account of their poor fit to the ‘ ecological statistics ’ of natural images gibson ( 2014 ). classical sampling theory prescribes anti - aliasing by low - pass filtering the data, removing information along with the artifacts. low - pass filtering consists of spatial averaging of the perturbed data with respect to a chosen kernel, typically a gaussian or a constant ( “ pillbox ” ). alternatively, one could “ denoise ” the embeddings by averaging output vectors, also a lossy operation. the choice of the kernel should match the statistics of the perturbations, which sets up a cat - and - mouse game where the adversary can easily modify the perturbations to bypass the anti - aliasing filter, namely _ adaptive _ attacks tramer et al. ( 2020 ), and the model needs to constantly be fine - tuned to “ anti - alias ” new forms of adversarial perturbations. in the context of deep neural 1 preprint version. under review. networks, existing defense methods that manipulate feature representations xie et al. ( 2019 ) ; bai et al. ( 2021 ) ; yan et al. ( 2021 ) ; kim et al. ( 2023 ) fundamentally adhere to this paradigm in principle. despite substantial engineering efforts, these methods remain inherently vulnerable to adaptive attacks because they rely on pre - defined filtering strategies that are fixed at inference time. * * desiderata : * * to break this cycle, we advocate a method to mitigate the effect of adversarial"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03224v1",
      "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance\n  of Latent Ensembles",
      "authors": [
        "Dong Lao",
        "Yuxiang Zhang",
        "Haniyeh Ehsani Oskouie",
        "Yangchao Wu",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "summary": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.",
      "published": "2025-10-03T17:57:25Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03224v1"
    },
    "chunk_id": 1,
    "text": "##y operation. the choice of the kernel should match the statistics of the perturbations, which sets up a cat - and - mouse game where the adversary can easily modify the perturbations to bypass the anti - aliasing filter, namely _ adaptive _ attacks tramer et al. ( 2020 ), and the model needs to constantly be fine - tuned to “ anti - alias ” new forms of adversarial perturbations. in the context of deep neural 1 preprint version. under review. networks, existing defense methods that manipulate feature representations xie et al. ( 2019 ) ; bai et al. ( 2021 ) ; yan et al. ( 2021 ) ; kim et al. ( 2023 ) fundamentally adhere to this paradigm in principle. despite substantial engineering efforts, these methods remain inherently vulnerable to adaptive attacks because they rely on pre - defined filtering strategies that are fixed at inference time. * * desiderata : * * to break this cycle, we advocate a method to mitigate the effect of adversarial perturbation that ( i ) operates at test time, without the need to update the model weights, and ( ii ) does not entail information loss associated with direct or indirect spatial filtering. in addition, it would be ideal if this method could ( iii ) be applied to existing network architectures without modifications, and ( iv ) be agnostic to the specific type of adversarial perturbation. * * stochastic resonance * * is a technique that resolves a quantized signal below the quantization level, by quantizing and ensembling perturbed versions of the signal benzi et al. ( 1981 ). it has been used extensively in cochlear implants, where power constraints limit the resolution of the digital circuitry stocks et al. ( 2002 ). it has also been used to ‘ super - resolve ’ vision transformer embeddings, where entire patches are encoded into a vector, which is computed at a coarsely subsampled grid lao et al. ( 2024 ). in this paper, instead, we use stochastic resonance for the opposite purpose, _ not _ to superresolve the quantized signal, but to perform latent ensembling to remove the effects of adversarial perturbations in the embedding. rather than averaging the data, or averaging their embedding as in classical denoising, _ we average _ _ transformed embeddings _ in latent space. this averaging is performed over small transformations sampled at random or deterministically from the group of planar translations, by computing the encoding of the transformed image, and then mapping the encoding back through the push - forward of the inverse transformation. this process can be expressed as a single formula in equation 1. since the embedding is typically computed on a coarse grid, but the transformations are sampled on the native lattice of the image, the resulting embedding is free of spatial averaging artifacts. as with other uses of stochastic resonance, the effect is seemingly paradoxical as _ we combat noise with _ _ noise _ : we apply purposeful perturbations to eliminate the effect of adversarial perturbations. our method can be thought of as marginalizing the translation group in latent space with respect to a chosen prior, which is the only design choice in our method. we choose the simplest, which is the constant prior. the purposeful perturbations alter the spatial sampling, and the implicit ensembling in latent space averages out the effect of sampling artifacts, thwarting the effect of adversarial perturbations. it is as if we were given multiple images with different ‘ noise ’, except that the noise in question is not the adversarial perturbation, but the splinters of adversarial perturbations obtained by different spatially quantized versions of the perturbed image, due to the translational perturbations, which are then averaged out by the latent ensembling. * * outcomes : * * our method fulfills the desiderata ( i ) - ( iv ) laid out earlier : ( i ) it does not require training or fine - tuning ; ( ii ) it minimizes information loss by latent ensembling of perturbed embeddings ; ( iii ) it can be applied to different network architectures and tasks, _ including _ networks already equipped with different defense techniques like adversarial training, and ( iv ) is agnostic to the specific perturbation. to measure the effectiveness of our method in mitigating the effects of adversarial perturbations, we test it on three vastly different tasks, including image classification, and two other dense prediction tasks : stereo matching and optical flow. where we are the first to show a significant and consistent improvement in robustness to various adversarial attacks. one could argue that there is still a cat - and - mouse game in our setting, if the adversary knows our technique and tailors the adversarial perturbations to bypass it. to assess this risk, we conduct “ worst - case ” adaptive tests to measure the performance of our method under adaptive attacks when the attacker knows the exact defense strategy, thus the adversarial perturbation is designed to maximally disrupt the result end - to - end, _ including _ our stochastic resonance. our results show that the method is resistant to breaking even when the adversary optimizes"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03224v1",
      "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance\n  of Latent Ensembles",
      "authors": [
        "Dong Lao",
        "Yuxiang Zhang",
        "Haniyeh Ehsani Oskouie",
        "Yangchao Wu",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "summary": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.",
      "published": "2025-10-03T17:57:25Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03224v1"
    },
    "chunk_id": 2,
    "text": "_ including _ networks already equipped with different defense techniques like adversarial training, and ( iv ) is agnostic to the specific perturbation. to measure the effectiveness of our method in mitigating the effects of adversarial perturbations, we test it on three vastly different tasks, including image classification, and two other dense prediction tasks : stereo matching and optical flow. where we are the first to show a significant and consistent improvement in robustness to various adversarial attacks. one could argue that there is still a cat - and - mouse game in our setting, if the adversary knows our technique and tailors the adversarial perturbations to bypass it. to assess this risk, we conduct “ worst - case ” adaptive tests to measure the performance of our method under adaptive attacks when the attacker knows the exact defense strategy, thus the adversarial perturbation is designed to maximally disrupt the result end - to - end, _ including _ our stochastic resonance. our results show that the method is resistant to breaking even when the adversary optimizes adaptively through it end - to - end. 2 r elated w ork the literature on adversarial attack and defense is extensive. we highlight some of the advances. * * adversarial training as defense. * * adversarial training increases the robustness of the model by training it with adversarially augmented images. the popular attack methods used are fast gradient 2 preprint version. under review. * * noisy features * * * * attacked * * * * image * * _ encode _ [UNK] * * “ * * boxer * * ” * * # # # * * [UNK] * * * * [UNK] * * * * high fidelity features * * “ panda ” _ & inverse _ | { [UNK] } [UNK] < br > [UNK] [UNK] = 1 | col2 | col3 | col4 | col5 | col6 | | - - - | - - - | - - - | - - - | - - - | - - - | | _ upsample _ < br > | _ upsample _ < br > | _ upsample _ < br > | _ upsample _ < br > | _ upsample _ < br > | _ upsample _ < br > | _ transformations _ | attacked < br > image | col2 | col3 | col4 | col5 | col6 | col7 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | _ transformations _ < br > { [UNK] } [UNK] = 1 < br > [UNK] | _ transformations _ < br > { [UNK] } [UNK] = 1 < br > [UNK] | _ transformations _ < br > { [UNK] } [UNK] = 1 < br > [UNK] | _ transformations _ < br > { [UNK] } [UNK] = 1 < br > [UNK] | _ transformations _ < br > { [UNK] } [UNK] = 1 < br > [UNK] | _ transformations _ < br > { [UNK] } [UNK] = 1 < br > [UNK] | _ transformations _ < br > { [UNK] } [UNK] = 1 < br > [UNK] | | * * + * * < br > * * stochastic * * < br > * * resonance * * < br > | | | | | | | | * * + * * < br > * * stochastic * * < br > * * resonance * * < br > | | | | | | | figure 1 : * * defense against adversarial attacks via stochastic resonance. * * _ neural networks are highly sensi - _ _ tive to small perturbations in the input space, which adversarial attacks exploit to manipulate network outputs. _ _ conventional defense strategies primarily focus on filtering out unreliable features or denoising either the in - _ _ put or the features. instead of removing noise, we propose a novel defense by introducing noise. based on _ _ stochastic resonance, controlled transformations are introduced to the input. features are then aggregated after _ _ inverting these transformations. the resulting method can be applied exclusively at inference time, requires no _ _ training, and is compatible with diverse network architectures. notably, it not only improves robustness against _ _ adversarial attacks but also increases the difficulty of crafting successful adversarial examples, even when the _ _ attacker is fully aware of whether and how stochastic resonance is being used ( i. e. adaptive attacks ). _ sign method ( fgsm ) goodfellow et al. ( 2014 ), and projected gradient descent ( pgd ) madry et al. ( 2017 ). alp kannan et al. ( 2018 ) minimizes the difference between the logits of pairs of clean and adversarially augmented images. trades zhang et al. ( 2019 ) decomposes prediction error for adversarial examples into natural error and boundary error to improve adversarial robustness at the cost of accuracy. mart wang et al. ( 2019 ) improves adversarial robustness by considering misclassified natural examples during training. subsequent work cai et al. ( 2018 ) ;"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03224v1",
      "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance\n  of Latent Ensembles",
      "authors": [
        "Dong Lao",
        "Yuxiang Zhang",
        "Haniyeh Ehsani Oskouie",
        "Yangchao Wu",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "summary": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.",
      "published": "2025-10-03T17:57:25Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03224v1"
    },
    "chunk_id": 3,
    "text": "at inference time, requires no _ _ training, and is compatible with diverse network architectures. notably, it not only improves robustness against _ _ adversarial attacks but also increases the difficulty of crafting successful adversarial examples, even when the _ _ attacker is fully aware of whether and how stochastic resonance is being used ( i. e. adaptive attacks ). _ sign method ( fgsm ) goodfellow et al. ( 2014 ), and projected gradient descent ( pgd ) madry et al. ( 2017 ). alp kannan et al. ( 2018 ) minimizes the difference between the logits of pairs of clean and adversarially augmented images. trades zhang et al. ( 2019 ) decomposes prediction error for adversarial examples into natural error and boundary error to improve adversarial robustness at the cost of accuracy. mart wang et al. ( 2019 ) improves adversarial robustness by considering misclassified natural examples during training. subsequent work cai et al. ( 2018 ) ; zhang et al. ( 2020 ) ; wang & wang ( 2022 ) ; jin et al. ( 2022 ) ; ghiasvand et al. ( 2024 ) improves adversarial robustness with curriculum learning bengio et al. ( 2009 ), model ensembling, second order statistics, and gradient tracking. on the other hand, some methods learn robust feature representation through a modified architecture or feature manipulation. galloway et al. ( 2019 ) ; benz et al. ( 2021 ) ; wang et al. ( 2022 ) investigate the effect of batch normalization on adversarial robustness. dhillon et al. ( 2018 ) ; madaan et al. ( 2020 ) prunes certain activations in the network that are susceptible to adversarial attacks. xiao et al. ( 2019 ) keep k - features with the largest magnitude and deactivate everything else. zoran et al. ( 2020 ) uses an attention mask to highlight robust regions on the feature. feature denoising ( fd ) xie et al. ( 2019 ) uses classical denoising techniques to deactivate abnormal activations. bai et al. ( 2021 ) ; yan et al. ( 2021 ) proposed channel activation suppression ( cas ) and channel - wise importancebased feature selection ( cifs ) to deactivate feature channels that are vulnerable to attacks. kim et al. ( 2023 ) improves the robustness with feature separation and recalibration ( fsr ). our method also operates in feature space, but purely during test time. while we choose some of these works as baselines, our method works in conjunction with any aforementioned methods. * * adversarial purification as defense * * another line of work focuses on purifying or augmenting the images before they are used as input. tang & zhang ( 2024 ) ; yeh et al. ( 2024 ) ; tsai et al. ( 2023 ) train an fgsm robust classifier, a diffusion model, or a mask auto - encoder, respectively, to purify adversarial examples. wang et al. ( 2021 ) optimizes both the model and the input to minimize the entropy of model predictions to adapt to changing attacks. cohen & giryes ( 2024 ) trains a random forest predictor to ensemble outputs from test - time augmented images. these works involve training a new model or updating the original model, while our method is purely test - time and does not require any training. [UNK] et al. ( 2021 ) ensembles model output from different augmentations, which is a special case of our method, as the ensemble is performed solely on the output, while we can ensemble at any layer, which both saves computational cost and achieves higher performance notably, we recognize that above methods focus solely on classification as a task for adversarial attacks. through extensive experiments, we demonstrate that our method can not only perform well on classification, but also on dense prediction tasks like optical flow, and stereo matching. * * stochastic resonance ( sr ) * * was proposed by benzi et al. ( 1981 ) and first applied in climate dynamics ( benzi et al., 1982 ) and later in signal processing ( wellens et al., 2003 ; kosko & mitaim, 2001 ; chen et al., 2007 ) and acoustics ( shu - yao et al., 2016 ; wang et al., 2014 ). recently, stochas 3 preprint version. under review. tic resonance transformer ( srt ) lao et al. ( 2024 ) uses sr to “ super - resolve ” vision transformer ( vit ) embeddings. in this work, we instead use sr to mitigate adversarial perturbations. since sr has been developed specifically to address _ quantization artifacts _, it has never before been used to mitigate classes of perturbations beyond aliasing. our novel use of the technique leverages the fact that group transformations and spatial quantization preserve the statistics of natural images, which are heavy - tailed, but do not preserve the"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03224v1",
      "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance\n  of Latent Ensembles",
      "authors": [
        "Dong Lao",
        "Yuxiang Zhang",
        "Haniyeh Ehsani Oskouie",
        "Yangchao Wu",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "summary": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.",
      "published": "2025-10-03T17:57:25Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03224v1"
    },
    "chunk_id": 4,
    "text": "sr ) * * was proposed by benzi et al. ( 1981 ) and first applied in climate dynamics ( benzi et al., 1982 ) and later in signal processing ( wellens et al., 2003 ; kosko & mitaim, 2001 ; chen et al., 2007 ) and acoustics ( shu - yao et al., 2016 ; wang et al., 2014 ). recently, stochas 3 preprint version. under review. tic resonance transformer ( srt ) lao et al. ( 2024 ) uses sr to “ super - resolve ” vision transformer ( vit ) embeddings. in this work, we instead use sr to mitigate adversarial perturbations. since sr has been developed specifically to address _ quantization artifacts _, it has never before been used to mitigate classes of perturbations beyond aliasing. our novel use of the technique leverages the fact that group transformations and spatial quantization preserve the statistics of natural images, which are heavy - tailed, but do not preserve the statistics of adversarial perturbations. 3 m ethod * * notation. * * a digital image _ x ∈ _ [ 0 _, l − _ 1 ] _ [ w ] [ × ] [ h ] _ can be described as a map from a discrete planar lattice λ _ ⊂ _ r [ 2 ] with _ h _ rows and _ w _ columns to _ l _ discrete levels, _ x _ : λ _ → _ [ 0 _, l − _ 1 ] ; a ‘ feature ’ or ‘ embedding ’ of an image _ x _ is the output of an encoder _ [UNK] _ that maps it to a vector space with _ k _ channels, typically through a parametric trained model : _ [UNK] _ : _ x → _ _ [UNK] _ ( _ x _ ) _ ∈ _ r _ [ k ] _ _. _ we represent a group transformation of the image through an operator _ g _ : r [ 2 ] _ → _ r [ 2 ], which can be restricted to the lattice λ through padding, sampling and quantization at the expense of invertibility : _ g _ : _ x → _ _ g _ ( _ x _ ) _ ∈ _ λ _ ⊂ _ r [ 2 ] _. _ for example, a translation by an integer pixel can be represented by an upper diagonal matrix _ g _, _ g _ ( _ x _ ) = _ gx _ with ones above the diagonal. the group _ g _ operating on _ x _ induces an operation on _ [UNK] _ via _ g _ _ ∗ _ _ [UNK] _ ( _ x _ ) = _ [. ] _ _ [UNK] _ ( _ g _ ( _ x _ ) ) _. _ we call the composition of _ [UNK] _ and _ g _ the encoding of the transformed image _ ψ _ ( _ x _ ) = _ [. ] _ _ [UNK] _ ( _ g _ ( _ x _ ) ) = _ [UNK] ◦ _ _ g _ ( _ x _ ) _. _ the main object of interest in our method is : _ g _ _ ∗ _ _ [ − ] _ [ 1 ] _ [ ψ ] _ [ ( ] _ [ x ] _ [ ) = ] _ [ g ] _ _ ∗ _ _ [ − ] _ [ 1 ] _ ◦ _ _ [UNK] ◦ _ _ g _ ( _ x _ ) _. _ this is obtained, reading right - to - left, by first transforming the image, then passing it through an encoder, and then transforming back the feature map through the push - forward action _ g _ _ ∗ _ _ [ − ] _ [ 1 ] [. ] * * perturbations. * * we consider two types of perturbations, extraneous and purposeful. the extraneous one could be an additive perturbation to an image, [UNK] _ x _ = _ x _ + _ n _, designed to maximally change the value of the embedding ( adversarial perturbation ) _ [UNK] _ ( [UNK] _ x _ ) : _ x _ [UNK] = _ x _ + _ n _ ( _ x _ ) _ | _ _ n _ ( _ x _ ) = arg max _ d _ ( _ [UNK] _ ( _ x _ ) _, [UNK] _ ( [UNK] _ x _ ) ) _, | n | < [UNK] _ for some small _ [UNK] _ designed so the perturbation is, ideally, imperceptible by humans. the purposeful perturbations are small group actions _ g _ _ i _ _, i _ = 1 _,..., n _, which could be sampled deterministically or at random according to some chosen distribution _ g _ _ i _ _ ∼ _ _ p _ _ g _, either way yielding a set _ { g _ 1 ( _ x _ ) _,..., g _ _ n _ ( _ x _ ) _ } _. our goal is to use these purposeful perturbations to combat the effects of extraneous adversarial perturbations. * * averaging"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03224v1",
      "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance\n  of Latent Ensembles",
      "authors": [
        "Dong Lao",
        "Yuxiang Zhang",
        "Haniyeh Ehsani Oskouie",
        "Yangchao Wu",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "summary": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.",
      "published": "2025-10-03T17:57:25Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03224v1"
    },
    "chunk_id": 5,
    "text": ": _ x _ [UNK] = _ x _ + _ n _ ( _ x _ ) _ | _ _ n _ ( _ x _ ) = arg max _ d _ ( _ [UNK] _ ( _ x _ ) _, [UNK] _ ( [UNK] _ x _ ) ) _, | n | < [UNK] _ for some small _ [UNK] _ designed so the perturbation is, ideally, imperceptible by humans. the purposeful perturbations are small group actions _ g _ _ i _ _, i _ = 1 _,..., n _, which could be sampled deterministically or at random according to some chosen distribution _ g _ _ i _ _ ∼ _ _ p _ _ g _, either way yielding a set _ { g _ 1 ( _ x _ ) _,..., g _ _ n _ ( _ x _ ) _ } _. our goal is to use these purposeful perturbations to combat the effects of extraneous adversarial perturbations. * * averaging, smoothing, and stochastic resonance. * * the resemblance between adversarial perturbations and aliasing artifacts has motivated the use of anti - aliasing, or smoothing, techniques to mitigate them. these consist of _ spatial averaging _ of the data prior to computing the map _ [UNK] _. if we call _ b _ _ ij _ _ [ σ ] _ [ a neighborhood of size ] _ [ σ > ] _ [ 0 ] [ around ] [ ( ] _ [ i, j ] _ [ ) ] _ [ ∈ ] _ [ λ ] [, ] _ b _ _ ij _ _ [ σ ] _ [ = ] _ [ { ] _ [ ( ] _ [ i ] _ _ [ ′ ] _ _ [, j ] _ _ [ ′ ] _ [ ) ] _ [ ∈ ] _ [ λ ] _ [ | ] [ d ] _ [ ( ( ] _ [ i, j ] _ [ ) ] _ [, ] _ [ ( ] _ [ i ] _ _ [ ′ ] _ _ [, j ] _ _ [ ′ ] _ [ ) ) ] _ [ ≤ ] _ _ [ σ ] [ } ] _ then the simplest form of smoothing is simply averaging in a neighborhood, [UNK] _ x _ _ i, j _ = [ 1 ] _ x _ _ i _ _ ′ _ _ j _ _ ′ _ ( _ i _ _ [ ′ ] _ _, j _ _ [ ′ ] _ ) _ ∈b _ _ i, j _ _ [ σ ] _ _ σ _ [ 2 ] which we write in terms of translations _ g _ ( _ x _ _ i, j _ ) = _ x _ _ i _ + _ u, j _ + _ v _ within the same neighborhood _ b _ _ [ σ ] _, _ x _ [UNK] = [ 1 ] _ n _ _ n _ _ g _ _ i _ ( _ x _ ) _. _ _ i _ = 1 4 preprint version. under review. figure 2 : * * results on cifar - 10 under varying levels of stochastic resonance. * * _ increasing the stochastic _ _ resonance level consistently enhances robustness across all settings, yielding clear gains over the baseline _ _ method ( fsr ). notably, our approach achieves superior performance even under adaptive adversarial attacks _ _ ( ours - worstcase ), despite the baseline being evaluated only in the non - adaptive case. _ one can then obtain an encoding by smoothing the embedding [UNK] _ [UNK] _ ( _ x _ ) = [ 1 ] _ n _ _ n _ _ [UNK] _ ( _ g _ _ i _ ( _ x _ ) ) _. _ _ i _ = 1 this can be interpreted as marginalizing the translation group with a prior _ p _ _ g _ when computing _ [UNK] _. notice that the average can be computed on a coarser lattice λ [ [UNK] ], but its value still depends on data in the finer grid λ. classical sampling theory teaches that smoothing mitigates the effect of highfrequency aliasing _ n _ at the cost of information loss on _ x _. stochastic resonance also marginalizes the translation group, but by _ averaging transformed data in _ _ latent space : _ ˆ _ [UNK] _ ( _ x _ ) = [ 1 ] _ n _ _ n _ _ − _ 1 _ g _ _ i∗ _ _ ◦ _ _ [UNK] ◦ _ _ g _ _ i _ ( _ x _ ) _. _ ( 1 ) _ i _ = 1 more general groups, and more general averaging kernels, can be considered although we find that the simplest case described here already suffices. stochastic resonance is _ not _ smoothing, as it averages transformed versions of the image without blurring it, thanks to the inverse push - forward. it is also _ not _ super - resolution, where fine - granularity details are hallucinated based on side information or priors, although it does allow resolving features computed on a coarse grid λ"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03224v1",
      "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance\n  of Latent Ensembles",
      "authors": [
        "Dong Lao",
        "Yuxiang Zhang",
        "Haniyeh Ehsani Oskouie",
        "Yangchao Wu",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "summary": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.",
      "published": "2025-10-03T17:57:25Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03224v1"
    },
    "chunk_id": 6,
    "text": "theory teaches that smoothing mitigates the effect of highfrequency aliasing _ n _ at the cost of information loss on _ x _. stochastic resonance also marginalizes the translation group, but by _ averaging transformed data in _ _ latent space : _ ˆ _ [UNK] _ ( _ x _ ) = [ 1 ] _ n _ _ n _ _ − _ 1 _ g _ _ i∗ _ _ ◦ _ _ [UNK] ◦ _ _ g _ _ i _ ( _ x _ ) _. _ ( 1 ) _ i _ = 1 more general groups, and more general averaging kernels, can be considered although we find that the simplest case described here already suffices. stochastic resonance is _ not _ smoothing, as it averages transformed versions of the image without blurring it, thanks to the inverse push - forward. it is also _ not _ super - resolution, where fine - granularity details are hallucinated based on side information or priors, although it does allow resolving features computed on a coarse grid λ [ [UNK] ] within a finer grid λ. stochastic resonance uses the averaging of perturbations in latent space to ensemble populations of embeddings, rather than averaging or interpolation of the same embedding. * * purposeful perturbation. * * the only design choice in the method is the set of purposeful perturbations. while that can be optimized for performance, we optimize for simplicity, restricting our attention to translation by integer pixels. we know that, for adversarial perturbations, _ d _ ( _ [UNK] _ ( [UNK] _ x _ ) _, [UNK] _ ( _ x _ ) ) is large, where _ d _ ( _ · _ ) defines the distance between features. ideally, for stochastic resonance, we want _ d _ ( _ [UNK] _ [ ˆ ] ( [UNK] _ x _ ) _, _ _ [UNK] _ [ ˆ ] ( _ x _ ) ) = 0 while keeping _ [UNK] _ [ ˆ ] as information - preserving as possible. the theory of stochastic resonance shows that, if we sub - sample a signal from its native granularity λ to a coarser grid [UNK] _ ⊂ _ λ, and choose the purposeful perturbations to act on the finer grid λ, under certain conditions one can recover the original signal at the finer granularity benzi et al. ( 1981 ). in this paper, we focus on testing whether _ [UNK] _ [ ˆ ] is insensitive to adversarial perturbations. we do so empirically in sect. 4. 4 e xperiments while _ g _ can be sampled from any invertible group transformation ( e. g., rotation, scaling ), we implement stochastic resonance using integer - pixel translations, denoted as _ { g _ _ i _ _ } _ = _ { _ ( _ x, y _ ) _ | x ∈ _ [ _ −d _ _ x _ _, d _ _ x _ ] _, j ∈ _ [ _ −d _ _ y _ _, d _ _ y _ ] _ } _, following the approach in srt lao et al. ( 2024 ), which avoids interpolation artifacts. while the networks ’ inherent sensitivity to pixel - level shifts is typically regarded as detrimental due to the “ flickering problem ” azulay & weiss ( 2019 ) ; sundaramoorthi & wang ( 2019 ), our approach, on the contrary, leverages it to defend against adversarial perturbations. given these perturbations _ { g _ _ i _ _ } _, ensembling can be performed at any chosen layer of the network. features are aggregated as described in eq. 1 and then passed to downstream network components. we first validate this approach on image classification ( sect. 4. 1 ) following standard benchmarks, and also provide ablation studies on levels / layers of latent ensemble and rotation as augmentation. 5 preprint version. under review. | resnet - 18 | 85. 02 < br > 85. 14 < br > 85. 78 < br > 79. 87 < br > 81. 46 < br > 85. 25 < br > 84. 93 < br > 84. 93 | 56. 21 < br > 56. 81 < br > 55. 57 < br > 56. 53 < br > 58. 07 < br > 59. 20 < br > 61. 02 < br > 58. 81 | 48. 22 < br > 48. 54 < br > 50. 42 < br > 49. 80 < br > 52. 47 < br > 53. 00 < br > 56. 08 < br > 53. 58 | 46. 37 < br > 46. 70 < br > 49. 91 < br > 48. 17 < br > 51. 02 < br > 51. 65 < br > 55. 17 < br > 52. 39 | 47. 38 < br > 47. 72 < br > 53. 47 < br > 49. 89 < br > 49. 44 < br > 52. 45 < br > 55. 53 < br > 52. 73 | | -"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03224v1",
      "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance\n  of Latent Ensembles",
      "authors": [
        "Dong Lao",
        "Yuxiang Zhang",
        "Haniyeh Ehsani Oskouie",
        "Yangchao Wu",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "summary": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.",
      "published": "2025-10-03T17:57:25Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03224v1"
    },
    "chunk_id": 7,
    "text": "25 < br > 84. 93 < br > 84. 93 | 56. 21 < br > 56. 81 < br > 55. 57 < br > 56. 53 < br > 58. 07 < br > 59. 20 < br > 61. 02 < br > 58. 81 | 48. 22 < br > 48. 54 < br > 50. 42 < br > 49. 80 < br > 52. 47 < br > 53. 00 < br > 56. 08 < br > 53. 58 | 46. 37 < br > 46. 70 < br > 49. 91 < br > 48. 17 < br > 51. 02 < br > 51. 65 < br > 55. 17 < br > 52. 39 | 47. 38 < br > 47. 72 < br > 53. 47 < br > 49. 89 < br > 49. 44 < br > 52. 45 < br > 55. 53 < br > 52. 73 | | - - - | - - - | - - - | - - - | - - - | - - - | | wideresnet - 34 | 84. 92 < br > * * 85. 03 * * | 60. 87 < br > * * 62. 43 * * | 56. 13 < br > * * 58. 64 * * | 55. 16 < br > * * 57. 87 * * | 54. 02 < br > * * 57. 18 * * | table 1 : * * defense against adversarial attacks on classification task ( cifar - 10 ). * * _ compared to baselines _ _ that filter or manipulate features, ours does not modify network architecture or weights. instead, ours performs _ _ an ensemble in the feature space. on cifar - 10, ours achieves state - of - the - art robustness without requiring any _ _ additional training. moreover, even in a worst - case adaptive adversary setting where the attacker is fully aware _ _ of the defense and how stochastic resonance is applied, the effectiveness of adversarial attacks is still notably _ _ reduced, while the computational cost for executing such attacks is significantly increased. _ | att. strength ( [UNK] ) | 8 / 2 | 255 | 4 / 2 | 255 | 2 / 2 | 255 | 1 / 25 | 55 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | metric | top - 1 | top - 5 | top - 1 | top - 5 | top - 1 | top - 5 | top - 1 | top - 5 | | no defense < br > ours ( _ d _ = 1 ) < br > ours ( _ d _ = 2 ) < br > ours ( _ d _ = 3 ) | 4. 51 < br > 11. 66 < br > 18. 78 < br > * * 25. 77 * * | 19. 55 < br > 46. 27 < br > 58. 58 < br > * * 65. 88 * * | 12. 25 < br > 27. 85 < br > 36. 42 < br > * * 42. 52 * * | 42. 15 < br > 65. 80 < br > 72. 86 < br > * * 76. 75 * * | 29. 79 < br > 45. 94 < br > 51. 58 < br > * * 54. 94 * * | 65. 09 < br > 77. 63 < br > 80. 85 < br > * * 82. 64 * * | 48. 09 < br > 57. 48 < br > 60. 41 < br > * * 62. 08 * * | 78. 13 < br > 83. 43 < br > 84. 77 < br > * * 85. 50 * * | table 2 : * * imagenet with vit - small. * * increasing the level of stochastic resonance consistently improves both top - 1 and top - 5 accuracy under adversarial attacks. relative to the clean baseline ( 72. 9 top - 1, 92. 91 top - 5 ), our method recovers up to 55. 8 % of the top - 1 accuracy loss and 68. 1 % of the top - 5 accuracy loss. | att. strength ( [UNK] ) | 8 / 2 | 255 | 4 / 2 | 255 | 2 / 2 | 255 | 1 / 2 | 255 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | metric | top - 1 | top - 5 | top - 1 | top - 5 | top - 1 | top - 5 | top - 1 | top - 5 | | no defense < br > initial conv. < br > res. block 1 < br > res. block 2 <"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03224v1",
      "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance\n  of Latent Ensembles",
      "authors": [
        "Dong Lao",
        "Yuxiang Zhang",
        "Haniyeh Ehsani Oskouie",
        "Yangchao Wu",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "summary": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.",
      "published": "2025-10-03T17:57:25Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03224v1"
    },
    "chunk_id": 8,
    "text": "the level of stochastic resonance consistently improves both top - 1 and top - 5 accuracy under adversarial attacks. relative to the clean baseline ( 72. 9 top - 1, 92. 91 top - 5 ), our method recovers up to 55. 8 % of the top - 1 accuracy loss and 68. 1 % of the top - 5 accuracy loss. | att. strength ( [UNK] ) | 8 / 2 | 255 | 4 / 2 | 255 | 2 / 2 | 255 | 1 / 2 | 255 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | metric | top - 1 | top - 5 | top - 1 | top - 5 | top - 1 | top - 5 | top - 1 | top - 5 | | no defense < br > initial conv. < br > res. block 1 < br > res. block 2 < br > res. block 3 | 8. 51 < br > 16. 91 < br > 22. 44 < br > * * 24. 88 * * < br > 21. 76 | 26. 19 < br > 34. 66 < br > 44. 95 < br > * * 48. 54 * * < br > 44. 28 | 9. 45 < br > 17. 36 < br > 23. 39 < br > * * 25. 90 * * < br > 22. 73 | 27. 92 < br > 35. 28 < br > 46. 03 < br > * * 49. 66 * * < br > 45. 47 | 11. 10 < br > 18. 12 < br > 24. 84 < br > * * 27. 23 * * < br > 24. 14 | 30. 63 < br > 36. 30 < br > 47. 64 < br > * * 51. 19 * * < br > 47. 14 | 15. 21 < br > 19. 59 < br > 27. 57 < br > * * 30. 11 * * < br > 27. 18 | 36. 76 < br > 38. 25 < br > 50. 80 < br > * * 54. 15 * * < br > 50. 20 | table 3 : * * layer - wise ablation on resnet - 50. * * adversarial perturbations resemble high - frequency noise. applying stochastic resonance through shallow layers is sufficient to defend against adversarial attacks, substantially reducing the overall computational cost. subsequently, we defend against adversarial attacks on dense prediction tasks, including stereo matching ( sec. 4. 2 ) and optical flow ( sec. 4. 3 ). this is achieved given that our method is agnostic to attack mechanisms, network pre - training, and largely independent of architecture, requiring only latent ensembling, resulting in a purely test - time, training - free approach with no auxiliary modules. 4. 1 i mage c lassification * * cifar - 10. * * we evaluate our method on cifar - 10 krizhevsky et al. ( 2009 ), building upon the standard and publicly available code base of fsr kim et al. ( 2023 ) and accompanying evaluation protocol. we apply stochastic resonance to networks pre - trained with at madry et al. ( 2017 ), trades zhang et al. ( 2019 ), and mart wang et al. ( 2019 ), using publicly released weights without any modification. our method operates with these methods purely at test time without any training. we conduct experiments on resnet - 18 he et al. ( 2016 ) and wideresnet - 34 zagoruyko & komodakis ( 2016 ), depending on the availability of author - released pre - trained weights. in all cases, feature ensembling is performed before the final linear layer. furthermore, we consider a worst - case adaptive adversary setting, where the attacker has full knowledge of the model weights, and knows every stochastic resonance transformation by accessing _ every single _ forward pass and its gradients. fig. 2 shows the results varying different levels of stochastic resonance. increasing the resonance level consistently enhances robustness in all attack settings, leading to substantial improvements over the baseline method ( fsr ). importantly, our approach surpasses the baseline even under adaptive adversarial attacks. additionally, we compare our method against multiple baselines, including feature - level manipulation methods ( fd xie et al. ( 2019 ), cas bai et al. ( 2021 ), cifs yan et al. ( 2021 ) ) and ensemble - based approach tte [UNK] et al. ( 2021 ). the results, summarized in tab. 1, demonstrate that stochastic resonance consistently outperforms all baselines across different attacks. even in the worst - case adaptive attack scenario, where the adversary accounts for all stochastic resonance forward passes, the model remains significantly more robust than the baseline methods. in 6 preprint version"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03224v1",
      "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance\n  of Latent Ensembles",
      "authors": [
        "Dong Lao",
        "Yuxiang Zhang",
        "Haniyeh Ehsani Oskouie",
        "Yangchao Wu",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "summary": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.",
      "published": "2025-10-03T17:57:25Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03224v1"
    },
    "chunk_id": 9,
    "text": "of the model weights, and knows every stochastic resonance transformation by accessing _ every single _ forward pass and its gradients. fig. 2 shows the results varying different levels of stochastic resonance. increasing the resonance level consistently enhances robustness in all attack settings, leading to substantial improvements over the baseline method ( fsr ). importantly, our approach surpasses the baseline even under adaptive adversarial attacks. additionally, we compare our method against multiple baselines, including feature - level manipulation methods ( fd xie et al. ( 2019 ), cas bai et al. ( 2021 ), cifs yan et al. ( 2021 ) ) and ensemble - based approach tte [UNK] et al. ( 2021 ). the results, summarized in tab. 1, demonstrate that stochastic resonance consistently outperforms all baselines across different attacks. even in the worst - case adaptive attack scenario, where the adversary accounts for all stochastic resonance forward passes, the model remains significantly more robust than the baseline methods. in 6 preprint version. under review. | col1 | attack strength ( [UNK] ) | 0. 02 | col4 | col5 | 0. 01 | col7 | col8 | 0. 005 | col10 | col11 | 0. 002 | col13 | col14 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | | metric | mae | rmse | d1 - err | mae | rmse | d1 - err | mae | rmse | d1 - err | mae | rmse | d1 - err | | fgsm | no defense < br > latent smoothing < br > ours ( _ d _ = 1 ) < br > error reduced ( % ) < br > ours ( _ d _ = 2 ) < br > error reduced ( % ) | 14. 83 < br > 13. 42 < br > 10. 12 < br > 31. 76 < br > * * 9. 22 * * < br > 37. 82 | 24. 10 < br > 22. 09 < br > 15. 81 < br > 34. 40 < br > * * 13. 88 * * < br > 42. 40 | 97. 33 < br > 96. 61 < br > 95. 80 < br > 1. 57 < br > * * 94. 61 * * < br > 2. 79 | 8. 49 < br > 8. 12 < br > 6. 46 < br > 23. 91 < br > * * 6. 13 * * < br > 27. 78 | 14. 53 < br > 13. 69 < br > 9. 92 < br > 31. 73 < br > * * 8. 87 * * < br > 38. 95 | 90. 49 < br > 89. 25 < br > 86. 30 < br > 4. 63 < br > * * 84. 49 * * < br > 6. 63 | 5. 05 < br > 4. 89 < br > 4. 39 < br > 13. 07 < br > * * 4. 19 * * < br > 16. 92 | 7. 70 < br > 7. 05 < br > 5. 93 < br > 22. 99 < br > * * 5. 43 * * < br > 29. 41 | 74. 71 < br > 73. 01 < br > 68. 55 < br > 7. 58 < br > * * 66. 74 * * < br > 10. 66 | 3. 01 < br > 2. 89 < br > 2. 78 < br > 7. 64 < br > * * 2. 73 * * < br > 9. 21 | 3. 49 < br > 3. 32 < br > 3. 18 < br > 8. 88 < br > * * 3. 12 * * < br > 10. 65 | 38. 12 < br > 36. 25 < br > 31. 99 < br > 16. 08 < br > * * 31. 18 * * < br > 18. 21 | | pgd | no defense < br > latent smoothing < br > ours ( _ d _ = 1 ) < br > error reduced ( % ) < br > ours ( _ d _ = 2 ) < br > error reduced ( % ) | 161. 70 < br > 161. 79 < br > 107. 86 < br > 33. 30 < br > * * 77. 59 * * < br > 52. 01 | 162. 61 < br > 162. 69 < br > 125. 14 < br > 23. 04 < br > * * 100. 14 * * < br > 38. 41 | 99. 99 < br > 99. 99 < br"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03224v1",
      "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance\n  of Latent Ensembles",
      "authors": [
        "Dong Lao",
        "Yuxiang Zhang",
        "Haniyeh Ehsani Oskouie",
        "Yangchao Wu",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "summary": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.",
      "published": "2025-10-03T17:57:25Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03224v1"
    },
    "chunk_id": 10,
    "text": ". 18 < br > 8. 88 < br > * * 3. 12 * * < br > 10. 65 | 38. 12 < br > 36. 25 < br > 31. 99 < br > 16. 08 < br > * * 31. 18 * * < br > 18. 21 | | pgd | no defense < br > latent smoothing < br > ours ( _ d _ = 1 ) < br > error reduced ( % ) < br > ours ( _ d _ = 2 ) < br > error reduced ( % ) | 161. 70 < br > 161. 79 < br > 107. 86 < br > 33. 30 < br > * * 77. 59 * * < br > 52. 01 | 162. 61 < br > 162. 69 < br > 125. 14 < br > 23. 04 < br > * * 100. 14 * * < br > 38. 41 | 99. 99 < br > 99. 99 < br > 98. 29 < br > 1. 70 < br > * * 96. 14 * * < br > 3. 85 | 131. 66 < br > 131. 46 < br > 69. 97 < br > 46. 86 < br > * * 44. 77 * * < br > 66. 02 | 140. 55 < br > 140. 41 < br > 84. 72 < br > 39. 72 < br > * * 66. 23 * * < br > 52. 87 | 98. 64 < br > 98. 57 < br > 91. 79 < br > 6. 94 < br > * * 89. 24 * * < br > 9. 53 | 63. 97 < br > 63. 86 < br > 20. 66 < br > 67. 70 < br > * * 17. 98 * * < br > 71. 89 | 88. 55 < br > 88. 21 < br > 42. 29 < br > 52. 24 < br > * * 32. 80 * * < br > 62. 94 | 85. 31 < br > 85. 39 < br > 73. 21 < br > 14. 18 < br > * * 71. 09 * * < br > 16. 66 | 6. 83 < br > 7. 28 < br > 4. 17 < br > 38. 95 < br > * * 3. 76 * * < br > 44. 99 | 17. 03 < br > 17. 44 < br > 8. 32 < br > 51. 15 < br > * * 6. 73 * * < br > 60. 52 | 39. 24 < br > 39. 81 < br > 29. 09 < br > 25. 87 < br > * * 28. 44 * * < br > 27. 53 | table 5 : * * stochastic resonance enhances stereo matching robustness. * * _ incorporating stochastic resonance _ _ significantly reduces prediction errors induced by adversarial attacks across all evaluation metrics, reducing _ _ error by up to 71. 89 % ( mae, when attacked by pgd with [UNK] _ = 0 _. _ 005 _ ). notably, this defense mechanism _ _ operates entirely at test time without requiring any model re - training, which sets it apart from existing methods. _ addition, stochastic resonance increases attack complexity under the adaptive settings, making adversarial noise generation more challenging for the attacker. as a result, the computational cost for generating adaptive adversarial perturbations increases substantially. for example, with stochastic resonance, 8x more wall - clock time is required to create adversarial examples with pgd - 100. * * imagenet. * * we further evaluate our approach on the imagenet deng et al. ( 2009 ) classification dataset using standard segmentation backbones, including resnet - 50 he et al. ( 2016 ) and vision transformer dosovitskiy et al. ( 2020 ), without adversarial training. as in the cifar experiments, we vary the level of stochastic resonance and conduct ablation studies by testing against pgd attacks of different strengths. tab. 2 reports the results for vit - small. consistent with the cifar - 10 findings, increasing the resonance level leads to consistent improvements in robustness, as measured by both top - 1 and top - 5 accuracy. notably, the vanilla vit - small model without attack achieves 72. 9 ( top - 1 ) and 92. 91 ( top - 5 ), which means our method recovers the accuracy drop under adversarial attacks by up to a relative 55. 8 % ( top - 1, when _ [UNK] _ = 4 _ / _ 255 ) and 68. 1 % ( top - 5, when _ [UNK] _ = 2 _ / _ 255 ). we further evaluate our method on resnet - 50 and observe a consistent trend, as shown in tab. 4. we also explored group transformations other than translation, e. g. rotations in tab. 4."
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03224v1",
      "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance\n  of Latent Ensembles",
      "authors": [
        "Dong Lao",
        "Yuxiang Zhang",
        "Haniyeh Ehsani Oskouie",
        "Yangchao Wu",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "summary": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.",
      "published": "2025-10-03T17:57:25Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03224v1"
    },
    "chunk_id": 11,
    "text": "##far experiments, we vary the level of stochastic resonance and conduct ablation studies by testing against pgd attacks of different strengths. tab. 2 reports the results for vit - small. consistent with the cifar - 10 findings, increasing the resonance level leads to consistent improvements in robustness, as measured by both top - 1 and top - 5 accuracy. notably, the vanilla vit - small model without attack achieves 72. 9 ( top - 1 ) and 92. 91 ( top - 5 ), which means our method recovers the accuracy drop under adversarial attacks by up to a relative 55. 8 % ( top - 1, when _ [UNK] _ = 4 _ / _ 255 ) and 68. 1 % ( top - 5, when _ [UNK] _ = 2 _ / _ 255 ). we further evaluate our method on resnet - 50 and observe a consistent trend, as shown in tab. 4. we also explored group transformations other than translation, e. g. rotations in tab. 4. for a fair comparison, we use the same number of augmentations as in the translation experiments. rotations behave similarly to translations at low levels of stochastic resonance, but performance degrades as the resonance level increases. we hypothesize that since convolutional filters are inherently translation - invariant but not rotation - invariant, aligning features under different rotations reduces feature quality. moreover, rotations are approximately 30 % slower due to interpolation overhead. att. strength ( _ [UNK] _ ) 8 / 255 4 / 255 2 / 255 1 / 255 | metric | top - 1 | top - 5 | top - 1 | top - 5 | top - 1 | top - 5 | top - 1 | top - 5 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | no defense < br > ours ( _ d _ = 1 ) < br > w / rotation < br > ours ( _ d _ = 2 ) < br > w / rotation < br > ours ( _ d _ = 3 ) < br > w / rotation | 8. 51 < br > 18. 40 < br > 20. 01 < br > 20. 01 < br > 18. 86 < br > * * 21. 17 * * < br > 15. 15 | 26. 19 < br > 40. 36 < br > 41. 32 < br > 42. 22 < br > 38. 67 < br > * * 43. 58 * * < br > 32. 89 | 9. 45 < br > 19. 54 < br > 20. 84 < br > 21. 02 < br > 19. 55 < br > * * 22. 04 * * < br > 15. 61 | 27. 92 < br > 42. 65 < br > 42. 39 < br > 43. 45 < br > 39. 5 < br > * * 44. 78 * * < br > 33. 46 | 11. 10 < br > 21. 02 < br > 22. 10 < br > 22. 44 < br > 20. 36 < br > * * 23. 44 * * < br > 16. 17 | 30. 63 < br > 43. 86 < br > 43. 89 < br > 45. 32 < br > 40. 48 < br > * * 46. 53 * * < br > 34. 19 | 15. 21 < br > 24. 66 < br > 24. 72 < br > 25. 80 < br > 22. 01 < br > * * 26. 58 * * < br > 17. 33 | 36. 76 < br > 47. 81 < br > 46. 89 < br > 48. 97 < br > 42. 50 < br > * * 49. 73 * * < br > 35. 59 | table 4 : * * stochastic resonance using translation v. s. * * * * rotation on resnet - 50. * * while rotations provide similar gains at low resonance levels, performance degrades as the resonance level increases, likely due to the lack of rotational invariance in convolutional filters. since adversarial perturbations often manifest as high - frequency noise, having a low - pass filter in early layers may form an effective defense. as our method applies to arbitrarily chosen layers, we vary the termination layer of stochastic resonance. as shown in tab. 3, applying it only through the first residual block already achieves strong adversarial robustness, while extending it to the second block yields the strongest result. this finding is significant : running stochastic resonance through shallow layers can be sufficient as a defense strategy, which reduces overall computational cost. 4. 2 s tereo m atching stereopagnosia wong et al. ( 2021 ) first introduced adversarial attacks to stereo matching, yet no test - time method has demonstrated an effective defense. the primary challenge arises from the in 7 preprint version. under review. figure 3 :"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03224v1",
      "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance\n  of Latent Ensembles",
      "authors": [
        "Dong Lao",
        "Yuxiang Zhang",
        "Haniyeh Ehsani Oskouie",
        "Yangchao Wu",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "summary": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.",
      "published": "2025-10-03T17:57:25Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03224v1"
    },
    "chunk_id": 12,
    "text": "- 50. * * while rotations provide similar gains at low resonance levels, performance degrades as the resonance level increases, likely due to the lack of rotational invariance in convolutional filters. since adversarial perturbations often manifest as high - frequency noise, having a low - pass filter in early layers may form an effective defense. as our method applies to arbitrarily chosen layers, we vary the termination layer of stochastic resonance. as shown in tab. 3, applying it only through the first residual block already achieves strong adversarial robustness, while extending it to the second block yields the strongest result. this finding is significant : running stochastic resonance through shallow layers can be sufficient as a defense strategy, which reduces overall computational cost. 4. 2 s tereo m atching stereopagnosia wong et al. ( 2021 ) first introduced adversarial attacks to stereo matching, yet no test - time method has demonstrated an effective defense. the primary challenge arises from the in 7 preprint version. under review. figure 3 : * * stereo matching robustness via stochastic resonance. * * _ we present visual results on stereo matching _ _ under various adversarial attack scenarios, including pgd and fgsm at different perturbation levels. these at - _ _ tacks significantly degrade the network ’ s predictions, leading to substantial errors. by incorporating stochastic _ _ resonance, we demonstrate a significant reduction in prediction errors. this technique holds significant po - _ _ tential for improving robustness in safety - critical real - world applications, such as autonomous driving, where _ _ stereo vision must remain reliable under diverse environmental conditions and adversarial threats. _ feasibility of data augmentations, as they risk altering the physics of the input, leading to incorrect estimation. in contrast, our feature - level ensemble is suitable for this task, as transformations introduced by stochastic resonance are “ undone ” in the latent space, ensuring that features remain aligned precisely with the original input. this process mirrors augundo wu et al. ( 2024 ) conceptually. we evaluate our method on the standard benchmark used in _ stereopagnosia _, derived from kitti geiger et al. ( 2012 ). experiments are conducted using fgsm and pgd attacks against a pre - trained psmnet chang & chen ( 2018 ). since no existing test - time defense is available, we adopt latent - space smoothing as a baseline. as shown in tab. 5, both attacks corrupt network predictions, with pgd proving substantially more effective due to its iterative nature. nevertheless, stochastic resonance consistently improves robustness across attack strengths. in particular, under pgd with _ [UNK] _ = 0 _. _ 005, our method reduces errors by up to 71. 89 % in terms of mae. crucially, these gains are achieved entirely at test time, without additional training or prior knowledge of the attack. fig. 3 provides qualitative results, featuring different attack strengths and methods. the adversarial perturbations introduce significant distortions, as indicated by bright regions in the visualized predictions. stochastic resonance effectively mitigates these distortions, drastically reducing prediction errors. this experiment is particularly relevant for safety - critical applications such as autonomous driving, where adversarial disturbances can arise not only from malicious attacks but also from environmental factors such as adverse weather conditions, varying illumination, or sensor degradation. while some defenses zhang et al. ( 2023 ) ; cheng et al. ( 2021 ; 2022 ) ; berger et al. ( 2022 ) have been proposed to train a more robust network under adverse conditions, test - time defenses remain largely unexplored. our method is the first to provide a viable solution in this setting. 4. 3 o ptical f low we further evaluate our method on optical flow, which computes the dense motion field between two images. the accuracy of optical flow is measured using the end - point error ( epe ). we note that multiple adversarial attacks exist for optical flow schrodi et al. ( 2022 ) ; ranjan et al. ( 2019 ) ; schmalfuss et al. ( 2022 ). among these attacks, pgd is stronger than patch - based attacks as adversarial patches have localized effects. therefore, in our experiments, we employ the raft teed & deng ( 2020 ) optical flow model and focus on global adversarial perturbations generated by pgd and fgsm. we test our method on the davis pont - tuset et al. ( 2017 ) dataset under both attacks. to defend against adversarial attacks, we apply stochastic resonance to the convolutional feature extractor of raft. since the perturbation is applied only at the feature extraction stage, no additional overhead is introduced in the computationally intensive matching module. quantitative results ( fig. 4 ) show that increasing stochastic resonance reduces epe, which aligns with our findings in classification. as in fig. 5, our approach effectively removes errors caused by adversarial noise. 8 preprint version. under review. pgd fgsm figure 5 : *"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03224v1",
      "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance\n  of Latent Ensembles",
      "authors": [
        "Dong Lao",
        "Yuxiang Zhang",
        "Haniyeh Ehsani Oskouie",
        "Yangchao Wu",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "summary": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.",
      "published": "2025-10-03T17:57:25Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03224v1"
    },
    "chunk_id": 13,
    "text": "( 2019 ) ; schmalfuss et al. ( 2022 ). among these attacks, pgd is stronger than patch - based attacks as adversarial patches have localized effects. therefore, in our experiments, we employ the raft teed & deng ( 2020 ) optical flow model and focus on global adversarial perturbations generated by pgd and fgsm. we test our method on the davis pont - tuset et al. ( 2017 ) dataset under both attacks. to defend against adversarial attacks, we apply stochastic resonance to the convolutional feature extractor of raft. since the perturbation is applied only at the feature extraction stage, no additional overhead is introduced in the computationally intensive matching module. quantitative results ( fig. 4 ) show that increasing stochastic resonance reduces epe, which aligns with our findings in classification. as in fig. 5, our approach effectively removes errors caused by adversarial noise. 8 preprint version. under review. pgd fgsm figure 5 : * * optical flow robustness via stochastic resonance. * * _ qualitative results ( visualized with a color _ _ wheel ) show that our method substantially mitigates the degradation caused by both pgd and fgsm attacks. _ _ this robustness is particularly relevant for visual perception systems that rely on accurate motion estimation. _ we further compare our method to an alternative ensembling approach that aggregates predictions in the output space, conceptually similar to tte [UNK] et al. ( 2021 ). in this variant, we apply the same stochastic transformations but instead ensemble at the output level rather than in the feature space. while this method provides marginal improvements, it remains less effective than our approach. this finding highlights the advantage of having the freedom to choose from any stage of the model to perform ensemble. in this particular experiment, we demonstrate that ensembling solely at the image encoding sub - module, while leaving the rest of the raft network unchanged, yields substantial improvements in robustness, thanks to the flexibility of our method. 5 d iscussion and c onclusion figure 4 : * * enhanced optical flow robustness with * * * * stochastic resonance. * * _ under pgd and fgsm, _ _ stochastic resonance significantly reduces endpoint er - _ _ ror in optical flow estimation. notably, our method per - _ _ forms ensembling in the latent feature space rather than _ _ the output space, providing greater flexibility. while _ _ ensembling in the output space offers minor perfor - _ _ mance gains, our approach consistently achieves supe - _ _ rior robustness across all levels of stochastic resonance. _ * * speed. * * stochastic resonance incurs low computational overhead when executed in parallel : raising the stochastic resonance level to 3 with resnet - 50 adds only 0. 06 seconds to the inference time on an nvidia 1080ti gpu. most of the overhead arises from creating perturbations implemented via python loops with torchvision ; we expect further speedups with efficient cuda implementations. even when executed _ sequentially _, the computational overhead is 0. 095 seconds. moreover, strong robustness can be attained by applying stochastic resonance only to shallow layers, offering substantially greater efficiency than existing ensemble - based defenses ( e. g. [UNK] et al. ( 2021 ) ) that require multiple passes through the entire network. moreover, our method is fully plug - and - play. in contrast, attack - specific adversarial training is over 6x slower than a vanilla training pipeline. as such, the computation of our method is well justified by its robustness gains and training - free nature. * * on - demand scaling. * * one of the key strengths of our approach is its flexibility : providing a tradeoff between robustness and computational cost. we offer a tunable “ knob ” that allows practitioners to adjust the level of resilience based on available resources on the fly : when the system has more computational capacity, add a higher level of stochastic resonance, vice versa. note that, such a design does not _ rely _ on additional computation, yet more computation can bring _ extra _ performance. moreover, our experiments show that the method generalizes across a wide range of tasks and architectures that include an encoder. this on - demand scaling mirrors inference - time scaling in language models, where performance can be improved without modifying the underlying pre - trained model. 9 preprint version. under review. * * limitations. * * despite its strengths, our method has some limitations. first, while we offer parallel computation as a remedy, the computational overhead introduced by stochastic resonance may not be negligible for scenarios with memory and power constraints. also, our current study focuses on integer - pixel translations. while this choice avoids interpolation artifacts and preserves spatial consistency, more generic transformations, including learned transformations, could be explored. * * conclusion. * * in this work, we present a signal - processing perspective for defending against adversarial attacks, motivated by the connection between adversarial perturbations and aliasing artifacts. accordingly, we propose a “ combat noise with"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03224v1",
      "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance\n  of Latent Ensembles",
      "authors": [
        "Dong Lao",
        "Yuxiang Zhang",
        "Haniyeh Ehsani Oskouie",
        "Yangchao Wu",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "summary": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.",
      "published": "2025-10-03T17:57:25Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03224v1"
    },
    "chunk_id": 14,
    "text": "on additional computation, yet more computation can bring _ extra _ performance. moreover, our experiments show that the method generalizes across a wide range of tasks and architectures that include an encoder. this on - demand scaling mirrors inference - time scaling in language models, where performance can be improved without modifying the underlying pre - trained model. 9 preprint version. under review. * * limitations. * * despite its strengths, our method has some limitations. first, while we offer parallel computation as a remedy, the computational overhead introduced by stochastic resonance may not be negligible for scenarios with memory and power constraints. also, our current study focuses on integer - pixel translations. while this choice avoids interpolation artifacts and preserves spatial consistency, more generic transformations, including learned transformations, could be explored. * * conclusion. * * in this work, we present a signal - processing perspective for defending against adversarial attacks, motivated by the connection between adversarial perturbations and aliasing artifacts. accordingly, we propose a “ combat noise with noise ” approach by introducing stochastic resonance as a defense mechanism. we formalize the problem and implement stochastic resonance using pixellevel translations paired with their inverse transformation in the feature space. the resulting method is training - free, agnostic to both tasks and attack types, and independent of network architectures. we evaluate our method across various tasks. empirical results on image classification demonstrate that our stochastic resonance approach achieves state - of - the - art robustness against diverse attack types, offering a clear advantage over feature - level denoising and filtering. even in the adaptive adversary scenario, where an attacker is aware of the use of stochastic resonance, our method maintains strong robustness. furthermore, we are the first to introduce test - time defense to dense prediction tasks. specifically, we apply this method to stereo matching and optical flow, achieving up to a 71 % reduction in prediction error. more importantly, these findings highlight the practical potential of stochastic resonance as a universal defense in real - world adversarial scenarios. 10 preprint version. under review. r eproducibility s tatement we provide sufficient technical details in the paper to ensure reproducibility. specifically, we describe the augmentations used for stochastic resonance, including augmentations ( e. g. translation, rotation ) and their corresponding inverse transformations, as well as the model architectures, datasets, and the network layers where our method is applied. attack settings and evaluation protocols are drawn directly from standard benchmark datasets and publicly available code base, ensuring comparability with prior work. all implementation details necessary to reproduce our experiments, including parameters and ablation settings, are provided in the main paper and further expanded in the appendix. our experiments can be reproduced on a single desktop - level gpu without requiring large - scale computational resources. we will release the complete source code and pre - computed adversarial data upon publication. llm s tatement all technical content of this work, including literature review, methodology, experiments, and analyses, was developed entirely by the authors. large language models ( llms ) were employed as a tool for proofreading, without contributing to the scientific or technical substance of the manuscript. r eferences aharon azulay and yair weiss. why do deep convolutional networks generalize so poorly to small image transformations? _ journal of machine learning research _, 20 ( 184 ) : 1 – 25, 2019. yang bai, yuyuan zeng, yong jiang, shu - tao xia, xingjun ma, and yisen wang. improving adversarial robustness via channel - wise activation suppressing. _ arxiv preprint arxiv : 2103. 08307 _, 2021. yoshua bengio, [UNK] louradour, ronan collobert, and jason weston. curriculum learning. in _ proceedings of the 26th annual international conference on machine learning _, pp. 41 – 48, 2009. philipp benz, chaoning zhang, and in so kweon. batch normalization increases adversarial vulnerability and decreases adversarial transferability : a non - robust feature perspective. in _ proceedings _ _ of the ieee / cvf international conference on computer vision _, pp. 7818 – 7827, 2021. roberto benzi, alfonso sutera, and angelo vulpiani. the mechanism of stochastic resonance. _ journal of physics a : mathematical and general _, 14 ( 11 ) : l453, 1981. roberto benzi, giorgio parisi, alfonso sutera, and angelo vulpiani. stochastic resonance in climatic change. _ tellus _, 34 ( 1 ) : 10 – 16, 1982. zachary berger, parth agrawal, tian yu liu, stefano soatto, and alex wong. stereoscopic universal perturbations across different architectures and datasets. in _ proceedings of the ieee / cvf _ _ conference on computer vision and pattern recognition _, pp. 15180 – 15190, 2022. qi - zhi cai, min du, chang liu, and dawn song"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03224v1",
      "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance\n  of Latent Ensembles",
      "authors": [
        "Dong Lao",
        "Yuxiang Zhang",
        "Haniyeh Ehsani Oskouie",
        "Yangchao Wu",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "summary": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.",
      "published": "2025-10-03T17:57:25Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03224v1"
    },
    "chunk_id": 15,
    "text": "proceedings _ _ of the ieee / cvf international conference on computer vision _, pp. 7818 – 7827, 2021. roberto benzi, alfonso sutera, and angelo vulpiani. the mechanism of stochastic resonance. _ journal of physics a : mathematical and general _, 14 ( 11 ) : l453, 1981. roberto benzi, giorgio parisi, alfonso sutera, and angelo vulpiani. stochastic resonance in climatic change. _ tellus _, 34 ( 1 ) : 10 – 16, 1982. zachary berger, parth agrawal, tian yu liu, stefano soatto, and alex wong. stereoscopic universal perturbations across different architectures and datasets. in _ proceedings of the ieee / cvf _ _ conference on computer vision and pattern recognition _, pp. 15180 – 15190, 2022. qi - zhi cai, min du, chang liu, and dawn song. curriculum adversarial training. _ arxiv preprint _ _ arxiv : 1805. 04807 _, 2018. nicholas carlini and david wagner. towards evaluating the robustness of neural networks. in _ 2017 _ _ ieee symposium on security and privacy ( sp ) _, pp. 39 – 57. ieee, 2017. jia - ren chang and yong - sheng chen. pyramid stereo matching network. in _ proceedings of the _ _ ieee conference on computer vision and pattern recognition _, pp. 5410 – 5418, 2018. hao chen, pramod k varshney, steven m kay, and james h michels. theory of the stochastic resonance effect in signal detection : part i — fixed detectors. _ ieee transactions on signal processing _, 55 ( 7 ) : 3172 – 3184, 2007. kelvin cheng, christopher healey, and tianfu wu. towards adversarially robust and domain generalizable stereo matching by rethinking dnn feature backbones. _ arxiv preprint arxiv : 2108. 00335 _, 2021. 11 preprint version. under review. kelvin cheng, tianfu wu, and christopher healey. revisiting non - parametric matching cost volumes for robust and generalizable stereo matching. _ advances in neural information processing _ _ systems _, 35 : 16305 – 16318, 2022. gilad cohen and raja giryes. simple post - training robustness using test time augmentations and random forest. in _ proceedings of the ieee / cvf winter conference on applications of computer _ _ vision _, pp. 3996 – 4006, 2024. jia deng, wei dong, richard socher, li - jia li, kai li, and li fei - fei. imagenet : a large - scale hierarchical image database. in _ 2009 ieee conference on computer vision and pattern recognition _, pp. 248 – 255. ieee, 2009. guneet s dhillon, kamyar azizzadenesheli, zachary c lipton, jeremy bernstein, jean kossaifi, aran khanna, and anima anandkumar. stochastic activation pruning for robust adversarial defense. _ arxiv preprint arxiv : 1803. 01442 _, 2018. alexey dosovitskiy, lucas beyer, alexander kolesnikov, dirk weissenborn, xiaohua zhai, thomas unterthiner, mostafa dehghani, matthias minderer, georg heigold, sylvain gelly, et al. an image is worth 16x16 words : transformers for image recognition at scale. _ arxiv preprint _ _ arxiv : 2010. 11929 _, 2020. angus galloway, anna golubeva, thomas tanay, medhat moussa, and graham w taylor. batch normalization is a cause of adversarial vulnerability. _ arxiv preprint arxiv : 1905. 02161 _, 2019. andreas geiger, philip lenz, and raquel urtasun. are we ready for autonomous driving? the kitti vision benchmark suite. in _ 2012 ieee conference on computer vision and pattern recognition _, pp. 3354 – 3361. ieee, 2012. sajjad ghiasvand, amirhossein reisizadeh, mahnoosh alizadeh, and ramtin pedarsani. robust decentralized learning with local updates and gradient tracking. _ arxiv preprint arxiv : 2405. 00965 _, 2024. james j gibson. _ the ecological approach to visual perception : classic edition _. psychology press, 2014. ian j goodfellow, jonathon shlens, and christian szegedy. explaining and harnessing adversarial examples. _ arxiv preprint arxiv : 1412. 6572 _, 2014. kaiming he, xiangyu zhang, shaoqing ren, and jian sun"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03224v1",
      "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance\n  of Latent Ensembles",
      "authors": [
        "Dong Lao",
        "Yuxiang Zhang",
        "Haniyeh Ehsani Oskouie",
        "Yangchao Wu",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "summary": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.",
      "published": "2025-10-03T17:57:25Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03224v1"
    },
    "chunk_id": 16,
    "text": "_, 2019. andreas geiger, philip lenz, and raquel urtasun. are we ready for autonomous driving? the kitti vision benchmark suite. in _ 2012 ieee conference on computer vision and pattern recognition _, pp. 3354 – 3361. ieee, 2012. sajjad ghiasvand, amirhossein reisizadeh, mahnoosh alizadeh, and ramtin pedarsani. robust decentralized learning with local updates and gradient tracking. _ arxiv preprint arxiv : 2405. 00965 _, 2024. james j gibson. _ the ecological approach to visual perception : classic edition _. psychology press, 2014. ian j goodfellow, jonathon shlens, and christian szegedy. explaining and harnessing adversarial examples. _ arxiv preprint arxiv : 1412. 6572 _, 2014. kaiming he, xiangyu zhang, shaoqing ren, and jian sun. deep residual learning for image recognition. in _ proceedings of the ieee conference on computer vision and pattern recognition _, pp. 770 – 778, 2016. gaojie jin, xinping yi, wei huang, sven schewe, and xiaowei huang. enhancing adversarial training with second - order statistics of weights. in _ proceedings of the ieee / cvf conference on _ _ computer vision and pattern recognition _, pp. 15273 – 15283, 2022. harini kannan, alexey kurakin, and ian goodfellow. adversarial logit pairing. _ arxiv preprint _ _ arxiv : 1803. 06373 _, 2018. woo jae kim, yoonki cho, junsik jung, and sung - eui yoon. feature separation and recalibration for adversarial robustness. in _ proceedings of the ieee / cvf conference on computer vision and _ _ pattern recognition _, pp. 8183 – 8192, 2023. bart kosko and sanya mitaim. robust stochastic resonance : signal detection and adaptation in impulsive noise. _ physical review e _, 64 ( 5 ) : 051110, 2001. alex krizhevsky, geoffrey hinton, et al. learning multiple layers of features from tiny images. 2009. alexey kurakin, ian j goodfellow, and samy bengio. adversarial examples in the physical world. in _ artificial intelligence safety and security _, pp. 99 – 112. chapman and hall / crc, 2018. dong lao, yangchao wu, tian yu liu, alex wong, and stefano soatto. sub - token vit embedding via stochastic resonance transformers. in _ international conference on machine learning _, pp. 25995 – 26006. pmlr, 2024. 12 preprint version. under review. bo luo, yannan liu, lingxiao wei, and qiang xu. towards imperceptible and robust adversarial example attacks against neural networks. in _ proceedings of the aaai conference on artificial _ _ intelligence _, volume 32, 2018. divyam madaan, jinwoo shin, and sung ju hwang. adversarial neural pruning with latent vulnerability suppression. in _ international conference on machine learning _, pp. 6575 – 6585. pmlr, 2020. aleksander madry, aleksandar makelov, ludwig schmidt, dimitris tsipras, and adrian vladu. towards deep learning models resistant to adversarial attacks. _ arxiv preprint arxiv : 1706. 06083 _, 2017. seyed - mohsen moosavi - dezfooli, alhussein fawzi, omar fawzi, and pascal frossard. universal adversarial perturbations. in _ proceedings of the ieee conference on computer vision and pattern _ _ recognition _, pp. 1765 – 1773, 2017. haniyeh ehsani oskouie, mohammad - shahram moin, and shohreh kasaei. attack on scene flow using point clouds. in _ 2024 ieee 34th international workshop on machine learning for signal _ _ processing ( mlsp ) _, pp. 1 – 6. ieee, 2024. juan c [UNK], motasem alfarra, guillaume jeanneret, laura rueda, ali thabet, bernard ghanem, and pablo [UNK]. enhancing adversarial robustness via test - time transformation ensembling. in _ proceedings of the ieee / cvf international conference on computer vision _, pp. 81 – 91, 2021. jordi pont - tuset, federico perazzi, sergi caelles, pablo [UNK], alex sorkine - hornung, and luc van gool. the 2017 davis challenge on video object segmentation. _ arxiv preprint _ _ arxiv :"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03224v1",
      "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance\n  of Latent Ensembles",
      "authors": [
        "Dong Lao",
        "Yuxiang Zhang",
        "Haniyeh Ehsani Oskouie",
        "Yangchao Wu",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "summary": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.",
      "published": "2025-10-03T17:57:25Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03224v1"
    },
    "chunk_id": 17,
    "text": ", 2017. haniyeh ehsani oskouie, mohammad - shahram moin, and shohreh kasaei. attack on scene flow using point clouds. in _ 2024 ieee 34th international workshop on machine learning for signal _ _ processing ( mlsp ) _, pp. 1 – 6. ieee, 2024. juan c [UNK], motasem alfarra, guillaume jeanneret, laura rueda, ali thabet, bernard ghanem, and pablo [UNK]. enhancing adversarial robustness via test - time transformation ensembling. in _ proceedings of the ieee / cvf international conference on computer vision _, pp. 81 – 91, 2021. jordi pont - tuset, federico perazzi, sergi caelles, pablo [UNK], alex sorkine - hornung, and luc van gool. the 2017 davis challenge on video object segmentation. _ arxiv preprint _ _ arxiv : 1704. 00675 _, 2017. anurag ranjan, joel janai, andreas geiger, and michael j. black. attacking optical flow. in _ proceedings of the ieee / cvf international conference on computer vision ( iccv ) _, october 2019. jenny schmalfuss, philipp scholze, and [UNK] bruhn. a perturbation - constrained adversarial attack for evaluating the robustness of optical flow. in _ european conference on computer vision _, pp. 183 – 200. springer, 2022. simon schrodi, tonmoy saikia, and thomas brox. towards understanding adversarial robustness of optical flow networks. in _ proceedings of the ieee / cvf conference on computer vision and _ _ pattern recognition _, pp. 8916 – 8924, 2022. ji shu - yao, yuan fei, chen ke - yu, and cheng en. application of stochastic resonance technology in underwater acoustic weak signal detection. in _ oceans 2016 - shanghai _, pp. 1 – 5. ieee, 2016. nigel g stocks, d allingham, and robert p morse. the application of suprathreshold stochastic resonance to cochlear implant coding. _ fluctuation and noise letters _, 2 ( 03 ) : l169 – l181, 2002. ganesh sundaramoorthi and timothy e wang. translation insensitive cnns. _ arxiv preprint _ _ arxiv : 1911. 11238 _, 2019. linyu tang and lei zhang. robust overfitting does matter : test - time adversarial purification with fgsm. in _ proceedings of the ieee / cvf conference on computer vision and pattern recognition _, pp. 24347 – 24356, 2024. zachary teed and jia deng. raft : recurrent all - pairs field transforms for optical flow. in _ computer _ _ vision – eccv 2020 : 16th european conference, glasgow, uk, august 23 – 28, 2020, proceedings, _ _ part ii 16 _, pp. 402 – 419. springer, 2020. florian tram ` er, nicolas papernot, ian goodfellow, dan boneh, and patrick mcdaniel. the space of transferable adversarial examples. _ arxiv preprint arxiv : 1704. 03453 _, 2017. florian tramer, nicholas carlini, wieland brendel, and aleksander madry. on adaptive attacks to adversarial example defenses. _ advances in neural information processing systems _, 33 : 1633 – 1645, 2020. 13 preprint version. under review. yun - yun tsai, ju - chin chao, albert wen, zhaoyuan yang, chengzhi mao, tapan shah, and junfeng yang. test - time detection and repair of adversarial samples via masked autoencoder. _ arxiv _ _ preprint arxiv : 2303. 12848 _, 2023. dequan wang, an ju, evan shelhamer, david wagner, and trevor darrell. fighting gradients with gradients : dynamic defenses against adversarial attacks. _ arxiv preprint arxiv : 2105. 08714 _, 2021. haotao wang, aston zhang, shuai zheng, xingjian shi, mu li, and zhangyang wang. removing batch normalization boosts adversarial training. in _ international conference on machine learn - _ _ ing _, pp. 23433 – 23445. pmlr, 2022. hongjun wang and yisen wang. self - ensemble adversarial training for improved robustness. _ arxiv _ _ preprint arxiv : 2203. 09678 _, 2022. jun wang, qingbo he, and fanrang kong. adaptive multiscale noise tuning stochastic resonance for health diagnosis of rolling element bearings. _ ieee transactions on instrumentation and mea - _ _ surement _, 64 ( 2 )"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03224v1",
      "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance\n  of Latent Ensembles",
      "authors": [
        "Dong Lao",
        "Yuxiang Zhang",
        "Haniyeh Ehsani Oskouie",
        "Yangchao Wu",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "summary": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.",
      "published": "2025-10-03T17:57:25Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03224v1"
    },
    "chunk_id": 18,
    "text": "2023. dequan wang, an ju, evan shelhamer, david wagner, and trevor darrell. fighting gradients with gradients : dynamic defenses against adversarial attacks. _ arxiv preprint arxiv : 2105. 08714 _, 2021. haotao wang, aston zhang, shuai zheng, xingjian shi, mu li, and zhangyang wang. removing batch normalization boosts adversarial training. in _ international conference on machine learn - _ _ ing _, pp. 23433 – 23445. pmlr, 2022. hongjun wang and yisen wang. self - ensemble adversarial training for improved robustness. _ arxiv _ _ preprint arxiv : 2203. 09678 _, 2022. jun wang, qingbo he, and fanrang kong. adaptive multiscale noise tuning stochastic resonance for health diagnosis of rolling element bearings. _ ieee transactions on instrumentation and mea - _ _ surement _, 64 ( 2 ) : 564 – 577, 2014. yisen wang, difan zou, jinfeng yi, james bailey, xingjun ma, and quanquan gu. improving adversarial robustness requires revisiting misclassified examples. in _ international conference on _ _ learning representations _, 2019. thomas wellens, vyacheslav shatokhin, and andreas buchleitner. stochastic resonance. _ reports _ _ on progress in physics _, 67 ( 1 ) : 45, 2003. alex wong, mukund mundhra, and stefano soatto. stereopagnosia : fooling stereo networks with adversarial perturbations. in _ proceedings of the aaai conference on artificial intelligence _, volume 35, pp. 2879 – 2888, 2021. yangchao wu, tian yu liu, hyoungseob park, stefano soatto, dong lao, and alex wong. augundo : scaling up augmentations for monocular depth completion and estimation. in _ european _ _ conference on computer vision _, pp. 274 – 293. springer, 2024. chang xiao, peilin zhong, and changxi zheng. enhancing adversarial defense by k - winners - takeall. _ arxiv preprint arxiv : 1905. 10510 _, 2019. cihang xie, yuxin wu, laurens van der maaten, alan l yuille, and kaiming he. feature denoising for improving adversarial robustness. in _ proceedings of the ieee / cvf conference on computer _ _ vision and pattern recognition _, pp. 501 – 509, 2019. hanshu yan, jingfeng zhang, gang niu, jiashi feng, vincent tan, and masashi sugiyama. cifs : improving adversarial robustness of cnns via channel - wise importance - based feature selection. in _ international conference on machine learning _, pp. 11693 – 11703. pmlr, 2021. cheng - han yeh, kuanchun yu, and chun - shien lu. test - time adversarial defense with opposite adversarial path and high attack time cost. _ arxiv preprint arxiv : 2410. 16805 _, 2024. sergey zagoruyko and nikos komodakis. wide residual networks. _ arxiv preprint _ _ arxiv : 1605. 07146 _, 2016. hongyang zhang, yaodong yu, jiantao jiao, eric xing, laurent el ghaoui, and michael jordan. theoretically principled trade - off between robustness and accuracy. in _ international conference _ _ on machine learning _, pp. 7472 – 7482. pmlr, 2019. howard zhang, yunhao ba, ethan yang, varan mehra, blake gella, akira suzuki, arnold pfahnl, chethan chinder chandrappa, alex wong, and achuta kadambi. weatherstream : light transport automation of single image deweathering. in _ proceedings of the ieee / cvf conference on _ _ computer vision and pattern recognition _, pp. 13499 – 13509, 2023. jingfeng zhang, xilie xu, bo han, gang niu, lizhen cui, masashi sugiyama, and mohan kankanhalli. attacks which do not kill training make adversarial learning stronger. in _ international _ _ conference on machine learning _, pp. 11278 – 11287. pmlr, 2020. daniel zoran, mike chrzanowski, po - sen huang, sven gowal, alex mott, and pushmeet kohli. towards robust image classification using sequential attention models. in _ proceedings of the _ _ ieee / cvf conference on computer vision and pattern recognition _, pp. 9483 – 9492, 2020. 14 preprint version. under review. a"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03224v1",
      "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance\n  of Latent Ensembles",
      "authors": [
        "Dong Lao",
        "Yuxiang Zhang",
        "Haniyeh Ehsani Oskouie",
        "Yangchao Wu",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "summary": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.",
      "published": "2025-10-03T17:57:25Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03224v1"
    },
    "chunk_id": 19,
    "text": "kadambi. weatherstream : light transport automation of single image deweathering. in _ proceedings of the ieee / cvf conference on _ _ computer vision and pattern recognition _, pp. 13499 – 13509, 2023. jingfeng zhang, xilie xu, bo han, gang niu, lizhen cui, masashi sugiyama, and mohan kankanhalli. attacks which do not kill training make adversarial learning stronger. in _ international _ _ conference on machine learning _, pp. 11278 – 11287. pmlr, 2020. daniel zoran, mike chrzanowski, po - sen huang, sven gowal, alex mott, and pushmeet kohli. towards robust image classification using sequential attention models. in _ proceedings of the _ _ ieee / cvf conference on computer vision and pattern recognition _, pp. 9483 – 9492, 2020. 14 preprint version. under review. a i mplementation for c lassification for our classification experiments, we built our implementation on top of standard network architectures, implementing sr on two main architectures derived from the fsr codebase kim et al. ( 2023 ) : - resnet - 18 he et al. ( 2016 ) : a standard residual network with 18 layers organized in four main blocks with increasing channel dimensions ( 64, 128, 256, 512 ). - wideresnet - 34 zagoruyko & komodakis ( 2016 ) : a wider variant of resnet with depth 34 and width factor 10, resulting in higher representational capacity with three main blocks with channel dimensions scaled by the width factor ( 160, 320, 640 ). for both architectures, we apply sr at the bottleneck layer ( after the final convolutional block ). given an input image batch _ x ∈ _ r _ [ b ] [ × ] _ [ 3 ] _ [ × ] [ h ] [ × ] [ w ] _ ( where _ b _ is the batch size ), our sr approach operates as follows. first, we create a set of ( 2 _ d _ _ x _ + 1 ) _ × _ ( 2 _ d _ _ y _ + 1 ) perturbed versions of the input by applying pixel - level translations within the range [ _ −d _ _ x _ _, d _ _ x _ ] _ × _ [ _ −d _ _ y _ _, d _ _ y _ ] pixels : _ x _ perturbed = _ { g _ _ i, j _ ( _ x _ ) _ | i ∈ _ [ _ −d _ _ y _ _, d _ _ y _ ] _, j ∈ _ [ _ −d _ _ x _ _, d _ _ x _ ] _ } _ ( 2 ) where _ g _ _ i, j _ translates the image by ( _ i, j _ ) pixels. these transformations are applied using pytorch ’ s “ transforms. functional. affine ” function with translation parameters while preserving the original image properties. all images are concatenated into one batch and processed through the network in parallel up to the bottleneck layer : _ f _ = _ [UNK] _ ( _ x _ perturbed ) ( 3 ) where _ [UNK] _ represents the network up to the bottleneck layer. this batch processing approach significantly improves computational efficiency compared to individual forward passes. after obtaining feature maps for all perturbed inputs, we aggregate them to create a single enhanced feature map : _ f _ ensembled = [ 1 ] _ n _ _ t _ _ −i, −j _ ( _ f _ _ i, j _ ) ( 4 ) _ i, j _ where _ t _ _ −i, −j _ represents the inverse spatial shift operation that realigns the feature map and _ n _ the number of augmentations. our implementation requires ( 2 _ d _ _ x _ + 1 ) _ × _ ( 2 _ d _ _ y _ + 1 ) forward passes through the network up to the bottleneck layer. for evaluation, we tested our approach against standard adversarial attacks ( fgsm goodfellow et al. ( 2014 ), pgd - 20 and pgd - 100 madry et al. ( 2017 ), and c & w carlini & wagner ( 2017 ) ), all bounded within _ [UNK] _ = 8 _ / _ 255 under _ [UNK] _ _ ∞ _ - norm. we also report an ensemble metric that measures the worst - case performance across all attacks for each test example, providing a comprehensive robustness assessment. b i mplementation for s tereo m atching for our stereo matching experiments, we built our implementation on top of standard stereo network architectures to ensure our approach remains model - agnostic and requires no training or fine - tuning. we integrated sr with psmnet chang & chen ( 2018 ), a pyramid stereo matching network with a stacked hourglass architecture that uses 3d convolutions on a cost volume"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03224v1",
      "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance\n  of Latent Ensembles",
      "authors": [
        "Dong Lao",
        "Yuxiang Zhang",
        "Haniyeh Ehsani Oskouie",
        "Yangchao Wu",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "summary": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.",
      "published": "2025-10-03T17:57:25Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03224v1"
    },
    "chunk_id": 20,
    "text": ") forward passes through the network up to the bottleneck layer. for evaluation, we tested our approach against standard adversarial attacks ( fgsm goodfellow et al. ( 2014 ), pgd - 20 and pgd - 100 madry et al. ( 2017 ), and c & w carlini & wagner ( 2017 ) ), all bounded within _ [UNK] _ = 8 _ / _ 255 under _ [UNK] _ _ ∞ _ - norm. we also report an ensemble metric that measures the worst - case performance across all attacks for each test example, providing a comprehensive robustness assessment. b i mplementation for s tereo m atching for our stereo matching experiments, we built our implementation on top of standard stereo network architectures to ensure our approach remains model - agnostic and requires no training or fine - tuning. we integrated sr with psmnet chang & chen ( 2018 ), a pyramid stereo matching network with a stacked hourglass architecture that uses 3d convolutions on a cost volume constructed by concatenating features. we apply sr at the feature extraction stage, before cost volume construction, where stereo correspondences are first established. given a pair of input stereo images _ x _ _ l _ _, x _ _ r _ _ ∈ _ r _ [ b ] [ × ] _ [ 3 ] _ [ × ] [ h ] [ × ] [ w ] _ ( where _ b _ is the batch size ), our sr approach operates as follows. first, we create a set of ( 2 _ d _ _ x _ + 1 ) _ × _ ( 2 _ d _ _ y _ + 1 ) perturbed versions of each input image by applying translations within the range [ _ −d _ _ x _ _, d _ _ x _ ] _ × _ [ _ −d _ _ y _ _, d _ _ y _ ] pixels : _ x _ _ l, _ perturbed = _ { g _ _ i, j _ ( _ x _ _ l _ ) _ | i ∈ _ [ _ −d _ _ y _ _, d _ _ y _ ] _, j ∈ _ [ _ −d _ _ x _ _, d _ _ x _ ] _ } _ ( 5 ) 15 preprint version. under review. _ x _ _ r, _ perturbed = _ { g _ _ i, j _ ( _ x _ _ r _ ) _ | i ∈ _ [ _ −d _ _ y _ _, d _ _ y _ ] _, j ∈ _ [ _ −d _ _ x _ _, d _ _ x _ ] _ }. _ ( 6 ) all images are concatenated into batches and processed through the feature extraction component of the network : _ f _ _ l _ = _ [UNK] _ ( _ x _ _ l, _ perturbed ) ( 7 ) _ f _ _ r _ = _ [UNK] _ ( _ x _ _ r, _ perturbed ) ( 8 ) where _ [UNK] _ represents the feature extraction component of the stereo network. this batch processing approach significantly improves computational efficiency compared to individual forward passes. after obtaining feature maps for all perturbed inputs, we aggregate them to create a single enhanced feature map. our implementation requires ( 2 _ d _ _ x _ + 1 ) _ × _ ( 2 _ d _ _ y _ + 1 ) forward passes through the feature extraction component of the network for each stereo image. for evaluation, we tested our approach against adversarial attacks generated using fgsm goodfellow et al. ( 2014 ) and i - fgsm kurakin et al. ( 2018 ) ( a special case of pgd ), bounded within various _ [UNK] _ values ( _ { _ 0 _. _ 002 _, _ 0 _. _ 005 _, _ 0 _. _ 01 _, _ 0 _. _ 02 _ } _ ) under _ [UNK] _ _ ∞ _ - norm. we measured performance using three standard stereo matching metrics : mean absolute error ( mae ), root mean square error ( rmse ), and d1 - error ( percentage of pixels with disparity error greater than 3 pixels or 5 % of the ground truth ) luo et al. ( 2018 ). c d etails about a ttack on o ptical f low to find an adversarial attack for optical flow estimated by a given neural network _ f _, we utilize a similar approach to oskouie et al. ( 2024 ) that aims to find a perturbation _ δ _ for given frames _ f _ 1 and _ f _ 2, maximizing the discrepancy between predicted and ground - truth optical flow _ of _. if the ground - truth optical flow is unavailable, we use the predicted optical flow from the unattacked frame as our surrogate ground - truth. our method applies _ δ _ to the first input frame, then uses a deep neural network to estimate optical flow from the perturbed frames. the objective is to maximize the average end - point"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03224v1",
      "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance\n  of Latent Ensembles",
      "authors": [
        "Dong Lao",
        "Yuxiang Zhang",
        "Haniyeh Ehsani Oskouie",
        "Yangchao Wu",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "summary": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.",
      "published": "2025-10-03T17:57:25Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03224v1"
    },
    "chunk_id": 21,
    "text": "error ( mae ), root mean square error ( rmse ), and d1 - error ( percentage of pixels with disparity error greater than 3 pixels or 5 % of the ground truth ) luo et al. ( 2018 ). c d etails about a ttack on o ptical f low to find an adversarial attack for optical flow estimated by a given neural network _ f _, we utilize a similar approach to oskouie et al. ( 2024 ) that aims to find a perturbation _ δ _ for given frames _ f _ 1 and _ f _ 2, maximizing the discrepancy between predicted and ground - truth optical flow _ of _. if the ground - truth optical flow is unavailable, we use the predicted optical flow from the unattacked frame as our surrogate ground - truth. our method applies _ δ _ to the first input frame, then uses a deep neural network to estimate optical flow from the perturbed frames. the objective is to maximize the average end - point error ( epe ) between the predicted and ground - truth optical flow, calculated as the mean euclidean distance between corresponding 2d flow vectors. in other words, the _ [UNK] _ - norm bounded adversary _ δ _ for optical - flow is calculated by optimizing the following max _ of, f _ ( _ f _ 1 + _ δ, f _ 2 ) _. _ ( 9 ) _ δ _ : _ [UNK] _ [ epe ] one _ l _ _ ∞ _ - bounded adversary _ a _ for the aforementioned optimization problem is fast gradient sign method ( fgsm ) goodfellow et al. ( 2014 ) which can be obtained by l = epe ( _ of, f _ ( _ f _ 1 _, f _ 2 ) ) _, _ _ a _ = _ f _ 1 + _ [UNK] · _ sign _ ∇ _ _ f _ 1 l _. _ ( 10 ) projected gradient descent ( pgd ) madry et al. ( 2017 ) represents an enhanced and more complex version of fgsm. this attack method generates adversarial examples through an iterative process and the formulation for this attack is as following _ f _ 1 [ ( ] _ [ t ] _ [ + 1 ) ] = π _ f _ 1 + _ s _ _ f _ 1 [ ( ] _ [ t ] _ [ ) ] + _ α · _ sign ( _ ∇ _ _ f _ 1 l ) _. _ ( 11 ) note that in pgd, since the perturbations are considered to be too minimal to significantly alter the flow dynamics, the ground - truth optical flow is not updated by intermediate perturbations applied to the input data. for our experimental setup, we chose to set the norm value _ [UNK] _ at 256 [ 10 ] [. furthermore, we configured the ] pgd algorithm to run for 10 iterations. the step size _ α _ was determined by dividing 2 _. _ 5 _ · [UNK] _ by the total number of iterations, ensuring a balanced progression throughout the optimization process. d a dditional v isualizations here we provide additional visualizations from our experiments comparing sr under both fgsm and pgd attack. we also provide a visual showing the results of fgsm and pgd pertubation on various images. 16 preprint version. under review. figure 6 : visual results on stereo matching against fgsm attack, without and with sr, _ [UNK] _ = 0 _. _ 02 figure 7 : visual results on stereo matching against fgsm attack, without and with sr, _ [UNK] _ = 0 _. _ 01 figure 8 : visual results on stereo matching against fgsm attack, without and with sr, _ [UNK] _ = 0 _. _ 005 figure 9 : visual results on stereo matching against pgd attack, without and with sr, _ [UNK] _ = 0 _. _ 01 17 preprint version. under review. figure 10 : visual results on stereo matching against pgd attack, without and with sr, _ [UNK] _ = 0 _. _ 005 figure 11 : visual results on stereo matching against pgd attack, without and with sr, _ [UNK] _ = 0 _. _ 002 * * image * * * * fgsm attacked * * * * fgsm noise * * * * pgd attacked * * * * pgd noise * * figure 12 : original images and their corresponding attacked images and perturbations using fgsm and pgd methods on optical flow. the attacks mostly target the main object observed in the image. 18"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03224v1",
      "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance\n  of Latent Ensembles",
      "authors": [
        "Dong Lao",
        "Yuxiang Zhang",
        "Haniyeh Ehsani Oskouie",
        "Yangchao Wu",
        "Alex Wong",
        "Stefano Soatto"
      ],
      "summary": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.",
      "published": "2025-10-03T17:57:25Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03224v1"
    },
    "chunk_id": 22,
    "text": ". _ 005 figure 11 : visual results on stereo matching against pgd attack, without and with sr, _ [UNK] _ = 0 _. _ 002 * * image * * * * fgsm attacked * * * * fgsm noise * * * * pgd attacked * * * * pgd noise * * figure 12 : original images and their corresponding attacked images and perturbations using fgsm and pgd methods on optical flow. the attacks mostly target the main object observed in the image. 18"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03223v1",
      "title": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention\n  Alignment",
      "authors": [
        "Hongxiang Zhang",
        "Yuan Tian",
        "Tianyi Zhang"
      ],
      "summary": "To solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and\nreinforcement learning. However, as reasoning chains extend, critical\nintermediate steps and the original prompt will be buried in the context,\nreceiving insufficient attention and leading to errors. In this paper, we\npropose Self-Anchor, a novel pipeline that leverages the inherent structure of\nreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories\ninto structured plans and automatically aligns the model's attention to the\nmost relevant inference steps, allowing the model to maintain focus throughout\ngeneration. Our experiment shows that Self-Anchor outperforms SOTA prompting\nmethods across six benchmarks. Notably, Self-Anchor significantly reduces the\nperformance gap between ``non-reasoning'' models and specialized reasoning\nmodels, with the potential to enable most LLMs to tackle complex reasoning\ntasks without retraining.",
      "published": "2025-10-03T17:56:33Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03223v1"
    },
    "chunk_id": 0,
    "text": "preprint # # - s elf - a nchor : l arge l anguage m odel r eason - - ing via s tep by step a ttention a lignment * * hongxiang zhang & yuan tian & tianyi zhang * * department of computer science purdue university lafayette, in 47907, usa _ { _ hxxzhang, tian211, tianyi _ } _ @ purdue. edu a bstract to solve complex reasoning tasks for large language models ( llms ), prompting - based methods offer a lightweight alternative to fine - tuning and reinforcement learning. however, as reasoning chains extend, critical intermediate steps and the original prompt will be buried in the context, receiving insufficient attention and leading to errors. in this paper, we propose s elf - a nchor, a novel pipeline that leverages the inherent structure of reasoning to steer llm attention. s elf - a nchor decomposes reasoning trajectories into structured plans and automatically aligns the model ’ s attention to the most relevant inference steps, allowing the model to maintain focus throughout generation. our experiment shows that s elf - a nchor outperforms sota prompting methods across six benchmarks. notably, s elf - a nchor significantly reduces the performance gap between “ non - reasoning ” models and specialized reasoning models, with the potential to enable most llms to tackle complex reasoning tasks without retraining. 1 i ntroduction reasoning abilities in large language models ( llms ) are key to solve complex tasks, from mathematical problem solving to logical inference and multi - step reasoning ( ahn et al., 2024 ; huang & chang, 2023 ; cheng et al., 2025 ). recent llms, such as openai o1 ( openai, 2024 ) and deepseekr1 ( deepseek - ai, 2025 ), have further advanced their reasoning capabilities through fine - tuning and reinforcement learning ( luo et al., 2024 ; et al., 2025 ). howevere, despite their impressive performance, they require substantial computation and a considerable amount of training data. as an alternative, prompting - based methods emerged to induce llms ’ inherent reasoning capabilities at test time without updating model parameters. methods such as self - refine ( madaan et al., 2023 ) and react ( yao et al., 2023 ) facilitate reasoning by iteratively expanding and refining the generation process. methods like self - planning ( jiang et al., 2024 ), plan - and - solve ( wang et al., 2023 ), and re - reading ( xu et al., 2024 ) explicitly decompose complex problems before solving them. however, a tradeoff of being training - free is that these prompting - based methods necessitate long reasoning chains because they depend on iterative generation or explicit planning. while this can be seen as the cost of training - free methods, recent studies have revealed another issue : longcontext reasoning can cause severe attention misalignmentt issue ( gu et al., 2024 ; chi et al., 2023 ; liu et al., 2024 ; sun et al., 2024 ; yao et al., 2021 ; tian & zhang, 2024 ; li et al., 2024 ; hong et al., 2025 ). as a key component in llms, the attention mechanism ( vaswani et al., 2023 ) enables llms to selectively integrate relevant information from preceding context. however, llm attention is an inherently limited resource. as the generation proceeds, the number of preceding tokens increases, making it increasingly difficult for the model to pay attention to the relevant context, especially when the context is long and complex ( tian & zhang, 2024 ; li et al., 2024 ; hong et al., 2025 ). in such cases, even with the ability to correctly predict next token based on the corresponding context, llms may attend to irrelevant context, thereby generating off - topic or wrong results. as shown in figure 1, the intermediate reasoning steps and most of the original prompt will be buried in the middle, receive insufficient attention, and consequently, introduce errors ( liu et al., 2024 ). 1 preprint to mitigate such attention misalignment issues, recent works explicitly steer llm attention to influence generation behavior. for example, pasta ( zhang et al., 2023 ) adjusts the self - attention distribution within a subset of attention heads, while spa ( tian & zhang, 2024 ) simulates attention steering through logit arithmetic. however, these methods mainly focus on developing robust attention steering mechanisms, while requiring humans to specify which tokens the model should pay more attention to. since such tokens can vary significantly at different generation steps and across different tasks, it is unrealistic for humans to manually decide for every generation step. figure 1 : comparison between existing reasoning methods and s elf - a"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03223v1",
      "title": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention\n  Alignment",
      "authors": [
        "Hongxiang Zhang",
        "Yuan Tian",
        "Tianyi Zhang"
      ],
      "summary": "To solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and\nreinforcement learning. However, as reasoning chains extend, critical\nintermediate steps and the original prompt will be buried in the context,\nreceiving insufficient attention and leading to errors. In this paper, we\npropose Self-Anchor, a novel pipeline that leverages the inherent structure of\nreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories\ninto structured plans and automatically aligns the model's attention to the\nmost relevant inference steps, allowing the model to maintain focus throughout\ngeneration. Our experiment shows that Self-Anchor outperforms SOTA prompting\nmethods across six benchmarks. Notably, Self-Anchor significantly reduces the\nperformance gap between ``non-reasoning'' models and specialized reasoning\nmodels, with the potential to enable most LLMs to tackle complex reasoning\ntasks without retraining.",
      "published": "2025-10-03T17:56:33Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03223v1"
    },
    "chunk_id": 1,
    "text": "corresponding context, llms may attend to irrelevant context, thereby generating off - topic or wrong results. as shown in figure 1, the intermediate reasoning steps and most of the original prompt will be buried in the middle, receive insufficient attention, and consequently, introduce errors ( liu et al., 2024 ). 1 preprint to mitigate such attention misalignment issues, recent works explicitly steer llm attention to influence generation behavior. for example, pasta ( zhang et al., 2023 ) adjusts the self - attention distribution within a subset of attention heads, while spa ( tian & zhang, 2024 ) simulates attention steering through logit arithmetic. however, these methods mainly focus on developing robust attention steering mechanisms, while requiring humans to specify which tokens the model should pay more attention to. since such tokens can vary significantly at different generation steps and across different tasks, it is unrealistic for humans to manually decide for every generation step. figure 1 : comparison between existing reasoning methods and s elf - a nchor. due to inherent attention patterns, existing reasoning methods may easily overlook intermediate reasoning and make mistakes. s elf - a nchor addresses this by decomposes the task into plans, and takes each plan as a component for attention alignment. to reduce human efforts, we introduce s elf - a nchor, a novel generative pipeline that explicitly aligns llm attention by leveraging the inherent structure of a reasoning chain. s elf - a nchor builds on two key insights : ( 1 ) complex reasoning problems can be decomposed into structured plans, and ( 2 ) each decomposed plan can naturally serve as a component for attention alignment. as illustrated in figure 1, s elf - a nchor decomposes the original prompt into plan steps with corresponding reasoning steps. during generation, it automatically selects and steers the model attention to the prompt and the corresponding plan. this enables the llm to keep attending to both the problem statement and immediate reasoning goals, thereby preventing attention mistakes among continuously expanding reasoning steps. we evaluate s elf - a nchor on six benchmarks and six base llms with varying sizes, and compare it with sota prompting methods. the evaluation benchmarks include three mathematical reasoning benchmarks ( gsm8k, aqua, math ), two commonsense benchmarks ( strategyqa & things for doing ), and an multi - task evaluation benchmark ( big - bench hard, bbh ). s elf - a nchor consistently improves accuracy on all the settings, outperforming all the prompting - based baselines by at least 5. 44 % on average. in addition, we demonstrate that s elf - a nchor achieves performance on par with five reasoning models but with substantially lower cost and complexity, suggesting a practical alternative to applying reinforcement learning to enhance the reasoning capability of llms. 2 m ethod 2. 1 s elf - a nchor * * reasoning as the scaffold for attention alignment. * * we are inspired by the observation that planning offers a natural scaffold for attention alignment. specifically, planning helps the model to understand and break down complex problems into subproblems ( jiang et al., 2024 ; wang et al., 2023 ). each decomposed plan step provides a correspondence to subsequent reasoning, which can naturally serve to guide attention alignment. building on this idea, we design s elf - a nchor to leverage the inherent structure in the reasoning chain to conduct the attention alignment. s elf 2 preprint a nchor prompts the model to decompose the prompt into plans, and then generates and corresponding reasoned solutions with explicit attention steering. * * attention steering mechanism. * * several studies have explored methods for attention steering ( zhang et al., 2023 ; shi et al., 2023 ; tian & zhang, 2024 ). these methods primarily address _ how to steer the model attention _. by contrast, our work focuses on an orthogonal problem — _ how _ _ to automatically select relevant context _ and uses these methods as a plug - and - play component. in this work, we choose selective prompt anchoring ( spa ) ( tian & zhang, 2024 ) as the underlying attention steering mechanism, since it is low - cost and efficient. we briefly summarize how spa works here and refer interested readers to the original paper for more technical details. given a set of tokens that an llm should pay more attention to, spa simulates attention steering through logit arithmetic. specifically, it estimates the influence of selected tokens by contrasting the original logits with the logits when these tokens are masked, and then add this influence back to the original logits. the steered logit is represented by the linear combination of the original logits and the logits with selected tokens masked, where _ ω _ _ i _ is a coefficient determining the attention steering strength. formally, it can be represented as * * logits * * [ steered ] _ i _ = _ ω _ _ i _ _ · _ * *"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03223v1",
      "title": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention\n  Alignment",
      "authors": [
        "Hongxiang Zhang",
        "Yuan Tian",
        "Tianyi Zhang"
      ],
      "summary": "To solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and\nreinforcement learning. However, as reasoning chains extend, critical\nintermediate steps and the original prompt will be buried in the context,\nreceiving insufficient attention and leading to errors. In this paper, we\npropose Self-Anchor, a novel pipeline that leverages the inherent structure of\nreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories\ninto structured plans and automatically aligns the model's attention to the\nmost relevant inference steps, allowing the model to maintain focus throughout\ngeneration. Our experiment shows that Self-Anchor outperforms SOTA prompting\nmethods across six benchmarks. Notably, Self-Anchor significantly reduces the\nperformance gap between ``non-reasoning'' models and specialized reasoning\nmodels, with the potential to enable most LLMs to tackle complex reasoning\ntasks without retraining.",
      "published": "2025-10-03T17:56:33Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03223v1"
    },
    "chunk_id": 2,
    "text": "these methods as a plug - and - play component. in this work, we choose selective prompt anchoring ( spa ) ( tian & zhang, 2024 ) as the underlying attention steering mechanism, since it is low - cost and efficient. we briefly summarize how spa works here and refer interested readers to the original paper for more technical details. given a set of tokens that an llm should pay more attention to, spa simulates attention steering through logit arithmetic. specifically, it estimates the influence of selected tokens by contrasting the original logits with the logits when these tokens are masked, and then add this influence back to the original logits. the steered logit is represented by the linear combination of the original logits and the logits with selected tokens masked, where _ ω _ _ i _ is a coefficient determining the attention steering strength. formally, it can be represented as * * logits * * [ steered ] _ i _ = _ ω _ _ i _ _ · _ * * logits * * [ original ] _ i _ + ( 1 _ − _ _ ω _ _ i _ ) _ · _ * * logits * * [ mask ] _ i _ _. _ ( 1 ) * * selection of attention alignment. * * building on this attention steering mechanism, we propose a novel strategy that dynamically aligns model attention to changing context tokens during generation. according to the attention sink phenomenon ( xiao et al., 2023 ), the model already attends strongly to initial tokens and the recent generated tokens. our method complementarily steer the model attention to the planning steps when conducting the corresponding reasoning. furthermore, s elf a nchor additionally steers the model attention to the question in the prompt, which serves as the core generation purpose, ensuring the model keeps focusing on the problem statement. [ 1 ] formally, we use _ f _ ( _ x, _ * * s * * ) to represent the generation function with attention steering, where _ x _ represents the entire preceding tokens and * * s * * represents the selected tokens where the model ’ s attention should be steered to. let sys denote the system prompt together with high - level background instructions ( e. g., _ “ you are a helpful assistant ” _ ), and let _ q _ denote the core question under consideration. thus, the original prompt can be represented as concat ( sys _, q _ ). the generation of s elf - a nchor consists of two parts : the _ planning _ and the corresponding _ reasoning _. at step _ i _, the planning is generated by plan _ i _ = _ f _ concatsys _, q, _ plan 1 _, _ plan 2 _,..., _ plan _ i− _ 1 _, _ _ * * q * * _ _. _ ( 2 ) the planning is generated by reason _ i _ = _ f _ concatsys _, q, _ plan 1 _, _ plan 2 _,..., _ plan _ i− _ 1 _, _ * * concat * * ( _ * * q * * _ * *, plan * * i ) _. _ ( 3 ) the generation proceeds by alternating between plan _ i _ and reason _ i _, until the process terminates with the final result. * * dynamic tuning of attention alignment strength. * * as reasoning trajectories progress, the required degree of attention alignment may vary at different steps. according to prior work ( geng et al., 2024 ; fu et al., 2025 ), llms ’ predicted probability distribution can be viewed as a confidence signal to determine their prediction quality. high - confidence prediction suggests reliable generation, implying a correct attention, whereas low confidence may indicate unreliable generation and attention drift. therefore, we introduce a step - level anchoring strength _ ω _ _ i _ that is dynamically adjusted based on model confidence. [ 2 ] let _ p _ _ i _ = _ { p _ 1 _, p _ 2 _,..., p _ _ m _ _ } _ represent the predicted probability at step _ i _. we calculate the confidence score using the harmonic mean of _ p _ _ i _ _ n _ _ p _ avg = ~ ~ ~ ~ ~ ~ _ n _ ~ ~ _ i _ = 1 _ p _ 1 _ i _ _. _ ( 4 ) this confidence score serves as an additional factor to scale the attention steering strength _ w _ _ i _ in equation 1. we discuss detailed design choices and experiments in appendix b. 1 alternative anchoring strategies are discussed in appendix d 2 our strength adjustment strategy builds upon the confidence - modulated strength strategy in spa ( tian & zhang, 2024 ). while spa adjusts the strength based on confidence for each logit at the vocabulary level, we introduce an additional factor to adjust the strength for each step. 3 preprint 3 e xperiments 3"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03223v1",
      "title": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention\n  Alignment",
      "authors": [
        "Hongxiang Zhang",
        "Yuan Tian",
        "Tianyi Zhang"
      ],
      "summary": "To solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and\nreinforcement learning. However, as reasoning chains extend, critical\nintermediate steps and the original prompt will be buried in the context,\nreceiving insufficient attention and leading to errors. In this paper, we\npropose Self-Anchor, a novel pipeline that leverages the inherent structure of\nreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories\ninto structured plans and automatically aligns the model's attention to the\nmost relevant inference steps, allowing the model to maintain focus throughout\ngeneration. Our experiment shows that Self-Anchor outperforms SOTA prompting\nmethods across six benchmarks. Notably, Self-Anchor significantly reduces the\nperformance gap between ``non-reasoning'' models and specialized reasoning\nmodels, with the potential to enable most LLMs to tackle complex reasoning\ntasks without retraining.",
      "published": "2025-10-03T17:56:33Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03223v1"
    },
    "chunk_id": 3,
    "text": "p _ _ i _ = _ { p _ 1 _, p _ 2 _,..., p _ _ m _ _ } _ represent the predicted probability at step _ i _. we calculate the confidence score using the harmonic mean of _ p _ _ i _ _ n _ _ p _ avg = ~ ~ ~ ~ ~ ~ _ n _ ~ ~ _ i _ = 1 _ p _ 1 _ i _ _. _ ( 4 ) this confidence score serves as an additional factor to scale the attention steering strength _ w _ _ i _ in equation 1. we discuss detailed design choices and experiments in appendix b. 1 alternative anchoring strategies are discussed in appendix d 2 our strength adjustment strategy builds upon the confidence - modulated strength strategy in spa ( tian & zhang, 2024 ). while spa adjusts the strength based on confidence for each logit at the vocabulary level, we introduce an additional factor to adjust the strength for each step. 3 preprint 3 e xperiments 3. 1 b enchmarks we evaluated s elf - a nchor on six benchmarks. the first three benchmarks incorporate gsm8k ( cobbe et al., 2021 ), aqua ( ling et al., 2017 ), and math ( hendrycks et al., 2021 ) represent arithmetic reasoning. the second two benchmarks include strategyqa ( geva et al., 2021 ), and thinking for doing ( t4d ) ( zhou et al., 2023 ) represent commonsense reasoning. lastly, we evaluated on a subset of big - bench hard ( bbh ) ( suzgun et al., 2022 ), which covers a diverse range of reasoning problems spanning the multi - step algorithmic reasoning, natural language understanding, the application of world knowledge, and multilingual knowledge. we report final answer accuracy across all benchmarks [ 3 ]. 3. 2 m odels and b aselines * * base models. * * we conduct our experiments on six non - reasoning llms spanning various scales. for non - reasoning models, we select llama - 3. 1 - 8b - instruct ( grattafiori et al., 2024 ), llama - 3. 2 - 3binstruct ( grattafiori et al., 2024 ), phi - 4 - mini - instruct ( abouelenin et al., 2025 ), qwen3 - 4b - instruct2507 ( team, 2025 ), phi - 4 ( abdin et al., 2024 ), and qwen3 - 30b - a3b - instruct - 2507 ( team, 2025 ). * * comparison baselines. * * we compare our method against three representative prompting methods for llm reasoning. first, we include * * cot * * ( wei et al., 2022 ; kojima et al., 2022 ), a widely used baseline that models are prompted to generate a reasoning process leading to the final answer. second, we include * * plan - and - solve + ( ps + ) * * ( wang et al., 2023 ), a prompting method that models are prompted to first generate a plan and then solve the problem. third, we include * * re - reading * * * * ( re2 ) * * ( xu et al., 2024 ), which asks the model to read the question again and then solve the problem. furthermore, we consider five state - of - the - art reasoning llms as baselines to see if non - reasoning llms combined with s elf - a nchor achieve competitive performance against reasoning models. the reasoning models include phi - 4 - mini - reasoning ( abouelenin et al., 2025 ), qwen34b - thinking - 2507 ( team, 2025 ), deepseek - r1 - distill - llama - 8b ( deepseek - ai, 2025 ), phi - 4reasoning ( abdin et al., 2024 ), and qwen3 - 30b - a3b - thinking - 2507 ( team, 2025 ). 3. 3 m ain r esults * * mathematical reasoning. * * arithmetic reasoning represents one of the most challenging aspects of llm reasoning capabilities. as shown in table 1, s elf - a nchor consistently improves accuracy across three arithmetic benchmarks. these gains reach over 10 % improvements on gsm8k, over 5 % on aqua, and up to 8 % on math across most models, outperforming all competing methods. while ps + and re2 also demonstrate potential for enhancing mathematical reasoning performance, our experiments show performance degradation on certain llms, suggesting limited generalization capabilities. interestingly, the three benchmarks span increasing difficulty levels, from grade - school problems ( cobbe et al., 2021 ) to gmet /"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03223v1",
      "title": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention\n  Alignment",
      "authors": [
        "Hongxiang Zhang",
        "Yuan Tian",
        "Tianyi Zhang"
      ],
      "summary": "To solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and\nreinforcement learning. However, as reasoning chains extend, critical\nintermediate steps and the original prompt will be buried in the context,\nreceiving insufficient attention and leading to errors. In this paper, we\npropose Self-Anchor, a novel pipeline that leverages the inherent structure of\nreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories\ninto structured plans and automatically aligns the model's attention to the\nmost relevant inference steps, allowing the model to maintain focus throughout\ngeneration. Our experiment shows that Self-Anchor outperforms SOTA prompting\nmethods across six benchmarks. Notably, Self-Anchor significantly reduces the\nperformance gap between ``non-reasoning'' models and specialized reasoning\nmodels, with the potential to enable most LLMs to tackle complex reasoning\ntasks without retraining.",
      "published": "2025-10-03T17:56:33Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03223v1"
    },
    "chunk_id": 4,
    "text": "8b ( deepseek - ai, 2025 ), phi - 4reasoning ( abdin et al., 2024 ), and qwen3 - 30b - a3b - thinking - 2507 ( team, 2025 ). 3. 3 m ain r esults * * mathematical reasoning. * * arithmetic reasoning represents one of the most challenging aspects of llm reasoning capabilities. as shown in table 1, s elf - a nchor consistently improves accuracy across three arithmetic benchmarks. these gains reach over 10 % improvements on gsm8k, over 5 % on aqua, and up to 8 % on math across most models, outperforming all competing methods. while ps + and re2 also demonstrate potential for enhancing mathematical reasoning performance, our experiments show performance degradation on certain llms, suggesting limited generalization capabilities. interestingly, the three benchmarks span increasing difficulty levels, from grade - school problems ( cobbe et al., 2021 ) to gmet / gre ( ling et al., 2017 ) level and competition - level problems ( hendrycks et al., 2021 ). s elf - a nchor demonstrates performance gain in all three benchmarks, suggesting superior generalization capabilities across diverse model architectures and reasoning complexity levels. * * commonsence reasoning. * * strategyqa requires multi - hop reasoning over commonsense knowledge. as detailed in table 1, s elf - a nchor persistently improves accuracy across six evaluated llms. in contrast, ps + and re2 occasionally outperform the baseline cot method. for t4d, a grounded social agent reasoning task requires mental state reasoning to determine appropriate actions. s elf - a nchor demonstrates significant performance gains over 9 % in four llms. in comparison, both ps + and re2 exhibit mixed performance ; they tend to be more effective in larger models. these findings highlight the challenge of applying generic prompting strategies to specialized reasoning domains. 3 prompt templates and evaluation details are provided in appendix e. 4 preprint table 1 : evaluation results on six benchmarks. best results are shown in * * green * *, and those indicating a performance drop compared to standard greedy decoding are shown in grey. math commonsense * * model * * * * method * * bbh gsm8k aqua math strqa t4d * * bbh. * * bbh aggregates challenging algorithmic and symbolic tasks. s elf - a nchor demonstrates average performance gains ranging from 1. 61 % to 15. 39 % [ 4 ]. among all sub - benchmarks, we find that tasks requiring tracking of intermediate reasoning benefit the most, for example _ date under - _ _ standing _, and _ logical deduction _. we attribute this to s elf - a nchor ’ s attention steering that augments critical reasoning steps and the original question throughout generation. in contrast, ps + and re2 show inconsistent improvements. in summary, these results highlight two takeaways. first, while prompting strategies are effective in some tasks, they lack robustness across benchmarks and model architectures, tending to be more effective on larger llms and simpler reasoning tasks. this may be because larger models are more capable of following instructions and external guidance to align reasoning trajectories. second, by integrating planning, structured reasoning, and automatic anchoring, s elf - a nchor achieves consistent improvements across tasks, model sizes, and architectures, demonstrating both robustness and effectiveness. 3. 4 c an s elf - a nchor r ival rl - enhanced t hinking m odel? recent advances in reasoning capabilities have been dominated by reinforcement learning - enhanced “ thinking ” models that employ extensive internal reasoning chains during inference. however, these models are costly to fine - tune and require large - scale training data. this raises a question : _ can non - _ _ reasoning llms combined with _ s elf - a nchor _ achieve competitive performance against reasoning _ _ models? _ to investigate this question, we compare our method applied to non - reasoning llms against corresponding thinking models. since thinking models typically require longer generated contexts to support their internal reasoning, we set 1. 5x larger maximum token length than the nonreasoning models in our experiments. table 2 presents our findings across mathematical reasoning, commonsense reasoning, and symbolic reasoning tasks. remarkably, our method applied to non - thinking models achieves competitive or superior performance compared to rl - enhanced thinking models. specifically, our approach closes the performance gap significantly with three arithmetic benchmarks in varying difficulties, achieving 4 we detail the subtask performance in appendix g 5 preprint table 2 : evaluation comparison with thinking models math commonsense * * model * * * * method * * bbh gsm8k aqua math strqa t4d cot 75. 36 61. 81 51. 00 67. 03 39. 54 60. 51 phi - 4 - mini - 4b s elf - a nchor 88. 02 68. 50 59."
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03223v1",
      "title": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention\n  Alignment",
      "authors": [
        "Hongxiang Zhang",
        "Yuan Tian",
        "Tianyi Zhang"
      ],
      "summary": "To solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and\nreinforcement learning. However, as reasoning chains extend, critical\nintermediate steps and the original prompt will be buried in the context,\nreceiving insufficient attention and leading to errors. In this paper, we\npropose Self-Anchor, a novel pipeline that leverages the inherent structure of\nreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories\ninto structured plans and automatically aligns the model's attention to the\nmost relevant inference steps, allowing the model to maintain focus throughout\ngeneration. Our experiment shows that Self-Anchor outperforms SOTA prompting\nmethods across six benchmarks. Notably, Self-Anchor significantly reduces the\nperformance gap between ``non-reasoning'' models and specialized reasoning\nmodels, with the potential to enable most LLMs to tackle complex reasoning\ntasks without retraining.",
      "published": "2025-10-03T17:56:33Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03223v1"
    },
    "chunk_id": 5,
    "text": ", we compare our method applied to non - reasoning llms against corresponding thinking models. since thinking models typically require longer generated contexts to support their internal reasoning, we set 1. 5x larger maximum token length than the nonreasoning models in our experiments. table 2 presents our findings across mathematical reasoning, commonsense reasoning, and symbolic reasoning tasks. remarkably, our method applied to non - thinking models achieves competitive or superior performance compared to rl - enhanced thinking models. specifically, our approach closes the performance gap significantly with three arithmetic benchmarks in varying difficulties, achieving 4 we detail the subtask performance in appendix g 5 preprint table 2 : evaluation comparison with thinking models math commonsense * * model * * * * method * * bbh gsm8k aqua math strqa t4d cot 75. 36 61. 81 51. 00 67. 03 39. 54 60. 51 phi - 4 - mini - 4b s elf - a nchor 88. 02 68. 50 59. 00 68. 69 49. 47 62. 42 reasoning 81. 27 60. 62 75. 00 66. 38 45. 04 59. 85 cot 86. 66 73. 62 82. 00 68. 03 70. 21 73. 33 qwen3 - 4b s elf - a nchor 87. 26 79. 92 86. 50 70. 13 71. 56 75. 31 reasoning 83. 24 67. 32 87. 00 68. 31 73. 40 75. 34 cot 61. 85 50. 79 44. 50 70. 24 26. 77 49. 45 llama3. 1 - 8b s elf - a nchor 76. 72 55. 51 52. 50 73. 54 40. 01 58. 53 reasoning 73. 62 62. 99 72. 50 65. 41 48. 58 64. 98 cot 73. 16 68. 11 74. 50 77. 51 73. 94 72. 08 phi - 4 - 15b s elf - a nchor 82. 41 79. 13 81. 00 77. 82 85. 99 75. 31 reasoning 81. 12 83. 20 95. 5 75. 43 74. 11 74. 98 cot 84. 46 81. 10 78. 00 78. 60 84. 92 67. 69 qwen3 - 30b s elf - a nchor 87. 41 83. 46 87. 00 79. 65 85. 56 69. 30 reasoning 94. 5 80. 31 85. 00 77. 26 80. 96 76. 54 within 5 % difference of most thinking models ; on commonsense reasoning tasks and bbh, s elf a nchor exceeds thinking model performance on most benchmarks and llms. noteably, we observe that thinking models demonstrate superior performance on tasks where corresponding non - reasoning models show poor baseline performance. for example, llama3. 1 and phi - 4 - mini show large gaps on math, and llama3. 1 underperforms on aqua and bbh. in these settings, post - training with reinforcement learning significantly boosts performance in areas where models previously performed poorly. in contrast, for tasks where non - reasoning models already demonstrate strong performance, reinforcement learning provides limited improvement. this pattern is also observed in kirk et al. ( 2023 ). nevertheless, s elf - a nchor shows consistent performance improvements across all tasks and difficulty levels. in summary, rather than learning implicit reasoning patterns through training, our approach leverages the inherent structure in the reasoning chain for attention alignment to improve the reasoning capabilities, yielding stable improvement across varying difficulty levels without additional training cost. these findings suggest that s elf - a nchor can serve as an effective alternative to computationally expensive rl - enhanced reasoning. 3. 5 w hich t ypes of t asks d o s elf - a nchor h elp the m ost? to understand which types of tasks s elf - a nchor help the most, we analyze performance gains across task complexity. we adapt the method for quantifying task complexity from wu et al. ( 2025 ) ; jin et al. ( 2024 ), where each task is represented by an individual question in a benchmark. for each benchmark, 200 questions are randomly sampled to compute the average accuracy per task across all experimented models. task complexity is then defined as 1 _ − _ accuracy [ 5 ], where lower accuracy indicates higher complexity. * * reasoning task complexity. * * first, we examine the relationship between task complexity and s elf - a nchor ’ s performance gains to understand how our method scales with task difficulty. we compare s elf - a nchor ’ s performance gains against re2, a strong baseline identified in our main results ( subsection 3. 3 ). for each task, we compute performance gain as the difference in accuracy between the two methods. as shown in figure 2a, the box plot summarizes the distribution of performance gains for tasks across complexity ranges. while tasks"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03223v1",
      "title": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention\n  Alignment",
      "authors": [
        "Hongxiang Zhang",
        "Yuan Tian",
        "Tianyi Zhang"
      ],
      "summary": "To solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and\nreinforcement learning. However, as reasoning chains extend, critical\nintermediate steps and the original prompt will be buried in the context,\nreceiving insufficient attention and leading to errors. In this paper, we\npropose Self-Anchor, a novel pipeline that leverages the inherent structure of\nreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories\ninto structured plans and automatically aligns the model's attention to the\nmost relevant inference steps, allowing the model to maintain focus throughout\ngeneration. Our experiment shows that Self-Anchor outperforms SOTA prompting\nmethods across six benchmarks. Notably, Self-Anchor significantly reduces the\nperformance gap between ``non-reasoning'' models and specialized reasoning\nmodels, with the potential to enable most LLMs to tackle complex reasoning\ntasks without retraining.",
      "published": "2025-10-03T17:56:33Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03223v1"
    },
    "chunk_id": 6,
    "text": "task complexity. we adapt the method for quantifying task complexity from wu et al. ( 2025 ) ; jin et al. ( 2024 ), where each task is represented by an individual question in a benchmark. for each benchmark, 200 questions are randomly sampled to compute the average accuracy per task across all experimented models. task complexity is then defined as 1 _ − _ accuracy [ 5 ], where lower accuracy indicates higher complexity. * * reasoning task complexity. * * first, we examine the relationship between task complexity and s elf - a nchor ’ s performance gains to understand how our method scales with task difficulty. we compare s elf - a nchor ’ s performance gains against re2, a strong baseline identified in our main results ( subsection 3. 3 ). for each task, we compute performance gain as the difference in accuracy between the two methods. as shown in figure 2a, the box plot summarizes the distribution of performance gains for tasks across complexity ranges. while tasks in the 0. 67 – 0. 83 complexity range show a few negative cases, the average improvement remains positive across all task complexities. overall, s elf - a nchor presents performance gains spanning all complexity levels, achieving approximately 7 % perfor 5 segmenting reasoning steps and task complexity details are provided in appendix e. 6 preprint | 60 < br > 40 < br > 20 < br > 0 < br > 20 < br > 40 < br > 60 < br > ( 0. 17 - 0. 33 ) ( 0. 33 - 0. 50 ) ( 0. 5 < br > task comp | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | ( 0. 17 ~ ~ - ~ ~ 0. 33 ) < br > ( 0. 33 ~ ~ - ~ ~ 0. 50 ) < br > ( 0. 5 < br > task comp < br > 60 < br > 40 < br > 20 < br > 0 < br > 20 < br > 40 < br > 60 < br > | | | | | | | | | | ( 0. 17 ~ ~ - ~ ~ 0. 33 ) < br > ( 0. 33 ~ ~ - ~ ~ 0. 50 ) < br > ( 0. 5 < br > task comp < br > 60 < br > 40 < br > 20 < br > 0 < br > 20 < br > 40 < br > 60 < br > | | | | | | | | | | ( 0. 17 ~ ~ - ~ ~ 0. 33 ) < br > ( 0. 33 ~ ~ - ~ ~ 0. 50 ) < br > ( 0. 5 < br > task comp < br > 60 < br > 40 < br > 20 < br > 0 < br > 20 < br > 40 < br > 60 < br > | | | | | | | | | | ( 0. 17 ~ ~ - ~ ~ 0. 33 ) < br > ( 0. 33 ~ ~ - ~ ~ 0. 50 ) < br > ( 0. 5 < br > task comp < br > 60 < br > 40 < br > 20 < br > 0 < br > 20 < br > 40 < br > 60 < br > | | | | | | | | | | ( 0. 17 ~ ~ - ~ ~ 0. 33 ) < br > ( 0. 33 ~ ~ - ~ ~ 0. 50 ) < br > ( 0. 5 < br > task comp < br > 60 < br > 40 < br > 20 < br > 0 < br > 20 < br > 40 < br > 60 < br > | | | | | | | | | | ( 0. 17 ~ ~ - ~ ~ 0. 33 ) < br > ( 0. 33 ~ ~ - ~ ~ 0. 50 ) < br > ( 0. 5 < br > task comp < br > 60 < br > 40 < br > 20 < br > 0 < br > 20 < br > 40 < br > 60 < br > | | | | | | | | | | ( 0. 17 ~ ~ - ~ ~ 0. 33 ) < br > ( 0. 33 ~ ~ - ~ ~ 0. 50 ) < br > ( 0. 5 < br > task comp < br > 60 < br > 40 < br > 20 < br > 0 < br > 20 < br > 40 < br > 60 < br > | | | | ~ ~ - ~ ~ 0. 67 ) < br > ( 0. 67 ~ ~ - ~ ~ 0. 83 ) < br > ( 0. 83 ~ ~ - ~ ~ 1. 00 ) < br > exity range"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03223v1",
      "title": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention\n  Alignment",
      "authors": [
        "Hongxiang Zhang",
        "Yuan Tian",
        "Tianyi Zhang"
      ],
      "summary": "To solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and\nreinforcement learning. However, as reasoning chains extend, critical\nintermediate steps and the original prompt will be buried in the context,\nreceiving insufficient attention and leading to errors. In this paper, we\npropose Self-Anchor, a novel pipeline that leverages the inherent structure of\nreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories\ninto structured plans and automatically aligns the model's attention to the\nmost relevant inference steps, allowing the model to maintain focus throughout\ngeneration. Our experiment shows that Self-Anchor outperforms SOTA prompting\nmethods across six benchmarks. Notably, Self-Anchor significantly reduces the\nperformance gap between ``non-reasoning'' models and specialized reasoning\nmodels, with the potential to enable most LLMs to tackle complex reasoning\ntasks without retraining.",
      "published": "2025-10-03T17:56:33Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03223v1"
    },
    "chunk_id": 7,
    "text": "~ - ~ ~ 0. 33 ) < br > ( 0. 33 ~ ~ - ~ ~ 0. 50 ) < br > ( 0. 5 < br > task comp < br > 60 < br > 40 < br > 20 < br > 0 < br > 20 < br > 40 < br > 60 < br > | | | | | | | | | | ( 0. 17 ~ ~ - ~ ~ 0. 33 ) < br > ( 0. 33 ~ ~ - ~ ~ 0. 50 ) < br > ( 0. 5 < br > task comp < br > 60 < br > 40 < br > 20 < br > 0 < br > 20 < br > 40 < br > 60 < br > | | | | ~ ~ - ~ ~ 0. 67 ) < br > ( 0. 67 ~ ~ - ~ ~ 0. 83 ) < br > ( 0. 83 ~ ~ - ~ ~ 1. 00 ) < br > exity range | ~ ~ - ~ ~ 0. 67 ) < br > ( 0. 67 ~ ~ - ~ ~ 0. 83 ) < br > ( 0. 83 ~ ~ - ~ ~ 1. 00 ) < br > exity range | ~ ~ - ~ ~ 0. 67 ) < br > ( 0. 67 ~ ~ - ~ ~ 0. 83 ) < br > ( 0. 83 ~ ~ - ~ ~ 1. 00 ) < br > exity range | ~ ~ - ~ ~ 0. 67 ) < br > ( 0. 67 ~ ~ - ~ ~ 0. 83 ) < br > ( 0. 83 ~ ~ - ~ ~ 1. 00 ) < br > exity range | ~ ~ - ~ ~ 0. 67 ) < br > ( 0. 67 ~ ~ - ~ ~ 0. 83 ) < br > ( 0. 83 ~ ~ - ~ ~ 1. 00 ) < br > exity range | ( a ) reasoning tasks complexity and performance gains comparison | 30 < br > 25 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | col10 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | 25 < br > 30 < br > | | | | | | | | | | | ( 0. 00 ~ ~ - ~ ~ 0. 13 ) < br > ( 0. 13 ~ ~ - ~ ~ 0. 27 ) < br > ( 0. 40 ~ ~ - ~ ~ 0. 53 ) < br > ( 0. 53 ~ ~ - ~ ~ 0. 67 ) < br > ( 0. 67 ~ ~ - ~ ~ 0. 80 ) < br > task complexity range < br > 5 < br > 10 < br > 15 < br > 20 < br > < br > | | | | | | | | | | | ( 0. 00 ~ ~ - ~ ~ 0. 13 ) < br > ( 0. 13 ~ ~ - ~ ~ 0. 27 ) < br > ( 0. 40 ~ ~ - ~ ~ 0. 53 ) < br > ( 0. 53 ~ ~ - ~ ~ 0. 67 ) < br > ( 0. 67 ~ ~ - ~ ~ 0. 80 ) < br > task complexity range < br > 5 < br > 10 < br > 15 < br > 20 < br > < br > | | | | | | | | | | | ( 0. 00 ~ ~ - ~ ~ 0. 13 ) < br > ( 0. 13 ~ ~ - ~ ~ 0. 27 ) < br > ( 0. 40 ~ ~ - ~ ~ 0. 53 ) < br > ( 0. 53 ~ ~ - ~ ~ 0. 67 ) < br > ( 0. 67 ~ ~ - ~ ~ 0. 80 ) < br > task complexity range < br > 5 < br > 10 < br > 15 < br > 20 < br > < br > | | | | | | | | | | | ( 0. 00 ~ ~ - ~ ~ 0. 13 ) < br > ( 0. 13 ~ ~ - ~ ~ 0. 27 ) < br > ( 0. 40 ~ ~ - ~ ~ 0. 53 ) < br > ( 0. 53 ~ ~ - ~ ~ 0. 67 ) < br > ( 0. 67 ~ ~ - ~ ~ 0. 80 ) < br > task complexity range < br > 5 < br > 10 < br > 15 < br > 20 < br > < br > | | | | | | | | | | ( b ) reasoning tasks complexity and reasoning chain length comparison. the lower value represents the easier task. figure 2 : analysis of task complexity and reasoning chain length mance improvement. these results demonstrate that"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03223v1",
      "title": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention\n  Alignment",
      "authors": [
        "Hongxiang Zhang",
        "Yuan Tian",
        "Tianyi Zhang"
      ],
      "summary": "To solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and\nreinforcement learning. However, as reasoning chains extend, critical\nintermediate steps and the original prompt will be buried in the context,\nreceiving insufficient attention and leading to errors. In this paper, we\npropose Self-Anchor, a novel pipeline that leverages the inherent structure of\nreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories\ninto structured plans and automatically aligns the model's attention to the\nmost relevant inference steps, allowing the model to maintain focus throughout\ngeneration. Our experiment shows that Self-Anchor outperforms SOTA prompting\nmethods across six benchmarks. Notably, Self-Anchor significantly reduces the\nperformance gap between ``non-reasoning'' models and specialized reasoning\nmodels, with the potential to enable most LLMs to tackle complex reasoning\ntasks without retraining.",
      "published": "2025-10-03T17:56:33Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03223v1"
    },
    "chunk_id": 8,
    "text": "- ~ ~ 0. 80 ) < br > task complexity range < br > 5 < br > 10 < br > 15 < br > 20 < br > < br > | | | | | | | | | | | ( 0. 00 ~ ~ - ~ ~ 0. 13 ) < br > ( 0. 13 ~ ~ - ~ ~ 0. 27 ) < br > ( 0. 40 ~ ~ - ~ ~ 0. 53 ) < br > ( 0. 53 ~ ~ - ~ ~ 0. 67 ) < br > ( 0. 67 ~ ~ - ~ ~ 0. 80 ) < br > task complexity range < br > 5 < br > 10 < br > 15 < br > 20 < br > < br > | | | | | | | | | | ( b ) reasoning tasks complexity and reasoning chain length comparison. the lower value represents the easier task. figure 2 : analysis of task complexity and reasoning chain length mance improvement. these results demonstrate that s elf - a nchor achieves consistent gains and generalizes effectively across varying task complexities. * * reasoning chain length vs. task complexity. * * next, we analyze how reasoning chain length scales with task difficulty. figure 2b shows the distribution of successful reasoning chain lengths across tasks of varying difficulty on llama3. 2 - 3b. the results show a clear trend that as complexity increases, s elf - a nchor tends to generate longer reasoning chains. this aligns with the observation in wu et al. ( 2025 ) that harder problems require longer reasoning chains to solve. we attribute this capability to the attention steering mechanism, which enables the model to focus on both problem context and immediate reasoning object throughout the reasoning, preventing attention drift as the reasoning chain extends. in summary, our analysis highlights two takeaways : ( 1 ) s elf - a nchor demonstrates consistent improvements across all complexity levels, confirming its ability to generalize beyond narrow task categories. ( 2 ) s elf - a nchor encourage the model to generate longer reasoning chains for difficult problems, supporting its effectiveness in scaling to complex tasks. 3. 6 e fficiency table 3 : efficiency comparison token / second * * model * * s elf - a nchor cot ps + re2 llama3. 2 - 3b 9. 97 10. 87 10. 84 12. 01 phi - 4 - mini - 4b 11. 02 12. 25 12. 24 12. 21 qwen3 - 4b 5. 41 6. 22 6. 22 6. 23 llama3. 1 - 8b 7. 54 8. 38 8. 26 8. 19 phi - 4 - 15b 7. 92 9. 00 8. 94 8. 88 qwen3 - 30b 1. 07 1. 39 1. 39 1. 37 s elf - a nchor achieved superior performance compared to state - of - the - art methods ; we are committed to evaluating its efficiency. table 3 reports inference throughput ( tokens / sec ) for s elf a nchor compared to baseline methods. on average, s elf - a nchor introduces minimal computational overhead, with throughput reductions typically below 1 – 2 tokens / sec relative to baselines. the results highlight a favorable trade - off ; s elf - a nchor consistently improves reasoning while maintaining comparable runtime cost. importantly, the cost - performance balance remains stable across both smaller ( 3b – 4b ) and larger ( 15b – 30b ) models, suggesting scalability without prohibitive latency. 7 preprint table 4 : performance comparing s elf - a nchor with and without attention steering math commonsense * * model * * * * method * * bbh gsm8k aqua math strqa t4d s elf - a nchor ( w / o attention steering ) 73. 01 53. 15 40. 90 71. 17 35. 28 52. 77 llama3. 1 - 8b s elf - a nchor 76. 72 55. 51 52. 50 73. 54 40. 01 58. 53 phi - 4 - mini - 4b s elf - a nchor ( w / o attention steering ) 78. 77 58. 66 55. 50 68. 60 38. 83 57. 44 s elf - a nchor 88. 02 68. 50 59. 00 68. 69 49. 47 62. 42 table 5 : an example of bbh. incorrect inferences are highlighted in red. correct ones are highlighted in * * green * *. _ * * sentence : the secretary came to the analyst ’ s office and helped her to book a flight. * * _ * * prompt * * _ * * options : ( a ) helped the secretary book a flight ( b ) helped the analyst book a flight ( c ) ambiguous * * _ * * s * * * * elf * * * * - a * * * * nchor *"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03223v1",
      "title": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention\n  Alignment",
      "authors": [
        "Hongxiang Zhang",
        "Yuan Tian",
        "Tianyi Zhang"
      ],
      "summary": "To solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and\nreinforcement learning. However, as reasoning chains extend, critical\nintermediate steps and the original prompt will be buried in the context,\nreceiving insufficient attention and leading to errors. In this paper, we\npropose Self-Anchor, a novel pipeline that leverages the inherent structure of\nreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories\ninto structured plans and automatically aligns the model's attention to the\nmost relevant inference steps, allowing the model to maintain focus throughout\ngeneration. Our experiment shows that Self-Anchor outperforms SOTA prompting\nmethods across six benchmarks. Notably, Self-Anchor significantly reduces the\nperformance gap between ``non-reasoning'' models and specialized reasoning\nmodels, with the potential to enable most LLMs to tackle complex reasoning\ntasks without retraining.",
      "published": "2025-10-03T17:56:33Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03223v1"
    },
    "chunk_id": 9,
    "text": "##b s elf - a nchor 76. 72 55. 51 52. 50 73. 54 40. 01 58. 53 phi - 4 - mini - 4b s elf - a nchor ( w / o attention steering ) 78. 77 58. 66 55. 50 68. 60 38. 83 57. 44 s elf - a nchor 88. 02 68. 50 59. 00 68. 69 49. 47 62. 42 table 5 : an example of bbh. incorrect inferences are highlighted in red. correct ones are highlighted in * * green * *. _ * * sentence : the secretary came to the analyst ’ s office and helped her to book a flight. * * _ * * prompt * * _ * * options : ( a ) helped the secretary book a flight ( b ) helped the analyst book a flight ( c ) ambiguous * * _ * * s * * * * elf * * * * - a * * * * nchor * * _ { _ ” step 1 : identify the pronoun ” : ” the pronoun is ’ her ’. ”, ( w / o attention steering ) ” step 2 : determine the antecedent of the pronoun ” : ” the antecedent of ’ her ’ is the subject of the sentence, which is ’ the secretary ’ ”, ” step 3 : analyze the sentence structure ” : the subject of the sentence is ’ the secretary ’, and the verb is ’ came ’. the object of the verb ’ came ’ is ’ to the analyst ’ s office ’. the verb ’ helped ’ has the pronoun ’ her ’ as its object. ”, ” step 4 : determine the antecedent of the pronoun based on the sentence structure ” : ” based on the sentence structure, the antecedent of the pronoun ’ her ’ is the subject of the sentence, which is ’ the secretary ’. ”, ” step 5 : choose the correct option ” : ” the correct option is ( a ) helped the secretary book a flight. ” _ } _ * * s * * * * elf * * * * - a * * * * nchor * * _ { _ ” step 1 : identify the pronoun ” : ” the pronoun in the sentence is ’ her ’. ”, ” step 2 : determine the antecedent of the pronoun ” : ” to find the antecedent, we need to look for the noun that ’ her ’ refers to. in this case, * * ’ her ’ is a possessive pronoun that refers to the analyst. * * ”, ” step 3 : analyze the sentence structure ” : ” the subject of the sentence is ’ the secretary ’, and the object of the verb ’ helped ’ is ’ her ’ ”, ” step 4 : identify the antecedent based on the sentence structure ” : ” ” step 5 : choose the correct option ” : ” since ’ her ’ refers to the analyst, the correct option is * * ’ her ’ refers to the analyst, not the secretary. ( b ) helped the analyst book a flight. * * ”, ” _ } _ in summary, s elf - a nchor achieves strong effectiveness and efficiency, offering improved reasoning performance with only minor latency overhead compared to state - of - the - art baselines. 3. 7 a blation study : t he effectiveness of attention steering to isolate the contribution of attention steering, we conducted an ablation study comparing s elf a nchor with and without attention steering on two representative llms across all six benchmarks. as illustrated in table 4, s elf - a nchor consistently outperformed its variant without attention steering, across all benchmarks, demonstrating the effectiveness of attention steering. table 5 further illustrates a representative example where attention steering prevents reasoning errors. in steps 2 and 4, the s elf - a nchor without attention steering approach incorrectly identifies “ her ” as referring to “ the secretary ” ; this may be because models over - focus on sentence subjects rather than maintaining focus on the syntactic relationships that determine pronoun reference. in contrast, s elf - a nchor correctly identifies that “ her ” refers to “ the analyst ” by maintaining attention on both the original question context and the current reasoning step [ 6 ]. this ablation confirms that, while structured reasoning provides a foundation for improved performance, it is often insufficient to prevent attention drift on its own. the attention anchoring component is crucial to ensure the model maintains focus throughout the reasoning process, leading to more robust and accurate results. 3. 8 f ailure c ase a nalysis to understand the failure modes in s elf - a nchor. we conducted a manual failure case analysis on 200 randomly sampled cases from _ casual _ ~ ~ _ j _ ~ ~ _ udgement _ and _ aqua _. our analysis identified three primary failure modes : * * reasoning errors ( 42 % ). * * the most frequent failure mode involves llm making mistakes during the reasoning. these include the misapplication of causal principles,"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03223v1",
      "title": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention\n  Alignment",
      "authors": [
        "Hongxiang Zhang",
        "Yuan Tian",
        "Tianyi Zhang"
      ],
      "summary": "To solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and\nreinforcement learning. However, as reasoning chains extend, critical\nintermediate steps and the original prompt will be buried in the context,\nreceiving insufficient attention and leading to errors. In this paper, we\npropose Self-Anchor, a novel pipeline that leverages the inherent structure of\nreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories\ninto structured plans and automatically aligns the model's attention to the\nmost relevant inference steps, allowing the model to maintain focus throughout\ngeneration. Our experiment shows that Self-Anchor outperforms SOTA prompting\nmethods across six benchmarks. Notably, Self-Anchor significantly reduces the\nperformance gap between ``non-reasoning'' models and specialized reasoning\nmodels, with the potential to enable most LLMs to tackle complex reasoning\ntasks without retraining.",
      "published": "2025-10-03T17:56:33Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03223v1"
    },
    "chunk_id": 10,
    "text": "that determine pronoun reference. in contrast, s elf - a nchor correctly identifies that “ her ” refers to “ the analyst ” by maintaining attention on both the original question context and the current reasoning step [ 6 ]. this ablation confirms that, while structured reasoning provides a foundation for improved performance, it is often insufficient to prevent attention drift on its own. the attention anchoring component is crucial to ensure the model maintains focus throughout the reasoning process, leading to more robust and accurate results. 3. 8 f ailure c ase a nalysis to understand the failure modes in s elf - a nchor. we conducted a manual failure case analysis on 200 randomly sampled cases from _ casual _ ~ ~ _ j _ ~ ~ _ udgement _ and _ aqua _. our analysis identified three primary failure modes : * * reasoning errors ( 42 % ). * * the most frequent failure mode involves llm making mistakes during the reasoning. these include the misapplication of causal principles, flawed deductions, and incorrect conditional reasoning. for example, in one _ casual _ ~ ~ _ j _ ~ ~ _ udgement _ instance, the model incorrectly treated a necessary but insufficient condition as the sole causal factor, leading to an invalid conclu 6 we provide additional case studies in appendix f for further illustration. 8 preprint sion. such errors suggest that, while attention anchoring helps maintain focus on relevant steps, it cannot fully compensate for weak logical priors or gaps in world knowledge. * * misunderstanding the problem ( 36. 5 % ). * * a substantial portion of failures stems from incomprehension of complex questions, leading to errors such as misidentifying all variables, misinterpreting the problem ’ s requirements, or incorrectly parsing the relationships between entities. for instance, in multi - variable problems, the model sometimes assigns numerical values to the wrong entity. * * computational errors ( 21. 5 % ). * * the remaining failures involve arithmetic mistakes, unit conversion errors, or algebraic slips. even when the reasoning chain is correct, a single miscalculation often propagates to the final answer. taken together, these findings suggest that s elf - a nchor primarily mitigates _ attention misalign - _ _ ment _, but does not fully resolve deeper issues of logical validity, semantic understanding, or computational precision. 4 r elated work * * prompt engineering for reasoning. * * prompt engineering has been widely adopted as a fundamental approach for enhancing llm reasoning capabilities ( liu et al., 2023 ; brown et al., 2020 ). a foundational line of work, initiated by chain - of - thought ( cot ) prompting ( wei et al., 2022 ), encourages explicit intermediate steps, which significantly improve performance on multi - step reasoning tasks. this has inspired numerous derivatives, including problem decomposition methods ( wang et al., 2023 ; zhou et al., 2022 ; khot et al., 2022 ; drozdov et al., 2022 ), as well as techniques focused on enhancing query comprehension ( xu et al., 2024 ; zheng et al., 2023 ; mekala et al., 2023 ; deng et al., 2023 ; mishra & nouri, 2022 ). while these prompting methods demonstrate effectiveness in specific domains, they rely on predetermined, static prompt formats for different tasks. on the other hand, llms remain sensitive to prompt variations and suffer from attention dilution during long generations ( liu et al., 2024 ; li et al., 2024 ; hong et al., 2025 ; lu et al., 2021 ; gu et al., 2024 ). s elf - a nchor addresses these limitations by integrating structured reasoning with dynamic attention steering. it goes beyond static prompting by enabling the model to recalibrate its focus on the most salient context at each step of the reasoning trajectory. * * attention steering. * * in contrast to the aforementioned prompt engineering, which devises better prompt strategies, attention steering methods directly guide llms during inference to emphasize the user - specified part of context. specifically, selective prompt anchoring ( spa ) ( tian & zhang, 2024 ) adjusts the logit probability distribution to emphasize the specified context. pasta ( zhang et al., 2023 ) identifies and reweights a subset of attention heads to redirect the model ’ s attention to user - specified parts. selective self - attention ( ssa ) ( zhang et al., 2024 ) augments the softmax nonlinearity with a principled temperature scaling strategy. toast ( shi et al., 2023 ) learns feature selection modules that guide attention toward task - relevant information. however, these methods require manual specification of anchor content, limiting their adaptability to diverse reasoning contexts. real - world applications demand automatic identification of relevant context elements across varying task requirement and reasoning patterns. s elf"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03223v1",
      "title": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention\n  Alignment",
      "authors": [
        "Hongxiang Zhang",
        "Yuan Tian",
        "Tianyi Zhang"
      ],
      "summary": "To solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and\nreinforcement learning. However, as reasoning chains extend, critical\nintermediate steps and the original prompt will be buried in the context,\nreceiving insufficient attention and leading to errors. In this paper, we\npropose Self-Anchor, a novel pipeline that leverages the inherent structure of\nreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories\ninto structured plans and automatically aligns the model's attention to the\nmost relevant inference steps, allowing the model to maintain focus throughout\ngeneration. Our experiment shows that Self-Anchor outperforms SOTA prompting\nmethods across six benchmarks. Notably, Self-Anchor significantly reduces the\nperformance gap between ``non-reasoning'' models and specialized reasoning\nmodels, with the potential to enable most LLMs to tackle complex reasoning\ntasks without retraining.",
      "published": "2025-10-03T17:56:33Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03223v1"
    },
    "chunk_id": 11,
    "text": "* * attention steering. * * in contrast to the aforementioned prompt engineering, which devises better prompt strategies, attention steering methods directly guide llms during inference to emphasize the user - specified part of context. specifically, selective prompt anchoring ( spa ) ( tian & zhang, 2024 ) adjusts the logit probability distribution to emphasize the specified context. pasta ( zhang et al., 2023 ) identifies and reweights a subset of attention heads to redirect the model ’ s attention to user - specified parts. selective self - attention ( ssa ) ( zhang et al., 2024 ) augments the softmax nonlinearity with a principled temperature scaling strategy. toast ( shi et al., 2023 ) learns feature selection modules that guide attention toward task - relevant information. however, these methods require manual specification of anchor content, limiting their adaptability to diverse reasoning contexts. real - world applications demand automatic identification of relevant context elements across varying task requirement and reasoning patterns. s elf - a nchor addresses this limitation by leveraging structured intermediate representations to enable context - aware anchor selection without human intervention. 5 c onclusion we presented s elf - a nchor, a lightweight pipeline that leverages the inherent structure of reasoning for attention alignment. across six diverse reasoning benchmarks, s elf - a nchor consistently outperforms existing baselines. notably, s elf - a nchor enhanced “ non - reasoning ” models achieve competitive performance with specialized reasoning models while maintaining significantly lower cost. moreover, our analysis reveals that s elf - a nchor ’ s advantages are generalizable to varying task complexities. we hope s elf - a nchor serves as a step toward more reliable llms reasoning that requires neither parameter updates nor additional sampling. 9 preprint 6 r eproducibility statement we have made extensive efforts to ensure the reproducibility of our work. additional implementation details, hyperparameters, and ablation studies are provided in the appendix. we also include complete descriptions of benchmark datasets, sampling procedures, and task complexity measures. lastly, to foster reproducibility and further research, source code will be made publicly available upon acceptance of this paper. 7 e thics statement this paper does not involve any ethical concerns. the proposed methods focus on improving reasoning ability and robustness in llms and do not raise issues related to the code of ethics. r eferences marah abdin, jyoti aneja, harkirat behl, [UNK] bubeck, ronen eldan, suriya gunasekar, michael harrison, russell j hewett, mojan javaheripi, piero kauffmann, et al. phi - 4 technical report. _ arxiv preprint arxiv : 2412. 08905 _, 2024. abdelrahman abouelenin, atabak ashfaq, adam atkinson, hany awadalla, nguyen bach, jianmin bao, alon benhaim, martin cai, vishrav chaudhary, congcong chen, et al. phi - 4 - mini technical report : compact yet powerful multimodal language models via mixture - of - loras. _ arxiv preprint _ _ arxiv : 2503. 01743 _, 2025. janice ahn, rishu verma, renze lou, di liu, rui zhang, and wenpeng yin. large language models for mathematical reasoning : progresses and challenges. in neele falk, sara papi, and mike zhang ( eds. ), _ proceedings of the 18th conference of the european chapter of the association _ _ for computational linguistics : student research workshop _, pp. 225 – 237, st. julian ’ s, malta, march 2024. association for computational linguistics. doi : 10. 18653 / v1 / 2024. eacl - srw. 17. [ url https : / / aclanthology. org / 2024. eacl - srw. 17 /. ] ( https : / / aclanthology. org / 2024. eacl - srw. 17 / ) tom brown, benjamin mann, nick ryder, melanie subbiah, jared d kaplan, prafulla dhariwal, arvind neelakantan, pranav shyam, girish sastry, amanda askell, et al. language models are few - shot learners. _ advances in neural information processing systems _, 33 : 1877 – 1901, 2020. fengxiang cheng, haoxuan li, fenrong liu, robert van rooij, kun zhang, and zhouchen lin. empowering llms with logical reasoning : a comprehensive survey. _ arxiv preprint arxiv : 2502. 15652 _, 2025. ta - chung chi, ting - han fan, and alexander i rudnicky. attention alignment and flexible positional embeddings improve transformer length extrapolation. _ arxiv preprint"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03223v1",
      "title": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention\n  Alignment",
      "authors": [
        "Hongxiang Zhang",
        "Yuan Tian",
        "Tianyi Zhang"
      ],
      "summary": "To solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and\nreinforcement learning. However, as reasoning chains extend, critical\nintermediate steps and the original prompt will be buried in the context,\nreceiving insufficient attention and leading to errors. In this paper, we\npropose Self-Anchor, a novel pipeline that leverages the inherent structure of\nreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories\ninto structured plans and automatically aligns the model's attention to the\nmost relevant inference steps, allowing the model to maintain focus throughout\ngeneration. Our experiment shows that Self-Anchor outperforms SOTA prompting\nmethods across six benchmarks. Notably, Self-Anchor significantly reduces the\nperformance gap between ``non-reasoning'' models and specialized reasoning\nmodels, with the potential to enable most LLMs to tackle complex reasoning\ntasks without retraining.",
      "published": "2025-10-03T17:56:33Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03223v1"
    },
    "chunk_id": 12,
    "text": "- srw. 17 /. ] ( https : / / aclanthology. org / 2024. eacl - srw. 17 / ) tom brown, benjamin mann, nick ryder, melanie subbiah, jared d kaplan, prafulla dhariwal, arvind neelakantan, pranav shyam, girish sastry, amanda askell, et al. language models are few - shot learners. _ advances in neural information processing systems _, 33 : 1877 – 1901, 2020. fengxiang cheng, haoxuan li, fenrong liu, robert van rooij, kun zhang, and zhouchen lin. empowering llms with logical reasoning : a comprehensive survey. _ arxiv preprint arxiv : 2502. 15652 _, 2025. ta - chung chi, ting - han fan, and alexander i rudnicky. attention alignment and flexible positional embeddings improve transformer length extrapolation. _ arxiv preprint arxiv : 2311. 00684 _, 2023. yung - sung chuang, yujia xie, hongyin luo, yoon kim, james r. glass, and pengcheng he. dola : decoding by contrasting layers improves factuality in large language models. in _ the twelfth _ _ international conference on learning representations _ [, 2024. url https : / / openreview. ] ( https : / / openreview. net / forum? id = th6nyl07na ) [ net / forum? id = th6nyl07na. ] ( https : / / openreview. net / forum? id = th6nyl07na ) karl cobbe, vineet kosaraju, mohammad bavarian, mark chen, heewoo jun, lukasz kaiser, matthias plappert, jerry tworek, jacob hilton, reiichiro nakano, et al. training verifiers to solve math word problems. _ arxiv preprint arxiv : 2110. 14168 _, 2021. deepseek - ai. deepseek - r1 : incentivizing reasoning capability in llms via reinforcement learning, [ 2025. url https : / / arxiv. org / abs / 2501. 12948. ] ( https : / / arxiv. org / abs / 2501. 12948 ) yihe deng, weitong zhang, zixiang chen, and quanquan gu. rephrase and respond : let large language models ask better questions for themselves. _ arxiv preprint arxiv : 2311. 04205 _, 2023. andrew drozdov, nathanael [UNK], ekin [UNK], nathan scales, xinying song, xinyun chen, olivier bousquet, and denny zhou. compositional semantic parsing with large language models. _ arxiv preprint arxiv : 2209. 15003 _, 2022. 10 preprint [ guiyao tie et al. a survey on post - training of large language models, 2025. url https : / / ] ( https : / / arxiv. org / abs / 2503. 06072 ) [ arxiv. org / abs / 2503. 06072. ] ( https : / / arxiv. org / abs / 2503. 06072 ) yichao fu, xuewei wang, yuandong tian, and jiawei zhao. deep think with confidence, 2025. [ url https : / / arxiv. org / abs / 2508. 15260. ] ( https : / / arxiv. org / abs / 2508. 15260 ) jiahui geng, fengyu cai, yuxia wang, heinz koeppl, preslav nakov, and iryna gurevych. a survey of confidence estimation and calibration in large language models. in kevin duh, helena gomez, and steven bethard ( eds. ), _ proceedings of the 2024 conference of the north american chapter _ _ of the association for computational linguistics : human language technologies ( volume 1 : _ _ long papers ) _, pp. 6577 – 6595, mexico city, mexico, june 2024. association for computational [ linguistics. doi : 10. 18653 / v1 / 2024. naacl - long. 366. url https : / / aclanthology. org / ] ( https : / / aclanthology. org / 2024. naacl - long. 366 / ) [ 2024. naacl - long. 366 /. ] ( https : / / aclanthology. org / 2024. naacl - long. 366 / ) mor geva, daniel khashabi, elad segal, tushar khot, dan roth, and jonathan berant. did aristotle use a lap"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03223v1",
      "title": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention\n  Alignment",
      "authors": [
        "Hongxiang Zhang",
        "Yuan Tian",
        "Tianyi Zhang"
      ],
      "summary": "To solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and\nreinforcement learning. However, as reasoning chains extend, critical\nintermediate steps and the original prompt will be buried in the context,\nreceiving insufficient attention and leading to errors. In this paper, we\npropose Self-Anchor, a novel pipeline that leverages the inherent structure of\nreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories\ninto structured plans and automatically aligns the model's attention to the\nmost relevant inference steps, allowing the model to maintain focus throughout\ngeneration. Our experiment shows that Self-Anchor outperforms SOTA prompting\nmethods across six benchmarks. Notably, Self-Anchor significantly reduces the\nperformance gap between ``non-reasoning'' models and specialized reasoning\nmodels, with the potential to enable most LLMs to tackle complex reasoning\ntasks without retraining.",
      "published": "2025-10-03T17:56:33Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03223v1"
    },
    "chunk_id": 13,
    "text": "##ena gomez, and steven bethard ( eds. ), _ proceedings of the 2024 conference of the north american chapter _ _ of the association for computational linguistics : human language technologies ( volume 1 : _ _ long papers ) _, pp. 6577 – 6595, mexico city, mexico, june 2024. association for computational [ linguistics. doi : 10. 18653 / v1 / 2024. naacl - long. 366. url https : / / aclanthology. org / ] ( https : / / aclanthology. org / 2024. naacl - long. 366 / ) [ 2024. naacl - long. 366 /. ] ( https : / / aclanthology. org / 2024. naacl - long. 366 / ) mor geva, daniel khashabi, elad segal, tushar khot, dan roth, and jonathan berant. did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies. _ transactions of _ _ the association for computational linguistics _, 9 : 346 – 361, 2021. aaron grattafiori, abhimanyu dubey, abhinav jauhri, abhinav pandey, abhishek kadian, ahmad al - dahle, aiesha letman, akhil mathur, alan schelten, alex vaughan, et al. the llama 3 herd of models. _ arxiv preprint arxiv : 2407. 21783 _, 2024. xiangming gu, tianyu pang, chao du, qian liu, fengzhuo zhang, cunxiao du, ye wang, and min lin. when attention sink emerges in language models : an empirical view. _ arxiv preprint _ _ arxiv : 2410. 10781 _, 2024. dan hendrycks, collin burns, saurav kadavath, akul arora, steven basart, eric tang, dawn song, and jacob steinhardt. measuring mathematical problem solving with the math dataset. _ neurips _, 2021. kelly hong, anton troynikov, and jeff huber. context rot : how increasing input tokens im [ pacts llm performance. technical report, chroma, july 2025. url https : / / research. ] ( https : / / research. trychroma. com / context - rot ) [ trychroma. com / context - rot. ] ( https : / / research. trychroma. com / context - rot ) jie huang and kevin chen - chuan chang. towards reasoning in large language models : a survey. in anna rogers, jordan boyd - graber, and naoaki okazaki ( eds. ), _ findings of the as - _ _ sociation for computational linguistics : acl 2023 _, pp. 1049 – 1065, toronto, canada, july 2023. association for computational linguistics. doi : 10. 18653 / v1 / 2023. findings - acl. 67. url [ https : / / aclanthology. org / 2023. findings - acl. 67 /. ] ( https : / / aclanthology. org / 2023. findings - acl. 67 / ) xue jiang, yihong dong, lecheng wang, zheng fang, qiwei shang, ge li, zhi jin, and wenpin jiao. self - planning code generation with large language models. _ acm transactions on software _ _ engineering and methodology _, 33 ( 7 ) : 1 – 30, 2024. mingyu jin, qinkai yu, dong shu, haiyan zhao, wenyue hua, yanda meng, yongfeng zhang, and mengnan du. the impact of reasoning step length on large language models. _ arxiv preprint _ _ arxiv : 2401. 04925 _, 2024. tushar khot, harsh trivedi, matthew finlayson, yao fu, kyle richardson, peter clark, and ashish sabharwal. decomposed prompting : a modular approach for solving complex tasks. _ arxiv _ _ preprint arxiv : 2210. 02406 _, 2022. robert kirk, ishita mediratta, christoforos nalmpantis, jelena luketina, eric hambro, edward grefenstette, and roberta raileanu. understanding the effects of rlhf on llm generalisation and diversity. _ arxiv preprint arxiv : 2310. 06452 _, 2023. takeshi kojima, shixiang shane gu, machel reid, yutaka matsuo, and yusuke iwasawa. large language models are zero - shot reasoners. _ advances in neural information processing systems _, 35 : 22199"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03223v1",
      "title": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention\n  Alignment",
      "authors": [
        "Hongxiang Zhang",
        "Yuan Tian",
        "Tianyi Zhang"
      ],
      "summary": "To solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and\nreinforcement learning. However, as reasoning chains extend, critical\nintermediate steps and the original prompt will be buried in the context,\nreceiving insufficient attention and leading to errors. In this paper, we\npropose Self-Anchor, a novel pipeline that leverages the inherent structure of\nreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories\ninto structured plans and automatically aligns the model's attention to the\nmost relevant inference steps, allowing the model to maintain focus throughout\ngeneration. Our experiment shows that Self-Anchor outperforms SOTA prompting\nmethods across six benchmarks. Notably, Self-Anchor significantly reduces the\nperformance gap between ``non-reasoning'' models and specialized reasoning\nmodels, with the potential to enable most LLMs to tackle complex reasoning\ntasks without retraining.",
      "published": "2025-10-03T17:56:33Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03223v1"
    },
    "chunk_id": 14,
    "text": ": 2401. 04925 _, 2024. tushar khot, harsh trivedi, matthew finlayson, yao fu, kyle richardson, peter clark, and ashish sabharwal. decomposed prompting : a modular approach for solving complex tasks. _ arxiv _ _ preprint arxiv : 2210. 02406 _, 2022. robert kirk, ishita mediratta, christoforos nalmpantis, jelena luketina, eric hambro, edward grefenstette, and roberta raileanu. understanding the effects of rlhf on llm generalisation and diversity. _ arxiv preprint arxiv : 2310. 06452 _, 2023. takeshi kojima, shixiang shane gu, machel reid, yutaka matsuo, and yusuke iwasawa. large language models are zero - shot reasoners. _ advances in neural information processing systems _, 35 : 22199 – 22213, 2022. kenneth li, tianle liu, naomi bashkansky, david bau, fernanda [UNK], hanspeter pfister, and martin wattenberg. measuring and controlling instruction ( in ) stability in language model dialogs, [ 2024. url https : / / arxiv. org / abs / 2402. 10962. ] ( https : / / arxiv. org / abs / 2402. 10962 ) 11 preprint wang ling, dani yogatama, chris dyer, and phil blunsom. program induction by rationale generation : learning to solve and explain algebraic word problems. in regina barzilay and min - yen kan ( eds. ), _ proceedings of the 55th annual meeting of the association for computational lin - _ _ guistics ( volume 1 : long papers ) _, pp. 158 – 167, vancouver, canada, july 2017. association for [ computational linguistics. doi : 10. 18653 / v1 / p17 - 1015. url https : / / aclanthology. ] ( https : / / aclanthology. org / p17 - 1015 / ) [ org / p17 - 1015 /. ] ( https : / / aclanthology. org / p17 - 1015 / ) nelson f. liu, kevin lin, john hewitt, ashwin paranjape, michele bevilacqua, fabio petroni, and percy liang. lost in the middle : how language models use long contexts. _ transactions of the _ _ association for computational linguistics _, 12 : 157 – 173, 2024. doi : 10. 1162 / tacl ~ ~ a 0 ~ ~ 0638. url [ https : / / aclanthology. org / 2024. tacl - 1. 9 /. ] ( https : / / aclanthology. org / 2024. tacl - 1. 9 / ) pengfei liu, weizhe yuan, jinlan fu, zhengbao jiang, hiroaki hayashi, and graham neubig. pretrain, prompt, and predict : a systematic survey of prompting methods in natural language processing. _ acm computing surveys _, 55 ( 9 ) : 1 – 35, 2023. yao lu, max bartolo, alastair moore, sebastian riedel, and pontus stenetorp. fantastically ordered prompts and where to find them : overcoming few - shot prompt order sensitivity. _ arxiv preprint _ _ arxiv : 2104. 08786 _, 2021. liangchen luo, yinxiao liu, rosanne liu, samrat phatale, meiqi guo, harsh lara, yunxuan li, lei shu, yun zhu, lei meng, jiao sun, and abhinav rastogi. improve mathematical reasoning [ in language models by automated process supervision, 2024. url https : / / arxiv. org / ] ( https : / / arxiv. org / abs / 2406. 06592 ) [ abs / 2406. 06592. ] ( https : / / arxiv. org / abs / 2406. 06592 ) aman madaan, niket tandon, prakhar gupta, skyler hallinan, luyu gao, sarah wiegreffe, uri alon, nouha dziri, shrimai prabhumoye, yiming yang, et al. self - refine : iterative refinement with self - feedback. _ advances in neural information processing systems _, 36 : 46534 – 46594, 2023. rajasekhar reddy mekala, yasaman razeghi, and sameer singh. echoprompt : instructing the model to rephrase queries for improved in - context learning. _ arxiv preprint arxiv : 2309. 10687 _,"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03223v1",
      "title": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention\n  Alignment",
      "authors": [
        "Hongxiang Zhang",
        "Yuan Tian",
        "Tianyi Zhang"
      ],
      "summary": "To solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and\nreinforcement learning. However, as reasoning chains extend, critical\nintermediate steps and the original prompt will be buried in the context,\nreceiving insufficient attention and leading to errors. In this paper, we\npropose Self-Anchor, a novel pipeline that leverages the inherent structure of\nreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories\ninto structured plans and automatically aligns the model's attention to the\nmost relevant inference steps, allowing the model to maintain focus throughout\ngeneration. Our experiment shows that Self-Anchor outperforms SOTA prompting\nmethods across six benchmarks. Notably, Self-Anchor significantly reduces the\nperformance gap between ``non-reasoning'' models and specialized reasoning\nmodels, with the potential to enable most LLMs to tackle complex reasoning\ntasks without retraining.",
      "published": "2025-10-03T17:56:33Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03223v1"
    },
    "chunk_id": 15,
    "text": "2024. url https : / / arxiv. org / ] ( https : / / arxiv. org / abs / 2406. 06592 ) [ abs / 2406. 06592. ] ( https : / / arxiv. org / abs / 2406. 06592 ) aman madaan, niket tandon, prakhar gupta, skyler hallinan, luyu gao, sarah wiegreffe, uri alon, nouha dziri, shrimai prabhumoye, yiming yang, et al. self - refine : iterative refinement with self - feedback. _ advances in neural information processing systems _, 36 : 46534 – 46594, 2023. rajasekhar reddy mekala, yasaman razeghi, and sameer singh. echoprompt : instructing the model to rephrase queries for improved in - context learning. _ arxiv preprint arxiv : 2309. 10687 _, 2023. swaroop mishra and elnaz nouri. help me think : a simple prompting strategy for non - experts to create customized content with models. _ arxiv preprint arxiv : 2208. 08232 _, 2022. [ openai. openai o1 system card, 2024. url https : / / arxiv. org / abs / 2412. 16720. ] ( https : / / arxiv. org / abs / 2412. 16720 ) baifeng shi, siyu gai, trevor darrell, and xin wang. toast : transfer learning via attention steering. _ arxiv preprint arxiv : 2305. 15542 _, 2023. mingjie sun, xinlei chen, j zico kolter, and zhuang liu. massive activations in large language models. _ arxiv preprint arxiv : 2402. 17762 _, 2024. mirac suzgun, nathan scales, nathanael [UNK], sebastian gehrmann, yi tay, hyung won chung, aakanksha chowdhery, quoc v le, ed h chi, denny zhou, et al. challenging big - bench tasks and whether chain - of - thought can solve them. _ arxiv preprint arxiv : 2210. 09261 _, 2022. [ qwen team. qwen3 technical report, 2025. url https : / / arxiv. org / abs / 2505. 09388. ] ( https : / / arxiv. org / abs / 2505. 09388 ) yuan tian and tianyi zhang. selective prompt anchoring for code generation. _ arxiv preprint _ _ arxiv : 2408. 09121 _, 2024. ashish vaswani, noam shazeer, niki parmar, jakob uszkoreit, llion jones, aidan n. gomez, [ lukasz kaiser, and illia polosukhin. attention is all you need, 2023. url https : / / arxiv. ] ( https : / / arxiv. org / abs / 1706. 03762 ) [ org / abs / 1706. 03762. ] ( https : / / arxiv. org / abs / 1706. 03762 ) lei wang, wanyu xu, yihuai lan, zhiqiang hu, yunshi lan, roy ka - wei lee, and ee - peng lim. plan - and - solve prompting : improving zero - shot chain - of - thought reasoning by large language models. _ arxiv preprint arxiv : 2305. 04091 _, 2023. jason wei, xuezhi wang, dale schuurmans, maarten bosma, fei xia, ed chi, quoc v le, denny zhou, et al. chain - of - thought prompting elicits reasoning in large language models. _ advances in _ _ neural information processing systems _, 35 : 24824 – 24837, 2022. 12 preprint yuyang wu, yifei wang, ziyu ye, tianqi du, stefanie jegelka, and yisen wang. when more is less : understanding chain - of - thought length in llms. _ arxiv preprint arxiv : 2502. 07266 _, 2025. guangxuan xiao, yuandong tian, beidi chen, song han, and mike lewis. efficient streaming language models with attention sinks. _ arxiv preprint arxiv : 2309. 17453 _, 2023. xiaohan xu, chongyang tao, tao shen, can xu, hongbo xu, guodong long, jian - guang lou, and shuai ma. re - reading improves reasoning in large language models. in _ proceedings of the 2024 _ _ conference on empirical methods in natural language processing _, pp. 15549 – 15575, 2024"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03223v1",
      "title": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention\n  Alignment",
      "authors": [
        "Hongxiang Zhang",
        "Yuan Tian",
        "Tianyi Zhang"
      ],
      "summary": "To solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and\nreinforcement learning. However, as reasoning chains extend, critical\nintermediate steps and the original prompt will be buried in the context,\nreceiving insufficient attention and leading to errors. In this paper, we\npropose Self-Anchor, a novel pipeline that leverages the inherent structure of\nreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories\ninto structured plans and automatically aligns the model's attention to the\nmost relevant inference steps, allowing the model to maintain focus throughout\ngeneration. Our experiment shows that Self-Anchor outperforms SOTA prompting\nmethods across six benchmarks. Notably, Self-Anchor significantly reduces the\nperformance gap between ``non-reasoning'' models and specialized reasoning\nmodels, with the potential to enable most LLMs to tackle complex reasoning\ntasks without retraining.",
      "published": "2025-10-03T17:56:33Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03223v1"
    },
    "chunk_id": 16,
    "text": "advances in _ _ neural information processing systems _, 35 : 24824 – 24837, 2022. 12 preprint yuyang wu, yifei wang, ziyu ye, tianqi du, stefanie jegelka, and yisen wang. when more is less : understanding chain - of - thought length in llms. _ arxiv preprint arxiv : 2502. 07266 _, 2025. guangxuan xiao, yuandong tian, beidi chen, song han, and mike lewis. efficient streaming language models with attention sinks. _ arxiv preprint arxiv : 2309. 17453 _, 2023. xiaohan xu, chongyang tao, tao shen, can xu, hongbo xu, guodong long, jian - guang lou, and shuai ma. re - reading improves reasoning in large language models. in _ proceedings of the 2024 _ _ conference on empirical methods in natural language processing _, pp. 15549 – 15575, 2024. shunyu yao, binghui peng, christos papadimitriou, and karthik narasimhan. self - attention networks can process bounded hierarchical languages. _ arxiv preprint arxiv : 2105. 11115 _, 2021. shunyu yao, jeffrey zhao, dian yu, nan du, izhak shafran, karthik narasimhan, and yuan cao. react : synergizing reasoning and acting in language models. in _ international conference on _ _ learning representations ( iclr ) _, 2023. qingru zhang, chandan singh, liyuan liu, xiaodong liu, bin yu, jianfeng gao, and tuo zhao. tell your model where to attend : post - hoc attention steering for llms. _ arxiv preprint _ _ arxiv : 2311. 02262 _, 2023. xuechen zhang, xiangyu chang, mingchen li, amit roy - chowdhury, jiasi chen, and samet oymak. selective attention : enhancing transformer through principled context control. _ advances in _ _ neural information processing systems _, 37 : 11061 – 11086, 2024. huaixiu steven zheng, swaroop mishra, xinyun chen, heng - tze cheng, ed h chi, quoc v le, and denny zhou. take a step back : evoking reasoning via abstraction in large language models. _ arxiv preprint arxiv : 2310. 06117 _, 2023. denny zhou, nathanael [UNK], le hou, jason wei, nathan scales, xuezhi wang, dale schuurmans, claire cui, olivier bousquet, quoc le, et al. least - to - most prompting enables complex reasoning in large language models. _ arxiv preprint arxiv : 2205. 10625 _, 2022. pei zhou, aman madaan, srividya pranavi potharaju, aditya gupta, kevin r mckee, ari holtzman, jay pujara, xiang ren, swaroop mishra, aida nematzadeh, et al. how far are large language models from agents with theory - of - mind? _ arxiv preprint arxiv : 2310. 03051 _, 2023. pei zhou, jay pujara, xiang ren, xinyun chen, heng - tze cheng, quoc v le, ed chi, denny zhou, swaroop mishra, and huaixiu steven zheng. self - discover : large language models self - compose reasoning structures. _ advances in neural information processing systems _, 37 : 126032 – 126058, 2024. 13 preprint a t he u se of l arge l anguage m odels ( llm s ) we leverage large language models ( llms ) primarily for grammar checking and polishing for our manuscript. b c alculating a verage c onfidence s cores we conduct an ablation study to evaluate different methods for calculating confidence scores from token - level probabilities. let _ p _ _ i _ = _ { p _ 1 _, p _ 2 _,..., p _ _ m _ _ } _ represent the set of token - level confidence scores for tokens generated in the current reasoning step _ i _. we compare three approaches for calculating average confidence scores at sequence level : * * harmonic mean : * * _ n _ _ p _ harmonic = ~ ~ ~ ~ ~ ~ _ n _ ~ ~ _ i _ = 1 _ p _ 1 _ i _ ( 5 ) * * geometric mean : * * 1 _ / n _ _ p _ geometric = _ n _ _ p _ _ i _ _ i _ = 1 ( 6 ) * * arithmetic mean : * * _ p _ arithmetic ="
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03223v1",
      "title": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention\n  Alignment",
      "authors": [
        "Hongxiang Zhang",
        "Yuan Tian",
        "Tianyi Zhang"
      ],
      "summary": "To solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and\nreinforcement learning. However, as reasoning chains extend, critical\nintermediate steps and the original prompt will be buried in the context,\nreceiving insufficient attention and leading to errors. In this paper, we\npropose Self-Anchor, a novel pipeline that leverages the inherent structure of\nreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories\ninto structured plans and automatically aligns the model's attention to the\nmost relevant inference steps, allowing the model to maintain focus throughout\ngeneration. Our experiment shows that Self-Anchor outperforms SOTA prompting\nmethods across six benchmarks. Notably, Self-Anchor significantly reduces the\nperformance gap between ``non-reasoning'' models and specialized reasoning\nmodels, with the potential to enable most LLMs to tackle complex reasoning\ntasks without retraining.",
      "published": "2025-10-03T17:56:33Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03223v1"
    },
    "chunk_id": 17,
    "text": "llms ) primarily for grammar checking and polishing for our manuscript. b c alculating a verage c onfidence s cores we conduct an ablation study to evaluate different methods for calculating confidence scores from token - level probabilities. let _ p _ _ i _ = _ { p _ 1 _, p _ 2 _,..., p _ _ m _ _ } _ represent the set of token - level confidence scores for tokens generated in the current reasoning step _ i _. we compare three approaches for calculating average confidence scores at sequence level : * * harmonic mean : * * _ n _ _ p _ harmonic = ~ ~ ~ ~ ~ ~ _ n _ ~ ~ _ i _ = 1 _ p _ 1 _ i _ ( 5 ) * * geometric mean : * * 1 _ / n _ _ p _ geometric = _ n _ _ p _ _ i _ _ i _ = 1 ( 6 ) * * arithmetic mean : * * _ p _ arithmetic = [ 1 ] _ n _ _ n _ _ p _ _ i _ ( 7 ) _ i _ = 1 table 6 presents the results across two reasoning benchmarks using llama3. 1 and phi - 4 - mini models. the harmonic mean consistently outperforms both geometric and arithmetic means across all settings. this is because the harmonic mean is more sensitive to low confidence values, which better captures potential attention drift during reasoning. the geometric mean performs second - best, as it also penalizes low values more than the arithmetic mean, though less aggressively than the harmonic mean. the arithmetic mean shows the weakest performance, as it can be dominated by high - confidence tokens and may miss instances where attention drift occurs for specific reasoning components. c s elf - a nchor p rompt d etails d a lternative d esign as described in section 2. 1, our primary s elf - a nchor design anchors attention to the original question and the current plan step during reasoning generation. we investigate an alternative design that anchors to all prior plan steps in addition to the current step and the original question. the motivation for this alternative is that maintaining attention to all previous planning steps might provide additional context for the current reasoning step. we compare two anchoring strategies : 14 preprint - * * s * * * * elf * * * * - a * * * * nchor * * * * ( primary ) : * * anchors to the original question and current plan step only, where _ a _ _ i _ = _ { _ question _, _ plan _ i _ _ } _ - * * anchor to all : * * anchors to the original question, current plan step, and all prior plan steps, where _ a _ _ i _ = _ { _ question _, _ plan 1 _, _ plan 2 _,..., _ plan _ i _ _ } _ table 7 presents the results comparing these two approaches across aqua and t4d benchmarks using llama3. 1 - 8b and phi - 4 - mini models. the primary s elf - a nchor design consistently outperforms the alternative that anchors to all prior steps. this performance difference may be because the alternative design dilutes attention across too many anchor points, reducing focus on the most relevant current step. in contrast, the primary design maintains sharp focus on the most relevant context while avoiding attention dilution. table 6 : mean selection ablation study. results show accuracy ( % ) on aqua - rat and t4d benchmarks. * * model * * * * method * * aqua - rat t4d llama3. 1 - 8b phi - 4 - mini cot 50. 79 26. 77 s elf - a nchor ( harmonic ) * * 55. 51 * * * * 40. 01 * * s elf - a nchor ( geometric ) 55. 11 35. 28 s elf - a nchor ( arithmetic ) 54. 72 35. 99 cot 61. 81 39. 54 s elf - a nchor ( harmonic ) * * 68. 50 * * * * 49. 47 * * s elf - a nchor ( geometric ) 67. 72 49. 11 s elf - a nchor ( arithmetic ) 67. 71 48. 40 table 7 : alternative anchoring design comparison. results show accuracy ( % ) on aqua - rat and t4d benchmarks. * * model * * * * method * * aqua - rat t4d cot 50. 79 26. 77 llama3. 1 - 8b s elf - a nchor * * 55. 51 * * * * 40. 01 * * anchor to all prior steps 53. 54 32. 62 cot 61. 81 39. 54 phi - 4 - mini s elf - a nchor * * 68. 50 * * * * 49. 47 * * anchor to all prior steps 67. 32"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03223v1",
      "title": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention\n  Alignment",
      "authors": [
        "Hongxiang Zhang",
        "Yuan Tian",
        "Tianyi Zhang"
      ],
      "summary": "To solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and\nreinforcement learning. However, as reasoning chains extend, critical\nintermediate steps and the original prompt will be buried in the context,\nreceiving insufficient attention and leading to errors. In this paper, we\npropose Self-Anchor, a novel pipeline that leverages the inherent structure of\nreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories\ninto structured plans and automatically aligns the model's attention to the\nmost relevant inference steps, allowing the model to maintain focus throughout\ngeneration. Our experiment shows that Self-Anchor outperforms SOTA prompting\nmethods across six benchmarks. Notably, Self-Anchor significantly reduces the\nperformance gap between ``non-reasoning'' models and specialized reasoning\nmodels, with the potential to enable most LLMs to tackle complex reasoning\ntasks without retraining.",
      "published": "2025-10-03T17:56:33Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03223v1"
    },
    "chunk_id": 18,
    "text": "54. 72 35. 99 cot 61. 81 39. 54 s elf - a nchor ( harmonic ) * * 68. 50 * * * * 49. 47 * * s elf - a nchor ( geometric ) 67. 72 49. 11 s elf - a nchor ( arithmetic ) 67. 71 48. 40 table 7 : alternative anchoring design comparison. results show accuracy ( % ) on aqua - rat and t4d benchmarks. * * model * * * * method * * aqua - rat t4d cot 50. 79 26. 77 llama3. 1 - 8b s elf - a nchor * * 55. 51 * * * * 40. 01 * * anchor to all prior steps 53. 54 32. 62 cot 61. 81 39. 54 phi - 4 - mini s elf - a nchor * * 68. 50 * * * * 49. 47 * * anchor to all prior steps 67. 32 47. 34 e i mplementation and evaluation details e. 1 p rompt example * * chain - of - thought. * * * * plan - and - solve +. * * we adopt the implementation from plan - and - solve + ( wang et al., 2023 ), for mathmatical reasoning we apply prompt : otherwise, we use : 15 preprint * * re - reading. * * e. 2 e valuation d etails we adopt standard metrics used in prior work ( chuang et al., 2024 ; wang et al., 2023 ; zhou et al., 2024 ), including accuracy and exact match, for aqua, bbh, t4d, and math. for gsm8k and strategyqa, we follow the factual accuracy evaluation protocol introduced by chuang et al. ( 2024 ). to ensure consistent answer extraction, we prompt all models to conclude their response with the phrase : “ conclude with the final answer using the format : “ final answer ” : ” _ < _ your answer _ > _ ” where _ < _ your answer _ > _ denotes either a multiple - choice option or a string answer. we then apply taskspecific heuristics to extract _ < _ your answer _ > _ from the output. for the math dataset, we randomly sample 200 test instances and manually verify the extracted answers to ensure correctness. e. 3 i mplementation d etails we follow the definitions of reasoning step segmentation and task complexity from ( wu et al., 2025 ; jin et al., 2024 ). the performance gain of a task is computed as the difference in accuracy between two methods on that task. to measure the number of reasoning steps, we split the full reasoning chain by “ _ \\ _ n ” and remove empty lines caused by consecutive breaks ( “ _ \\ _ n _ \\ _ n ” ). the remaining lines are counted as the cot length. f c ase s tudy in this section, we provided a qualitative example to illustrate the reasoning trajectory generated by each method. the task is to determine whether a prime number can be represented by the number of days in a week. cot 1 and re 3 immediately arrive at an incorrect conclusion by misidentifying 7 as a non - prime number. ps + 2 follows a more structured plan but also makes a critical error in its final conclusion, contradicting its own evidence. in contrast, s elf - a nchor 4 successfully decomposes the problem, correctly identifies 7 as a prime number, and reaches the correct answer by systematically executing its reasoning plan. * * algorithm 1 * * chain - of - thought ( cot ) 1 : _ * * question : * * _ can a prime number be represented by the number of days in a week? 2 : * * prompt : * * let ’ s think step by step. 3 : * * model completion : * * no, a prime number cannot be represented by the number of days in a week because the number of days in a week is 7, which is not a prime number. prime numbers are numbers greater than 1 that have no positive divisors other than 1 and themselves. since 7 is divisible by 1 and 7, it is not a prime number. 4 : * * final answer : no * * g n umerical e xperiment r esult on b ig - b ench - h ard 16 preprint * * algorithm 2 * * plan - and - solve ( ps + ) 1 : _ * * question : * * _ can a prime number be represented by the number of days in a week? 2 : * * prompt : * * let ’ s first prepare relevant information and make a plan. then, let ’ s answer the question step by step ( pay attention to commonsense and logical coherence ). 3 : * * model completion : * * step 1 : gather information : prime numbers are natural numbers greater than 1 that have no positive"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03223v1",
      "title": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention\n  Alignment",
      "authors": [
        "Hongxiang Zhang",
        "Yuan Tian",
        "Tianyi Zhang"
      ],
      "summary": "To solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and\nreinforcement learning. However, as reasoning chains extend, critical\nintermediate steps and the original prompt will be buried in the context,\nreceiving insufficient attention and leading to errors. In this paper, we\npropose Self-Anchor, a novel pipeline that leverages the inherent structure of\nreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories\ninto structured plans and automatically aligns the model's attention to the\nmost relevant inference steps, allowing the model to maintain focus throughout\ngeneration. Our experiment shows that Self-Anchor outperforms SOTA prompting\nmethods across six benchmarks. Notably, Self-Anchor significantly reduces the\nperformance gap between ``non-reasoning'' models and specialized reasoning\nmodels, with the potential to enable most LLMs to tackle complex reasoning\ntasks without retraining.",
      "published": "2025-10-03T17:56:33Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03223v1"
    },
    "chunk_id": 19,
    "text": "a week because the number of days in a week is 7, which is not a prime number. prime numbers are numbers greater than 1 that have no positive divisors other than 1 and themselves. since 7 is divisible by 1 and 7, it is not a prime number. 4 : * * final answer : no * * g n umerical e xperiment r esult on b ig - b ench - h ard 16 preprint * * algorithm 2 * * plan - and - solve ( ps + ) 1 : _ * * question : * * _ can a prime number be represented by the number of days in a week? 2 : * * prompt : * * let ’ s first prepare relevant information and make a plan. then, let ’ s answer the question step by step ( pay attention to commonsense and logical coherence ). 3 : * * model completion : * * step 1 : gather information : prime numbers are natural numbers greater than 1 that have no positive divisors other than 1 and themselves. the number of days in a week is 7. 4 : step 2 : plan the solution : we will first identify prime numbers less than 7 to see if any match the number of days in a week. - then, we will determine if any prime number can represent the number of days in a week based on our findings. 5 : step 3 : execute the plan : prime numbers less than 7 are 2, 3, 5, and 7. - among these, 2, 3, and 5 are less than 7 and are indeed prime numbers. - none of these prime numbers ( 2, 3, 5 ) match the number of days in a week ( 7 ). 6 : step 4 : analyze and draw a conclusion : since none of the prime numbers less than 7 ( 2, 3, 5 ) match the number of days in a week ( 7 ), a prime number cannot be represented by the number of days in a week. 7 : * * step 5 : final answer : the final answer is no * * * * algorithm 3 * * re - reading ( re ) 1 : _ * * question : * * _ can a prime number be represented by the number of days in a week? 2 : * * prompt : * * read the question again 3 : * * model completion : * * no, a prime number cannot be represented by the number of days in a week because the number of days in a week is 7, which is not a prime number. 4 : prime numbers are numbers greater than 1 that have no positive divisors other than 1 and themselves. 5 : the number 7 is a prime number, but the question seems to be asking if the number of days in a week ( 7 ) can be represented by a prime number, which it already is. 6 : however, if the question is interpreted as asking if there is a prime number that equals the number of days in a week, the answer would still be ” no ” because 7 is already a prime number. 7 : if the question is asking if the number of days in a week ( 7 ) can be represented by any prime number, the answer would be ” yes ” because 7 itself is a prime number. 8 : however, the phrasing of the question suggests that it is asking if the number of days in a week can be represented by a prime number other than 7, in which case the answer would be ” no. ” 9 : for clarity, i will assume the question is asking if the number of days in a week ( 7 ) can be represented by a prime number other than itself, and the final answer is ” no. ” 10 : * * ” final answer ” : ” no ” * * * * algorithm 4 * * s elf - a nchor 1 : _ * * question : * * _ can a prime number be represented by the number of days in a week? 2 : * * prompt : * * decompose the given problem into step - by - step plan, reasoning the plan and solve the problem step by step in json format. for each plan step, provide a key - value pair : the key is the plan step, the value is the detailed reasoning for that step. 3 : * * model completion : * * ” understand the question. ” : ” the question asks if a prime number can be represented by the number of days in a week. ”, 4 : ” identify the number of days in a week. ” : ” there are 7 days in a week. ”, 5 : ” determine if 7 is a prime number. ” : ” a prime number is a natural number greater than 1 that has no positive divisors other than 1 and itself. ”, 6 : ” check if 7 meets the criteria of a prime number. ” : ” 7 is greater than 1 and its only divisors are 1 and 7. ”, 7 : * * ” final answer ” : ”"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03223v1",
      "title": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention\n  Alignment",
      "authors": [
        "Hongxiang Zhang",
        "Yuan Tian",
        "Tianyi Zhang"
      ],
      "summary": "To solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and\nreinforcement learning. However, as reasoning chains extend, critical\nintermediate steps and the original prompt will be buried in the context,\nreceiving insufficient attention and leading to errors. In this paper, we\npropose Self-Anchor, a novel pipeline that leverages the inherent structure of\nreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories\ninto structured plans and automatically aligns the model's attention to the\nmost relevant inference steps, allowing the model to maintain focus throughout\ngeneration. Our experiment shows that Self-Anchor outperforms SOTA prompting\nmethods across six benchmarks. Notably, Self-Anchor significantly reduces the\nperformance gap between ``non-reasoning'' models and specialized reasoning\nmodels, with the potential to enable most LLMs to tackle complex reasoning\ntasks without retraining.",
      "published": "2025-10-03T17:56:33Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03223v1"
    },
    "chunk_id": 20,
    "text": "the given problem into step - by - step plan, reasoning the plan and solve the problem step by step in json format. for each plan step, provide a key - value pair : the key is the plan step, the value is the detailed reasoning for that step. 3 : * * model completion : * * ” understand the question. ” : ” the question asks if a prime number can be represented by the number of days in a week. ”, 4 : ” identify the number of days in a week. ” : ” there are 7 days in a week. ”, 5 : ” determine if 7 is a prime number. ” : ” a prime number is a natural number greater than 1 that has no positive divisors other than 1 and itself. ”, 6 : ” check if 7 meets the criteria of a prime number. ” : ” 7 is greater than 1 and its only divisors are 1 and 7. ”, 7 : * * ” final answer ” : ” yes ” * * 17 preprint table 8 : bbh details * * bbh * * * * model * * * * method * * * * disambiguation * * * * qa * * * * causal * * * * judgement * * * * date * * ~ ~ * * u * * ~ ~ * * nderstanding * * * * logical * * ~ ~ * * d * * ~ ~ * * eduction * * * * salient * * ~ ~ * * t * * ~ ~ * * ranslation * * ~ ~ * * e * * ~ ~ * * rror * * * * detection * * * * snarks * * cot 100 91 / 187 182 67 110 125 llama3. 1 - 8b ps + 138 108 136 78 124 122 re - read 124 98 190 85 121 127 s elf - a nchor 152 100 160 128 132 127 cot 88 / 250 71 102 34 95 89 llama3. 2 - 3b ps + 104 63 97 86 98 105 re - read 74 84 127 40 89 105 s elf - a nchor 131 101 131 101 96 129 cot 162 / 250 113 154 114 149 134 phi4 - mini - 4b ps + 160 126 138 130 136 124 re - read 162 115 165 113 135 148 s elf - a nchor 152 116 174 128 140 142 cot 183 / 250 121 174 208 167 148 qwen3 - mini - 4b ps + 179 108 165 207 160 150 re - read 179 121 203 230 147 154 s elf - a nchor 185 115 193 224 161 150 cot 180 120 203 169 152 160 phi - 4 - 15b ps + 180 117 140 186 155 156 re - read 179 120 221 191 158 154 s elf - a nchor 176 122 218 203 148 161 cot 105 125 182 185 172 155 qwen3 - 30b ps + 114 122 172 181 165 156 re - read 113 125 185 210 174 156 s elf - a nchor 110 123 196 200 160 157 18"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 0,
    "text": "2025 - 10 - 06 # # # * * low - probability tokens sustain exploration in reinforcement learning * * * * with verifiable reward * * guanhua huang [ 1, ] _ [ ∗ ] _, tingqiang xu [ 1, 2, ] _ [ ∗ ] _ [ † ], mingze wang [ 1, 3, † ], qi yi [ 1 ], xue gong [ 1 ], siheng li [ 1, 4, † ], ruibin xiong [ 1 ] kejiao li [ 1 ], yuhao jiang [ 1 ], bo zhou [ 1 ] [ ‡ ] 1 * * llm department, tencent * * 2 * * tsinghua university * * 3 * * peking university * * 4 * * the chinese university of hong kong * * * * abstract * * reinforcement learning with verifiable rewards ( rlvr ) has propelled large language models in complex reasoning, yet its scalability is often hindered by a training bottleneck where performance plateaus as policy entropy collapses, signaling a loss of exploration. previous methods typically address this by maintaining high policy entropy, yet the precise mechanisms that govern meaningful exploration have remained underexplored. our analysis suggests that an unselective focus on entropy risks amplifying irrelevant tokens and destabilizing training. this paper investigates the exploration dynamics within rlvr and identifies a key issue : the gradual elimination of valuable low - probability exploratory tokens, which we term _ * * reasoning sparks * * _. we find that while abundant in pre - trained models, these sparks are systematically extinguished during rlvr due to over - penalization, leading to a degeneracy in exploration. to address this, we introduce low - probability regularization ( lp - reg ). its core mechanism regularizes the policy towards a heuristic proxy distribution. this proxy is constructed by filtering out presumed noise tokens and re - normalizing the distribution over the remaining candidates. the result is a less - noisy proxy where the probability of _ reasoning sparks _ is amplified, which then serves as a soft regularization target to shield these valuable tokens from elimination via kl divergence. experiments show that lp - reg enables stable on - policy training for around 1, 000 steps, a regime where baseline entropy - control methods collapse. this sustained exploration leads to state - of - the - art performance, achieving a 60. 17 % average accuracy on five math benchmarks, an improvement of 2. 66 % over [ prior methods. code is available at https : / / github. com / carlanlark / lp - reg. ] ( https : / / github. com / carlanlark / lp - reg ) * * 1 * * * * introduction * * the advent of large reasoning models has reshaped the trajectory of artificial intelligence, with paradigmatic examples including openai o1 ( openai et al., 2024 ) and deepseek - r1 ( deepseek - ai et al., 2025 ). a central technique underpinning these systems is reinforcement learning with verifiable reward ( rlvr ), which assigns reward to verifiable solutions through rule - based verification. these models generate extended chain - of - thought ( cot ) reasoning ( wei et al., 2023 ) to solve challenging problems in domains like mathematical olympiads ( he et al., 2024b ). however, a notable bottleneck emerges during rl training that limits its scalability, frequently culminating in a performance plateau and subsequent collapse. this failure is consistently accompanied by a rapid decay in policy entropy, indicating a severe loss of exploration capacity ( yu et al., 2025 ; cui et al., 2025 ; wang et al., 2025 ). previous approaches have recognized this declining exploration, attempting to address it through various entropy control mechanisms. methods such as adaptive entropy regularization ( he et al., 2025 ), high entropy change blocking ( cui et al., 2025 ), or selective token updates ( wang et al., 2025 ) aim to maintain higher entropy as a proxy for exploration. however, relying on overall entropy can be an indirect and imprecise tool. an indiscriminate focus on maximizing randomness risks amplifying noise and destabilizing training ( omer veysel [ [UNK] ] [UNK] agatan & akg [UNK] un [UNK], 2025 ), suggesting a deeper issue beyond simply the quantity of randomness. our analysis suggests the performance bottleneck may stem from the systematic elimination of valuable lowprobability exploratory tokens. we term these tokens * * reasoning sparks * * ; they include words like “ wait ”, “ however ”, or “ perhaps ”, which often serve as logical connectives or expressions of uncertainty that naturally initiate diverse reasoning pathways ( figure 1a ). as the aggregated violin plots in figure 1c show, standard grpo training suppresses the low - probability sampling of these important exploratory tokens, causing the suppression"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 1,
    "text": "al., 2025 ), or selective token updates ( wang et al., 2025 ) aim to maintain higher entropy as a proxy for exploration. however, relying on overall entropy can be an indirect and imprecise tool. an indiscriminate focus on maximizing randomness risks amplifying noise and destabilizing training ( omer veysel [ [UNK] ] [UNK] agatan & akg [UNK] un [UNK], 2025 ), suggesting a deeper issue beyond simply the quantity of randomness. our analysis suggests the performance bottleneck may stem from the systematic elimination of valuable lowprobability exploratory tokens. we term these tokens * * reasoning sparks * * ; they include words like “ wait ”, “ however ”, or “ perhaps ”, which often serve as logical connectives or expressions of uncertainty that naturally initiate diverse reasoning pathways ( figure 1a ). as the aggregated violin plots in figure 1c show, standard grpo training suppresses the low - probability sampling of these important exploratory tokens, causing the suppression of _ reasoning sparks _. furthermore, we find that indiscriminately boosting randomness amplifies the low - probability sampling of irrelevant tokens ( e. g., “ cost ”, “ fine ” ), which are semantically out of context for the mathematical reasoning task. we refer to the low - probability appearance of these irrelevant tokens as noise. this amplification leads to an even faster performance collapse than the baseline, as shown in figure 1b. _ ∗ _ equal contribution. - work completed during an internship at tencent. - correspondence to bo zhou : chaysezhou @ tencent. com. 1 ` ` ` the answer is 2. ` ` ` 99 % 1 % ` ` ` answer : \\ boxed { 2 } wait, [UNK], answer : \\ boxed { 3 } ` ` ` ( a ) _ reasoning sparks _ : low - probability exploratory tokens that initiates a new reasoning path. | 0. 60 cy ( grpo + entrop lp - reg | py loss | | - - - | - - - | | 0 < br > 200 < br > 40 < br > trai < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > < br > < br > < br > 0 < br > 200 < br > 40 < br > trai < br > 0. 0 < br > 0. 1 < br > 0. 2 < br > 0. 3 < br > 0. 4 < br > 0. 5 < br > 0. 6 < br > train entropy < br > gr < br > ~ ~ gr ~ ~ < br > lp ~ ~ - ~ ~ | | | 0 < br > 200 < br > 40 < br > trai < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > < br > < br > < br > 0 < br > 200 < br > 40 < br > trai < br > 0. 0 < br > 0. 1 < br > 0. 2 < br > 0. 3 < br > 0. 4 < br > 0. 5 < br > 0. 6 < br > train entropy < br > gr < br > ~ ~ gr ~ ~ < br > lp ~ ~ - ~ ~ | | ( b ) training dynamics ( d ) aggregated distribution of observed sampling probabilities for a class of irrelevant tokens ( e. g., “ cost ”, “ fine ” ). ( c ) aggregated distribution of observed sampling probabilities for a class of meaningful exploratory tokens ( e. g., “ wait ”, “ however ” ). figure 1 : selectively preserving low - probability tokens is key to overcoming performance plateaus in reasoning rl. * * ( a ) * * an illustration of a _ reasoning spark _. * * ( b ) * * standard grpo training reaches a performance plateau and collapses, accompanied by decaying entropy. an indiscriminate entropy bonus ( grpo + entropy loss ) leads to an even faster collapse. * * ( c ) * * we reveal the cause : grpo systematically suppresses the low - probability sampling of important exploratory tokens ( like “ wait ” ), and forces these tokens ’ sampling distributions to collapse towards high probabilities. ent - loss fails to fix this. in contrast, our method, lp - reg, successfully preserves a healthy, wide distribution, sustaining exploration. * * ( d ) * * the failure of entropy bonuses is explained by their indiscriminate nature : they amplify the low - probability sampling of irrelevant tokens, creating noise and thereby degrading exploration quality. the aggregated statistics in ( c ) and ( d ) demonstrate a systemic effect beyond single - token instances. detailed plots for individual tokens are available in appendix b. 1. these findings present a central challenge : a successful exploration strategy should protect valuable _ reasoning _ _ sparks _ without simultaneously amplifying the destructive effects of irrelevant noise"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 2,
    "text": "##minate entropy bonus ( grpo + entropy loss ) leads to an even faster collapse. * * ( c ) * * we reveal the cause : grpo systematically suppresses the low - probability sampling of important exploratory tokens ( like “ wait ” ), and forces these tokens ’ sampling distributions to collapse towards high probabilities. ent - loss fails to fix this. in contrast, our method, lp - reg, successfully preserves a healthy, wide distribution, sustaining exploration. * * ( d ) * * the failure of entropy bonuses is explained by their indiscriminate nature : they amplify the low - probability sampling of irrelevant tokens, creating noise and thereby degrading exploration quality. the aggregated statistics in ( c ) and ( d ) demonstrate a systemic effect beyond single - token instances. detailed plots for individual tokens are available in appendix b. 1. these findings present a central challenge : a successful exploration strategy should protect valuable _ reasoning _ _ sparks _ without simultaneously amplifying the destructive effects of irrelevant noise. to address this challenge, we introduce low - probability regularization ( lp - reg ). the primary goal of lp - reg is to preserve valuable low - probability tokens via regularization. to avoid amplifying noise, the method leverages a key observation : within the low - probability range, meaningful exploratory tokens ( like “ wait ” ) consistently exhibit a higher average probability than irrelevant noise ( like “ cost ” ) in the immediate next - token prediction. based on this statistical distinction, lp - reg first discards low - probability tokens presumed to be noise using a probability threshold. it then redistributes the probability mass from these discarded tokens among the remaining candidates. this process constructs a less - noisy proxy distribution where valuable low - probability tokens are preserved and their relative probabilities amplified. finally, lp - reg penalizes the deviation of the original policy from this proxy using a forward kl divergence, which selectively protects the low - probability tokens that were preserved in the less - noisy proxy distribution. our experimental evaluation demonstrates the effectiveness of lp - reg. our method enables stable on - policy training for around 1, 000 steps, a regime where many entropy - control methods have collapsed, resulting in better performance. on five widely used math benchmarks, this results in a 60. 17 % average accuracy on qwen3 - 14b - base, improving upon prior methods by 2. 66 %. our contributions are summarized as follows : - in contrast to prior work focusing on overall policy entropy, we identify the suppression of _ reasoning _ _ sparks _ as a key issue and provide evidence that their preservation is crucial for sustained performance. - we introduce low - probability regularization ( lp - reg ), a method that creates a more stable exploratory environment by filtering out presumed meaningless noise to protect the remaining low - probability tokens. - we demonstrate through extensive experiments that lp - reg achieves state - of - the - art performance, while also enabling stable on - policy training over extended periods where baselines collapse. - we provide a comprehensive analysis showing that our approach of filtering presumed meaningless noise yields superior results compared to indiscriminate entropy - control methods. 2 * * 2 * * * * related work * * * * reinforcement learning for llms * * recently, reinforcement learning has become the dominant framework for enhancing the reasoning abilities of large language models ( llms ) ( openai et al., 2024 ; deepseek - ai et al., 2025 ). by leveraging automatic checkers or symbolic verification, reinforcement learning with verifiable rewards ( rlvr ) achieved further breakthroughs in improving the reasoning capability of llms ( shao et al., 2024a ; yang et al., 2025 ; team et al., 2025 ). based on rlvr and grpo ( shao et al., 2024a ), subsequent methods such as dapo yu et al. ( 2025 ), vapo ( yue et al., 2025 ), and other policy optimization variants ( zhao et al., 2025 ; cui et al., 2025 ; zheng et al., 2025 ) have been proposed to improve the stability, efficiency, and scalability of rl for reasoning models. * * entropy collapse in rl training * * a recurring difficulty in training reasoning models with rl is the rapid collapse of policy entropy during the early stages of training. this phenomenon, which reflects excessive exploitation and insufficient exploration, has been widely recognized as a bottleneck for scaling rl in reasoning models. to mitigate collapse, researchers have explored several directions, including selectively regularizing updates at high - entropy “ forking ” tokens ( wang et al., 2025 ), amplifying advantages at exploratory positions ( cheng et al., 2025 ), modifying clipping strategies ( yu et al., 2025 ; zhao et al., 2025 ; cui et al., 2025 ; zheng et al., 2025 ), or doing weight clipping ( minimax"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 3,
    "text": "policy optimization variants ( zhao et al., 2025 ; cui et al., 2025 ; zheng et al., 2025 ) have been proposed to improve the stability, efficiency, and scalability of rl for reasoning models. * * entropy collapse in rl training * * a recurring difficulty in training reasoning models with rl is the rapid collapse of policy entropy during the early stages of training. this phenomenon, which reflects excessive exploitation and insufficient exploration, has been widely recognized as a bottleneck for scaling rl in reasoning models. to mitigate collapse, researchers have explored several directions, including selectively regularizing updates at high - entropy “ forking ” tokens ( wang et al., 2025 ), amplifying advantages at exploratory positions ( cheng et al., 2025 ), modifying clipping strategies ( yu et al., 2025 ; zhao et al., 2025 ; cui et al., 2025 ; zheng et al., 2025 ), or doing weight clipping ( minimax et al., 2025 ; su et al., 2025 ). while these methods primarily operate by monitoring policy entropy, which is correlational rather than causal to exploration, our analysis delves directly into the next - token prediction distribution. this allows for a more semantically grounded and causally - informed investigation of the probabilities of individual candidates and their role in exploration dynamics. * * intrinsic confidence of llms * * as the capabilities of large language models ( llms ) have rapidly advanced, they have demonstrated an increasingly strong and reliable sense of intrinsic confidence ( saurav et al., 2022 ; loka et al., 2024 ; amir et al., 2025 ). research investigates how these intrinsic confidence signals, often reflected in the next - token prediction distribution, can guide complex reasoning and exploration ( amirhosein et al., 2025 ; xuezhi & denny, 2024 ; xuandong et al., 2025 ). studies have shown that tokens with higher relative probabilities in the next - token prediction are often more contextually appropriate than their lower - probability counterparts ( nguyen et al., 2025 ; xu et al., 2025 ; fu et al., 2025 ). building on this, some work has explored entropy minimization, which sharpens the model ’ s confidence distribution. this approach can improve inference performance by encouraging the model to commit to consistent and high - confidence solution paths ( gao et al., 2025 ; agarwal et al., 2025 ). our work builds upon a similar insight, leveraging the model ’ s intrinsic confidence to distinguish between valuable _ reasoning _ _ sparks _ and irrelevant noise within this low - probability range. * * 3 * * * * preliminaries * * * * 3. 1 * * * * reinforcement learning with verifiable rewards * * reinforcement learning ( rl ) has played a critical role in llms ( murphy, 2024 ). formally, _ j _ rl ( _ * * θ * * _ ) = * * e * * ( _ q _, _ a _ ) _ ∼ _ _ d _, _ o _ _ ∼ _ _ π _ _ θ _ ( _ · | _ _ q _ ) _ r _ ( _ o _, _ a _ ), ( 1 ) where _ r _ ( _ o _, _ a _ ) denotes the reward assigned to an output _ o _ given a reference answer _ a _. in reinforcement learning with verifiable rewards ( rlvr ), this reward is computed through rule - based functions, such as math - verify [ 1 ]. recent studies have demonstrated that large - scale rlvr encourages models to perform more deliberative reasoning by producing extended chains of thought prior to the final prediction, thereby substantially improving their capacity to solve complex problems ( deepseek - ai et al., 2025 ). in practice, eq. 1 is typically optimized using policy gradient methods, such as proximal policy optimization ( ppo ) ( schulman et al., 2017 ) and group relative policy optimization ( grpo ) ( shao et al., 2024b ). * * 3. 2 * * * * group - relative policy optimization * * grpo is a representative actor - only policy gradient method for optimizing llms. it directly estimates the advantage of each token by leveraging multiple samples drawn from the same prompt. formally, the advantage is defined as _ a _ _ i _, _ t _ = _ [ r ] _ [ ( ] _ [ o ] _ _ [ i ] _ [ ) ] _ [ − ] _ std [ mean ] ( _ g _ ) [ ( ] _ [ g ] _ [ ) ], ( 2 ) where _ { _ _ o _ 1,..., _ o _ _ g _ _ } _ are independent outputs sampled from the same prompt, with group size _ g _, _ g _ ="
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 4,
    "text": "such as proximal policy optimization ( ppo ) ( schulman et al., 2017 ) and group relative policy optimization ( grpo ) ( shao et al., 2024b ). * * 3. 2 * * * * group - relative policy optimization * * grpo is a representative actor - only policy gradient method for optimizing llms. it directly estimates the advantage of each token by leveraging multiple samples drawn from the same prompt. formally, the advantage is defined as _ a _ _ i _, _ t _ = _ [ r ] _ [ ( ] _ [ o ] _ _ [ i ] _ [ ) ] _ [ − ] _ std [ mean ] ( _ g _ ) [ ( ] _ [ g ] _ [ ) ], ( 2 ) where _ { _ _ o _ 1,..., _ o _ _ g _ _ } _ are independent outputs sampled from the same prompt, with group size _ g _, _ g _ = _ { _ _ r _ ( _ o _ 1 ),..., _ r _ ( _ o _ _ g _ ) _ } _ denotes their associated rewards, and _ r _ ( _ o _ _ i _ ) is the reward of output _ o _ _ i _. in this formulation, _ a _ _ i _, _ t _ represents the advantage of the _ t _ - th token in _ o _ _ i _. the policy is then optimized on the basis of these advantages using the ppo 1 [ https : / / github. com / huggingface / math - verify ] ( https : / / github. com / huggingface / math - verify ) 3 surrogate objective : _ j _ grpo ( _ * * θ * * _ ) = * * e * * ( _ q _, _ a _ ) _ ∼ _ _ d _, _ { _ _ o _ _ i _ _ } _ _ ig _ = 1 _ [ ∼ ] _ _ [ π ] _ _ * * [ θ ] * * _ old [ ( ] _ [ · | ] _ _ [ q ] _ [ ) ] _ | _ _ o _ _ i _ _ | _ # # # ∑ _ t _ = 1 ( 3 ) min _ r _ _ i _, _ t _ _ a _ _ i _, _ t _, clip _ r _ _ i _, _ t _, 1 _ − _ _ [UNK] _, 1 + _ [UNK] _ _ a _ _ i _, _ t _ _ − _ _ β d _ kl ( _ π _ _ * * θ * * _ _ ∥ _ _ π _ ref ), 1 _ g _ _ g _ # # # ∑ _ i _ = 1 1 _ | _ _ o _ _ i _ _ | _ where _ β _ controls the strength of kl regularization between the current policy _ π _ _ θ _ and the reference policy _ π _ ref. the probability ratio _ π _ _ θ _ _ o _ _ i _, _ t _ _ | _ _ q _, _ o _ _ i _, _ < _ _ t _ _ r _ _ i _, _ t _ = _ π _ _ θ _ old ~ ~ ~ ~ _ o _ _ i _, _ t _ _ | _ _ q _, _ o _ _ i _, _ < _ _ t _ ~ ~ ~ ~ ( 4 ) serves as the importance sampling weight for off - policy training, where _ π _ _ θ _ old denotes the behavior policy. the hyperparameter _ [UNK] _ specifies the clipping ratio, which constrains the updated policy from deviating excessively from the behavior policy, thereby ensuring stability during optimization. * * 4 * * * * low - probability regularization * * to address the premature elimination of valuable _ reasoning sparks _, we propose a regularization method termed * * low - * * * * probability regularization ( lp - reg ) * *. this method is designed to be integrated into policy gradient algorithms to create a more stable exploratory environment. the central idea is to leverage the model ’ s own predictive distribution to construct a less - noisy proxy for regularization, preserving low - probability tokens. * * 4. 1 * * * * proxy distribution * * _ π _ * * proxy * * the foundation of lp - reg is the construction of a proxy distribution, which represents a filtered variant of the current policy _ π _ _ * * θ * * _. it is constructed in two steps : | col1 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | col10 | col11 | col12 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | -"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 5,
    "text": "- * * * * probability regularization ( lp - reg ) * *. this method is designed to be integrated into policy gradient algorithms to create a more stable exploratory environment. the central idea is to leverage the model ’ s own predictive distribution to construct a less - noisy proxy for regularization, preserving low - probability tokens. * * 4. 1 * * * * proxy distribution * * _ π _ * * proxy * * the foundation of lp - reg is the construction of a proxy distribution, which represents a filtered variant of the current policy _ π _ _ * * θ * * _. it is constructed in two steps : | col1 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | col10 | col11 | col12 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | = 0. | 02 | | | | | | | | | | ( b ) renormalized policy pro | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | col10 | oxy | col12 | col13 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | pr | pr | pr | pr | pr | pr | pr | pr | pr | pr | xy | xy | xy | | | | | | | | | | | | | | | | | | | | | | reno | rmalize | sum | = 1 | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 < br > 2 < br > 4 < br > 6 < br > 8 < br > 10 < br > 12 < br > 14 < br > 16 < br > 18 < br > token index | 0 < br > 2 < br > 4 < br > 6 < br > 8 < br > 10 < br > 12 < br > 14 < br > 16 < br > 18 < br > token index | 0 < br > 2 < br > 4 < br > 6 < br > 8 < br > 10 < br > 12 < br > 14 < br > 16 < br > 18 < br > token index | 0 < br > 2 < br > 4 < br > 6 < br > 8 < br > 10 < br > 12 < br > 14 < br > 16 < br > 18 < br > token index | 0 < br > 2 < br > 4 < br > 6 < br > 8 < br > 10 < br > 12 < br > 14 < br > 16 < br > 18 < br > token index | 0 < br > 2 < br > 4 < br > 6 < br > 8 < br > 10 < br > 12 < br > 14 < br > 16 < br > 18 < br > token index | 0 < br > 2 < br > 4 < br > 6 < br > 8 < br > 10 < br > 12 < br > 14 < br > 16 < br > 18 < br > token index | 0 < br > 2 < br > 4 < br > 6 < br > 8 < br > 10 < br > 12 < br > 14 < br > 16 < br > 18 < br > token index | 0 < br > 2 < br > 4 < br > 6 < br > 8 < br > 10 < br > 12 < br > 14 < br > 16 < br > 18 < br > token index | 0 < br > 2 < br > 4 < br > 6 < br > 8 < br > 10 < br > 12 < br > 14 < br > 16 < br > 18 < br > token index | 0 < br > 2 < br > 4 < br > 6 < br > 8 < br > 10 < br > 12 < br > 14 < br > 16 < br > 18 < br > token index | 0 < br > 2 < br > 4 < br > 6 < br > 8 < br > 10 < br > 12 < br > 14 < br > 16 < br > 18 < br > token index | 0 < br > 2 < br > 4 < br > 6 < br > 8 < br > 10 < br > 12 < br"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 6,
    "text": "| 0 < br > 2 < br > 4 < br > 6 < br > 8 < br > 10 < br > 12 < br > 14 < br > 16 < br > 18 < br > token index | 0 < br > 2 < br > 4 < br > 6 < br > 8 < br > 10 < br > 12 < br > 14 < br > 16 < br > 18 < br > token index | 0 < br > 2 < br > 4 < br > 6 < br > 8 < br > 10 < br > 12 < br > 14 < br > 16 < br > 18 < br > token index | 0 < br > 2 < br > 4 < br > 6 < br > 8 < br > 10 < br > 12 < br > 14 < br > 16 < br > 18 < br > token index | 0 < br > 2 < br > 4 < br > 6 < br > 8 < br > 10 < br > 12 < br > 14 < br > 16 < br > 18 < br > token index | figure 2 : an example of probability renormalization. _ π _ proxy assigns zero probability to tokens with _ π _ _ * * θ * * _ _ ≤ _ _ τ _ and renormalizes the probability mass to tokens with _ π _ _ * * θ * * _ _ > _ _ τ _. 1. * * filtering noise tokens : * * we first filter out a set of low - confidence tokens, which are presumed to be noise, defined as those whose probability _ π _ _ * * θ * * _ ( _ o _ _ | · _ ) is under a threshold _ τ _. this threshold controls the filtering strategy, for which we explore two primary choices : - * * fixed threshold : * * a simple approach where _ τ _ is a constant hyperparameter, e. g., 0. 02. - * * min - p threshold : * * following ( nguyen et al., 2025 ), _ τ _ is defined relative to the peak probability : _ τ _ = _ κ _ _ · _ max _ o _ _ ′ _ _ ∈ _ _ v _ _ π _ _ * * θ * * _ ( _ o _ _ [ ′ ] _ _ | · _ ), where _ κ _ _ ∈ _ ( 0, 1 ) is a hyperparameter. this makes the filtering adaptive to the distribution ’ s sharpness. our primary experiments employ the min - p strategy for its adaptiveness, though fixed thresholds are also shown to be effective in our ablation studies. 2. * * probability renormalization : * * as shown in figure 2, the proxy distribution _ π _ proxy assigns zero probability to tokens filtered out in the previous step and renormalizes the probability mass across the remaining tokens : _ π _ proxy ( _ o _ _ | · _ ) = _ π _ _ * * θ * * _ ( _ o _ _ | · _ ) ∑ _ o _ _ ′ _ s. t. _ π _ _ * * θ * * _ ( _ o _ _ ′ | · _ ) _ > _ _ τ _ _ π _ _ * * θ * * _ ( _ o _ ~ ~ _ [ ′ ] _ ~ ~ _ | · _ ) if _ π _ _ * * θ * * _ ( _ o _ _ | · _ ) _ > _ _ τ _. ( 5 ) 0 otherwise this process effectively treats tokens with low relative probabilities as potential noise, while preserving all others to form a high - confidence reference. 4 * * 4. 2 * * * * low - probability regularization objective * * the low - probability regularization ( lp - reg ) penalty is integrated into the grpo framework as a selective regularization term. the final objective function is : _ | _ _ o _ _ i _ _ | _ # # # ∑ _ t _ = 1 _ j _ ( _ * * θ * * _ ) = * * e * * _ b∼d _, ( _ q _, _ a _ ) _ ∼b _, _ { _ _ o _ _ i _ _ } _ _ ig _ = 1 _ [ ∼ ] _ _ [ π ] _ _ * * [ θ ] * * _ old [ ( ] _ [ · | ] _ _ [ q ] _ [ ) ] 1 ∑ _ i _ _ [ g ] _ = 1 _ [ | ] _ _ [ o ] _ _ [ i ] _ _ [ | ] _ _ g _ # # # ∑ _ i _ = 1 clip ( _ r _ _ i _, _ t _ ( _ * * θ * * _ ), 0, _ u _ ) _ · _ _ a _ _ i _, _ t _ _ − _ _ β _ _ · _ _ i _ _ π _ _ * * θ * * _ ( _ o _ _ i _, _ t _ _ |"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 7,
    "text": "= * * e * * _ b∼d _, ( _ q _, _ a _ ) _ ∼b _, _ { _ _ o _ _ i _ _ } _ _ ig _ = 1 _ [ ∼ ] _ _ [ π ] _ _ * * [ θ ] * * _ old [ ( ] _ [ · | ] _ _ [ q ] _ [ ) ] 1 ∑ _ i _ _ [ g ] _ = 1 _ [ | ] _ _ [ o ] _ _ [ i ] _ _ [ | ] _ _ g _ # # # ∑ _ i _ = 1 clip ( _ r _ _ i _, _ t _ ( _ * * θ * * _ ), 0, _ u _ ) _ · _ _ a _ _ i _, _ t _ _ − _ _ β _ _ · _ _ i _ _ π _ _ * * θ * * _ ( _ o _ _ i _, _ t _ _ | _ _ q _, _ o _ _ i _, _ < _ _ t _ ) _ < _ _ δ _ _ ρ _ _ [ b ] _ _ [ ∧ ] _ _ [ π ] _ [ proxy ] [ ( ] _ [ o ] _ _ i _, _ t _ _ [ | ] _ _ [ q ] _ [, ] _ [ o ] _ _ i _, _ < _ _ t _ [ ) ] _ [ > ] _ [ 0 ] _ [ ∧ ] _ _ [ a ] _ _ i _, _ t _ _ [ < ] _ [ 0 ] ( 6 ) _ · d _ kl ( _ π _ proxy ( _ · | _ _ q _, _ o _ _ i _, _ < _ _ t _ ) _ ∥ _ _ π _ _ * * θ * * _ ( _ · | _ _ q _, _ o _ _ i _, _ < _ _ t _ ) ) [ ] the first term is the policy gradient objective from grpo. we modify its clipping by removing the lower bound to avoid clipping low - probability exploratory actions and adding a large upper bound _ u _ for numerical stability. the second term is the lp - reg penalty, designed to protect _ reasoning sparks _. it is activated by the indicator function _ i _ [ _ · _ ] only for tokens that satisfy three conditions simultaneously : first, their sampling probability _ π _ _ * * θ * * _ is below a dynamic low - percentile threshold _ δ _ _ ρ _ _ [ b ] _ [, which is calculated as the lowest ] _ [ ρ ] _ [ - th percentile of the sampling probabilities ] of all tokens within the current training batch _ b _ ; second, their probability in the proxy distribution _ π _ proxy is greater than zero ; and third, the token receives a negative advantage signal ( _ a _ _ i _, _ t _ _ < _ 0 ). this final condition ensures the regularization applies exclusively to tokens receiving a negative learning signal, preventing their potential over - penalization while leaving updates from positive experiences unaffected. we use the forward kl divergence, _ d _ kl ( _ π _ proxy _ ∥ _ _ π _ _ * * θ * * _ ) as the regularization function. it imposes a significant penalty when _ π _ _ * * θ * * _ ( _ o _ _ | · _ ) approaches zero for a token _ o _ with non - zero probability in _ π _ proxy, providing a targeted penalty against token elimination without forcing the policy to strictly match the heuristic proxy distribution. * * 5 * * * * experiments * * * * 5. 1 * * * * experimental setup * * * * baselines * * we compare lp - reg against a suite of strong baselines, including a foundational algorithm and several state - of - the - art methods designed to enhance exploration through entropy control. our primary baseline is * * grpo * * ( shao et al., 2024a ), a value - free policy optimization algorithm that employs group - relative advantage estimation, making it a common choice for rlvr. to represent classical entropy regularization methods, we implement * * grpo + entropy loss * *, which directly incorporates the principles of maximum entropy rl by adding a policy entropy bonus to the grpo objective function. we also compare against several advanced methods : * * clip - higher * * ( yu et al., 2025 ), a core component of dapo that encourages higher entropy by using an asymmetric clipping range in the ppo objective ; * * selective high - entropy training ( 80 / 20 ) * * ( wang et al., 2025 ), a method that restricts policy gradient updates to only the top 20 % of tokens with the highest generation entropy ; * * kl - cov * * ( cui et al., 2025 ), which prevents entropy collapse by applying a selective"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 8,
    "text": "grpo * * ( shao et al., 2024a ), a value - free policy optimization algorithm that employs group - relative advantage estimation, making it a common choice for rlvr. to represent classical entropy regularization methods, we implement * * grpo + entropy loss * *, which directly incorporates the principles of maximum entropy rl by adding a policy entropy bonus to the grpo objective function. we also compare against several advanced methods : * * clip - higher * * ( yu et al., 2025 ), a core component of dapo that encourages higher entropy by using an asymmetric clipping range in the ppo objective ; * * selective high - entropy training ( 80 / 20 ) * * ( wang et al., 2025 ), a method that restricts policy gradient updates to only the top 20 % of tokens with the highest generation entropy ; * * kl - cov * * ( cui et al., 2025 ), which prevents entropy collapse by applying a selective kl - divergence penalty to tokens with the highest covariance between their log probabilities and advantages ; and * * gspo * * ( zheng et al., 2025 ), which modifies the clipping mechanism to operate at the sequence level to promote higher training entropy. * * training settings * * all experiments are conducted within the verl ( sheng et al., 2024 ) framework to ensure a standardized and fair comparison. we use two base models for our experiments : qwen3 - 14b - base and qwen2. 532b. the 14b models are trained on 32 nvidia h20 gpus, while the 32b model is trained on 64 nvidia h20 gpus, with an average training step time of 600 _ − _ 1400 seconds. for the reinforcement learning from verifier rewards ( rlvr ) phase, models are trained on the dapo - math - 17k yu et al. ( 2025 ) dataset with a maximum response length of 8, 192 tokens. we use a global batch size of 256. for off - policy methods, we use a mini - batch size of 32, resulting in 8 gradient updates per rollout. to ensure a fair comparison, a “ step ” in our experimental results consistently refers to a single rollout for all methods. consequently, each reported step for off - policy training corresponds to 8 gradient updates. a constant learning rate of 1 _ × _ 10 _ [ − ] _ [ 6 ] is applied without a warmup schedule. we set the group number as 8 for all grpo - based methods. to ensure numerical stability, we set the policy gradient ’ s clipping by setting the upper bound of the importance sampling ratio to _ u _ = 10. for our proposed lp - reg, which uses the min - p threshold, we set the probability percentile threshold _ ρ _ to 0. 5 % for qwen2. 5 - 32b - base and 1 % for qwen3 - 14b - base, the kl regularization coefficient _ β _ to 1. 0, and the min - p ratio _ κ _ to 0. 02. the proxy distribution, _ π _ proxy, is constructed from the data - generating policy ( _ π _ _ θ _ old in the off - policy setting and the current policy _ π _ _ * * θ * * _ in the on - policy setting ). for all baseline methods, we adopt the hyperparameters specified in their original public implementations to ensure a faithful reproduction. specifically for the grpo + entropy loss baseline, we set the entropy coefficient to 0. 002 within the verl framework. 5 * * evaluation * * for evaluation, we assess model performance across five diverse mathematical reasoning benchmarks : aime24 ( maa ), aime25 ( maa ), math - 500 ( hendrycks et al., 2021 ), olympiadbench ( he et al., 2024a ), and minerva math ( lewkowycz et al., 2022 ). following ( cui et al., 2025 ), we employ distinct decoding strategies based on the benchmark. for aime24 and aime25, which have smaller test sets, we use sampled decoding with a temperature of 0. 6 and generate 16 independent responses per problem to obtain a robust performance estimate. for the remaining benchmarks, including math - 500, olympiadbench, and minerva, we utilize greedy decoding to evaluate performance. * * 5. 2 * * * * results * * as shown in figure 3 and table 1, lp - reg achieves state - of - the - art performance across five challenging mathematical reasoning benchmarks on both 14b and 32b model scales. on the qwen3 - 14b model, on - policy lp - reg sets a new benchmark with an average accuracy of 60. 17 %, surpassing the next best method, 80 / 20, by 2. 66 %. notably,"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 9,
    "text": "lewkowycz et al., 2022 ). following ( cui et al., 2025 ), we employ distinct decoding strategies based on the benchmark. for aime24 and aime25, which have smaller test sets, we use sampled decoding with a temperature of 0. 6 and generate 16 independent responses per problem to obtain a robust performance estimate. for the remaining benchmarks, including math - 500, olympiadbench, and minerva, we utilize greedy decoding to evaluate performance. * * 5. 2 * * * * results * * as shown in figure 3 and table 1, lp - reg achieves state - of - the - art performance across five challenging mathematical reasoning benchmarks on both 14b and 32b model scales. on the qwen3 - 14b model, on - policy lp - reg sets a new benchmark with an average accuracy of 60. 17 %, surpassing the next best method, 80 / 20, by 2. 66 %. notably, lp - reg ’ s advantage is more pronounced on the newer qwen3 - 14b base model compared to the older qwen2. 5 - 32b. we hypothesize that as base models improve, their capacity for nuanced, low - probability reasoning increases, creating a richer substrate for the emergence of valuable _ reasoning sparks _, which lp - reg can then effectively protect and leverage. our experiments consistently show the superiority of on - policy training over off - policy methods across 14b and 32b scales. this is due to the inherent stability of on - policy updates, which avoid distribution shifts caused by mismatched data - sampling and training policies. off - policy methods, such as clip - higher, often rely on importance sampling clipping, leading to instability. while competitive on qwen2. 5 - 32b, clip - higher ’ s performance drops on qwen3 - 14b, highlighting its fragility. in contrast, lp - reg ’ s self - contained, policy - intrinsic regularization ensures its effectiveness in both on - policy and off - policy settings, unlike competing methods that are heavily reliant on off - policy importance sampling. beyond raw performance, lp - reg demonstrates a distinct entropy signature indicative of a healthy explorationexploitation balance. as shown in figure 3, methods like clip - higher induce a continuous, often artificial increase in policy entropy. lp - reg, however, facilitates a dynamic, multi - phase entropy trajectory : entropy initially decreases as the model learns core reasoning patterns, then gradually increases to foster exploration as performance improves, and finally stabilizes within a healthy range as accuracy converges. this adaptive behavior stems from our confidenceaware regularization, which selectively protects _ reasoning sparks _ without amplifying low - probability out - of - context irrelevant noise. method aime24 aime25 math - 500 minerva olympiad bench avg. * * qwen2. 5 - 32b - base * * * * qwen3 - 14b - base * * table 1 : main results on five mathematical reasoning benchmarks across two model scales. our method, lp - reg, achieves the best average performance on both models. on - policy ( on. ) and off - policy ( off. ) training methods are highlighted with distinct colors. 6 | ( off. ) grpo ( | col2 | | - - - | - - - | | | | | | | | | | | | | | | | | col1 | col2 | | - - - | - - - | | 5 < br > 0 | | | 5 < br > 0 | | figure 3 : training dynamics on the qwen3 - 14b - base model. to best illustrate the performance differences, we compare the top - performing methods. lp - reg demonstrates superior and more stable performance throughout training. full training dynamics for the qwen2. 5 - 32b model are available in appendix a. 1. figure 4 : ablation studies for core components of lp - reg on the qwen3 - 14b - base model. the results confirm that targeting our noise filtering threshold _ τ _ is critical for stable performance. the adaptiveness of the min - p threshold is also shown to be beneficial over a fixed one. * * 5. 3 * * * * ablation study * * we conduct a series of ablation studies to analyze the core components of lp - reg and validate our key design choices. * * importance of noise filtering. * * lp - reg only protects tokens deemed meaningful by the proxy distribution ( _ π _ proxy _ > _ 0 ). to test this, we remove the filter and fork all tokens below the noise threshold _ τ _ from contributing to gradient updating ( lp - reg w / o _ τ _ ). figure 4 shows that this leads to a catastrophic performance collapse and entropy explosion. this confirms that filtering is critical to ignore the extreme tail of the distribution, which consists of irrelevant noise that destabilizes training if regularized. * * dynamic"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 10,
    "text": "on the qwen3 - 14b - base model. the results confirm that targeting our noise filtering threshold _ τ _ is critical for stable performance. the adaptiveness of the min - p threshold is also shown to be beneficial over a fixed one. * * 5. 3 * * * * ablation study * * we conduct a series of ablation studies to analyze the core components of lp - reg and validate our key design choices. * * importance of noise filtering. * * lp - reg only protects tokens deemed meaningful by the proxy distribution ( _ π _ proxy _ > _ 0 ). to test this, we remove the filter and fork all tokens below the noise threshold _ τ _ from contributing to gradient updating ( lp - reg w / o _ τ _ ). figure 4 shows that this leads to a catastrophic performance collapse and entropy explosion. this confirms that filtering is critical to ignore the extreme tail of the distribution, which consists of irrelevant noise that destabilizes training if regularized. * * dynamic vs. fixed threshold. * * we conduct a comparison between the dynamic min - p noise threshold ( lp - reg w / dynamic _ τ _ ) and the fixed noise threshold ( lp - reg w / fixed _ τ _ ) in section 4. 1. as shown in figure 4, the fixed threshold underperforms compared to the dynamic threshold, which we adopt as the default. however, it still significantly surpasses the standard grpo. this indicates that while the core filtering principle is effective, the dynamic nature of min - p provides a more robust estimate of the model ’ s confidence across different contexts, better preserving genuine _ reasoning sparks _. we conduct further ablation studies on the high - entropy token regularization and reverse kl regularization. for detailed results and analysis, please refer to appendix a. 2. * * 6 * * * * analysis * * to understand the mechanisms behind lp - reg ’ s performance, we conduct a series of analyses focusing on how it overcomes the exploration bottleneck by targeting and preserving valuable reasoning tokens. * * 6. 1 * * * * probability - entropy distribution of exploratory tokens * * we begin by exploring the distinction between low - probability tokens and high - entropy tokens. figure 5 highlights this contrast by comparing tokens from the top 1 % lowest probability with those from the top 1 % highest entropy. the difference is striking : low - probability tokens frequently include semantically meaningful exploratory markers such as _ “ but, ” “ wait, ” “ perhaps, ” _ and _ “ alternatively, ” _ which often signal a shift in the reasoning trajectory. in 7 figure 5 : the word cloud statistics. contrast, high - entropy tokens are dominated by common functional terms ( e. g., _ “ sqrt, ” “ times ” _ ) or formatting symbols ( e. g., _ \\ _ n ), which carry little exploratory intent. this explains why entropy - based regularization often fails to enhance exploration : it confuses noise with exploration. however, the set of low - probability tokens is also not uniformly useful. it also includes noisy artifacts such as spurious newline characters ( _ \\ _ n ) or formatting debris, whose regularization can destabilize training rather than enhance reasoning. to mitigate this, lp - reg applies a threshold _ τ _ that filters out such noise. ablation studies in section 5. 3 confirm the necessity of this step : removing the threshold results in unstable training dynamics and degraded reasoning performance. thus, lp - reg ’ s effectiveness stems not only from targeting low - probability tokens but also from selectively excluding irrelevant noise. * * 6. 2 * * * * sampling dynamics of exploratory tokens * * | 3. 0 < br > 2. 5 | col2 | col3 | mea < br > mean e | n prob : 0. < br > ntropy : 0. | 9099 ± 0. 2 < br > 1576 ± 0. 2 | 036 < br > 717 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > sampled probability < br > 0. 0 < br > 0. 5 < br > 1. 0 < br > 1. 5 < br > 2. 0 < br > < br > | | | | | | | | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > sampled probability < br > 0. 0 < br > 0. 5 < br > 1. 0 < br > 1. 5 < br > 2. 0 < br > < br > | | | | | | | | 0. 0 < br > 0. 2 < br >"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 11,
    "text": "- - | - - - | - - - | - - - | - - - | - - - | | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > sampled probability < br > 0. 0 < br > 0. 5 < br > 1. 0 < br > 1. 5 < br > 2. 0 < br > < br > | | | | | | | | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > sampled probability < br > 0. 0 < br > 0. 5 < br > 1. 0 < br > 1. 5 < br > 2. 0 < br > < br > | | | | | | | | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > sampled probability < br > 0. 0 < br > 0. 5 < br > 1. 0 < br > 1. 5 < br > 2. 0 < br > < br > | | | | | | | | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > sampled probability < br > 0. 0 < br > 0. 5 < br > 1. 0 < br > 1. 5 < br > 2. 0 < br > < br > | | | | | | | | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > sampled probability < br > 0. 0 < br > 0. 5 < br > 1. 0 < br > 1. 5 < br > 2. 0 < br > < br > | | | | | | | | 0 | col2 | mea < br > mean e | n prob : 0. < br > ntropy : 1. | 4565 ± 0. 3 < br > 5960 ± 1. 4 | 172 < br > 706 | | - - - | - - - | - - - | - - - | - - - | - - - | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > sampled probability < br > | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > sampled probability < br > | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > sampled probability < br > | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > sampled probability < br > | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > sampled probability < br > | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > sampled probability < br > | | 4 < br > 3 | col2 | mea < br > mean e | n prob : 0. < br > ntropy : 0. | 7169 ± 0. 3 < br > 6183 ± 0. 5 | 100 < br > 867 | | - - - | - - - | - - - | - - - | - - - | - - - | | 3 < br > 4 < br > | | | | | | | 1 < br > 2 < br > | | | | | | | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > sampled probability < br > 0 | | | | | | figure 6 : probability – entropy scatter plots of explorative tokens, displaying a random sample of 5 % of all data points. figure 6 shows the probability – entropy distributions of key explorative tokens ( “ but ”, “ wait ”, “ perhaps ”, “ alternatively"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 12,
    "text": "< br > mean e | n prob : 0. < br > ntropy : 0. | 7169 ± 0. 3 < br > 6183 ± 0. 5 | 100 < br > 867 | | - - - | - - - | - - - | - - - | - - - | - - - | | 3 < br > 4 < br > | | | | | | | 1 < br > 2 < br > | | | | | | | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > sampled probability < br > 0 | | | | | | figure 6 : probability – entropy scatter plots of explorative tokens, displaying a random sample of 5 % of all data points. figure 6 shows the probability – entropy distributions of key explorative tokens ( “ but ”, “ wait ”, “ perhaps ”, “ alternatively ”, and “ however ” ) under three methods : grpo, grpo + entropy loss, and our lp - reg. with the baseline grpo, these tokens are concentrated in low - entropy, high - probability regions. in this case, tokens like “ wait ” tend to appear only when the model is already confident, turning them into deterministic patterns rather than initiating a new exploration path with uncertainty. adding an entropy loss changes this behavior, but in an uncontrolled way. some sampled “ wait ” tokens appear at extremely high entropy levels ( sometimes exceeding 10 ), which superficially boosts diversity but produces little useful exploratory signal. these scattered occurrences do not integrate meaningfully into the reasoning process. our lp - reg method yields a more balanced dynamic. explorative tokens are sampled across a broad range of entropy values, from high probability to low probability states. this balance prevents their probabilities from collapsing under negative feedback while keeping them informative for reasoning. as a result, tokens like “ wait ” remain viable options throughout training, allowing the model to explore alternative reasoning paths rather than overfitting to fixed usage patterns. figure 7 further compares the frequency of explorative tokens ( “ but ”, “ wait ”, “ perhaps ”, “ alternatively ”, and “ however ” ) under grpo and lp - reg. our method consistently maintains a higher fraction of these tokens, demonstrating that lp - reg not only broadens their probability – entropy distribution but also sustains their practical use throughout training. 8 | step 256 | step 256 | col3 | col4 | col5 | col6 | col7 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | but < br > wait < br > perhaps < br > alternatively < br > however < br > 0. 0000 < br > 0. 0005 < br > 0. 0010 < br > 0. 0015 < br > 0. 0020 < br > 0. 0025 < br > 0. 0030 < br > 0. 0035 < br > | | | | | | | | but < br > wait < br > perhaps < br > alternatively < br > however < br > 0. 0000 < br > 0. 0005 < br > 0. 0010 < br > 0. 0015 < br > 0. 0020 < br > 0. 0025 < br > 0. 0030 < br > 0. 0035 < br > | | | | | | | | but < br > wait < br > perhaps < br > alternatively < br > however < br > 0. 0000 < br > 0. 0005 < br > 0. 0010 < br > 0. 0015 < br > 0. 0020 < br > 0. 0025 < br > 0. 0030 < br > 0. 0035 < br > | | | | | | | | but < br > wait < br > perhaps < br > alternatively < br > however < br > 0. 0000 < br > 0. 0005 < br > 0. 0010 < br > 0. 0015 < br > 0. 0020 < br > 0. 0025 < br > 0. 0030 < br > 0. 0035 < br > | | | | | | | | but < br > wait < br > perhaps < br > alternatively < br > however < br > 0. 0000 < br > 0. 0005 < br > 0. 0010 < br > 0. 0015 < br > 0. 0020 < br > 0. 0025 < br > 0. 0030 < br > 0. 0035 < br > | | | | | | | | but < br > wait < br > perhaps < br > alternatively < br > however < br > 0. 0000 < br > 0. 0005 < br > 0. 00"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 13,
    "text": "br > wait < br > perhaps < br > alternatively < br > however < br > 0. 0000 < br > 0. 0005 < br > 0. 0010 < br > 0. 0015 < br > 0. 0020 < br > 0. 0025 < br > 0. 0030 < br > 0. 0035 < br > | | | | | | | | but < br > wait < br > perhaps < br > alternatively < br > however < br > 0. 0000 < br > 0. 0005 < br > 0. 0010 < br > 0. 0015 < br > 0. 0020 < br > 0. 0025 < br > 0. 0030 < br > 0. 0035 < br > | | | | | | | | but < br > wait < br > perhaps < br > alternatively < br > however < br > 0. 0000 < br > 0. 0005 < br > 0. 0010 < br > 0. 0015 < br > 0. 0020 < br > 0. 0025 < br > 0. 0030 < br > 0. 0035 < br > | | | | | | | | but < br > wait < br > perhaps < br > alternatively < br > however < br > 0. 0000 < br > 0. 0005 < br > 0. 0010 < br > 0. 0015 < br > 0. 0020 < br > 0. 0025 < br > 0. 0030 < br > 0. 0035 < br > | | | | | | | | but < br > wait < br > perhaps < br > alternatively < br > however < br > 0. 0000 < br > 0. 0005 < br > 0. 0010 < br > 0. 0015 < br > 0. 0020 < br > 0. 0025 < br > 0. 0030 < br > 0. 0035 < br > | | | | | | | | but < br > wait < br > perhaps < br > alternatively < br > however < br > 0. 0000 < br > 0. 0005 < br > 0. 0010 < br > 0. 0015 < br > 0. 0020 < br > 0. 0025 < br > 0. 0030 < br > 0. 0035 < br > | | ut < br > w | ait < br > perh | aps < br > alterna | tively < br > ho | ever | | step 768 | col2 | col3 | col4 | col5 | | - - - | - - - | - - - | - - - | - - - | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | but < br > w | ait < br > perh | aps < br > alterna | ively < br > ho | ever | figure 7 : frequency of explorative tokens during training. * * 6. 3 * * * * probabilistic distinction between reasoning sparks and noise * * our introduction established a challenge for a successful exploration strategy : it must protect valuable, lowprobability _ reasoning sparks _ without simultaneously amplifying the destructive effects of irrelevant noise. this raises a critical question : is there a systemic, observable difference between these two classes of tokens within the low - probability range that our method can exploit? to investigate this, we analyze the next - token prediction distribution throughout the training process. due to storage limitations, we focus our analysis on the top - 64 most probable tokens, but specifically examine those within a low - probability range ( 0 to 0. 1 ) to isolate the phenomenon from high - probability tokens. figure 8 plots the average probability of two distinct classes of tokens over time : a group of meaningful exploratory tokens ( e. g., “ wait ”, “ perhaps ” ) and a group of irrelevant tokens ( e. g., “ cost ”, “ fine ” ). | ex | plorator | y token | col4 | col5 | col6 | col7 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | ~ ~ irr ~ ~ | ~ ~ levant ~ ~ | ~ ~ token ~ ~ | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | figure 8 : probabilistic distinction between exploratory and irrelevant tokens across training steps in standard grpo training. the results reveal a clear and consistent"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 14,
    "text": "probability of two distinct classes of tokens over time : a group of meaningful exploratory tokens ( e. g., “ wait ”, “ perhaps ” ) and a group of irrelevant tokens ( e. g., “ cost ”, “ fine ” ). | ex | plorator | y token | col4 | col5 | col6 | col7 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | ~ ~ irr ~ ~ | ~ ~ levant ~ ~ | ~ ~ token ~ ~ | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | figure 8 : probabilistic distinction between exploratory and irrelevant tokens across training steps in standard grpo training. the results reveal a clear and consistent statistical distinction : across all training stages, the average next - token probability of meaningful exploratory tokens is persistently higher than that of irrelevant tokens. it can be attributed to the intrinsic confidence of llms ( nguyen et al., 2025 ; xu et al., 2025 ; fu et al., 2025 ). this persistent probabilistic gap provides the foundational justification for our lp - reg design. it suggests that while a perfect separation is not possible, a probability threshold _ τ _, as defined for our proxy distribution in section 4. 1, can serve as a principled filtering mechanism. by setting such a threshold, we can effectively filter out a substantial portion of the lowest - probability irrelevant tokens, which constitute destabilizing noise, while simultaneously retaining a majority of the valuable exploratory tokens that give rise to _ reasoning sparks _. this allows lp - reg to focus its regularization on tokens that are more likely to be meaningful, providing a targeted and robust approach to preserving high - quality exploration. * * 7 * * * * conclusion * * in this work, we investigated the exploration collapse in reinforcement learning with verifiable rewards. we identified a key mechanism driving this failure : the systematic elimination of a class of valuable, low - probability exploratory tokens we term _ reasoning sparks _. to address this, we introduced low - probability regularization ( lp - reg ), a method designed to selectively preserve these crucial exploratory pathways. lp - reg is founded on the key insight that within the low - probability range, meaningful exploratory tokens consistently exhibit higher average probabilities than semantically irrelevant tokens, whose low - probability appearances act as noise. by leveraging this statistical distinction to filter out irrelevant noise and regularizing the policy towards the remainder, our method effectively protects valuable low - probability tokens from being extinguished. this focus on exploration quality over quantity enables stable on - policy training for around 1, 000 steps, resulting in a 2. 66 % test accuracy improvement over baselines and underscoring the importance of preserving the _ reasoning sparks _ within the policy ’ s low - probability tail. 9 * * references * * shivam agarwal, zimin zhang, lifan yuan, jiawei han, and hao peng. the unreasonable effectiveness of entropy [ minimization in llm reasoning, 2025. url https : / / arxiv. org / abs / 2505. 15134. ] ( https : / / arxiv. org / abs / 2505. 15134 ) taubenfeld amir, sheffer tom, ofek eran, feder amir, goldstein ariel, gekhman zorik, and yona gal. confidence improves self - consistency in llms. _ arxiv preprint arxiv : 2502. 06233 _, 2025. url [ https : / / www. arxiv. ] ( https : / / www. arxiv. org / abs / 2502. 06233 ) [ org / abs / 2502. 06233. ] ( https : / / www. arxiv. org / abs / 2502. 06233 ) ghasemabadi amirhosein, mills keith, g., li baochun, and niu di. guided by gut : efficient test - time scaling with reinforced intrinsic confidence. _ arxiv preprint arxiv : 2505. 20325v1 _, 2025. url [ https : / / www. arxiv. ] ( https : / / www. arxiv. org / abs / 2505. 20325v1 ) [ org / abs / 2505. 20325v1. ] ( https : / / www. arxiv. org / abs / 2505. 20325v1 ) daixuan cheng, shaohan huang, xuekai zhu, bo dai, wayne xin zhao, zhenliang zhang, and furu wei. reasoning with exploration : an entropy perspective on reinforcement learning for llms, 2025. url [ https : ]"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 15,
    "text": "( https : / / www. arxiv. org / abs / 2502. 06233 ) ghasemabadi amirhosein, mills keith, g., li baochun, and niu di. guided by gut : efficient test - time scaling with reinforced intrinsic confidence. _ arxiv preprint arxiv : 2505. 20325v1 _, 2025. url [ https : / / www. arxiv. ] ( https : / / www. arxiv. org / abs / 2505. 20325v1 ) [ org / abs / 2505. 20325v1. ] ( https : / / www. arxiv. org / abs / 2505. 20325v1 ) daixuan cheng, shaohan huang, xuekai zhu, bo dai, wayne xin zhao, zhenliang zhang, and furu wei. reasoning with exploration : an entropy perspective on reinforcement learning for llms, 2025. url [ https : ] ( https : / / arxiv. org / abs / 2506. 14758 ) [ / / arxiv. org / abs / 2506. 14758. ] ( https : / / arxiv. org / abs / 2506. 14758 ) ganqu cui, yuchen zhang, jiacheng chen, lifan yuan, zhi wang, yuxin zuo, haozhan li, yuchen fan, huayu chen, weize chen, zhiyuan liu, hao peng, lei bai, wanli ouyang, yu cheng, bowen zhou, and ning ding. the entropy mechanism of reinforcement learning for reasoning language models, 2025. url [ https : ] ( https : / / arxiv. org / abs / 2505. 22617 ) [ / / arxiv. org / abs / 2505. 22617. ] ( https : / / arxiv. org / abs / 2505. 22617 ) deepseek - ai, daya guo, dejian yang, haowei zhang, junxiao song, ruoyu zhang, runxin xu, qihao zhu, shirong ma, peiyi wang, xiao bi, xiaokang zhang, xingkai yu, yu wu, z. f. wu, zhibin gou, zhihong shao, zhuoshu li, ziyi gao, aixin liu, bing xue, bingxuan wang, bochao wu, bei feng, chengda lu, chenggang zhao, chengqi deng, chenyu zhang, chong ruan, damai dai, deli chen, dongjie ji, erhang li, fangyun lin, fucong dai, fuli luo, guangbo hao, guanting chen, guowei li, h. zhang, han bao, hanwei xu, haocheng wang, honghui ding, huajian xin, huazuo gao, hui qu, hui li, jianzhong guo, jiashi li, jiawei wang, jingchang chen, jingyang yuan, junjie qiu, junlong li, j. l. cai, jiaqi ni, jian liang, jin chen, kai dong, kai hu, kaige gao, kang guan, kexin huang, kuai yu, lean wang, lecong zhang, liang zhao, litong wang, liyue zhang, lei xu, leyi xia, mingchuan zhang, minghua zhang, minghui tang, meng li, miaojun wang, mingming li, ning tian, panpan huang, peng zhang, qiancheng wang, qinyu chen, qiushi du, ruiqi ge, ruisong zhang, ruizhe pan, runji wang, r. j. chen, r. l. jin, ruyi chen, shanghao lu, shangyan zhou, shanhuang chen, shengfeng ye, shiyu wang, shuiping yu, shunfeng zhou, shuting pan, s. s. li, shuang zhou, shaoqing wu, shengfeng ye, tao yun, tian pei, tianyu sun, t. wang, wangding zeng, wanjia zhao, wen liu, wenfeng liang, wenjun gao, wenqin yu, wentao zhang, w. l. xiao, wei an, xiaodong liu, xiaohan wang, xiaokang chen, xiaotao nie, xin cheng, xin liu, xin xie, xingchao liu, xinyu yang, xinyuan li, xuecheng su, xuheng lin, x. q. li, xiangyue jin, xiaojin shen, xiaosha chen, xiaowen sun, xiaoxiang wang, xinnan song, xinyi zhou, xianzu wang, xinxia shan, y. k. li, y"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 16,
    "text": ", shengfeng ye, shiyu wang, shuiping yu, shunfeng zhou, shuting pan, s. s. li, shuang zhou, shaoqing wu, shengfeng ye, tao yun, tian pei, tianyu sun, t. wang, wangding zeng, wanjia zhao, wen liu, wenfeng liang, wenjun gao, wenqin yu, wentao zhang, w. l. xiao, wei an, xiaodong liu, xiaohan wang, xiaokang chen, xiaotao nie, xin cheng, xin liu, xin xie, xingchao liu, xinyu yang, xinyuan li, xuecheng su, xuheng lin, x. q. li, xiangyue jin, xiaojin shen, xiaosha chen, xiaowen sun, xiaoxiang wang, xinnan song, xinyi zhou, xianzu wang, xinxia shan, y. k. li, y. q. wang, y. x. wei, yang zhang, yanhong xu, yao li, yao zhao, yaofeng sun, yaohui wang, yi yu, yichao zhang, yifan shi, yiliang xiong, ying he, yishi piao, yisong wang, yixuan tan, yiyang ma, yiyuan liu, yongqiang guo, yuan ou, yuduan wang, yue gong, yuheng zou, yujia he, yunfan xiong, yuxiang luo, yuxiang you, yuxuan liu, yuyang zhou, y. x. zhu, yanhong xu, yanping huang, yaohui li, yi zheng, yuchen zhu, yunxian ma, ying tang, yukun zha, yuting yan, z. z. ren, zehui ren, zhangli sha, zhe fu, zhean xu, zhenda xie, zhengyan zhang, zhewen hao, zhicheng ma, zhigang yan, zhiyu wu, zihui gu, zijia zhu, zijun liu, zilin li, ziwei xie, ziyang song, zizheng pan, zhen huang, zhipeng xu, zhongyu zhang, and zhen zhang. deepseek - r1 : incentivizing reasoning capability in llms via [ reinforcement learning, 2025. url https : / / arxiv. org / abs / 2501. 12948. ] ( https : / / arxiv. org / abs / 2501. 12948 ) yichao fu, xuewei wang, yuandong tian, and jiawei zhao. deep think with confidence, 2025. url [ https : ] ( https : / / arxiv. org / abs / 2508. 15260 ) [ / / arxiv. org / abs / 2508. 15260. ] ( https : / / arxiv. org / abs / 2508. 15260 ) zitian gao, lynx chen, haoming luo, joey zhou, and bryan dai. one - shot entropy minimization, 2025. url [ https : / / arxiv. org / abs / 2505. 20282. ] ( https : / / arxiv. org / abs / 2505. 20282 ) chaoqun he, renjie luo, yuzhuo bai, shengding hu, zhen thai, junhao shen, jinyi hu, xu han, yujie huang, yuxiang zhang, jie liu, lei qi, zhiyuan liu, and maosong sun. olympiadbench : a challenging benchmark for promoting agi with olympiad - level bilingual multimodal scientific problems. in lun - wei ku, andre martins, and vivek srikumar ( eds. ), _ proceedings of the 62nd annual meeting of the association for computational _ _ linguistics ( volume 1 : long papers ) _, pp. 3828 – 3850, bangkok, thailand, august 2024a. association for computational linguistics. doi : 10. 18653 / v1 / 2024. acl - long. 211. url [ https : / / aclanthology. org / ] ( https : / / aclanthology. org / 2024. acl - long. 211 / ) [ 2024. acl - long. 211 /. ] ( https : / / aclanthology. org / 2024. acl - long. 211 / ) chaoqun he, renjie luo, yuzhuo bai, shengding hu, zhen leng thai, junhao shen, jinyi hu, xu han, yujie huang, yuxiang zhang, jie liu, lei qi, zhiyuan liu, and maosong sun. olympiadbench : a challenging benchmark for promoting agi"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 17,
    "text": "for computational _ _ linguistics ( volume 1 : long papers ) _, pp. 3828 – 3850, bangkok, thailand, august 2024a. association for computational linguistics. doi : 10. 18653 / v1 / 2024. acl - long. 211. url [ https : / / aclanthology. org / ] ( https : / / aclanthology. org / 2024. acl - long. 211 / ) [ 2024. acl - long. 211 /. ] ( https : / / aclanthology. org / 2024. acl - long. 211 / ) chaoqun he, renjie luo, yuzhuo bai, shengding hu, zhen leng thai, junhao shen, jinyi hu, xu han, yujie huang, yuxiang zhang, jie liu, lei qi, zhiyuan liu, and maosong sun. olympiadbench : a challenging benchmark for promoting agi with olympiad - level bilingual multimodal scientific problems, 2024b. 10 jujie he, jiacai liu, chris yuhao liu, rui yan, chaojie wang, peng cheng, xiaoyu zhang, fuxiang zhang, jiacheng xu, wei shen, siyuan li, liang zeng, tianwen wei, cheng cheng, bo an, yang liu, and yahui zhou. skywork [ open reasoner 1 technical report, 2025. url https : / / arxiv. org / abs / 2505. 22312. ] ( https : / / arxiv. org / abs / 2505. 22312 ) dan hendrycks, collin burns, saurav kadavath, akul arora, steven basart, eric tang, dawn song, and jacob steinhardt. measuring mathematical problem solving with the math dataset. in _ thirty - fifth conference _ _ on neural information processing systems datasets and benchmarks track ( round 2 ) _, 2021. url [ https : ] ( https : / / openreview. net / forum? id = 7bywt2mqsce ) [ / / openreview. net / forum? id = 7bywt2mqsce. ] ( https : / / openreview. net / forum? id = 7bywt2mqsce ) aitor lewkowycz, anders johan andreassen, david dohan, ethan dyer, henryk michalewski, vinay venkatesh ramasesh, ambrose slone, cem anil, imanol schlag, theo gutman - solo, yuhuai wu, behnam neyshabur, guy gur - ari, and vedant misra. solving quantitative reasoning problems with language models. in alice h. oh, alekh agarwal, danielle belgrave, and kyunghyun cho ( eds. ), _ advances in neural information processing _ _ systems _ [, 2022. url https : / / openreview. net / forum? id = ifxtzerxdm7. ] ( https : / / openreview. net / forum? id = ifxtzerxdm7 ) li loka, chen zhenhao, chen guangyi, zhang yixuan, su yusheng, xing eric, and zhang kun. confidence matters : revisiting intrinsic self - correction capabilities of large language models. _ arxiv preprint arxiv : 2402. 12563 _, 2024. [ url https : / / www. arxiv. org / abs / 2402. 12563. ] ( https : / / www. arxiv. org / abs / 2402. 12563 ) maa. american invitational mathematics examination ( aime ). mathematics competition series, n. d. url [ https : / / maa. org / math - competitions / aime. ] ( https : / / maa. org / math - competitions / aime ) minimax, :, aili chen, aonian li, bangwei gong, binyang jiang, bo fei, bo yang, boji shan, changqing yu, chao wang, cheng zhu, chengjun xiao, chengyu du, chi zhang, chu qiao, chunhao zhang, chunhui du, congchao guo, da chen, deming ding, dianjun sun, dong li, enwei jiao, haigang zhou, haimo zhang, han ding, haohai sun, haoyu feng, huaiguang cai, haichao zhu, jian sun, jiaqi zhuang, jiaren cai, jiayuan song, jin zhu, jingyang li, jinhao tian, jinli liu, junhao xu, junjie yan, junteng liu, junxian he, kaiyi feng,"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 18,
    "text": "https : / / maa. org / math - competitions / aime ) minimax, :, aili chen, aonian li, bangwei gong, binyang jiang, bo fei, bo yang, boji shan, changqing yu, chao wang, cheng zhu, chengjun xiao, chengyu du, chi zhang, chu qiao, chunhao zhang, chunhui du, congchao guo, da chen, deming ding, dianjun sun, dong li, enwei jiao, haigang zhou, haimo zhang, han ding, haohai sun, haoyu feng, huaiguang cai, haichao zhu, jian sun, jiaqi zhuang, jiaren cai, jiayuan song, jin zhu, jingyang li, jinhao tian, jinli liu, junhao xu, junjie yan, junteng liu, junxian he, kaiyi feng, ke yang, kecheng xiao, le han, leyang wang, lianfei yu, liheng feng, lin li, lin zheng, linge du, lingyu yang, lunbin zeng, minghui yu, mingliang tao, mingyuan chi, mozhi zhang, mujie lin, nan hu, nongyu di, peng gao, pengfei li, pengyu zhao, qibing ren, qidi xu, qile li, qin wang, rong tian, ruitao leng, shaoxiang chen, shaoyu chen, shengmin shi, shitong weng, shuchang guan, shuqi yu, sichen li, songquan zhu, tengfei li, tianchi cai, tianrun liang, weiyu cheng, weize kong, wenkai li, xiancai chen, xiangjun song, xiao luo, xiao su, xiaobo li, xiaodong han, xinzhu hou, xuan lu, xun zou, xuyang shen, yan gong, yan ma, yang wang, yiqi shi, yiran zhong, yonghong duan, yongxiang fu, yongyi hu, yu gao, yuanxiang fan, yufeng yang, yuhao li, yulin hu, yunan huang, yunji li, yunzhi xu, yuxin mao, yuxuan shi, yuze wenren, zehan li, zelin li, zhanxu tian, zhengmao zhu, zhenhua fan, zhenzhen wu, zhichao xu, zhihang yu, zhiheng lyu, zhuo jiang, zibo gao, zijia wu, zijian song, and zijun sun. minimax - m1 : scaling test - time [ compute efficiently with lightning attention, 2025. url https : / / arxiv. org / abs / 2506. 13585. ] ( https : / / arxiv. org / abs / 2506. 13585 ) kevin murphy. reinforcement learning : an overview. _ arxiv preprint arxiv : 2412. 05265 _, 2024. minh nhat nguyen, andrew baker, clement neo, allen roush, andreas kirsch, and ravid shwartz - ziv. turning up the heat : min - p sampling for creative and coherent llm outputs, 2025. url [ https : / / arxiv. org / abs / ] ( https : / / arxiv. org / abs / 2407. 01082 ) [ 2407. 01082. ] ( https : / / arxiv. org / abs / 2407. 01082 ) openai, :, aaron jaech, adam kalai, adam lerer, adam richardson, ahmed el - kishky, aiden low, alec helyar, aleksander madry, alex beutel, alex carney, alex iftimie, alex karpenko, alex tachard passos, alexander neitz, alexander prokofiev, alexander wei, allison tam, ally bennett, ananya kumar, andre saraiva, andrea vallone, andrew duberstein, andrew kondrich, andrey mishchenko, andy applebaum, angela jiang, ashvin nair, barret zoph, behrooz ghorbani, ben rossen, benjamin sokolowsky, boaz barak, bob mcgrew, borys minaiev, botao hao, bowen baker, brandon houghton, brandon mckinzie, brydon eastman, camillo lugaresi, cary bassin, cary hudson, chak ming li, charles de bourcy, chelsea voss, chen shen, chong zhang, chris koch, chris orsinger, christopher hesse, claudia fischer"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 19,
    "text": "##utel, alex carney, alex iftimie, alex karpenko, alex tachard passos, alexander neitz, alexander prokofiev, alexander wei, allison tam, ally bennett, ananya kumar, andre saraiva, andrea vallone, andrew duberstein, andrew kondrich, andrey mishchenko, andy applebaum, angela jiang, ashvin nair, barret zoph, behrooz ghorbani, ben rossen, benjamin sokolowsky, boaz barak, bob mcgrew, borys minaiev, botao hao, bowen baker, brandon houghton, brandon mckinzie, brydon eastman, camillo lugaresi, cary bassin, cary hudson, chak ming li, charles de bourcy, chelsea voss, chen shen, chong zhang, chris koch, chris orsinger, christopher hesse, claudia fischer, clive chan, dan roberts, daniel kappler, daniel levy, daniel selsam, david dohan, david farhi, david mely, david robinson, dimitris tsipras, doug li, dragos oprica, eben freeman, eddie zhang, edmund wong, elizabeth proehl, enoch cheung, eric mitchell, eric wallace, erik ritter, evan mays, fan wang, felipe petroski such, filippo raso, florencia leoni, foivos tsimpourlas, francis song, fred von lohmann, freddie sulit, geoff salmon, giambattista parascandolo, gildas chabot, grace zhao, greg brockman, guillaume leclerc, hadi salman, haiming bao, hao sheng, hart andrin, hessam bagherinezhad, hongyu ren, hunter lightman, hyung won chung, ian kivlichan, ian o ’ connell, ian osband, ignasi clavera gilaberte, ilge akkaya, ilya kostrikov, ilya sutskever, irina kofman, jakub pachocki, james lennon, jason wei, jean harb, jerry twore, jiacheng feng, jiahui yu, jiayi weng, jie tang, jieqi yu, joaquin quinonero candela, joe palermo, joel parish, johannes heidecke, john hallman, john rizzo, jonathan [UNK] gordon, jonathan uesato, jonathan ward, joost huizinga, julie wang, kai chen, kai xiao, karan singhal, karina nguyen, karl cobbe, katy shi, kayla wood, kendra rimbach, keren gu - lemberg, kevin liu, kevin lu, kevin stone, kevin yu, lama ahmad, lauren yang, leo liu, leon maksin, leyton ho, liam fedus, lilian weng, linden li, lindsay mccallum, lindsey held, lorenz kuhn, lukas kondraciuk, lukasz kaiser, luke metz, 11 madelaine boyd, maja trebacz, manas joglekar, mark chen, marko tintor, mason meyer, matt jones, matt kaufer, max schwarzer, meghan shah, mehmet yatbaz, melody y. guan, mengyuan xu, mengyuan yan, mia glaese, mianna chen, michael lampe, michael malek, michele wang, michelle fradin, mike mcclay, mikhail pavlov, miles wang, mingxuan wang, mira murati, mo bavarian, mostafa rohaninejad, nat mcaleese, neil chowdhury, neil chowdhury, nick ryder, nikolas tezak, noam brown, ofir nachum, oleg boiko, oleg murk, olivia watkins, patrick chao, paul ashbourne, pavel izmailov, peter zhokhov, rachel dias, rahul arora, randall lin, rapha gontijo lopes, raz gaon, reah miyara, reimar leike, renny hwang, rhythm garg, robin brown, roshan james, rui shu, ryan cheu, ryan greene, saachi jain, sam altman, sam toizer, sam toyer, samuel miserendino, sandhini agarwal, santiago hernandez, sasha baker, scott mckinney, scottie"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 20,
    "text": ", mira murati, mo bavarian, mostafa rohaninejad, nat mcaleese, neil chowdhury, neil chowdhury, nick ryder, nikolas tezak, noam brown, ofir nachum, oleg boiko, oleg murk, olivia watkins, patrick chao, paul ashbourne, pavel izmailov, peter zhokhov, rachel dias, rahul arora, randall lin, rapha gontijo lopes, raz gaon, reah miyara, reimar leike, renny hwang, rhythm garg, robin brown, roshan james, rui shu, ryan cheu, ryan greene, saachi jain, sam altman, sam toizer, sam toyer, samuel miserendino, sandhini agarwal, santiago hernandez, sasha baker, scott mckinney, scottie yan, shengjia zhao, shengli hu, shibani santurkar, shraman ray chaudhuri, shuyuan zhang, siyuan fu, spencer papay, steph lin, suchir balaji, suvansh sanjeev, szymon sidor, tal broda, aidan clark, tao wang, taylor gordon, ted sanders, tejal patwardhan, thibault sottiaux, thomas degry, thomas dimson, tianhao zheng, timur garipov, tom stasi, trapit bansal, trevor creech, troy peterson, tyna eloundou, valerie qi, vineet kosaraju, vinnie monaco, vitchyr pong, vlad fomenko, weiyi zheng, wenda zhou, wes mccabe, wojciech zaremba, yann dubois, yinghai lu, yining chen, young cha, yu bai, yuchen he, yuchen zhang, yunyun wang, zheng shao, [ and zhuohan li. openai o1 system card, 2024. url https : / / arxiv. org / abs / 2412. 16720. ] ( https : / / arxiv. org / abs / 2412. 16720 ) kadavath saurav, conerly tom, askell amanda, henighan tom, drain dawn, perez ethan, schiefer nicholas, hatfield - dodds zac, dassarma nova, tran - johnson eli, johnston scott, el - showk sheer, jones andy, elhage nelson, hume tristan, chen anna, bai yuntao, bowman sam, fort stanislav, ganguli deep, hernandez danny, jacobson josh, kernion jackson, kravec shauna, lovitt liane, ndousse kamal, olsson catherine, ringer sam, amodei dario, brown tom, clark jack, joseph nicholas, mann ben, mccandlish sam, olah chris, and kaplan jared. language models ( mostly ) know what they know. _ arxiv preprint arxiv : 2207. 05221 _, 2022. url [ https : / / www. arxiv. org / abs / 2207. 05221. ] ( https : / / www. arxiv. org / abs / 2207. 05221 ) john schulman, filip wolski, prafulla dhariwal, alec radford, and oleg klimov. proximal policy optimization algorithms. _ arxiv preprint arxiv : 1707. 06347 _, 2017. zhihong shao, peiyi wang, qihao zhu, runxin xu, junxiao song, xiao bi, haowei zhang, mingchuan zhang, y. k. li, y. wu, and daya guo. deepseekmath : pushing the limits of mathematical reasoning in open language [ models, 2024a. url https : / / arxiv. org / abs / 2402. 03300. ] ( https : / / arxiv. org / abs / 2402. 03300 ) zhihong shao, peiyi wang, qihao zhu, runxin xu, junxiao song, xiao bi, haowei zhang, mingchuan zhang, yk li, y wu, et al. deepseekmath : pushing the limits of mathematical reasoning in open language models. _ arxiv preprint arxiv : 2402. 03300 _, 2024b. guangming sheng, chi zhang, zilingfeng ye, xibin wu, wang zhang, ru zhang, yanghua peng, haibin lin, and chuan wu. hybridflow : a flexible and efficient rlhf framework."
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 21,
    "text": "##uan zhang, y. k. li, y. wu, and daya guo. deepseekmath : pushing the limits of mathematical reasoning in open language [ models, 2024a. url https : / / arxiv. org / abs / 2402. 03300. ] ( https : / / arxiv. org / abs / 2402. 03300 ) zhihong shao, peiyi wang, qihao zhu, runxin xu, junxiao song, xiao bi, haowei zhang, mingchuan zhang, yk li, y wu, et al. deepseekmath : pushing the limits of mathematical reasoning in open language models. _ arxiv preprint arxiv : 2402. 03300 _, 2024b. guangming sheng, chi zhang, zilingfeng ye, xibin wu, wang zhang, ru zhang, yanghua peng, haibin lin, and chuan wu. hybridflow : a flexible and efficient rlhf framework. _ arxiv preprint arxiv : 2409. 19256 _, 2024. zhenpeng su, leiyu pan, xue bai, dening liu, guanting dong, jiaming huang, wenping hu, fuzheng zhang, kun gai, and guorui zhou. klear - reasoner : advancing reasoning capability via gradient - preserving clipping [ policy optimization, 2025. url https : / / arxiv. org / abs / 2508. 07629. ] ( https : / / arxiv. org / abs / 2508. 07629 ) kimi team, angang du, bofei gao, bowei xing, changjiu jiang, cheng chen, cheng li, chenjun xiao, chenzhuang du, chonghua liao, chuning tang, congcong wang, dehao zhang, enming yuan, enzhe lu, fengxiang tang, flood sung, guangda wei, guokun lai, haiqing guo, han zhu, hao ding, hao hu, hao yang, hao zhang, haotian yao, haotian zhao, haoyu lu, haoze li, haozhen yu, hongcheng gao, huabin zheng, huan yuan, jia chen, jianhang guo, jianlin su, jianzhou wang, jie zhao, jin zhang, jingyuan liu, junjie yan, junyan wu, lidong shi, ling ye, longhui yu, mengnan dong, neo zhang, ningchen ma, qiwei pan, qucheng gong, shaowei liu, shengling ma, shupeng wei, sihan cao, siying huang, tao jiang, weihao gao, weimin xiong, weiran he, weixiao huang, weixin xu, wenhao wu, wenyang he, xianghui wei, xianqing jia, xingzhe wu, xinran xu, xinxing zu, xinyu zhou, xuehai pan, y. charles, yang li, yangyang hu, yangyang liu, yanru chen, yejie wang, yibo liu, yidao qin, yifeng liu, ying yang, yiping bao, yulun du, yuxin wu, yuzhi wang, zaida zhou, zhaoji wang, zhaowei li, zhen zhu, zheng zhang, zhexu wang, zhilin yang, zhiqi huang, zihao huang, ziyao xu, zonghan yang, and zongyu lin. kimi k1. 5 : scaling reinforcement learning with llms, 2025. [ url https : / / arxiv. org / abs / 2501. 12599. ] ( https : / / arxiv. org / abs / 2501. 12599 ) shenzhi wang, le yu, chang gao, chujie zheng, shixuan liu, rui lu, kai dang, xionghui chen, jianxin yang, zhenru zhang, yuqiong liu, an yang, andrew zhao, yang yue, shiji song, bowen yu, gao huang, and junyang lin. beyond the 80 / 20 rule : high - entropy minority tokens drive effective reinforcement learning for llm [ reasoning, 2025. url https : / / arxiv. org / abs / 2506. 01939. ] ( https : / / arxiv. org / abs / 2506. 01939 ) jason wei, xuezhi wang, dale schuurmans, maarten bosma, brian ichter, fei xia, ed chi, quoc le, and denny zhou. chain - of - thought prompting elicits reasoning in large language models, 2023. url [ https : ] ( https : / / arxiv. org / abs"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 22,
    "text": "##e zheng, shixuan liu, rui lu, kai dang, xionghui chen, jianxin yang, zhenru zhang, yuqiong liu, an yang, andrew zhao, yang yue, shiji song, bowen yu, gao huang, and junyang lin. beyond the 80 / 20 rule : high - entropy minority tokens drive effective reinforcement learning for llm [ reasoning, 2025. url https : / / arxiv. org / abs / 2506. 01939. ] ( https : / / arxiv. org / abs / 2506. 01939 ) jason wei, xuezhi wang, dale schuurmans, maarten bosma, brian ichter, fei xia, ed chi, quoc le, and denny zhou. chain - of - thought prompting elicits reasoning in large language models, 2023. url [ https : ] ( https : / / arxiv. org / abs / 2201. 11903 ) [ / / arxiv. org / abs / 2201. 11903. ] ( https : / / arxiv. org / abs / 2201. 11903 ) 12 zenan xu, zexuan qiu, guanhua huang, kun li, siheng li, chenchen zhang, kejiao li, qi yi, yuhao jiang, bo zhou, fengzong lian, and zhanhui kang. adaptive termination for multi - round parallel reasoning : an [ universal semantic entropy - guided framework, 2025. url https : / / arxiv. org / abs / 2507. 06829. ] ( https : / / arxiv. org / abs / 2507. 06829 ) zhao xuandong, kang zhewei, feng aosong, levine sergey, and song dawn. learning to reason without external rewards. _ arxiv preprint arxiv : 2505. 19590v2 _, 2025. url [ https : / / www. arxiv. org / abs / 2505. ] ( https : / / www. arxiv. org / abs / 2505. 19590v2 ) [ 19590v2. ] ( https : / / www. arxiv. org / abs / 2505. 19590v2 ) wang xuezhi and zhou denny. chain - of - thought reasoning without prompting. _ arxiv preprint arxiv : 2402. 10200v2 _, [ 2024. url https : / / www. arxiv. org / abs / 2402. 10200v2. ] ( https : / / www. arxiv. org / abs / 2402. 10200v2 ) an yang, anfeng li, baosong yang, beichen zhang, binyuan hui, bo zheng, bowen yu, chang gao, chengen huang, chenxu lv, chujie zheng, dayiheng liu, fan zhou, fei huang, feng hu, hao ge, haoran wei, huan lin, jialong tang, jian yang, jianhong tu, jianwei zhang, jianxin yang, jiaxi yang, jing zhou, jingren zhou, junyang lin, kai dang, keqin bao, kexin yang, le yu, lianghao deng, mei li, mingfeng xue, mingze li, pei zhang, peng wang, qin zhu, rui men, ruize gao, shixuan liu, shuang luo, tianhao li, tianyi tang, wenbiao yin, xingzhang ren, xinyu wang, xinyu zhang, xuancheng ren, yang fan, yang su, yichang zhang, yinger zhang, yu wan, yuqiong liu, zekun wang, zeyu cui, zhenru zhang, zhipeng zhou, and zihan qiu. qwen3 [ technical report, 2025. url https : / / arxiv. org / abs / 2505. 09388. ] ( https : / / arxiv. org / abs / 2505. 09388 ) qiying yu, zheng zhang, ruofei zhu, yufeng yuan, xiaochen zuo, yu yue, weinan dai, tiantian fan, gaohong liu, lingjun liu, xin liu, haibin lin, zhiqi lin, bole ma, guangming sheng, yuxuan tong, chi zhang, mofan zhang, wang zhang, hang zhu, jinhua zhu, jiaze chen, jiangjie chen, chengyi wang, hongli yu, yuxuan song, xiangpeng wei, hao zhou, jingjing liu, wei - ying ma, ya - qin zhang, lin yan, mu qiao, yonghui wu, and mingxuan wang. dapo : an open - source ll"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 23,
    "text": ", 2025. url https : / / arxiv. org / abs / 2505. 09388. ] ( https : / / arxiv. org / abs / 2505. 09388 ) qiying yu, zheng zhang, ruofei zhu, yufeng yuan, xiaochen zuo, yu yue, weinan dai, tiantian fan, gaohong liu, lingjun liu, xin liu, haibin lin, zhiqi lin, bole ma, guangming sheng, yuxuan tong, chi zhang, mofan zhang, wang zhang, hang zhu, jinhua zhu, jiaze chen, jiangjie chen, chengyi wang, hongli yu, yuxuan song, xiangpeng wei, hao zhou, jingjing liu, wei - ying ma, ya - qin zhang, lin yan, mu qiao, yonghui wu, and mingxuan wang. dapo : an open - source llm reinforcement learning system at scale, 2025. url [ https : / / arxiv. org / abs / 2503. 14476. ] ( https : / / arxiv. org / abs / 2503. 14476 ) yu yue, yufeng yuan, qiying yu, xiaochen zuo, ruofei zhu, wenyuan xu, jiaze chen, chengyi wang, tiantian fan, zhengyin du, xiangpeng wei, xiangyu yu, gaohong liu, juncai liu, lingjun liu, haibin lin, zhiqi lin, bole ma, chi zhang, mofan zhang, wang zhang, hang zhu, ru zhang, xin liu, mingxuan wang, yonghui wu, and lin yan. vapo : efficient and reliable reinforcement learning for advanced reasoning tasks, 2025. url [ https : / / arxiv. org / abs / 2504. 05118. ] ( https : / / arxiv. org / abs / 2504. 05118 ) yuzhong zhao, yue liu, junpeng liu, jingye chen, xun wu, yaru hao, tengchao lv, shaohan huang, lei cui, qixiang ye, fang wan, and furu wei. geometric - mean policy optimization, 2025. url [ https : / / arxiv. ] ( https : / / arxiv. org / abs / 2507. 20673 ) [ org / abs / 2507. 20673. ] ( https : / / arxiv. org / abs / 2507. 20673 ) chujie zheng, shixuan liu, mingze li, xiong - hui chen, bowen yu, chang gao, kai dang, yuqiong liu, rui men, an yang, jingren zhou, and junyang lin. group sequence policy optimization, 2025. url [ https : ] ( https : / / arxiv. org / abs / 2507. 18071 ) [ / / arxiv. org / abs / 2507. 18071. ] ( https : / / arxiv. org / abs / 2507. 18071 ) omer veysel [UNK] [UNK] agatan and barı [UNK] [UNK] akgun. failure modes of maximum entropy rlhf, 2025. url [UNK] [ https : / / arxiv. ] ( https : / / arxiv. org / abs / 2509. 20265 ) [ org / abs / 2509. 20265. ] ( https : / / arxiv. org / abs / 2509. 20265 ) 13 # # * * appendix * * * * a * * * * details of experiments * * * * a. 1 * * * * further training dynamics * * the training dynamics of lp - reg and other rlvr methods on the qwen2. 5 - 32b base model are presented in figure 9. the results show that lp - reg maintains a comparable performance in test accuracy throughout the training process, underscoring the benefits of our low - probability token regularization strategy for preventing exploration collapse. figure 9 : training dynamics on the qwen2. 5 - 32b - base model. to best illustrate the performance differences, we compare the top - performing methods. * * a. 2 * * * * further ablation study * * figure 10 : ablation study comparing low - probability token regularization versus high - entropy token regularization for lp - reg ( on - policy ) on the qwen3 - 14b - base model. the test datasets used are aime - 24 and aime - 25, with the average score reported over 16 test runs. * * low probability vs. high entropy. * * to verify that targeting low - probability tokens is superior to the conventional wisdom of targeting high entropy, we conduct a comparison between the high - entropy token regularization ( w / highest _ h _ regularization ) and the low - probability regularization ("
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 24,
    "text": "- reg maintains a comparable performance in test accuracy throughout the training process, underscoring the benefits of our low - probability token regularization strategy for preventing exploration collapse. figure 9 : training dynamics on the qwen2. 5 - 32b - base model. to best illustrate the performance differences, we compare the top - performing methods. * * a. 2 * * * * further ablation study * * figure 10 : ablation study comparing low - probability token regularization versus high - entropy token regularization for lp - reg ( on - policy ) on the qwen3 - 14b - base model. the test datasets used are aime - 24 and aime - 25, with the average score reported over 16 test runs. * * low probability vs. high entropy. * * to verify that targeting low - probability tokens is superior to the conventional wisdom of targeting high entropy, we conduct a comparison between the high - entropy token regularization ( w / highest _ h _ regularization ) and the low - probability regularization ( w / lowest _ π _ _ * * θ * * _ regularization, vanilla lp - reg ). instead of applying lp - reg to the lowest 1 % probability tokens, we apply an identical regularization mechanism to the tokens with the highest 1 % entropy. as shown in figure 10, this approach not only fails to improve performance but also fails to sustain high entropy, which collapses after an initial spike. this result reinforces our claim from the introduction : high entropy is a poor proxy for valuable exploration. as our analysis in section 6. 1 further corroborates, high - entropy tokens are often common function words or formatting characters, not the meaningful, low - probability exploratory tokens we term _ reasoning sparks _. regularizing them pollutes the learning signal without protecting the structured, low - probability reasoning paths necessary for progress. * * forward kl vs. reverse kl. * * we compare the performance of our chosen “ forward kl ” formulation, which is _ d _ kl ( _ π _ proxy _ ∥ _ _ π _ _ * * θ * * _ ), against the ” reverse kl ” formulation, _ d _ kl ( _ π _ _ * * θ * * _ _ ∥ _ _ π _ proxy ), in equation 6. as shown in figure 11, our forward kl significantly outperforms the reverse kl. this result stems from the fact that our proxy distribution, _ π _ proxy, is a heuristic reference derived from the current policy, not an ideal target distribution. the reverse kl, 14 _ d _ kl ( _ π _ _ * * θ * * _ _ ∥ _ _ π _ proxy ), penalizes any deviation of _ π _ _ * * θ * * _ from _ π _ proxy, effectively forcing the policy to strictly imitate this non - ideal, heuristic target. this aggressive imitation constrains the protection of potentially valuable exploratory tokens. in contrast, the forward kl, _ d _ kl ( _ π _ proxy _ ∥ _ _ π _ _ * * θ * * _ ), provides a much softer regularization : it only penalizes the policy for completely discarding tokens that _ π _ proxy considers plausible, without forcing a strict match. this allows the policy to use _ π _ proxy as a stabilizing guide while retaining the freedom to explore beyond it, which empirically leads to better performance. | 0. 60 < br > 0. 55 < br > 0. 50 < br > 0. 45 < br > 0. 40 < br > 0. 35 < br > 0. 30 < br > 0 200 < br > trai | col2 | | - - - | - - - | | 0 < br > 200 < br > < br > trai < br > 0. 30 < br > 0. 35 < br > 0. 40 < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > 0. 60 < br > | | | 0 < br > 200 < br > < br > trai < br > 0. 30 < br > 0. 35 < br > 0. 40 < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > 0. 60 < br > | | | 0 < br > 200 < br > < br > trai < br > 0. 30 < br > 0. 35 < br > 0. 40 < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > 0. 60 < br > | | | 0 < br > 200 < br > < br > trai < br > 0. 30 < br > 0. 35 < br > 0. 40 < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > 0. 60 < br > | | | 0 < br > 200 < br > < br > trai < br > 0. 30 <"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 25,
    "text": "> 200 < br > < br > trai < br > 0. 30 < br > 0. 35 < br > 0. 40 < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > 0. 60 < br > | | | 0 < br > 200 < br > < br > trai < br > 0. 30 < br > 0. 35 < br > 0. 40 < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > 0. 60 < br > | | | 0 < br > 200 < br > < br > trai < br > 0. 30 < br > 0. 35 < br > 0. 40 < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > 0. 60 < br > | | | 0 < br > 200 < br > < br > trai < br > 0. 30 < br > 0. 35 < br > 0. 40 < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > 0. 60 < br > | | | 0 < br > 200 < br > < br > trai < br > 0. 30 < br > 0. 35 < br > 0. 40 < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > 0. 60 < br > | 400 < br > 600 < br > 800 < br > ning steps | figure 11 : ablation study comparing the forward and reverse kl formulations for the lp - reg penalty on the qwen3 - 14b - base model. the results demonstrate the superiority of the forward kl, which uses the heuristic proxy distribution as a soft guide, over the reverse kl, which forces a strict imitation. | 15 | col2 | | - - - | - - - | | 0 < br > 100 < br > 200 < br > tra < br > 0. 30 < br > 0. 35 < br > 0. 40 < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > 0. 60 < br > avg. test accuracy ( % ) | | | 0 < br > 100 < br > 200 < br > tra < br > 0. 30 < br > 0. 35 < br > 0. 40 < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > 0. 60 < br > avg. test accuracy ( % ) | | | 0 < br > 100 < br > 200 < br > tra < br > 0. 30 < br > 0. 35 < br > 0. 40 < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > 0. 60 < br > avg. test accuracy ( % ) | | | 0 < br > 100 < br > 200 < br > tra < br > 0. 30 < br > 0. 35 < br > 0. 40 < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > 0. 60 < br > avg. test accuracy ( % ) | | | 0 < br > 100 < br > 200 < br > tra < br > 0. 30 < br > 0. 35 < br > 0. 40 < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > 0. 60 < br > avg. test accuracy ( % ) | | | 0 < br > 100 < br > 200 < br > tra < br > 0. 30 < br > 0. 35 < br > 0. 40 < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > 0. 60 < br > avg. test accuracy ( % ) | | | 0 < br > 100 < br > 200 < br > tra < br > 0. 30 < br > 0. 35 < br > 0. 40 < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > 0. 60 < br > avg. test accuracy ( % ) | 300 < br > 400 < br > 500 < br > 600 < br > ining steps | ( a ) ablation study on _ ρ _ which defined the low - probability percentile threshold _ δ _ _ ρ _ _ [ b ] _. | entile threshold δbρ. 3 | col2 | | - - - | - - - | | 0 < br > 100 < br > 200 < br > tra < br > 0. 30 < br > 0. 35 < br > 0. 40 < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > 0. 60 < br > avg. test"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 26,
    "text": "| 0 < br > 100 < br > 200 < br > tra < br > 0. 30 < br > 0. 35 < br > 0. 40 < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > 0. 60 < br > avg. test accuracy ( % ) | 300 < br > 400 < br > 500 < br > 600 < br > ining steps | ( a ) ablation study on _ ρ _ which defined the low - probability percentile threshold _ δ _ _ ρ _ _ [ b ] _. | entile threshold δbρ. 3 | col2 | | - - - | - - - | | 0 < br > 100 < br > 200 < br > tra < br > 0. 30 < br > 0. 35 < br > 0. 40 < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > 0. 60 < br > avg. test accuracy ( % ) | | | 0 < br > 100 < br > 200 < br > tra < br > 0. 30 < br > 0. 35 < br > 0. 40 < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > 0. 60 < br > avg. test accuracy ( % ) | | | 0 < br > 100 < br > 200 < br > tra < br > 0. 30 < br > 0. 35 < br > 0. 40 < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > 0. 60 < br > avg. test accuracy ( % ) | | | 0 < br > 100 < br > 200 < br > tra < br > 0. 30 < br > 0. 35 < br > 0. 40 < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > 0. 60 < br > avg. test accuracy ( % ) | | | 0 < br > 100 < br > 200 < br > tra < br > 0. 30 < br > 0. 35 < br > 0. 40 < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > 0. 60 < br > avg. test accuracy ( % ) | | | 0 < br > 100 < br > 200 < br > tra < br > 0. 30 < br > 0. 35 < br > 0. 40 < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > 0. 60 < br > avg. test accuracy ( % ) | | | 0 < br > 100 < br > 200 < br > tra < br > 0. 30 < br > 0. 35 < br > 0. 40 < br > 0. 45 < br > 0. 50 < br > 0. 55 < br > 0. 60 < br > avg. test accuracy ( % ) | 300 < br > 400 < br > 500 < br > 600 < br > ining steps | ( b ) ablation study on _ κ _ which defined the noise threshold _ τ _ = _ κ _ _ · _ max _ o _ _ ′ _ _ ∈ _ _ v _ _ π _ _ * * θ * * _ ( _ o _ _ [ ′ ] _ _ | · _ ) figure 12 : training dynamics of lp - reg method with different hyperparameters. * * a. 3 * * * * hyperparameter sensitivity analysis * * in this section, we analyze the sensitivity of two core hyperparameters in lp - reg to demonstrate the robustness of our method : the low - probability percentile _ ρ _ and the min - p ratio _ κ _. the results are presented in figure 12. the parameter _ ρ _, as defined in our objective function ( equation 6 ), determines the percentile threshold for identifying low - probability tokens that are candidates for regularization. a higher _ ρ _ means a wider range of tokens are protected. as shown in the top panel of figure 12, we evaluated _ ρ _ with values of 0. 005, 0. 010, and 0. 015. the training trajectories for average test accuracy are comparable, and the final performance across all three settings is highly comparable. this indicates that lp - reg is not overly sensitive to the precise scope of tokens being protected within this reasonable range. the hyperparameter _ κ _ controls the adaptiveness of the min - p filtering threshold, which defines the boundary for what is treated as noise. a smaller _ κ _ results in a more conservative filtering strategy, removing fewer tokens. our 15 sensitivity analysis for _ κ _, presented in the bottom panel of figure 12, shows a similar trend of stability. across the tested values of 0. 01, 0. 02, and 0. 03, the training curves and final performance remain consistently high"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 27,
    "text": "probability tokens that are candidates for regularization. a higher _ ρ _ means a wider range of tokens are protected. as shown in the top panel of figure 12, we evaluated _ ρ _ with values of 0. 005, 0. 010, and 0. 015. the training trajectories for average test accuracy are comparable, and the final performance across all three settings is highly comparable. this indicates that lp - reg is not overly sensitive to the precise scope of tokens being protected within this reasonable range. the hyperparameter _ κ _ controls the adaptiveness of the min - p filtering threshold, which defines the boundary for what is treated as noise. a smaller _ κ _ results in a more conservative filtering strategy, removing fewer tokens. our 15 sensitivity analysis for _ κ _, presented in the bottom panel of figure 12, shows a similar trend of stability. across the tested values of 0. 01, 0. 02, and 0. 03, the training curves and final performance remain consistently high and tightly clustered. taken together, these results demonstrate the robustness of lp - reg. the method ’ s effectiveness is not contingent on extensive, fine - grained hyperparameter tuning, highlighting its practical applicability. * * b * * * * further analysis * * * * b. 1 * * * * details of sampling probability density * * this section provides a detailed, token - by - token breakdown of the aggregated distributions presented in figure 1c and figure 1d of the main paper, reinforcing the conclusions drawn from our analysis. figure 14 exhibits the individual distribution of observed sampling probabilities for a class of meaningful lowprobability exploratory tokens we term _ reasoning sparks _ : “ but ”, “ wait ”, “ perhaps ”, “ alternatively ”, and “ however ”. a consistent trend is observable across all five tokens, validating our claims in the introduction. with standard grpo training, the ability to sample these tokens at low probabilities is systematically eliminated, causing their distributions to collapse and shift towards higher probabilities. the indiscriminate entropy bonus ( grpo + entropy loss ) is largely ineffective at restoring this crucial low - probability tail. in stark contrast, our proposed method, lp - reg, consistently maintains a healthy, wide distribution for each of these tokens, demonstrating its effectiveness in preserving the model ’ s capacity for exploration. conversely, figure 15 details the behavior of a class of what we term irrelevant tokens ( e. g. “ cost ”, “ fine ”, “ balanced ”, “ ere ”, and “ trans ” ). we refer to the low - probability sampling of these tokens as irrelevant noise, which can be destructive to the training process. these individual plots clearly illustrate the detrimental side effect of a simple entropy bonus. for nearly every token, the grpo + entropy loss baseline significantly amplifies the sampling of this irrelevant noise, which, as shown in our main analysis, contributes to a faster performance collapse. lp - reg, by design, avoids this amplification and maintains a suppressed probability distribution for these tokens, comparable to or even more constrained than the standard grpo baseline. these detailed visualizations confirm that the elimination of _ reasoning sparks _ and the amplification of irrelevant noise are not artifacts of aggregation but are consistent patterns at the individual token level. this provides strong, granular evidence for the central challenge our paper addresses and highlights the necessity of a selective preservation mechanism like lp - reg. * * b. 2 * * * * details of probability - entropy distribution * * to supplement the aggregated analysis presented in figure 6 of the main text, this section provides a detailed breakdown of the probability - entropy distributions for individual meaningful exploratory tokens. figure 16 shows a consistent pattern across all representative tokens, ranging from “ but ” ( figure 16a ) to “ however ” ( figure 16e ). for frequently occurring tokens such as “ but ”, “ wait ”, and “ perhaps ”, we randomly subsample one out of every 20 instances for visualization. under the baseline grpo, these sparks are consistently confined to a low - entropy, highprobability region, indicating a collapse into deterministic usage. in contrast, the addition of an entropy loss pushes these tokens into highly scattered, often excessively high - entropy states, suggesting an uncontrolled and potentially noisy form of exploration. our method, lp - reg, strikes a crucial balance, maintaining a structured and broad distribution across a healthy range of entropy values. this consistent behavior demonstrates that the trends identified in the aggregated data are not artifacts of averaging. the individual plots offer strong, disaggregated evidence for our central claim : lp - reg effectively preserves the exploratory potential of reasoning sparks by preventing both the deterministic collapse seen in the baseline and the chaotic scattering induced by the indiscriminate entropy bonus. * * b. 3 * * * * training dynamics of regularized token * * to better understand how lp - reg operates during training, we analyze the dynamics of the probability threshold _ δ _ _ ρ _ _ ["
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 28,
    "text": ", these sparks are consistently confined to a low - entropy, highprobability region, indicating a collapse into deterministic usage. in contrast, the addition of an entropy loss pushes these tokens into highly scattered, often excessively high - entropy states, suggesting an uncontrolled and potentially noisy form of exploration. our method, lp - reg, strikes a crucial balance, maintaining a structured and broad distribution across a healthy range of entropy values. this consistent behavior demonstrates that the trends identified in the aggregated data are not artifacts of averaging. the individual plots offer strong, disaggregated evidence for our central claim : lp - reg effectively preserves the exploratory potential of reasoning sparks by preventing both the deterministic collapse seen in the baseline and the chaotic scattering induced by the indiscriminate entropy bonus. * * b. 3 * * * * training dynamics of regularized token * * to better understand how lp - reg operates during training, we analyze the dynamics of the probability threshold _ δ _ _ ρ _ _ [ b ] _ [ and the proportion of low - probability tokens subjected to regularization ] _ | _ _ π _ _ * * θ * * _ ( _ o _ _ | · _ ) _ | < _ _ πδ _ _ * * θ * * _ _ ρ _ _ [ b ] _ ( _ ∧ _ _ o _ _ | · _ _ π _ ) _ < _ proxy _ δ _ _ ρ _ _ [ b ] _ _ | _ ( _ o _ _ | · _ ) _ > _ 0 _ | _. as shown in figure 13, the threshold _ δ _ _ ρ _ _ [ b ] _ [ gradually decreases with training steps. in parallel, the regularization ratio also declines ] steadily. this trend suggests that as training progresses, the extreme low - probability range becomes increasingly dominated by irrelevant tokens, constituting what we term irrelevant noise. in parallel, the semantically meaningful exploratory tokens are lifted into higher - probability regions, thus requiring less regularization. * * b. 4 * * * * case study * * to further illustrate the effect of the filter applied on low - probability tokens, figure 17 presents a case study of a model - generated response, where low - probability tokens are highlighted according to whether they were preserved or filtered. tokens with probability greater than _ τ _ are those retained by the filter, while tokens with probability 16 | probability threshold and regularization ratio | col2 | robability thresho | col4 | old and regulariz | col6 | zation ra | atio | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | 128 < br > 256 < br > 384 < br > 512 < br > 640 < br > 768 < br > training steps < br > 0. 00 < br > 0. 02 < br > 0. 04 < br > 0. 06 < br > 0. 08 < br > probability threshold and regularization ratio < br > probability threshold < br > regularization ratio < br > 7. 5 < br > 10. 0 < br > 12. 5 < br > 15. 0 < br > 17. 5 < br > 20. 0 < br > 22. 5 < br > 25. 0 < br > 27. 5 < br > regularization ratio | 128 < br > 256 < br > 384 < br > 512 < br > 640 < br > 768 < br > training steps < br > 0. 00 < br > 0. 02 < br > 0. 04 < br > 0. 06 < br > 0. 08 < br > probability threshold and regularization ratio < br > probability threshold < br > regularization ratio < br > 7. 5 < br > 10. 0 < br > 12. 5 < br > 15. 0 < br > 17. 5 < br > 20. 0 < br > 22. 5 < br > 25. 0 < br > 27. 5 < br > regularization ratio | obability thresho | obability thresho | ld and regulariz < br > probabili < br > regulari | ld and regulariz < br > probabili < br > regulari | ation r < br > ty thresho < br > zation rati | tio < br > ld < br > o < br > 17. 5 < br > 20. 0 < br > 22. 5 < br > 25. 0 < br > 27. 5 < br > ization ratio | | 128 < br > 256 < br > 384 < br > 512 < br > 640 < br > 768 < br > training steps < br > 0. 00 < br > 0. 02 < br > 0. 04 < br > 0. 06 < br > 0. 08 < br > probability threshold and regularization ratio < br > probability threshold < br > regularization ratio < br > 7"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 29,
    "text": "25. 0 < br > 27. 5 < br > regularization ratio | obability thresho | obability thresho | ld and regulariz < br > probabili < br > regulari | ld and regulariz < br > probabili < br > regulari | ation r < br > ty thresho < br > zation rati | tio < br > ld < br > o < br > 17. 5 < br > 20. 0 < br > 22. 5 < br > 25. 0 < br > 27. 5 < br > ization ratio | | 128 < br > 256 < br > 384 < br > 512 < br > 640 < br > 768 < br > training steps < br > 0. 00 < br > 0. 02 < br > 0. 04 < br > 0. 06 < br > 0. 08 < br > probability threshold and regularization ratio < br > probability threshold < br > regularization ratio < br > 7. 5 < br > 10. 0 < br > 12. 5 < br > 15. 0 < br > 17. 5 < br > 20. 0 < br > 22. 5 < br > 25. 0 < br > 27. 5 < br > regularization ratio | | | | | | | | | 128 < br > 256 < br > 384 < br > 512 < br > 640 < br > 768 < br > training steps < br > 0. 00 < br > 0. 02 < br > 0. 04 < br > 0. 06 < br > 0. 08 < br > probability threshold and regularization ratio < br > probability threshold < br > regularization ratio < br > 7. 5 < br > 10. 0 < br > 12. 5 < br > 15. 0 < br > 17. 5 < br > 20. 0 < br > 22. 5 < br > 25. 0 < br > 27. 5 < br > regularization ratio | | | | | | | | | 128 < br > 256 < br > 384 < br > 512 < br > 640 < br > 768 < br > training steps < br > 0. 00 < br > 0. 02 < br > 0. 04 < br > 0. 06 < br > 0. 08 < br > probability threshold and regularization ratio < br > probability threshold < br > regularization ratio < br > 7. 5 < br > 10. 0 < br > 12. 5 < br > 15. 0 < br > 17. 5 < br > 20. 0 < br > 22. 5 < br > 25. 0 < br > 27. 5 < br > regularization ratio | | | | | | | | figure 13 : training dynamics of the probability threshold and regularization ratio. smaller than _ τ _ are suppressed. the preserved tokens include meaningful exploratory markers such as ” then ”, ” wait ”, which guide the reasoning trajectory, whereas the discarded set largely consists of relatively irrelevant tokens such as ” we ”, ” also ”, ” that ”. this qualitative evidence complements our quantitative analysis, demonstrating that lp - reg effectively leverages the min - p transformation to distinguish between valuable low - probability exploratory tokens ( _ reasoning sparks _ ) and tokens that constitute destabilizing, irrelevant noise. 17 | col1 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | n = | 656 < br > n = | 56 < br > n = | 656 < br > n = 2 | 239 < br > n = 11 | 311 < br > n = 28 | 73 < br > | ~ ~ = 2172 ~ ~ 8 < br > n = 35 | 21 | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | col1 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | n | 31 < br > n | 31 < br > n | 31 < br > n = 1 | 454 < br > n = 15 | 102 < br > n = 17 | 53 < br > | ~ ~ n = 8388 ~ ~ < br > n = 17 | 57 | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | col1 | col2 | col3 | col4 | col5"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 30,
    "text": "| | | | | | | | | | | | | | | | | | | | | | | | | | | | | col1 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | n | 31 < br > n | 31 < br > n | 31 < br > n = 1 | 454 < br > n = 15 | 102 < br > n = 17 | 53 < br > | ~ ~ n = 8388 ~ ~ < br > n = 17 | 57 | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | col1 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | n = 12 < br > n | n = 12 < br > n | 12 < br > n = 12 < br > n = 1 | 12 < br > n = 12 < br > n = 1 | 965 < br > n = 4 | 86 < br > n = 16 | 65 < br > | ~ ~ n = 6875 ~ ~ < br > n = 10 | 59 | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | col1 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | n = 14 < br > n | n = 14 < br > n | 14 < br > n = 14 < br > n = 4 | 14 < br > n = 14 < br > n = 4 | 891 < br > n = 1 | 19 < br > n = 7 | 55 < br > | n = 3125 < br > n = 61 | 50 | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | ( d ) density of observed sampling probabilities for token “ alternatively ”. ( a ) density of observed sampling probabilities for token “ but ”. ( b ) density of observed sampling probabilities for token “ wait ”. ( c ) density of observed sampling probabilities for token “ perhaps ”. | col1 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | n = | 499 < br > n = | 99 < br > n = | 499 < br > n = 1 | 864 < br > n = 2 | 52 < br > n = 2 | 00 < br > | ~ ~ n = 1907 ~ ~ < br > n = 40 | 92 | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | ( e ) density of observed sampling probabilities for token “ however ”. figure 14 : individual density of observed sampling probabilities for meaningful exploratory tokens : “ but ”, “ wait ”, “ perhaps ”, “ alternatively ”, and “ however ”. 18 | col1 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | n = | 156 < br > n = | 56 < br > n = | 156 < br > ~ ~ n = 60 ~ ~ | n = 5 | 1 < br > ~ ~ n = 89 ~ ~ | n = 107 | n = 246 < br > n | 96 | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | col1 | col2 | col3 | col4 | col5 | col6 | col7 | | - - - | - - - | - - - | - - -"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 31,
    "text": ", and “ however ”. 18 | col1 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | n = | 156 < br > n = | 56 < br > n = | 156 < br > ~ ~ n = 60 ~ ~ | n = 5 | 1 < br > ~ ~ n = 89 ~ ~ | n = 107 | n = 246 < br > n | 96 | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | col1 | col2 | col3 | col4 | col5 | col6 | col7 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | n = 3 < br > n | 3 < br > n = 3 < br > n = 13 | n = 4 | 1 < br > n = 32 | n = 23 | n = 130 < br > n | 23 | | | | | | | | | | | | | | | | | | | | | | | | | | col1 | col2 | col3 | col4 | col5 | col6 | col7 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | n = 1 < br > n | 1 < br > n = 1 < br > n = 43 | n = 2 | 1 < br > n = 30 | n = 38 | n = 95 < br > n | 30 | | | | | | | | | | | | | | | | | | | | | | | | | | col1 | col2 | col3 | col4 | col5 | col6 | | - - - | - - - | - - - | - - - | - - - | - - - | | n | 27 < br > n | = 27 < br > | n = 27 < br > n = 0 < br > n = 17 | n = 0 < br > n = 0 < br > n = | 7 < br > n = 0 | | | | | | | | | | | | | | | | | | | | | | ( d ) density of observed sampling probabilities for token “ ere ”. ( a ) density of observed sampling probabilities for token “ cost ”. ( b ) density of observed sampling probabilities for token “ fine ”. ( c ) density of observed sampling probabilities for token “ balanced ”. | col1 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | n | 5 < br > n | 5 < br > n | 5 < br > n = 208 | n = 6 | 4 < br > n = 79 | n = 166 | n = 446 < br > n | 91 | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | ( e ) density of observed sampling probabilities for token “ trans ”. figure 15 : individual density of observed sampling probabilities for irrelevant tokens : “ cost ”, “ fine ”, “ balanced ”, “ ere ”, and “ trans ”. 19 | 3. 5 | mean prob : | n = 21728 : 0. 9315 ± 0. 1801 | col4 | mean prob : 0. | | - - - | - - - | - - - | - - - | - - - | |. 5 < br > 3. 0 < br >. 5 | ~ ~ mean prob ~ ~ < br > mean entropy |. 8 < br > 1. 0 < br > < br > ~ ~ : 0. 9315 ± 0. 1801 ~ ~ < br > : 0. 1189 ± 0. 2440 < br > 0. 0 < br > 0. 2 < br > 0 < br > < br > 0 < br > 2 < br > 4 < br > 6 < br > 8 < br > 10 < br > entropy | | mean prob : 0. < br > mean entropy : 1. | |. 5 < br > 3. 0 < br >. 5 | | | | | | 2. 0 < br > | | | | | | 1. 0 <"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 32,
    "text": "1801 | col4 | mean prob : 0. | | - - - | - - - | - - - | - - - | - - - | |. 5 < br > 3. 0 < br >. 5 | ~ ~ mean prob ~ ~ < br > mean entropy |. 8 < br > 1. 0 < br > < br > ~ ~ : 0. 9315 ± 0. 1801 ~ ~ < br > : 0. 1189 ± 0. 2440 < br > 0. 0 < br > 0. 2 < br > 0 < br > < br > 0 < br > 2 < br > 4 < br > 6 < br > 8 < br > 10 < br > entropy | | mean prob : 0. < br > mean entropy : 1. | |. 5 < br > 3. 0 < br >. 5 | | | | | | 2. 0 < br > | | | | | | 1. 0 < br > 1. 5 | | | | | | 1. 0 < br > 1. 5 | | | | | | 1. 0 < br > 1. 5 | | | | | | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0 < br > < br > 0. 0 < br > 0. 5 | | | | | | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0 < br > < br > 0. 0 < br > 0. 5 | | | |. 4 < br > 0. 6 < br > 0. 8 < br > | | m | n = 3582 mean prob : 0. 7323 ± 0. 303 | | - - - | - - - | | me | mean prob : 0. 7323 ± 0. 30 < br > an entropy : 0. 5976 ± 0. 58 | | | | | | | | | | | | | | | 6 < br > 0. 8 < br > 1. 0 < br > | ( a ) scattered probability – entropy plot of observed sampling instances for the token “ but ”. | col1 | mean prob : | n = 8388 : 0. 8975 ± 0. 2159 | col4 | mean prob : 0. | | - - - | - - - | - - - | - - - | - - - | |. 5 < br > 2. 0 | mean prob < br > mean entropy |. 8 < br > 1. 0 < br > < br > : 0. 8975 ± 0. 2159 < br > : 0. 1747 ± 0. 2816 < br > 0. 0 < br > 0. 2 < br > 0 < br > < br > 0 < br > 2 < br > 4 < br > 6 < br > 8 < br > 10 < br > entropy | | mean prob : 0. < br > mean entropy : 1. | |. 5 < br > 1. 0 < br > | | | | | |. 5 < br > 1. 0 < br > | | | | | |. 5 < br > 1. 0 < br > | | | | | | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0 < br > < br > 0. 0 < br > | | | | | | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0 < br > < br > 0. 0 < br > | | | |. 4 < br > 0. 6 < br > 0. 8 < br > | | m | n = 1715 mean prob : 0. 7356 ± 0. 307 | | - - - | - - - | | me | mean prob : 0. 7356 ± 0. 30 < br > an entropy : 0. 5430 ± 0. 53 | | | | | | | | | | | | 6 < br > 0. 8 < br > 1. 0 < br > | ( b ) scattered probability – entropy plot of observed sampling instances for the token | ait ”. 2. 00 | mean prob grpo | | - - - | - - - | | 1. 25 < br > 1. 50 < br > 1. 75 | mean pro < br > mean entropy | | 1. 25 < br > 1. 50 < br > 1. 75 | | |. 75 < br > 1. 00 | | |. 75 < br > 1. 00 | | | 0. 50 < br > | | | 0. 50 < br > | | | 0. 0 < br > 0. 2 < br >"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 33,
    "text": "| - - - | - - - | | me | mean prob : 0. 7356 ± 0. 30 < br > an entropy : 0. 5430 ± 0. 53 | | | | | | | | | | | | 6 < br > 0. 8 < br > 1. 0 < br > | ( b ) scattered probability – entropy plot of observed sampling instances for the token | ait ”. 2. 00 | mean prob grpo | | - - - | - - - | | 1. 25 < br > 1. 50 < br > 1. 75 | mean pro < br > mean entropy | | 1. 25 < br > 1. 50 < br > 1. 75 | | |. 75 < br > 1. 00 | | |. 75 < br > 1. 00 | | | 0. 50 < br > | | | 0. 50 < br > | | | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > < br > < br > 0. 00 < br >. 25 | | | col1 | meamne eannt proropby : : 20 |.. 13175327 ±± 10.. 92695351 4. 0 me < br > 3. 5 < br > 3. 0 < br > 2. 5 entropy < br > 2. 0 < br > 1. 5 < br > 1. 0 < br > 0. 5 < br > 1. 0 0. 00. 0 0. 2 0. 4 0. | me | amne eannt proropby : : 00.. 67603499 ±± 00.. 6311 | | - - - | - - - | - - - | - - - | - - - | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | 0. 4 < br > 0. 6 < br > 0. 8 < br > | 0. 4 < br > 0. 6 < br > 0. 8 < br > | 0. 4 < br > 0. 6 < br > 0. 8 < br > | 6 < br > 0. 8 < br > 1. 0 < br > | ( c ) scattered probability – entropy plot of observed sampling instances for the token “ perhaps ”. | 1. 6 | mean prob : grpo | | - - - | - - - | | 1. 2 < br > 1. 4 < br > | mean prob : < br > mean entropy : | | 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > | | | 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > | | | 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > | | | 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > | | | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0 < br > < br > 0. 0 < br >. 2 | | | col1 | mean prob : 0. 3 | n = 1419 3093 ± 0. 2816 | m | n = 615 mean prob : 0. 6740 ± 0. 315 | | - - - | - - - | - - - | - - - | - - - | | | mean prob : 0. < br > mean entropy : 2. | 3093 ± 0. 2816 < br > 0874 ± 2. 0776 < br > 2. 5 < br > 3. 0 < br > 3. 5 < br > 4. 0 < br > ropy | me | mean prob : 0. 6740 ± 0. 31 < br > an entropy : 0. 7196 ± 0. 59 | | | mean prob : 0. < br > mean entropy : 2. | 3093 ± 0. 2816 < br > 0874 ± 2. 0776 < br > 2. 5 < br > 3. 0 < br > 3. 5 < br > 4. 0 < br > ropy | | | | | | | | | | | | 1. 0 < br > 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. < br > < br > 0. 0 < br > 0. 5 < br > 1. 0 < br > 1. 5 < br > 2. 0 < br > ent | | | | | | | | | |"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 34,
    "text": "5 < br > 3. 0 < br > 3. 5 < br > 4. 0 < br > ropy | me | mean prob : 0. 6740 ± 0. 31 < br > an entropy : 0. 7196 ± 0. 59 | | | mean prob : 0. < br > mean entropy : 2. | 3093 ± 0. 2816 < br > 0874 ± 2. 0776 < br > 2. 5 < br > 3. 0 < br > 3. 5 < br > 4. 0 < br > ropy | | | | | | | | | | | | 1. 0 < br > 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. < br > < br > 0. 0 < br > 0. 5 < br > 1. 0 < br > 1. 5 < br > 2. 0 < br > ent | | | | | | | | | | | | | | | | | | | | | | |. 4 < br > 0. 6 < br > 0. 8 < br > |. 4 < br > 0. 6 < br > 0. 8 < br > |. 4 < br > 0. 6 < br > 0. 8 < br > | 6 < br > 0. 8 < br > 1. 0 < br > | ( d ) scattered probability – entropy plot of observed sampling instances for the token “ alternatively ”. | col1 | mean prob : | | - - - | - - - | | 1. 2 < br > 1. 4 < br > 1. 6 | mean prob : < br > ~ ~ mean entropy : ~ ~ | | 1. 2 < br > 1. 4 < br > 1. 6 | | | 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > | | | 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > | | | 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > | | | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0 < br > < br > 0. 0 < br >. 2 | | | col1 | meamne eannt proropby : : 20.. | 03075811 ±± 20.. 13311360 < br > 3. 5 < br > 3. 0 < br > 2. 5 < br > tropy < br > 2. 0 | me | amne eannt proropby : : 00.. 86402011 ±± 00.. 6312 | | - - - | - - - | - - - | - - - | - - - | | | mean prob : 0. < br > mean entropy : 2. | 3781 ± 0. 3130 < br > 0051 ± 2. 1316 < br > 2. 0 < br > 2. 5 < br > 3. 0 < br > 3. 5 < br > tropy | | | | | | | | | | | | 1. 0 < br > 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. < br > < br > 0. 0 < br > 0. 5 < br > 1. 0 < br > 1. 5 < br > en | | | | | | 1. 0 < br > 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. < br > < br > 0. 0 < br > 0. 5 < br > 1. 0 < br > 1. 5 < br > en | | | | | | | | | | |. 4 < br > 0. 6 < br > 0. 8 < br > |. 4 < br > 0. 6 < br > 0. 8 < br > |. 4 < br > 0. 6 < br > 0. 8 < br > | 6 < br > 0. 8 < br > 1. 0 < br > | ( e ) scattered probability – entropy plot of observed sampling instances for the token “ however ”. figure 16 : individual scattered probability – entropy plot of observed sampling instances for meaningful tokens : “ but ”, “ wait ”, “ perhaps ”, “ alternatively ”, and “ however ”. 20 figure 17 : an example generated by qwen3 - 14b - base model trained by lp - reg from math reasoning. 21"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03222v1",
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "authors": [
        "Guanhua Huang",
        "Tingqiang Xu",
        "Mingze Wang",
        "Qi Yi",
        "Xue Gong",
        "Siheng Li",
        "Ruibin Xiong",
        "Kejiao Li",
        "Yuhao Jiang",
        "Bo Zhou"
      ],
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "published": "2025-10-03T17:56:13Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03222v1"
    },
    "chunk_id": 35,
    "text": "| | | | | |. 4 < br > 0. 6 < br > 0. 8 < br > |. 4 < br > 0. 6 < br > 0. 8 < br > |. 4 < br > 0. 6 < br > 0. 8 < br > | 6 < br > 0. 8 < br > 1. 0 < br > | ( e ) scattered probability – entropy plot of observed sampling instances for the token “ however ”. figure 16 : individual scattered probability – entropy plot of observed sampling instances for meaningful tokens : “ but ”, “ wait ”, “ perhaps ”, “ alternatively ”, and “ however ”. 20 figure 17 : an example generated by qwen3 - 14b - base model trained by lp - reg from math reasoning. 21"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03217v1",
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "authors": [
        "José Cambronero",
        "Michele Tufano",
        "Sherry Shi",
        "Renyao Wei",
        "Grant Uy",
        "Runxiang Cheng",
        "Chin-Jung Liu",
        "Shiying Pan",
        "Satish Chandra",
        "Pat Rondon"
      ],
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "published": "2025-10-03T17:53:28Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03217v1"
    },
    "chunk_id": 0,
    "text": "# # * * abstain and validate : a dual - llm policy for reducing noise in * * * * agentic program repair * * jose cambronero [ 1 ], michele tufano [ 1 ], sherry shi [ 1 ], renyao wei [ 1 ], grant uy [ 1 ], runxiang cheng [ 1 ], chin - jung liu [ 1 ], shiying pan [ 1 ], pat rondon [ 1 ], satish chandra [ 2 ∗ ] 1 google, usa 2 meta, usa { jcambronero, tufanomichele, sherryyshi, renyaow, grantuy, chengsam, chinjungliu, shiyingp, rondon } @ google. com schandra @ acm. org * * abstract * * agentic automated program repair ( apr ) is increasingly tackling complex, repository - level bugs in industry, but ultimately agentgenerated patches still need to be reviewed by a human before committing them to ensure they address the bug. showing unlikely patches to developers can lead to substantial noise, wasting valuable developer time and eroding trust in automated code changes. we introduce two complementary llm - based policies to reduce such noise : bug abstention and patch validation policies. bug abstention excludes bugs that the agentic apr system is unlikely to fix. patch validation rejects patches that are unlikely to be a good fix for the given bug. we evaluate both policies on three sets of bugs from google ’ s codebase, and their candidate patches generated by an internal agentic apr system. on a set of 174 human - reported bugs, removing bugs and patch trajectories rejected by our policies can raise success rates by up to 13 percentage points and 15 percentage points, respectively, and by up to 39 percentage points in combination. on null pointer exceptions and sanitizer - reported bugs with machine - generated bug reports, patch validation also improves average single - sample success rates. this two - policy approach provides a practical path to the reliable, industrial - scale deployment of agentic apr systems. * * 1 * * * * introduction * * a substantial portion of software development involves diagnosing and repairing bugs. to mitigate this cost, the research community has long invested in automated program repair ( apr ) [ 16 – 18, 23 ]. more recently, advanced language models have enabled more complex, autonomous “ repository - level ” program repair, where a system manages diagnosis, localization, and repair. systems like sweagent [ 35 ], autocoderover [ 36 ], specrover [ 28 ], and repairagent [ 3 ] show that agent - based apr can tackle such challenge, achieving pass @ 1 bug resolution rates up to 75. 20 % on benchmarks like swe - bench - verified ( trae as of 09 / 02 / 2025 [ 11 ] ). in an industry setting, however, maximizing the rate of successful patches shown to a developer from an apr system is as important as maximizing the system ’ s overall bug resolution rate. while pass @ 1 rates are improving, deploying these agents in production still requires a human developer to review and validate the generated patches. because developer time is limited, reviewing patches for intractable bugs or unlikely fixes wastes valuable time. reducing such noise from unproductive apr attempts is thus crucial, not only to save developer time but also to build developer trust in automated ∗ work done while at google. code changes, which is essential for ai tool adoption [ 4, 24 ]. this work aims to tackle this challenge by proposing two policies. first, inspired by abstention in classification [ 6, 12, 13 ], we introduce bug abstention ( section 3. 1 ). we use an llm to predict if our apr system is likely to produce an acceptable patch for a given bug, using only the bug report information. this check is performed _ before _ the agent attempts a repair. if the predicted probability of success is below a threshold, we abstain from running the repair agent. this avoids showing developers unlikely patches and saves compute costs from futile repair attempts. second, for any patches produced, we employ a multi - stage patch validation policy to predict if the patch is correct ( section 3. 2 ). this policy composes deterministic checks ( e. g., running tests ) and an llm - based filter. the llm filter first generates a “ fix specification ” — a guideline for a correct fix — based on the bug description and original source files, without knowledge of any ground - truth solution. a second llm call uses this specification and the agent ’ s trajectory to produce a boolean ( fixed or not ) outcome, an explanation, and a confidence score derived from token - level log probabilities. we evaluate the bug abstention and patch validation policies both independently and in combination ( section 4 ). our combined, two - policy approach first employs bug abstention to screen out bugs unlikely to"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03217v1",
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "authors": [
        "José Cambronero",
        "Michele Tufano",
        "Sherry Shi",
        "Renyao Wei",
        "Grant Uy",
        "Runxiang Cheng",
        "Chin-Jung Liu",
        "Shiying Pan",
        "Satish Chandra",
        "Pat Rondon"
      ],
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "published": "2025-10-03T17:53:28Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03217v1"
    },
    "chunk_id": 1,
    "text": "is below a threshold, we abstain from running the repair agent. this avoids showing developers unlikely patches and saves compute costs from futile repair attempts. second, for any patches produced, we employ a multi - stage patch validation policy to predict if the patch is correct ( section 3. 2 ). this policy composes deterministic checks ( e. g., running tests ) and an llm - based filter. the llm filter first generates a “ fix specification ” — a guideline for a correct fix — based on the bug description and original source files, without knowledge of any ground - truth solution. a second llm call uses this specification and the agent ’ s trajectory to produce a boolean ( fixed or not ) outcome, an explanation, and a confidence score derived from token - level log probabilities. we evaluate the bug abstention and patch validation policies both independently and in combination ( section 4 ). our combined, two - policy approach first employs bug abstention to screen out bugs unlikely to be fixed, then runs the apr system on the remaining bugs, and finally uses patch validation to filter the generated patches. our evaluation shows these policies are complementary, improving success rates most effectively when combined. we evaluate our policies on three sets of bugs from google ’ s codebase ( section 5 ). similar to recent work [ 14, 20, 27 ], the first set has 174 human - reported bugs with known ground - truth fixes and fail - to - pass reproduction tests. we evaluate both policies on repair trajectories generated by our react - style apr system for this set. we further study patch validation on 198 machine - reported java null pointer exception ( npe ) bugs from a live deployment and 50 historical, sanitizer - reported bugs with known reproduction tests. because our goal is to reduce developer noise, we introduce “ filtered - success @ k ”. this metric computes success ( e. g., fail - to - pass or human acceptance ) only on the subset of patches and bugs that are “ allowed ” by our policies, rather than over the entire population. on our human - reported bug set, the baseline fail - to - pass @ 1 rate is 0. 11. applying bug abstention or patch validation alone raises this rate to 0. 21 or 0. 29, respectively. when combined, these policies form a configurable funnel that significantly improves the quality of patches shown to developers. a moderately permissive setting raises the filtered fail - to - pass @ 1 to 0. 35. a stricter funnel configuration raises this rate to 0. 53 — a 1 - in - 2 success rate — at google et al. * * figure 1 : bug abstention rejects issues that are unlikely to be fixed by our apr system. after the agent generates patches, * * * * validation decides whether these are likely to have addressed the issue. jointly they reduce developer noise from apr. * * the cost of showing patches for fewer bugs. on machine - reported bug sets, patch validation alone also shows significant gains : for npe bugs, it raises the filtered - accept @ 1 from 0. 38 to 0. 62, and for sanitizer bugs, it improves the rate by up to 15 percentage points over a baseline using known reproduction tests. to summarize, our contributions in this work are : - a bug abstention policy to select bugs suitable for agentic apr. - a multi - stage patch validation policy to assess candidate patch correctness. - an extensive evaluation on three industrial bug sets. * * 2 * * * * background : react - style agentic apr * * our agentic apr system consists of an llm - driven react - style loop with coding tools designed to interact with an isolated google environment [ 26 ]. at the start of the process, the agent is provided with a bug report, which may contain varying degrees of information about the underlying bug. the agent then proceeds for a sequence of up to _ [UNK] _ steps, where each step is defined as one llm output and an associated tool execution. the tools are : code search, viewing a file, editing a file, running tests, and finishing the repair trajectory. the llm output consists of two portions : a thought, describing the agent ’ s intentions in natural language, and an action, a simple unix - style function calling format which we parse and then use to execute the associated tool [ ∗ ]. the llm output and environment responses are added to an append - only history. for more details on the underlying agent, we refer the interested reader to [ 27 ]. * * 3 * * * * abstention and validation policies * * we introduce two key components into an agentic apr system to reduce developer noise. in figure 1, we augment the core apr agent module ( in blue ) with a component before the repair loop ( bug abstention ) and a component after the repair loop ( patch validation ). the bug abstention policy filters out bugs that the apr agent"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03217v1",
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "authors": [
        "José Cambronero",
        "Michele Tufano",
        "Sherry Shi",
        "Renyao Wei",
        "Grant Uy",
        "Runxiang Cheng",
        "Chin-Jung Liu",
        "Shiying Pan",
        "Satish Chandra",
        "Pat Rondon"
      ],
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "published": "2025-10-03T17:53:28Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03217v1"
    },
    "chunk_id": 2,
    "text": "one llm output and an associated tool execution. the tools are : code search, viewing a file, editing a file, running tests, and finishing the repair trajectory. the llm output consists of two portions : a thought, describing the agent ’ s intentions in natural language, and an action, a simple unix - style function calling format which we parse and then use to execute the associated tool [ ∗ ]. the llm output and environment responses are added to an append - only history. for more details on the underlying agent, we refer the interested reader to [ 27 ]. * * 3 * * * * abstention and validation policies * * we introduce two key components into an agentic apr system to reduce developer noise. in figure 1, we augment the core apr agent module ( in blue ) with a component before the repair loop ( bug abstention ) and a component after the repair loop ( patch validation ). the bug abstention policy filters out bugs that the apr agent is unlikely to fix, while the patch validation policy filters out patches that are unlikely to be a correct fix for a given bug. we now describe these policies in more detail. * * 3. 1 * * * * bug abstention policy * * abstention is a well - known technique in classification [ 8 ], and amounts to allowing a _ [UNK] _ - label classifier to produce an extra label ∗ one of our experiments relies on gemini function calling instead of custom parsing. corresponding to “ unknown ” ( i. e. abstaining from making a decision ). analogously, in the repair setting, we say a system abstains from a bug if it decides that it will not attempt repair. importantly, the abstention policy can only access the bug, which comprises textual bug title, description, and accompanying metadata, to make its decision ; it does not receive any additional human feedback. we also choose not to provide codebase access to the abstention policy, which may otherwise require making the policy agentic and losing some efficiency gains. we choose to model this problem in a probabilistic fashion to produce a score, rather than a boolean decision. intuitively, we want this score to approximate the inherent probability of a single repair attempt succeeding. we then convert this into a decision by comparing it to a configurable threshold, _ [UNK] _. _ 3. 1. 1 _ _ formalization. _ let _ [UNK] _ ∈b be a bug in a set of bugs that has been provided to our repair system as they require code changes for their resolution. we assume that knowing that these bugs require explicit code changes is already determined in a pre - filtering phase or because a user has informed the system. let there be _ [UNK] _ independent bernoulli trials reflecting _ [UNK] _ independent repair attempts by the repair agent on _ [UNK] _. the outcome of the _ [UNK] _ - th trial for bug _ [UNK] _, _ [UNK] _ _ [UNK], [UNK] _, is 1 if the agent generates a successful patch in trial _ [UNK] _ and 0 otherwise. accordingly, we define the * * empirical probability of the agent ’ s * * * * success on bug * * _ [UNK] _ as ˆ _ [UNK] _ _ [UNK] _ = _ [UNK] _ [ 1 ] _ [UNK] _ = 1 _ [ [UNK] ] _ _ [ [UNK], [UNK] ] _ [, or the expected value of a ] repair trial. this empirical value ˆ _ [UNK] _ _ [UNK] _ is an observation - based estimate of the * * unknown, true probability of success for bug * * _ [UNK] _, with respect to a particular repair system, which we denote as _ [UNK] _ _ [UNK] _ = _ [UNK] _ ( _ [UNK] _ _ [UNK], [UNK] _ = 1 ). estimating ˆ _ [UNK] _ _ [UNK] _ requires a success criterion, such as a test oracle or human reviewer. during deployment, however, such criterion is either unavailable ( no test ), or renders the estimation unnecessary ( manual review on all patches ). thus, for a given bug _ [UNK] _, we leverage an abstention model _ [UNK] _ _ [UNK] _ to produce _ [UNK] _ _ [UNK] _ ( _ [UNK] _ ), which then is used to estimate ˆ _ [UNK] _ _ [UNK] _, _ a priori _. we aim to turn _ [UNK] _ _ [UNK] _ ( _ [UNK] _ ) into a decision policy that allows us to filter down the original bug set b to a new set b [ ′ ], such that b [ ′ ] ⊆b and e _ [UNK] _ ′ ∈b ′ [ _ [UNK] _ _ [UNK] _ ′ ] _ > _ e _ [UNK] _ ∈b [ _ [UNK] _ _ [UNK] _ ], demonstrating a reduced probability of wasted repair attempts. explicitly, the abstention model ’ s prediction can be turned into a decision policy through a threshold. let this be expressed as a function, _ [UNK] _ _ [UNK] _, which maps the model ’ s predicted success likelihood to an action from the set { attemptrepair"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03217v1",
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "authors": [
        "José Cambronero",
        "Michele Tufano",
        "Sherry Shi",
        "Renyao Wei",
        "Grant Uy",
        "Runxiang Cheng",
        "Chin-Jung Liu",
        "Shiying Pan",
        "Satish Chandra",
        "Pat Rondon"
      ],
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "published": "2025-10-03T17:53:28Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03217v1"
    },
    "chunk_id": 3,
    "text": "for a given bug _ [UNK] _, we leverage an abstention model _ [UNK] _ _ [UNK] _ to produce _ [UNK] _ _ [UNK] _ ( _ [UNK] _ ), which then is used to estimate ˆ _ [UNK] _ _ [UNK] _, _ a priori _. we aim to turn _ [UNK] _ _ [UNK] _ ( _ [UNK] _ ) into a decision policy that allows us to filter down the original bug set b to a new set b [ ′ ], such that b [ ′ ] ⊆b and e _ [UNK] _ ′ ∈b ′ [ _ [UNK] _ _ [UNK] _ ′ ] _ > _ e _ [UNK] _ ∈b [ _ [UNK] _ _ [UNK] _ ], demonstrating a reduced probability of wasted repair attempts. explicitly, the abstention model ’ s prediction can be turned into a decision policy through a threshold. let this be expressed as a function, _ [UNK] _ _ [UNK] _, which maps the model ’ s predicted success likelihood to an action from the set { attemptrepair _, _ abstain }. given a predefined threshold, _ [UNK] _ ∈ [ 0 _, _ 1 ], the decision rule is formalized as : abstain and validate : a dual - llm policy for reducing noise in agentic program repair _ [UNK] _ _ [UNK] _ ( _ [UNK] _ _ [UNK] _ ( _ [UNK] _ ) _, [UNK] _ ) = attemptrepair if _ [UNK] _ _ [UNK] _ ( _ [UNK] _ ) ≥ _ [UNK] _ abstain if _ [UNK] _ _ [UNK] _ ( _ [UNK] _ ) _ < [UNK] _ our abstention policy queries an llm to produce a prediction of the ( unobserved ) probability of an attempt successfully addressing a given bug. we use an instruction - style prompt and instruct the model to produce one of two possible outcomes, success ( attempt repair ) or failure ( abstain ), given a prompt with some representation _ [UNK] _ ( _ [UNK] _ ) of the given bug _ [UNK] _. we define _ [UNK] _ _ [UNK] _ ( outcome ) as the model predicted probability of that token. since success and failure are the only two possible outputs based on the instructions, the llm ’ s decoding should place relatively little weight on other tokens and so _ [UNK] _ _ [UNK] _ ( success | _ [UNK] _ ( _ [UNK] _ ) ) + _ [UNK] _ _ [UNK] _ ( failure | _ [UNK] _ ( _ [UNK] _ ) ) ≈ 1. we confirmed this property on a held - out set of bugs during our development. _ 3. 1. 2 _ _ bug representations. _ as is well known, the prompt used to query an llm can have a substantial impact on its performance [ 19, 31 ]. we describe two possible bug representations for our prompt. - _ [UNK] _ 1 ( _ [UNK] _ ) * * instruction prompting with title and descrip - * * * * tion. * * the llm is provided with the title and description of from the bug report, along with the capabilities of the agent used in our experiments. specifically, we provide information on the commands available to the agent, as well as the execution budget for the expected agent runs. the associated prompt ( shown in the appendix as listing 1 ) instructs the model to analyze the bug ’ s title and description and output only success or failure. - _ [UNK] _ 2 ( _ [UNK] _ ) * * instruction prompting adding guidelines. * * this representation builds on top of _ [UNK] _ 1 ( _ [UNK] _ ) by incorporating guidelines that can be used to determine the likelihood of success ful bug resolution. we derived these guidelines — detailed in listing 2 ( appendix ) — through a manual process on a held - out set of 50 human - filed bugs. four authors inspected the bug titles and descriptions, determined subjective difficulty levels, and provided short guideline that would help identifying bugs that could be resolved by reasonable attempts from an agent. one author collated the inspection outcomes into 5 basic guideline categories, such as “ clear problem & action ” and “ precise code localization ”. these guidelines are added to the prompt. * * 3. 2 * * * * patch validation policy * * patch validation performs an analogous accept / reject decision at the patch - level. specifically, it predicts whether a * * particular * * repair trajectory produced a successful patch for a specific bug. _ 3. 2. 1 _ _ formalization. _ let _ [UNK] _ be a particular trajectory from the repair agent when attempting to repair bug _ [UNK] _. given some representation of the trajectory, _ [UNK] _ ( _ [UNK] _ ), the policy predicts a triplet _ [UNK] _ _ [UNK] _ ( _ [UNK], [UNK] _ ( _ [UNK] _ ) ) ∈ { false _, _ true } ×σ [ ∗ ] ×r, where the first element is a binary judgment for patch correctness, the second element is a natural language explanation of the judgment, and the third element is an optional confidence score for the patch ’ s correctness. we then define a decision function"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03217v1",
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "authors": [
        "José Cambronero",
        "Michele Tufano",
        "Sherry Shi",
        "Renyao Wei",
        "Grant Uy",
        "Runxiang Cheng",
        "Chin-Jung Liu",
        "Shiying Pan",
        "Satish Chandra",
        "Pat Rondon"
      ],
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "published": "2025-10-03T17:53:28Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03217v1"
    },
    "chunk_id": 4,
    "text": "and “ precise code localization ”. these guidelines are added to the prompt. * * 3. 2 * * * * patch validation policy * * patch validation performs an analogous accept / reject decision at the patch - level. specifically, it predicts whether a * * particular * * repair trajectory produced a successful patch for a specific bug. _ 3. 2. 1 _ _ formalization. _ let _ [UNK] _ be a particular trajectory from the repair agent when attempting to repair bug _ [UNK] _. given some representation of the trajectory, _ [UNK] _ ( _ [UNK] _ ), the policy predicts a triplet _ [UNK] _ _ [UNK] _ ( _ [UNK], [UNK] _ ( _ [UNK] _ ) ) ∈ { false _, _ true } ×σ [ ∗ ] ×r, where the first element is a binary judgment for patch correctness, the second element is a natural language explanation of the judgment, and the third element is an optional confidence score for the patch ’ s correctness. we then define a decision function over this triplet, which can use the binary judgment or the patch correctness confidence score to filter out patches and allow for the intelligent allocation of human effort, filtering out less likely patches as noise and reducing review time. in our implementation, we compute _ [UNK] _ _ [UNK] _ using a multi - stage approach. we first perform build and test regression checks to remove patches that have known issues. specifically, we use google ’ s unified build system to extract targets that have any modified files as a direct dependency. alternatively, if the bug we are tackling has a known reproduction test, we replace this regression check with a filter that rejects any patches that fail to pass the reproduction test. next, our reviewer applies a simple heuristic which removes trajectories that have a final test command issued by the agent that results in a failure. note that this may capture different test targets than the build / test check as the agent is not restricted to executing only direct dependencies. finally, our validation employs a two - staged llm prediction, which we now describe in detail. _ 3. 2. 2 _ _ fix specification. _ past literature in the area of llms - as - judges has explored the use of generated rubrics to perform more accurate scoring of an answer [ 32 ]. however, this rubric is often based on additional information such as the reference answer [ 37 ], which is naturally unavailable in our setting, where we are attempting to repair a program without knowing the fix ahead of time. however, we do take inspiration from this line of research, and explore the llm ’ s ability to generate a set of criteria for determining if an agent attempt has successfully addressed a bug _ without _ access to any ground truth — we refer to this as a “ fix specification. ” we simply provide this specification as part of the llm judge prompt to produce a score for the patch. to generate the fix specification, we prompt an llm with the bug information and the _ original _ source code contents of the files that were edited in the agent ’ s candidate patch. importantly, this connects the fix specification and the agent ’ s attempt by re - using the localization information from the agent ’ s trajectory to generate the fix specification. note that this agent trajectory _ does not _ contain any information from the ground - truth fix — that is, the specification can only be derived from information known at the start of the repair attempt. we do not impose any format or structure on the generated specification and instead allow the llm to freely generate this content. in practice, the model often generates clear markdown with a diagnosis and list of expected properties of a correct change. _ 3. 2. 3 _ _ reviewing with a specification. _ once the llm has generated a fix specification, a second llm call judges the agent ’ s attempt. this prompt includes the bug information, the unified - diff - format patch produced from the agent ’ s trajectory, test result information ( extracted from the trajectory ) for any test targets run by the agent, and the generated fix specification. a test result consists of a numbered test attempt for a particular test suite target, and the associated environment response ( including logs for a failure ). if no test result information is found, we simply state “ no testing information is available ”. _ 3. 2. 4 _ _ reviewing without a specification. _ besides our specificationbased validation, we experiment with a variant of validation that consumes the bug description and the concatenation of all prompt messages and responses that were produced during the agent ’ s execution. recent work [ 25 ] has used this representation to judge an agent ’ s attempts to solve swe - bench tasks. _ 3. 2. 5 _ _ patch validation outputs. _ as described previously, the output of the validation policy is a triplet consisting of a judgment, a natural - language explanation, and a real - valued confidence score. to enforce this format, we employ constrained decoding [ 10, 29 ]. we define the patch"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03217v1",
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "authors": [
        "José Cambronero",
        "Michele Tufano",
        "Sherry Shi",
        "Renyao Wei",
        "Grant Uy",
        "Runxiang Cheng",
        "Chin-Jung Liu",
        "Shiying Pan",
        "Satish Chandra",
        "Pat Rondon"
      ],
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "published": "2025-10-03T17:53:28Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03217v1"
    },
    "chunk_id": 5,
    "text": "any test targets run by the agent, and the generated fix specification. a test result consists of a numbered test attempt for a particular test suite target, and the associated environment response ( including logs for a failure ). if no test result information is found, we simply state “ no testing information is available ”. _ 3. 2. 4 _ _ reviewing without a specification. _ besides our specificationbased validation, we experiment with a variant of validation that consumes the bug description and the concatenation of all prompt messages and responses that were produced during the agent ’ s execution. recent work [ 25 ] has used this representation to judge an agent ’ s attempts to solve swe - bench tasks. _ 3. 2. 5 _ _ patch validation outputs. _ as described previously, the output of the validation policy is a triplet consisting of a judgment, a natural - language explanation, and a real - valued confidence score. to enforce this format, we employ constrained decoding [ 10, 29 ]. we define the patch correctness confidence score for the response heuristically. if validation returns a negative binary judgment, this score is set to zero. if the validation returns a positive binary judgment, we set this score to the exponential of the average token log probabilities. while not a well - defined probability, our evaluation shows this score can improve performance over binary labels. _ 3. 2. 6 _ _ decisions over patch validation outputs. _ we can make decisions based on the binary judgment or the patch correctness confidence score extracted from the validation outputs. we consider two variants ( 1 ) * * binary * *, where we use the binary judgment and accept patches with a positive label ; ( 2 ) * * percentile of patch * * * * correctness confidence score * *, where we estimate a particular percentile cutoff across all patches for all bugs in the given set and then accept patches with a score at or above that cutoff. while percentile thresholding needs a set of patches to perform a judgment, it mitigates the risks of score drift, e. g. due to population or model changes, and closely aligns with the idea of budget - based reviewing ( i. e., a human reviews the top ≤ _ [UNK] _ patches ). * * 4 * * * * composing abstention and validation * * while abstention and validation policies can be used independently, these two policies can also be combined. we present and evaluate a simple sequential combination of the two policies. let _ [UNK] _ represent our repair system, which, given a _ [UNK] _ bug, generates multiple trajectories independently. each trajectory _ [UNK] _ has a _. _ patch property representing all changes made by the agent. let _ [UNK] _ _ [UNK] _ ( _ [UNK] _ ) be the probability predicted by the abstention policy for sampling a successful fix for bug _ [UNK] _. let _ [UNK] _ _ [UNK] _ ( _ [UNK], [UNK] _ ) be the patch validation policy output. let _ [UNK] _ _ [UNK] _ be the abstention threshold and _ [UNK] _ _ [UNK] _ be the decision function over the validation ’ s output. then the set of patches ultimately shown for human review is : { _ [UNK]. _ patch | _ [UNK] _ _ [UNK] _ ( _ [UNK] _ ) ≥ _ [UNK] _ _ [UNK] _ _, [UNK] _ ∈ _ [UNK] _ ( _ [UNK] _ ) _, [UNK] _ _ [UNK] _ ( _ [UNK] _ _ [UNK] _ ( _ [UNK], [UNK] _ ) ) }. we leave alternate compositions ( e. g., probability - based ) or further optimizations ( e. g., accounting for bug / review cost and fix value ) for future work. * * 5 * * * * evaluation * * we now describe our datasets, metrics, and research questions. * * 5. 1 * * * * datasets * * we use three industrial bug datasets ( table 1 ) for evaluation. bug abstention only applies to human - reported bugs. machine - reported bugs ( i. e., npe and sanitizer bugs ) are all good candidates for apr by construction, as they contain reproduction tests or stack traces. _ 5. 1. 1 _ _ human - reported bugs : _ from google ’ s monorepo, we collected a set of 174 human - reported bugs filed within a year by following a curation process similar to that for popular benchmarks like swe - bench and recent agentic apr work in industry [ 20, 27 ]. specifically, we adhere to the curation process detailed in [ 27 ] and additionally restrict examples to those with at most 31 test targets that depend on the associated ground truth files. bug curation steps detailed in appendix a. google et al. we then generated 20 trajectories with a 25 - step limit for each of the 174 bugs using our agentic apr system ( section 2 ) using gemini 2. 5 pro [ 7 ] with temperature 0. 2 and top _ p 0. 95. we consider the success criterion to be whether the held - out fail to - pass"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03217v1",
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "authors": [
        "José Cambronero",
        "Michele Tufano",
        "Sherry Shi",
        "Renyao Wei",
        "Grant Uy",
        "Runxiang Cheng",
        "Chin-Jung Liu",
        "Shiying Pan",
        "Satish Chandra",
        "Pat Rondon"
      ],
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "published": "2025-10-03T17:53:28Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03217v1"
    },
    "chunk_id": 6,
    "text": ") are all good candidates for apr by construction, as they contain reproduction tests or stack traces. _ 5. 1. 1 _ _ human - reported bugs : _ from google ’ s monorepo, we collected a set of 174 human - reported bugs filed within a year by following a curation process similar to that for popular benchmarks like swe - bench and recent agentic apr work in industry [ 20, 27 ]. specifically, we adhere to the curation process detailed in [ 27 ] and additionally restrict examples to those with at most 31 test targets that depend on the associated ground truth files. bug curation steps detailed in appendix a. google et al. we then generated 20 trajectories with a 25 - step limit for each of the 174 bugs using our agentic apr system ( section 2 ) using gemini 2. 5 pro [ 7 ] with temperature 0. 2 and top _ p 0. 95. we consider the success criterion to be whether the held - out fail to - pass test succeeds. we have found this criterion closely matches correctness in human - reported bugs from our codebase [ 27 ]. _ 5. 1. 2 _ _ null pointer exception ( npe ) bugs. _ we collected a set of 198 machine - reported npe bugs that our agent attempted to repair during a live deployment. every bug report includes a stack trace of the exception. the report may also include a section ( message blob ) that provides additional machine - generated debugging information. during deployment, our system used patch validation with fix specification to filter patches, normalize patches, and choose a single patch per bug based on majority voting. the normalization step includes normalizing identifier strings ( mapping each unique likely identifier string to a unique index ) and post - patch least - linecount tie - breakers. a patch was then sent for human review, and submitted to the codebase if a code owner accepted it as fix. during live deployment, our apr system setup differed in the following : function - calling is through gemini instead of custom react parsing, asynchronous step execution to allow long - running calls without blocking concurrent repairs nor overloading services, at most 5 trajectories were generated with 25 - step limit per bug. _ 5. 1. 3 _ _ sanitizer bugs. _ we collected a set of 50 sanitizer - reported bugs with a known ground - truth fix following the curation procedure described in our past work [ 27 ]. these bugs cover issues such as memory errors, data races, datatype overflows, typecasting errors, and fuzzer - detected errors. we use the same apr agent configuration as for our human - reported bug set. * * 5. 2 * * * * metrics * * we report precision and recall for both policies. for repair performance, we focus on a standard pass @ k metric, and a variant where bugs and patches are filtered by the corresponding policies. let b [ ′ ] be the set of bugs with at least one repair run / trajectory available after bug abstention has filtered bugs and patch validation has filtered patches, _ [UNK] _ [ ′ ] be the total number of runs remaining after applying patch validation, and _ [UNK] _ [ ′ ] be the successful count among those. then the filtered - success @ k metric is defined as : the success criterion differs by bug types. for human - reported bugs, we use the held - out ground - truth test to compute fail - topass and report filtered - fail - to - pass @ k. for npe bugs, which were open at the time of collection and may not have any tests, we use human acceptance annotations and report filtered - accept @ k. the annotations are from real code owners, or authors if the patch had not been reviewed by owners during live deployment, e. g., a patch not picked by majority voting ( § 5. 1. 2 ). for sanitizer bugs, which have known ground - truth fixes and a reproduction test at reporting time for filtering patches, we manually compare patches to groundtruth fixes for semantic equivalence, and report filtered - accept @ k. for both bug policies, we also include comparisons to a no - skill policy which always accepts bugs ( or patches, respectively ). under filtered - success @ _ [UNK] _ = e b [ ′ ] [ 1 − _ [UNK] _ ′ _ [UNK] _ − _ [UNK] _ ′ ~ ~ ~ ~ _ [UNK] _ ′ ~ ~ ~ ~ [ ] ] abstain and validate : a dual - llm policy for reducing noise in agentic program repair * * set * * * * description * * * * # * * * * policies * * * * success cri - * * * * teria * * human human reported bugs with known fix. npe open bugs from a live deployment of a repair system. sanitizer sanitizer reported bugs with known fix. 174 abstention passes held + validation out reproduc tion test. 198 validation confirmed correct by code"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03217v1",
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "authors": [
        "José Cambronero",
        "Michele Tufano",
        "Sherry Shi",
        "Renyao Wei",
        "Grant Uy",
        "Runxiang Cheng",
        "Chin-Jung Liu",
        "Shiying Pan",
        "Satish Chandra",
        "Pat Rondon"
      ],
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "published": "2025-10-03T17:53:28Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03217v1"
    },
    "chunk_id": 7,
    "text": "time for filtering patches, we manually compare patches to groundtruth fixes for semantic equivalence, and report filtered - accept @ k. for both bug policies, we also include comparisons to a no - skill policy which always accepts bugs ( or patches, respectively ). under filtered - success @ _ [UNK] _ = e b [ ′ ] [ 1 − _ [UNK] _ ′ _ [UNK] _ − _ [UNK] _ ′ ~ ~ ~ ~ _ [UNK] _ ′ ~ ~ ~ ~ [ ] ] abstain and validate : a dual - llm policy for reducing noise in agentic program repair * * set * * * * description * * * * # * * * * policies * * * * success cri - * * * * teria * * human human reported bugs with known fix. npe open bugs from a live deployment of a repair system. sanitizer sanitizer reported bugs with known fix. 174 abstention passes held + validation out reproduc tion test. 198 validation confirmed correct by code owner or manual inspection. 50 validation confirmed correct by manual in spection. | 1. 2 < br > 1. 0 < br > 0. 8 < br > density < br > 0. 6 < br > 0. 4 < br > 0. 2 < br > 0. 0 | distribution of e | mpirical vs. model | probabilities < br > source < br > r1 - abstention < br > r2 - abstention w / guidelines < br > empirical success rate | col5 | col6 | | - - - | - - - | - - - | - - - | - - - | - - - | | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > 1. 2 < br > density | | | r1 ~ ~ - ~ ~ absten < br > r2 ~ ~ - ~ ~ absten < br > ~ ~ empirical s ~ ~ | tion < br > tion w / g < br > ~ ~ ccess r ~ ~ | uidelines < br > ~ ~ te ~ ~ | | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > 1. 2 < br > density | | | | | | | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > 1. 2 < br > density | | | | | | | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > 1. 2 < br > density | | | | | | | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > 1. 2 < br > density | | | | | | | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > 1. 2 < br > density | | | | | | | 0 % < br > 20 % < br > 40 % < br > | 0 % < br > 20 % < br > 40 % < br > | 60 % < br > 80 % < br > 100 % < br > probability | 60 % < br > 80 % < br > 100 % < br > probability | 60 % < br > 80 % < br > 100 % < br > probability | 60 % < br > 80 % < br > 100 % < br > probability | * * table 1 : benchmarks, policies applied, and success criteria. * * this no - skill policy, the precision of predictions corresponds to the prevalence successful cases in the population. * * 5. 3 * * * * research questions * * we aim to answer the following four research questions : * * rq1 * * : can bug abstention successfully abstain on our human - reported bugs? does this improve filtered - fail - to - pass @ k? * * rq2 * * : can patch validation successfully predict if a patch should be rejected on our human - reported bugs? does this improve filteredfail - to - pass @ k? * * rq3 * * : does combining bug abstention and patch validation further improve filtered - fail - to - pass @ k on our human - reported bugs? * * rq4 * * : how does patch validation improve filtered - accept @ k on bugs with systematically - generated reports ( npe and sanitizer bugs ) and known reproduction tests ( sanitizer bugs )? *"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03217v1",
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "authors": [
        "José Cambronero",
        "Michele Tufano",
        "Sherry Shi",
        "Renyao Wei",
        "Grant Uy",
        "Runxiang Cheng",
        "Chin-Jung Liu",
        "Shiying Pan",
        "Satish Chandra",
        "Pat Rondon"
      ],
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "published": "2025-10-03T17:53:28Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03217v1"
    },
    "chunk_id": 8,
    "text": "applied, and success criteria. * * this no - skill policy, the precision of predictions corresponds to the prevalence successful cases in the population. * * 5. 3 * * * * research questions * * we aim to answer the following four research questions : * * rq1 * * : can bug abstention successfully abstain on our human - reported bugs? does this improve filtered - fail - to - pass @ k? * * rq2 * * : can patch validation successfully predict if a patch should be rejected on our human - reported bugs? does this improve filteredfail - to - pass @ k? * * rq3 * * : does combining bug abstention and patch validation further improve filtered - fail - to - pass @ k on our human - reported bugs? * * rq4 * * : how does patch validation improve filtered - accept @ k on bugs with systematically - generated reports ( npe and sanitizer bugs ) and known reproduction tests ( sanitizer bugs )? * * 6 * * * * results * * we now present our experimental results. at the time of these experiments, our abstention policy uses gemini 2. 0 flash ( newer models are now available ) patch validation policy uses gemini 2. 5 pro, and both perform greedy decoding ( temperature = 0 ). we expect to use a smaller model for abstention for efficiency as it runs on a larger number of inputs than patch validation. * * 6. 1 * * * * rq1 : bug abstention policy * * we evaluate bug abstention on the two bug representation variants : with and without the use of general guidelines ( section 3. 1. 2 ). figure 2 shows a comparison of model - predicted probabilities and the empirical success rate ( section 3. 1. 1 ) of repair runs for the 174 human - reported bugs. the empirical success rate ( green ) is the fraction of trajectories that have a passing outcome on the held - out reproduction test, which indicates the inherent difficulty of apr. as shown, it is heavily skewed, with the vast majority of bugs having a very low true success rate, concentrated in the 0 – 15 % range. the skewness confirms that an agentic apr system can benefit from an abstention mechanism to avoid wasting human review effort. * * figure 2 : using abstention with guidelines better aligns * * * * model probabilities with observed ( left - skewed ) rates. * * abstention with representation _ [UNK] _ 1 ( i. e., without guidelines ) produces a more uniform distribution of repair success probability. in contrast, abstention with _ [UNK] _ 2 ( i. e., with guidelines ) produces a distribution that much more aligns to that of the empirical success rate. we further measured the wasserstein distance [ 1 ] between each predicted distribution and the empirical success rate distribution : the distance from _ [UNK] _ 2 ( 0. 126 ) was nearly three times smaller than that from _ [UNK] _ 1 ( 0. 363 ), indicating that _ [UNK] _ 2 is a much better overall fit for bug abstention. like the empirical data, abstention predictions with _ [UNK] _ 2 are correctly concentrated at lower probability values, while still assigning a higher repair success probability to easier bugs. figure 3 presents precision - recall curves for both abstention policy variants, a horizontal line for the prevalence of a success, and a summary average precision ( ap ) score. for purposes of this classification, we define success as any bug that has at least one repair trajectory that passes the held - out reproduction test among the 20 trajectories of the bug. the prevalence of success corresponds to the precision that could be expected from a no - skill policy, which just accepts all bugs, and all patches for these bugs. for our humanreported bug set, this prevalence corresponds to 27 % of all bugs having at least one successful repair trajectory without any abstention filtering. we observe that both abstention policy variants can improve over prevalence ; adding guidelines further provides improvements across a range of recall values. to turn the abstention predictions into a decision policy, we select _ [UNK] _ = 0 _. _ 5 as a sensible default for the abstention policy threshold based on a separate development bug set. using this threshold produces a precision / recall of 0. 44 / 0. 41 in that set. this threshold is also intuitive, as it prioritizes bugs with a predicted success probability greater than failure. more importantly, it achieves a strong balance between precision and recall, effectively filtering out a large number of bugs unlikely to be fixed while retaining a significant portion of the fixable ones. figure 4 shows the pass @ k ( when abstension is not applied ) and the corresponding filtered - fail - to - pass @ k ( when abstention is applied ) of our agentic apr system on the set of 174 humanreported bugs. we use _ [UNK] _ = 0 _. _ 5 when applying abstention. applying abstention improves the system ’ s efficacy, and the _"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03217v1",
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "authors": [
        "José Cambronero",
        "Michele Tufano",
        "Sherry Shi",
        "Renyao Wei",
        "Grant Uy",
        "Runxiang Cheng",
        "Chin-Jung Liu",
        "Shiying Pan",
        "Satish Chandra",
        "Pat Rondon"
      ],
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "published": "2025-10-03T17:53:28Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03217v1"
    },
    "chunk_id": 9,
    "text": "a range of recall values. to turn the abstention predictions into a decision policy, we select _ [UNK] _ = 0 _. _ 5 as a sensible default for the abstention policy threshold based on a separate development bug set. using this threshold produces a precision / recall of 0. 44 / 0. 41 in that set. this threshold is also intuitive, as it prioritizes bugs with a predicted success probability greater than failure. more importantly, it achieves a strong balance between precision and recall, effectively filtering out a large number of bugs unlikely to be fixed while retaining a significant portion of the fixable ones. figure 4 shows the pass @ k ( when abstension is not applied ) and the corresponding filtered - fail - to - pass @ k ( when abstention is applied ) of our agentic apr system on the set of 174 humanreported bugs. we use _ [UNK] _ = 0 _. _ 5 when applying abstention. applying abstention improves the system ’ s efficacy, and the _ [UNK] _ 2 abstention variant demonstrates the most significant gain. the baseline ( no google et al. | 1. 0 no - skill classifier ( prevalence = 0. 27 ) < br > r1 - abstention ( ap = 0. 389 ) < br > r2 - abstention w / guidelines ( ap = 0. 43 < br > 0. 8 < br > 0. 6 < br > precision < br > 0. 4 < br > 0. 2 < br > 0. 0 < br > 0. 0 0. 2 0. 4 0. 6 0. 8 | no - skill classifier ( prevalence = 0. 27 ) < br > r1 - abstention ( ap = 0. 389 ) < br > r2 - abstention w / guidelines ( ap = 0. 43 | 4 ) < br > 1. 0 | | - - - | - - - | - - - | | 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0. 8 < br > < br > 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > 0. 8 < br > 1. 0 < br > precision < br > no ~ ~ - ~ ~ skill classifier ( prevalence = 0. 27 ) < br > r1 ~ ~ - ~ ~ abstention ( ap = 0. 389 ) < br > r2 ~ ~ - ~ ~ abstention w / guidelines ( ap = 0. 43 | | | * * figure 3 : both abstention variants outperform randomly sam - * * * * pling to identify bugs with at least one successful repair. * * * * adding guidelines helps. ( ap = average precision ) * * * * figure 4 : abstention can raise fail - to - pass @ k by removing * * * * bugs that are less likely to succeed with our apr system. * * abstention ) achieves pass @ 1 of 11. 29 %. by filtering bugs with the _ [UNK] _ 1 abstention policy, the filtered - fail - to - pass @ 1 rate increases to 16. 81 %. the _ [UNK] _ 2 abstention achieves an even higher filtered - fail - topass @ 1 of 21. 05 %. this trend of improvement continues as more repair attempts are made : when _ [UNK] _ = 20, ( filtered - fail - to - ) pass @ k climbs from 27. 01 % ( no abstention ) to 44. 74 % ( _ [UNK] _ 2 abstention ). if we consider having at least one passing trajectory in 20 as a groundtruth positive label for a bug and an abstention probability above our threshold as a predicted positive label, our abstention policy results in a 16. 5 % false positive rate, defined as a ratio of false positives to ground - truth negatives. these results strongly suggest that abstention effectively discards bugs with a low fix probability, allowing the apr system to concentrate on more - promising bugs. * * 6. 2 * * * * rq2 : patch validation policy * * we compare three patch validation policy variants : ( 1 ) _ no - skill policy _, i. e., prevalence, which reports the fraction of successful trajectories after filtering patches that fail build and test regression checks, ( 2 ) * * figure 5 : patch correctness score allows more aggressive val - * * * * idation, with precision up to 3 * * × * * the success prevalence. * * _ validation _ that uses fix specification ( section 3. 2. 3 ), and ( 3 ) _ no - spec - _ _ validation _ that does not use fix specification and reviews the agent ’ s whole trajectory ( section 3. 2. 4 ). to determine the build and test regression checks, we extract from google ’ s unified build system any targets that have a modified file as a direct dependency."
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03217v1",
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "authors": [
        "José Cambronero",
        "Michele Tufano",
        "Sherry Shi",
        "Renyao Wei",
        "Grant Uy",
        "Runxiang Cheng",
        "Chin-Jung Liu",
        "Shiying Pan",
        "Satish Chandra",
        "Pat Rondon"
      ],
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "published": "2025-10-03T17:53:28Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03217v1"
    },
    "chunk_id": 10,
    "text": "bugs with a low fix probability, allowing the apr system to concentrate on more - promising bugs. * * 6. 2 * * * * rq2 : patch validation policy * * we compare three patch validation policy variants : ( 1 ) _ no - skill policy _, i. e., prevalence, which reports the fraction of successful trajectories after filtering patches that fail build and test regression checks, ( 2 ) * * figure 5 : patch correctness score allows more aggressive val - * * * * idation, with precision up to 3 * * × * * the success prevalence. * * _ validation _ that uses fix specification ( section 3. 2. 3 ), and ( 3 ) _ no - spec - _ _ validation _ that does not use fix specification and reviews the agent ’ s whole trajectory ( section 3. 2. 4 ). to determine the build and test regression checks, we extract from google ’ s unified build system any targets that have a modified file as a direct dependency. we retrieve this direct dependency by identifying the build system rules that include the modified file in their definitions. given google ’ s monorepo, transitive dependencies can quickly grow, and so we use this restricted set of rules as a practical approximation to identifying and removing regressions. our experiments show that while using fix specification improves both precision and recall over the ablation, the absolute precision remains modest at 0. 3. the no - spec validation ’ s binary judgment is heavily biased towards positive judgment, providing low recall of failing patches and prevalence - level precision for successful patches. the no - spec validation ’ s bias towards positive judgment results in a high false positive rate ( ratio of false positives to ground - truth negatives ) of 0. 64 compared to 0. 28 for the variant that uses the fix specification. we show that despite the modest predictive power of binary judgment, the validation ’ s patch correctness score can be used to distinguish between predictions. as a reminder, we define this score as zero for negative binary judgments and as the exponential of the average log probabilities of the response tokens for positive binary judgments. figure 5 shows precision - recall curves for both the validation and the no - spec validation, as well as a horizontal line for the no - skill policy after regression checks. at stricter thresholds, our spec - based validation ( in blue ) can yield a precision up to three times higher ( at the cost of recall ) than that of the prevalence rate, offering a substantial noise reduction for a subset of bugs. we find that the no - spec validation can improve over the no - skill policy but achieves lower precision at the same recall than the spec - based validation. with the 75th and 90th percentile cutoffs, the specbased validation achieves a false positive rate ( fpr ) of 0. 13 and 0. 04, respectively, while the no - spec validation achieves an fpr of 0. 15 and 0. 06, respectively. we now study the impact of different decision procedures for patch validation with filtered - fail - to - pass @ k. we evaluate two decision procedures described in section 3. 2. 6 for validation. specifically, one procedure uses binary judgment : validation - binary and abstain and validate : a dual - llm policy for reducing noise in agentic program repair no - spec - validation - binary. the other uses the 75th and 90th percentile thresholds of all patches ’ correctness scores : validation - p75 and validation - p90 ( and similarly for no - spec - validation ). figure 6 compares the filtered fail - to - pass @ k of these patch validation variants against build - and - test, which is a baseline that samples patches that pass build and test regression checks. the filtered fail - to - pass @ k of build - and - test are 0. 14 and 0. 19 when _ [UNK] _ equals to 1 and 3, respectively. on no - spec validation, using binary judgment provides no improvement. however, using the 75th and 90th percentile thresholds of patch correctness scores, no - spec validation raises filtered fail - to - pass @ 1 to 0. 16 and 0. 22, respectively. similarly, on spec - based validation, using 75th and 90th percentile thresholds of patch correctness scores better improve filtered fail - to - pass @ 1 than using binary judgment. binary judgment only modestly improves filtered fail - to - pass @ 1 ( 0. 16 ), while the 75th and 90th percentile thresholds improve filtered fail - to - pass @ 1 more substantially to 0. 21 ( + 7 percentage points, + 50 % relative improvement ) and 0. 29 ( + 15 percentage points, + 100 % relative improvement ), respectively. overall, using an aggressive validation policy results in fewer bugs that have at least one patch that can be surfaced. however, given that our goal is to reduce developer noise, we prioritize increasing the likelihood of success for any patches that remain. in figure 6, filtered - fail - to - pass"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03217v1",
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "authors": [
        "José Cambronero",
        "Michele Tufano",
        "Sherry Shi",
        "Renyao Wei",
        "Grant Uy",
        "Runxiang Cheng",
        "Chin-Jung Liu",
        "Shiying Pan",
        "Satish Chandra",
        "Pat Rondon"
      ],
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "published": "2025-10-03T17:53:28Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03217v1"
    },
    "chunk_id": 11,
    "text": "thresholds of patch correctness scores, no - spec validation raises filtered fail - to - pass @ 1 to 0. 16 and 0. 22, respectively. similarly, on spec - based validation, using 75th and 90th percentile thresholds of patch correctness scores better improve filtered fail - to - pass @ 1 than using binary judgment. binary judgment only modestly improves filtered fail - to - pass @ 1 ( 0. 16 ), while the 75th and 90th percentile thresholds improve filtered fail - to - pass @ 1 more substantially to 0. 21 ( + 7 percentage points, + 50 % relative improvement ) and 0. 29 ( + 15 percentage points, + 100 % relative improvement ), respectively. overall, using an aggressive validation policy results in fewer bugs that have at least one patch that can be surfaced. however, given that our goal is to reduce developer noise, we prioritize increasing the likelihood of success for any patches that remain. in figure 6, filtered - fail - to - pass @ k improves further as a validation variant with more aggressive filtering is applied. while this improvement trend matches our goal on reducing developer noise, it also presents a tradeoff occurring in patch validation between reducing developer noise ( by discarding more agent trajectories ) and increasing bug resolution rate. to better understand this tradeoff, we compute “ ( pass & validation ) @ k ”, where at least one patch must both pass the reproduction test and satisfy the validation, and present the results in figure 7. figure 7 shows that : more aggressive filtering in validation reduces overall bug resolution rate. for example, ( pass & validation ) @ 1 decreases by 2, 4, and 7 percentage points for binary judgment, 75th percentile threshold judgment, and 90th percentile threshold judgment, respectively. in summary, when employing a validation policy, there is this tradeoff between wasted compute and developer attention to consider. the validation policy ultimately rejects many generated patches, which lowers overall bug resolution rates and leads to early flattening in figure 6, but ensures the patches shown to developers are more likely to be plausible. * * 6. 3 * * * * rq3 : combined abstention - and - validation * * we now evaluate a dual - policy framework that combines abstention and validation : it filters bugs via the abstention policy, then filters patches via the validation policy ( section 4 ). for evaluation, we set the abstention threshold to 0. 5, rejecting any bugs with a predicted value below that. we use spec - based validation, and consider both binary and percentile - threshold judgments. figure 8 compares ( filtered - ) fail - to - pass @ k between the combined variants ( combined - * ), a policy that only applies abstention and excludes trajectories that produce no patches ( abstention ), and a baseline that applies neither abstention and validation ( no - filter ). combined abstention and binary validation can raise filtered failto - pass @ 1 to 0. 29 over abstention alone ( + 5 percentage points ) or * * figure 6 : validation can raise filtered - fail - to - pass @ 1 up to * * * * 15 percentage points compared to using only build and test * * * * regression checks. we show the same plot zoomed in for easy * * * * comparison. parentheses show number of bugs with at least * * * * one patch after validation. * * validation alone ( + 13 percentage points ). more aggressive filtering, such as 75th percentile can increase filtered - fail - to - pass @ 1 to 0. 35 ( + 11 percentage points relative to abstention alone and + 14 to the same validation alone ). these percentile thresholds create a configurable funnel for developer review. a strict policy ( combined - p90 ) narrows the intake to just 12 bugs, but its output is high - confidence, with a filtered fail - to - pass @ 1 of 0. 53 ( a 1 - in - 2 success rate ). a more permissive policy ( combined - p75 ) widens the intake, doubling the number of bugs for inspection while still yielding a high success rate of roughly 1 - in - 3. while it is not surprising that using validation can improve on bug - abstention - only success rates, as validation has access to more information ( e. g., the agent - generated patch ) and is judging a single instance, we also observe improvements over the validation - only version. this is interesting because patch validation — just like the bug abstention policy — has access to the bug report. we hypothesize, that given a patch, validation is more likely to be persuaded of the * * figure 7 : more aggressive filtering tradeoffs between reduc - * * * * ing developer noise and increasing bug resolution rate. * * * * figure 8 : abstention and validation are complementary, * * * * jointly they can raise filtered fail - to - pass @ k. * * success of the attempt, while the abstention policy is more"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03217v1",
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "authors": [
        "José Cambronero",
        "Michele Tufano",
        "Sherry Shi",
        "Renyao Wei",
        "Grant Uy",
        "Runxiang Cheng",
        "Chin-Jung Liu",
        "Shiying Pan",
        "Satish Chandra",
        "Pat Rondon"
      ],
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "published": "2025-10-03T17:53:28Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03217v1"
    },
    "chunk_id": 12,
    "text": "- p75 ) widens the intake, doubling the number of bugs for inspection while still yielding a high success rate of roughly 1 - in - 3. while it is not surprising that using validation can improve on bug - abstention - only success rates, as validation has access to more information ( e. g., the agent - generated patch ) and is judging a single instance, we also observe improvements over the validation - only version. this is interesting because patch validation — just like the bug abstention policy — has access to the bug report. we hypothesize, that given a patch, validation is more likely to be persuaded of the * * figure 7 : more aggressive filtering tradeoffs between reduc - * * * * ing developer noise and increasing bug resolution rate. * * * * figure 8 : abstention and validation are complementary, * * * * jointly they can raise filtered fail - to - pass @ k. * * success of the attempt, while the abstention policy is more likely to reflect overall quality of bug report. figure 9 visualizes the process of our dual - policy framework as a configurable funnel. the funnel presents the filtered fail - to - pass @ 1 rate on human - reported bugs at each stage. starting with the full set of 174 bugs, where our apr system has a baseline pass @ 1 rate of 11. 29 %, the abstention policy first filters this down to 39 more promising bugs, increasing the filtered fail - to - pass @ 1 rate to 21. 5 %. the combined validation policies ( combined - * ) further refine this set. the combined - binary policy leaves 33 bugs with a rate of 29 %. more aggressive filtering with combined - p75 and the strictest combined - p90 variant narrow the funnel to 25 and 12 bugs, respectively, boosting the quality of patches to achieve high filtered fail - to - pass @ 1 rates of 35 % and 53 %. overall, figure 9 demonstrates the trade - off between the volume of bugs attempted and the precision of the patches ultimately shown to developers. google et al. * * figure 9 : abstention and validation funnel. our combined * * * * policies filter an initial set of 174 bugs, progressively nar - * * * * rowing the set to increase the quality of patches shown to * * * * a developer. each stage reduces the number of bugs but in - * * * * creases the filtered fail - to - pass @ 1 rate, from a baseline of * * * * 11. 29 % to 53 % for the most selective configuration. * * * * 6. 4 * * * * rq4 : validation on npe and sanitizer bugs * * we further evaluate patch validation in bug categories that have more systematic information in their bug reports, and so are assumed good candidates for apr by construction ( i. e., these bugs pass abstention by construction ). we consider the machine - reported npe and sanitizer bugs, whose bug reports always have a stack trace and reproduction test, respectively. figure 10 shows filtered - accept @ k by manually inspecting the correctness of patches for npe bugs, whose bug reports have stack traces. the baseline ( build - and - test ) filters patches that did not pass build and test regression checks. we observe that validation using binary judgment provide little improvement over these regression checks. however, validation using the more - aggressive percentile - threshold judgment can result in improvements to filteredaccept @ 1 of + 8 percentage points and + 24 percentage points, with 75th and 90th percentile thresholds, respectively. no - spec validation at 90th percentile produces a bigger filtered - accept @ 1 improvement than that at 75th percentile ( + 20 percentage points vs + 24 percentage points relative to regression checks ), but both of them perform worse than the spec - based variant at 90th percentile ( i. e., validation - p90 ). figure 11 shows mean filtered - accept @ k ( based on manual inspection of patch correctness ) for sanitizer bugs, whose bug reports have reproduction tests. as a result, we filter any patches first by the reproduction test and then apply the validation policy. the baseline ( repro - test ) filters patches that did not pass reproduction abstain and validate : a dual - llm policy for reducing noise in agentic program repair sanitizer # bugs repro - test validation - binary validation - p75 validation - p90 data _ race 17 3. 11 2. 93 2. 43 3. 04 fuzz + property testing 3 na na na na heap _ buffer _ overflow 1 1. 43 1. 43 1. 54 1. 54 invalid _ bool _ load 2 1. 49 1. 65 1. 25 na invalid _ enum _ load 1 na na na na leak _ detected 2 1. 52 1. 72 4. 29 3. 81 misaligned _ pointer _ use 6 1. 34 1. 33 2. 14 1. 43 null _ pointer _"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03217v1",
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "authors": [
        "José Cambronero",
        "Michele Tufano",
        "Sherry Shi",
        "Renyao Wei",
        "Grant Uy",
        "Runxiang Cheng",
        "Chin-Jung Liu",
        "Shiying Pan",
        "Satish Chandra",
        "Pat Rondon"
      ],
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "published": "2025-10-03T17:53:28Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03217v1"
    },
    "chunk_id": 13,
    "text": "inspection of patch correctness ) for sanitizer bugs, whose bug reports have reproduction tests. as a result, we filter any patches first by the reproduction test and then apply the validation policy. the baseline ( repro - test ) filters patches that did not pass reproduction abstain and validate : a dual - llm policy for reducing noise in agentic program repair sanitizer # bugs repro - test validation - binary validation - p75 validation - p90 data _ race 17 3. 11 2. 93 2. 43 3. 04 fuzz + property testing 3 na na na na heap _ buffer _ overflow 1 1. 43 1. 43 1. 54 1. 54 invalid _ bool _ load 2 1. 49 1. 65 1. 25 na invalid _ enum _ load 1 na na na na leak _ detected 2 1. 52 1. 72 4. 29 3. 81 misaligned _ pointer _ use 6 1. 34 1. 33 2. 14 1. 43 null _ pointer _ use 1 2. 86 3. 33 na na signed _ integer _ overflow 2 1. 2 1. 27 1. 56 2. 5 stack _ use _ after _ scope 2 1. 85 1. 85 1. 67 3. 33 use _ of _ uninitialized _ value 13 2. 05 1. 93 2. 05 1. 95 * * table 2 : lift ( filtered - accept @ 1 / original accept @ 1 ) varies * * * * for different sanitizer bug types. the higher the better. * * metric abstain attemptrepair average # code - like identifiers 3. 03 5. 28 average character length 771. 67 1239. 26 fraction with repository root 0. 12 0. 31 fraction possible build rule 0. 01 0. 03 fraction markdown code ticks 0. 17 0. 20 * * table 3 : abstention - accepted bugs more frequently have the * * * * presence of the monorepo root directory. * * to reproduction test filtering slightly reduces lift, while adding the 70th percentile validation keeps the same lift. for data races, adding validation actually reduces lift compared to just using reproduction tests. we hypothesize that : for these bugs, a patch that adds locking mechanism indeed resolves the data race and can pass patch validation, but still may not be an acceptable solution for a google developer if it introduces downsides such as larger critical sections. for some categories, e. g. leaks and misaligned pointer usage, a less aggressive validation ( 75th percentile ) achieves better lift than a more aggressive one ( 90th percentile ). we hypothesize that a true bug reproduction test, such as that included in the sanitizer ’ s bug report, results in a set of plausible patches that are increasingly difficult for validation to assess, compared to the patches produced for the less - constrained bugs such as the human - reported ones. this points to a few future research directions. first, generating additional executable tests to help assess patch correctness is a particularly promising direction. for example, autocodesherpa [ 15 ] generates property - based tests to assist reviewing and filtering agent - generated patches. as pointed out, after filtering with the reproduction test, sampling _ [UNK] _ = 4 produces a mean filtered accept rate of 0. 74. supporting developers when inspecting more patches may help maintain a high success rate. * * 7 * * * * discussion * * the abstention policy has access to the bug report when making a judgment. we compute basic properties on our human - reported bug set to characterize their influence on policy outcomes. as shown in figure 12 and table 3, bugs accepted by abstention tend to have longer titles and descriptions ( combined ), and higher count of words that are possible code identifiers ( based on underscore or capitalization changes ). similarly, accepted bugs tend to have a slightlyhigher presence of google ’ s source repository root directory and possible code markdown, indicated by triple backticks. * * figure 10 : more aggressive validation can increase filtered * * * * accept @ k for npe bugs. * * * * figure 11 : aggressive validation increases filtered accept @ 1 * * * * for sanitizer bugs. but just reviewing more patches can lead * * * * to higher filtered - accept @ k, with 4 patches sufficing. * * tests. for sanitizer bugs, validation can lift filtered - accept @ 1 but increasing _ [UNK] _ quickly outstrips the validation policy. at _ [UNK] _ = 4, sampling patches from the set that passes the reproduction test provides better results ( 0. 74 ) than using the validation ’ s filtering. when we consider _ [UNK] _ = 1 and using 90th percentile threshold, no - spec variant no - spec - validation - p90 ( 0. 65 ) outperforms the spec - based variant validation - p90 ( 0. 62 ) and baseline repro - test ( 0. 5 ). we inspected whether patch validation performs differently based on"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03217v1",
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "authors": [
        "José Cambronero",
        "Michele Tufano",
        "Sherry Shi",
        "Renyao Wei",
        "Grant Uy",
        "Runxiang Cheng",
        "Chin-Jung Liu",
        "Shiying Pan",
        "Satish Chandra",
        "Pat Rondon"
      ],
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "published": "2025-10-03T17:53:28Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03217v1"
    },
    "chunk_id": 14,
    "text": "10 : more aggressive validation can increase filtered * * * * accept @ k for npe bugs. * * * * figure 11 : aggressive validation increases filtered accept @ 1 * * * * for sanitizer bugs. but just reviewing more patches can lead * * * * to higher filtered - accept @ k, with 4 patches sufficing. * * tests. for sanitizer bugs, validation can lift filtered - accept @ 1 but increasing _ [UNK] _ quickly outstrips the validation policy. at _ [UNK] _ = 4, sampling patches from the set that passes the reproduction test provides better results ( 0. 74 ) than using the validation ’ s filtering. when we consider _ [UNK] _ = 1 and using 90th percentile threshold, no - spec variant no - spec - validation - p90 ( 0. 65 ) outperforms the spec - based variant validation - p90 ( 0. 62 ) and baseline repro - test ( 0. 5 ). we inspected whether patch validation performs differently based on the sanitizer bug type. table 2 shows the lift for each sanitizer bug category, defined as the ratio of filtered - accept @ 1 to the raw accept @ 1, where per - bug accept @ 1 is averaged by sanitizer type. if a policy removes all patches associated with a sanitizer bug type or there are no patches ( in the unfiltered set ) that are correct, we enter na in the table. we find that patch validation performance indeed varies by bug type. for the two main categories of bugs in our evaluation set — data races and use of uninitialized values — validation does not provide a meaningful improvement over just filtering with reproduction tests. for use of uninitialized value errors, adding the binary validation and 90th percentile validation google et al. | 0. 8 tributi | col2 | col3 | col4 | | - - - | - - - | - - - | - - - | | 0 < br > 2 < br > < br > 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > | | abstention policy accepts < br > false < br > true | abstention policy accepts < br > false < br > true | | 0 < br > 2 < br > < br > 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > | | abstention policy accepts < br > false < br > true | false < br > true | | 0 < br > 2 < br > < br > 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > | | 000 < br > 4000 < br > 6000 < br > 8000 < br > 10000 < br > 1200 < br > haracter length of title and description | 000 < br > 4000 < br > 6000 < br > 8000 < br > 10000 < br > 1200 < br > haracter length of title and description | * * ( a ) description length * * | 0. 8 tributi | col2 | | - - - | - - - | | 0 < br > 10 < br > number of code ~ ~ - ~ ~ like i < br > 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > | abstention policy accep < br > false < br > true | | 0 < br > 10 < br > number of code ~ ~ - ~ ~ like i < br > 0. 0 < br > 0. 2 < br > 0. 4 < br > 0. 6 < br > | 20 < br > 30 < br > 40 < br > dentifiers in title and descrip | * * ( b ) code - like identifiers * * * * figure 12 : bugs accepted by the abstention policy tend to * * * * have slightly longer title and descriptions and more words * * * * that could be possible code identifiers. * * similarly, we considered the size of the patches accepted by the 75th percentile - based patch validation for our human - reported bug set. we only consider patches that underwent llm policy judgment. we count the number of line - level operations ( addition / deletions ) per patch. we find that validation - accepted patches had on average 18. 38 operations, compared to 22. 69 for rejected patches. we now look at an example of a patch that validation ( at 90th percentile ) incorrectly accepted. figure 13 shows the associated report indicating cases for a change in number formatting ( when _ “ points are chosen to be burnt ” _ ). the report leaves unspecified what should happen in other cases, but a human would likely take this to mean that other cases should still render the decimal point. the ground - truth patch makes decimal rendering a function"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03217v1",
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "authors": [
        "José Cambronero",
        "Michele Tufano",
        "Sherry Shi",
        "Renyao Wei",
        "Grant Uy",
        "Runxiang Cheng",
        "Chin-Jung Liu",
        "Shiying Pan",
        "Satish Chandra",
        "Pat Rondon"
      ],
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "published": "2025-10-03T17:53:28Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03217v1"
    },
    "chunk_id": 15,
    "text": "to * * * * have slightly longer title and descriptions and more words * * * * that could be possible code identifiers. * * similarly, we considered the size of the patches accepted by the 75th percentile - based patch validation for our human - reported bug set. we only consider patches that underwent llm policy judgment. we count the number of line - level operations ( addition / deletions ) per patch. we find that validation - accepted patches had on average 18. 38 operations, compared to 22. 69 for rejected patches. we now look at an example of a patch that validation ( at 90th percentile ) incorrectly accepted. figure 13 shows the associated report indicating cases for a change in number formatting ( when _ “ points are chosen to be burnt ” _ ). the report leaves unspecified what should happen in other cases, but a human would likely take this to mean that other cases should still render the decimal point. the ground - truth patch makes decimal rendering a function argument and modifies necessary call sites ( not shown for brevity ). in contrast, the agent patch modifies the constant true to false, which will impact all call sites. the generated specification identifies the correct method to change, but does not scope to particular call sites. the validation policy then incorrectly accepts. * * 8 * * * * threats to validity * * human and sanitizer - reported bugs were drawn from a set that has a known ground - truth patch, and some of our filtering relies on ground - truth patch properties ( e. g., existence of a test ). these constraints allow us to focus on patches within scope for an agent and employ ground - truth tests as an evaluation oracle. for sanitizerreported bugs, where reproduction tests are already available at the time of reporting, having the ground - truth patch allows us to perform a manual comparison to determine correctness. this curation approach closely mirrors that used to create popular benchmarks like swe - bench, as well as industry practices [ 20, 27 ]. manual correctness assessment may diverge from the decisions that would have been made by real code owners for patches that they did not inspect. to mitigate this risk, we employed multiple annotators, consulting others in cases of ambiguity. like other large - scale industrial software engineering studies [ 2, 12, 21 ], the bugs and code in this work are drawn from a single company ( google ) and reflect internal practices. projects or companies that write substantially different bug reports, or adhere to different development practices, may observe different policy impacts. * * 9 * * * * related work * * we used passerine, our existing agentic apr system [ 27 ], to evaluate both bug abstention and patch validation. specrover [ 28 ] produces function - level specifications to guide the repair agent. similarly, our validation policy employs a specification generation step to guide the patch judgment but this specification is at the file level, can be derived from multiple files, and is used only after the repair agent has concluded. pan et al [ 25 ] showed that a fine - tuned llm can be used to pick the best patch per bug based on the agent ’ s trajectory. our no - spec validation employs a similar concatenation of trajectory prompt messages. however, our llm patch validation relies on prompting only and is used to filter out patches rather than pick a patch per bug. our patch validation filters on build / test regression checks, or a reproduction test if available. similarly, agentless [ 34 ] uses ( generated ) tests to filter out unlikely candidates. abstention [ 5 ] has long been employed in classification to reduce mispredictions resulting from ambiguity or lack of information. past work has explored this topic extensively, learning abstention policies in boosting algorithms [ 8 ], fairness guarantees [ 30 ], and, more recently, in the context of generative models [ 33 ]. concurrent to our work, bouncerbench [ 22 ] introduces the concept of “ bouncers ” to reduce the overconfidence of an agentic software engineer. bouncers reject underspecified tasks and unlikely patches, closely matching our abstention and validation policies. the benchmark bouncerbench opens up this challenge to the community and represents a complementary analysis to our own, which focuses on evaluating these policies in an industrial context. abstain and validate : a dual - llm policy for reducing noise in agentic program repair maddila et al. [ 20 ] concurrently introduced a patch critic in an industrial agentic apr system. our work shows that abstention can reduce developer noise further and can be complementary to a validation policy. our evaluation also covers additional bug categories ( with and without known reproduction tests ). works in llm - as - judge for code, such as codejudge [ 32 ] and crupi et al. [ 9 ], are closely related to our patch validation policy. in particular, reference - free judging is a close analogue to patch validation,"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03217v1",
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "authors": [
        "José Cambronero",
        "Michele Tufano",
        "Sherry Shi",
        "Renyao Wei",
        "Grant Uy",
        "Runxiang Cheng",
        "Chin-Jung Liu",
        "Shiying Pan",
        "Satish Chandra",
        "Pat Rondon"
      ],
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "published": "2025-10-03T17:53:28Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03217v1"
    },
    "chunk_id": 16,
    "text": "##ers ” to reduce the overconfidence of an agentic software engineer. bouncers reject underspecified tasks and unlikely patches, closely matching our abstention and validation policies. the benchmark bouncerbench opens up this challenge to the community and represents a complementary analysis to our own, which focuses on evaluating these policies in an industrial context. abstain and validate : a dual - llm policy for reducing noise in agentic program repair maddila et al. [ 20 ] concurrently introduced a patch critic in an industrial agentic apr system. our work shows that abstention can reduce developer noise further and can be complementary to a validation policy. our evaluation also covers additional bug categories ( with and without known reproduction tests ). works in llm - as - judge for code, such as codejudge [ 32 ] and crupi et al. [ 9 ], are closely related to our patch validation policy. in particular, reference - free judging is a close analogue to patch validation, but we focus exclusively on program repair and use judgments to filter patches to reduce noise ( at the expense of recall ). * * 10 * * * * conclusion * * we present a dual - policy framework to reduce developer noise from an agentic apr system. a bug abstention policy rejects bugs unlikely to be solved by the apr system, while a patch validation policy rejects unlikely candidate fixes. we evaluate these policies on three sets of bugs drawn from google ’ s codebase and on patches produced by our agentic apr system. on a set of human - reported bugs with known fixes, abstention and validation can raise success rates up to 13 percentage points and 15 percentage points, respectively, and up to 39 percentage points in combination. in practical terms, this improvement transforms the developer experience : instead of expecting a successful patch roughly 1 in 10 times, developers can now expect a correct patch in 1 in 2 cases presented for their review ( combined - p90 ). a more relaxed policy configuration ( combined - p75 ) doubles the number of patches for inspection while still yielding a high success rate of roughly 1 in 3. the patch validation policy can also be used to improve success rates for null pointer exceptions and sanitizer - reported bugs. * * references * * [ 1 ] martin arjovsky, soumith chintala, and leon bottou. wasserstein generative adversarial networks. in _ international conference on machine learning _, pages 214 – 223. pmlr, 2017. [ 2 ] christian bird, nachiappan nagappan, brendan murphy, harald gall, and premkumar devanbu. don ’ t touch my code! examining the effects of ownership on software quality. in _ proceedings of the 19th acm sigsoft symposium _ _ and the 13th european conference on foundations of software engineering _, pages 4 – 14, 2011. [ 3 ] islem bouzenia, premkumar devanbu, and michael pradel. repairagent : an autonomous, llm - based agent for program repair. in _ international conference _ _ on software engineering ( icse ) _, 2025. [ 4 ] adam brown, sarah d ’ angelo, ambar murillo, ciera jaspan, and collin green. identifying the factors that influence trust in ai code completion. in _ proceedings _ _ of the 1st acm international conference on ai - powered software _, pages 1 – 9, 2024. [ 5 ] c. chow. on optimum recognition error and reject tradeoff. _ ieee transactions _ _ on information theory _, 16 ( 1 ) : 41 – 46, 1970. [ 6 ] chi - keung chow. an optimum character recognition system using decision functions. _ ire transactions on electronic computers _, ( 4 ) : 247 – 254, 2009. [ 7 ] gheorghe comanici, eric bieber, mike schaekermann, ice pasupat, noveen sachdeva, inderjit dhillon, marcel blistein, ori ram, dan zhang, evan rosen, et al. gemini 2. 5 : pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities. _ arxiv preprint _ _ arxiv : 2507. 06261 _, 2025. [ 8 ] corinna cortes, giulia desalvo, and mehryar mohri. boosting with abstention. _ advances in neural information processing systems _, 29, 2016. [ 9 ] giuseppe crupi, rosalia tufano, alejandro velasco, antonio mastropaolo, denys poshyvanyk, and gabriele bavota. on the effectiveness of llm - as - a - judge for code generation and summarization. _ ieee transactions on software engineering _, 51 ( 8 ) : 2329 –"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03217v1",
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "authors": [
        "José Cambronero",
        "Michele Tufano",
        "Sherry Shi",
        "Renyao Wei",
        "Grant Uy",
        "Runxiang Cheng",
        "Chin-Jung Liu",
        "Shiying Pan",
        "Satish Chandra",
        "Pat Rondon"
      ],
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "published": "2025-10-03T17:53:28Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03217v1"
    },
    "chunk_id": 17,
    "text": "##upat, noveen sachdeva, inderjit dhillon, marcel blistein, ori ram, dan zhang, evan rosen, et al. gemini 2. 5 : pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities. _ arxiv preprint _ _ arxiv : 2507. 06261 _, 2025. [ 8 ] corinna cortes, giulia desalvo, and mehryar mohri. boosting with abstention. _ advances in neural information processing systems _, 29, 2016. [ 9 ] giuseppe crupi, rosalia tufano, alejandro velasco, antonio mastropaolo, denys poshyvanyk, and gabriele bavota. on the effectiveness of llm - as - a - judge for code generation and summarization. _ ieee transactions on software engineering _, 51 ( 8 ) : 2329 – 2345, 2025. [ 10 ] daniel deutsch, shyam upadhyay, and dan roth. a general - purpose algorithm for constrained sequential inference. in _ proceedings of the 23rd conference on _ _ computational natural language learning ( conll ) _, pages 482 – 492, 2019. [ 11 ] pengfei gao, zhao tian, xiangxin meng, xinchen wang, ruida hu, yuanan xiao, yizhou liu, zhao zhang, junjie chen, cuiyun gao, et al. trae agent : an llm - based agent for software engineering with test - time scaling. _ arxiv preprint _ _ arxiv : 2507. 23370 _, 2025. [ 12 ] philip j guo, thomas zimmermann, nachiappan nagappan, and brendan murphy. characterizing and predicting which bugs get fixed : an empirical study of microsoft windows. in _ proceedings of the 32nd acm / ieee international conference _ _ on software engineering - volume 1 _, pages 495 – 504, 2010. [ 13 ] radu herbei and marten h wegkamp. classification with reject option. _ the _ _ canadian journal of statistics / la revue canadienne de statistique _, pages 709 – 721, 2006. [ 14 ] carlos e jimenez, john yang, alexander wettig, shunyu yao, kexin pei, ofir press, and karthik narasimhan. swe - bench : can language models resolve real - world github issues? _ arxiv preprint arxiv : 2310. 06770 _, 2023. [ 15 ] sungmin kang, haifeng ruan, and abhik roychoudhury. autocodesherpa : symbolic explanations in ai coding agents. _ arxiv preprint arxiv : 2507. 22414 _, 2025. [ 16 ] claire le goues, thanhvu nguyen, stephanie forrest, and westley weimer. genprog : a generic method for automatic software repair. _ ieee transactions on _ _ software engineering _, 38 ( 1 ) : 54 – 72, 2011. [ 17 ] claire le goues, michael pradel, and abhik roychoudhury. automated program repair. _ communications of the acm _, 62 ( 12 ) : 56 – 65, 2019. [ 18 ] fan long and martin rinard. staged program repair with condition synthesis. in _ proceedings of the 2015 10th joint meeting on foundations of software engineering _, pages 166 – 178, 2015. [ 19 ] sheng lu, hendrik schuff, and iryna gurevych. how are prompts different in terms of sensitivity? in _ proceedings of the 2024 conference of the north ameri - _ _ can chapter of the association for computational linguistics : human language _ _ technologies ( volume 1 : long papers ) _, pages 5833 – 5856, 2024. [ 20 ] chandra maddila, adam tait, claire chang, daniel cheng, nauman ahmad, vijayaraghavan murali, marshall roch, arnaud avondet, aaron meltzer, victor montalvao, et al. agentic program repair from test failures at scale : a neurosymbolic approach with static analysis and test execution feedback. _ arxiv _ _ preprint arxiv : 2507. 18755 _, 2025. [ 21 ] alexandru marginean, johannes bader, satish chandra, mark harman, yue jia, ke mao, alexander mols, and andrew scott. sapfix : automated end - to - end repair at scale. in _ 2019 ieee / acm 41st international conference on software engineering : _ _ software engineering in practice ( icse - seip ) _, pages 269 – 278. ieee, 2019"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03217v1",
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "authors": [
        "José Cambronero",
        "Michele Tufano",
        "Sherry Shi",
        "Renyao Wei",
        "Grant Uy",
        "Runxiang Cheng",
        "Chin-Jung Liu",
        "Shiying Pan",
        "Satish Chandra",
        "Pat Rondon"
      ],
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "published": "2025-10-03T17:53:28Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03217v1"
    },
    "chunk_id": 18,
    "text": ", pages 5833 – 5856, 2024. [ 20 ] chandra maddila, adam tait, claire chang, daniel cheng, nauman ahmad, vijayaraghavan murali, marshall roch, arnaud avondet, aaron meltzer, victor montalvao, et al. agentic program repair from test failures at scale : a neurosymbolic approach with static analysis and test execution feedback. _ arxiv _ _ preprint arxiv : 2507. 18755 _, 2025. [ 21 ] alexandru marginean, johannes bader, satish chandra, mark harman, yue jia, ke mao, alexander mols, and andrew scott. sapfix : automated end - to - end repair at scale. in _ 2019 ieee / acm 41st international conference on software engineering : _ _ software engineering in practice ( icse - seip ) _, pages 269 – 278. ieee, 2019. [ 22 ] noble saji mathews and meiyappan nagappan. is your automated software engineer trustworthy? _ arxiv preprint arxiv : 2506. 17812 _, 2025. [ 23 ] hoang duong thien nguyen, dawei qi, abhik roychoudhury, and satish chandra. semfix : program repair via semantic analysis. in _ 2013 35th international _ _ conference on software engineering ( icse ) _, pages 772 – 781. ieee, 2013. [ 24 ] yannic noller, ridwan shariffdeen, xiang gao, and abhik roychoudhury. trust enhancement issues in program repair, 2022. [ 25 ] jiayi pan, xingyao wang, graham neubig, navdeep jaitly, heng ji, alane suhr, and yizhe zhang. training software engineering agents and verifiers with swe - gym. in _ forty - second international conference on machine learning _, 2025. [ 26 ] rachel potvin and josh levenberg. why google stores billions of lines of code in [ a single repository. https : / / cacm. acm. org / research / why - google - stores - billions - ] ( https : / / cacm. acm. org / research / why - google - stores - billions - of - lines - of - code - in - a - single - repository / ) [ of - lines - of - code - in - a - single - repository /, july 2016. accessed on 2025 - 09 - 22. ] ( https : / / cacm. acm. org / research / why - google - stores - billions - of - lines - of - code - in - a - single - repository / ) [ 27 ] pat rondon, renyao wei, jose cambronero, jurgen cito, aaron sun, siddhant sanyam, michele tufano, and satish chandra. evaluating agent - based program repair at google. _ arxiv preprint arxiv : 2501. 07531 _, 2025. [ 28 ] haifeng ruan, yuntong zhang, and abhik roychoudhury. specrover : code intent extraction via llms. in _ 2025 ieee / acm 47th international conference on _ _ software engineering ( icse ) _, pages 963 – 974, los alamitos, ca, usa, may 2025. ieee computer society. [ 29 ] torsten scholak, nathan schucher, and dzmitry bahdanau. picard : parsing incrementally for constrained auto - regressive decoding from language models. in marie - francine moens, xuanjing huang, lucia specia, and scott wen - tau yih, editors, _ proceedings of the 2021 conference on empirical methods in natural lan - _ _ guage processing _, pages 9895 – 9901, online and punta cana, dominican republic, november 2021. association for computational linguistics. [ 30 ] nicolas schreuder and evgenii chzhen. classification with abstention but without disparities. in cassio de campos and marloes h. maathuis, editors, _ pro - _ _ ceedings of the thirty - seventh conference on uncertainty in artificial intelligence _, volume 161 of _ proceedings of machine learning research _, pages 1227 – 1236. pmlr, 27 – 30 jul 2021. [ 31 ] mahan tafreshipour, aaron imani, eric huang, eduardo santana de almeida, thomas zimmermann, and iftekhar ahmed. prompting in the wild : an empirical study of prompt evolution in software repositories. in _ 2025 ieee / acm 22nd _ _ international conference on mining software repositories ( ms"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03217v1",
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "authors": [
        "José Cambronero",
        "Michele Tufano",
        "Sherry Shi",
        "Renyao Wei",
        "Grant Uy",
        "Runxiang Cheng",
        "Chin-Jung Liu",
        "Shiying Pan",
        "Satish Chandra",
        "Pat Rondon"
      ],
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "published": "2025-10-03T17:53:28Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03217v1"
    },
    "chunk_id": 19,
    "text": "in natural lan - _ _ guage processing _, pages 9895 – 9901, online and punta cana, dominican republic, november 2021. association for computational linguistics. [ 30 ] nicolas schreuder and evgenii chzhen. classification with abstention but without disparities. in cassio de campos and marloes h. maathuis, editors, _ pro - _ _ ceedings of the thirty - seventh conference on uncertainty in artificial intelligence _, volume 161 of _ proceedings of machine learning research _, pages 1227 – 1236. pmlr, 27 – 30 jul 2021. [ 31 ] mahan tafreshipour, aaron imani, eric huang, eduardo santana de almeida, thomas zimmermann, and iftekhar ahmed. prompting in the wild : an empirical study of prompt evolution in software repositories. in _ 2025 ieee / acm 22nd _ _ international conference on mining software repositories ( msr ) _, pages 686 – 698. ieee, 2025. [ 32 ] weixi tong and tianyi zhang. codejudge : evaluating code generation with large language models. in yaser al - onaizan, mohit bansal, and yun - nung chen, editors, _ proceedings of the 2024 conference on empirical methods in natural _ _ language processing _, pages 20032 – 20051, miami, florida, usa, november 2024. association for computational linguistics. [ 33 ] bingbing wen, jihan yao, shangbin feng, chenjun xu, yulia tsvetkov, bill howe, and lucy lu wang. know your limits : a survey of abstention in large language models. _ transactions of the association for computational linguistics _, 13 : 529 – 556, 2025. [ 34 ] chunqiu steven xia, yinlin deng, soren dunn, and lingming zhang. agentless : demystifying llm - based software engineering agents. _ arxiv preprint _ _ arxiv : 2407. 01489 _, 2024. [ 35 ] john yang, carlos e jimenez, alexander wettig, kilian lieret, shunyu yao, karthik narasimhan, and ofir press. swe - agent : agent - computer interfaces enable automated software engineering. _ advances in neural information processing _ _ systems _, 37 : 50528 – 50652, 2024. google et al. [ 36 ] yuntong zhang, haifeng ruan, zhiyu fan, and abhik roychoudhury. autocoderover : autonomous program improvement. in _ proceedings of the 33rd _ _ acm sigsoft international symposium on software testing and analysis _, pages 1592 – 1604, 2024. [ 37 ] changsheng zhuge, mingchen zhao, dylan r. ashley, wenyi wang, dmitrii khizbullin, yunyang xiong, zechun liu, ernie chang, krishnamoorthi raghuraman, yuandong tian, yangyang shi, vikas chandra, and jurgen schmidhuber. agent - as - a - judge : evaluate agents with agents. _ arxiv preprint arxiv : 2410. 10934v2 _, 2025. abstain and validate : a dual - llm policy for reducing noise in agentic program repair * * a * * * * human - reported bug curation * * in this section, we describe the criteria for curating human - reported bugs that have a known ground truth patch for completeness. the criteria closely follows [ 27 ], with the addition of the test target criteria. namely, each bug must satisfy the following : ( 1 ) was reported during a period of a year and closed with code changes after a model - based cutoff date in the recent past – we use the cutoff to prevent old code changes that are more likely to be stale. ( 2 ) has a known ground - truth fix and an associated fail - topass test that could be used as a held - out test oracle. this fail - to - pass test must execute without any build errors and fail in the pre - patch code and execute and succeed in the post - patch code. ( 3 ) the bug and submitted code changes have a 1 : 1 relationship, mitigating risk of tangled commits ( 4 ) did not have screenshots in their description ( multimodal repairs are out of scope for this work ) ( 5 ) affected files for any of the following languages : c + +, c, dart, java, kotlin, typescript, javascript, go, and python and conversely excluded changes that affected sql, html, css, configuration languages, binary data files, or multimedia data files ( 6 ) had a unidiff ground - truth commit of less than 150"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03217v1",
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "authors": [
        "José Cambronero",
        "Michele Tufano",
        "Sherry Shi",
        "Renyao Wei",
        "Grant Uy",
        "Runxiang Cheng",
        "Chin-Jung Liu",
        "Shiying Pan",
        "Satish Chandra",
        "Pat Rondon"
      ],
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "published": "2025-10-03T17:53:28Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03217v1"
    },
    "chunk_id": 20,
    "text": "cutoff to prevent old code changes that are more likely to be stale. ( 2 ) has a known ground - truth fix and an associated fail - topass test that could be used as a held - out test oracle. this fail - to - pass test must execute without any build errors and fail in the pre - patch code and execute and succeed in the post - patch code. ( 3 ) the bug and submitted code changes have a 1 : 1 relationship, mitigating risk of tangled commits ( 4 ) did not have screenshots in their description ( multimodal repairs are out of scope for this work ) ( 5 ) affected files for any of the following languages : c + +, c, dart, java, kotlin, typescript, javascript, go, and python and conversely excluded changes that affected sql, html, css, configuration languages, binary data files, or multimedia data files ( 6 ) had a unidiff ground - truth commit of less than 150 lines ( 7 ) had < = 31 test targets that depended on the files changed in the ground - truth patch. * * b * * * * bug abstention prompts * * the section contains the full prompts for the bug abstention policies described in section 3. 1. 2. * * listing 1 : prompt for bug representation * * _ [UNK] _ 1 ( _ [UNK] _ ) * *. * * you are tasked to predict whether an llm - based agentic approach will successfully fix a bug. the agent can use a suite of tools by issuing commands, including : - ` ` ` code _ search ` ` ` to find relevant code. - ` ` ` cat ` ` ` to read file contents. - ` ` ` ls ` ` ` to list directory contents. - ` ` ` find _ and _ replace _ text ` ` ` to modify files. - ` ` ` bazel ` ` ` to run tests. the agent is presented with a bug report and can perform a maximum of 25 steps. analyze the following bug and predict if the agent will succeed. your output must be a single word : either \" success \" or \" failure \". do not provide any other text, explanation, or punctuation. # bug title { bug. title } # bug description { bug. description } * * listing 2 : prompt for bug representation * * _ [UNK] _ 2 ( _ [UNK] _ ) * *. * * # guidelines these guidelines provide criteria for determining if a bug is likely to be solved by the agent. - clear problem & action : the bug report explicitly and clearly describes the incorrect behavior, and the required change is well - understood. - precise code localization : the report points to the exact file, code line, function, or configuration that needs attention, or it's easily identifiable from provided information ( e. g., stack traces ). - simple, localized fix anticipated : the likely solution involves a small, straightforward, and localized change. - actionable reproduction & sufficient context : the issue can be easily and reliably reproduced with the information provided, and sufficient context is available within the report for the agent to proceed effectively. - self - contained and complete : all necessary information for addressing the bug is provided and self contained within the report, requiring minimal external look - up or inference. * * c * * * * patch validation prompts * * this section contains the full prompts for the patch validation policy described in section 3. 2. listing 3 shows the prompt for the specification generation step. * * listing 3 : using the original bug description and file contents * * * * to generate a specification. * * system : you are an expert software engineer that reviews a bug and lists out a specification for the desired behavior. you should cover properties desirable for a fix. be specific, do not provide general properties that apply to all bugs. do not provide properties that are about artifacts like documentation. user : here is a bug, please create a fix specification : # bug title { bug. title } # bug description { bug. description } # original source code $ cat { file _ path } { file _ content } # specification listing 4 shows the llm prompt used for validating a patch, along with the use of the generated specification. * * listing 4 : using the original bug report, candidate patch, any * * * * test information, and the fix specification generated in the * * * * prior step, to decide if a patch is likely to fix a bug. * * system : setting : you are a software engineer reviewing code changes to fix bugs. your job is to review how a bug2code agent tried to fix a bug. return a reviewresponse with whether the bug is fixed and explaining why. user : * * figure 14 : if we consider samples of size k of trajectories * * * * that pass the held - out reproduction test, more aggressive * * * * validation is more likely to incorrectly reject"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03217v1",
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "authors": [
        "José Cambronero",
        "Michele Tufano",
        "Sherry Shi",
        "Renyao Wei",
        "Grant Uy",
        "Runxiang Cheng",
        "Chin-Jung Liu",
        "Shiying Pan",
        "Satish Chandra",
        "Pat Rondon"
      ],
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "published": "2025-10-03T17:53:28Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03217v1"
    },
    "chunk_id": 21,
    "text": "create a fix specification : # bug title { bug. title } # bug description { bug. description } # original source code $ cat { file _ path } { file _ content } # specification listing 4 shows the llm prompt used for validating a patch, along with the use of the generated specification. * * listing 4 : using the original bug report, candidate patch, any * * * * test information, and the fix specification generated in the * * * * prior step, to decide if a patch is likely to fix a bug. * * system : setting : you are a software engineer reviewing code changes to fix bugs. your job is to review how a bug2code agent tried to fix a bug. return a reviewresponse with whether the bug is fixed and explaining why. user : * * figure 14 : if we consider samples of size k of trajectories * * * * that pass the held - out reproduction test, more aggressive * * * * validation is more likely to incorrectly reject patches. * * * * figure 15 : patches accepted by the patch validation policy * * * * have slightly fewer line - level operations compared to those * * * * it rejected. * * approach binary label precision recall prevalence ( build / test ) true 0. 19 no - spec validation ( binary ) false 0. 99 0. 07 no - spec validation ( binary ) true 0. 2 1 validation ( binary ) false 0. 91 0. 58 validation ( binary ) true 0. 3 0. 76 * * table 4 : precision / recall table on the binary judgment : val - * * * * idation ’ s binary judgment provides modest predictive per - * * * * formance. removing the specification usage reduces perfor - * * * * mance substantially. * * google et al. here's a log of an attempt by a bug2code agent to fix a bug : # bug title { bug. title } # bug description { bug. description } # patch { patch } # test information { test _ information } # specification : based on the bug report and source code, here is a specification for the desired behavior of the fix. # # # fix specification { specification } * * c. 1 * * * * additional results * * table 4 presents the per - label precision / recall for binary validation policies. to focus on the validation ’ s ability to identify successful trajectories, we also consider a variant of recall. specifically, we compute the average ( over bugs ) probability that at least one trajectory is accepted by the validation, given a sample of k trajectories that satisfy the held - out reproduction test. in effect, if our repair system produced only good fixes, how often would we show at least one repair to a user if we generated k trajectories. we denote this mean ( validation recall ) @ k. to compute percentile - based thresholding we determine cutoffs over all trajectories that pass build and test regressions first, before filtering. as shown in figure 14, percentile - based thresholding results in more false negatives – rejecting patches that we should have shown to humans. when sampling a single successful patch, the binary validation will show a patch at a rate of 0. 54, compared to 0. 36 and 0. 16 for 75th and 90th percentile thresholding, respectively. figure 15 shows that patches accepted by the validation policy have slightly more line - level operations compared to those rejected. * * c. 2 * * * * patch validation decisions : false positives * * listing c. 2 shows the generated specification and validation policy output for the false positive example discussed in section 7. \" here is a fix specification for the bug. # # # desired behavior specification 1. * * conditional decimal formatting for amounts * * the amount displayed in the amount input field must be formatted based on whether it is an integral value. - if the ` ` ` money ` ` ` object represents an integer ( e. g., the fractional part is zero ), it must be formatted as a string without decimal places ( e. g., \" 500 \" ). abstain and validate : a dual - llm policy for reducing noise in agentic program repair google et al. abstain and validate : a dual - llm policy for reducing noise in agentic program repair let _ [UNK] _ _ [UNK] _ be the value of successfully closing a bug _ [UNK] _ with a fix. let _ [UNK] _ _ [UNK] _ be the cost on the code base of leaving the bug unrepaired. let _ [UNK] _ _ [UNK] _ be the cost to produce a repair trajectory. let _ [UNK] _ [ ∗ ] be the true, unknown, probability of a trajectory solving bug _ [UNK] _. the expected net value of the abstention policy is then : _ [UNK] _ [ ∗ ] ( _ [UNK] _ _ [UNK] _ ) + ( 1 − _ [UNK] _ [ ∗ ] ) ( − _ [UNK] _ _ [UNK] _ ) − _ [UNK] _ _ [UNK]"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03217v1",
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "authors": [
        "José Cambronero",
        "Michele Tufano",
        "Sherry Shi",
        "Renyao Wei",
        "Grant Uy",
        "Runxiang Cheng",
        "Chin-Jung Liu",
        "Shiying Pan",
        "Satish Chandra",
        "Pat Rondon"
      ],
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "published": "2025-10-03T17:53:28Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03217v1"
    },
    "chunk_id": 22,
    "text": ", it must be formatted as a string without decimal places ( e. g., \" 500 \" ). abstain and validate : a dual - llm policy for reducing noise in agentic program repair google et al. abstain and validate : a dual - llm policy for reducing noise in agentic program repair let _ [UNK] _ _ [UNK] _ be the value of successfully closing a bug _ [UNK] _ with a fix. let _ [UNK] _ _ [UNK] _ be the cost on the code base of leaving the bug unrepaired. let _ [UNK] _ _ [UNK] _ be the cost to produce a repair trajectory. let _ [UNK] _ [ ∗ ] be the true, unknown, probability of a trajectory solving bug _ [UNK] _. the expected net value of the abstention policy is then : _ [UNK] _ [ ∗ ] ( _ [UNK] _ _ [UNK] _ ) + ( 1 − _ [UNK] _ [ ∗ ] ) ( − _ [UNK] _ _ [UNK] _ ) − _ [UNK] _ _ [UNK] _ if _ [UNK] _ _ [UNK] _ ( _ [UNK] _ ) ≥ _ [UNK] _ _ [UNK] _ − _ [UNK] _ _ [UNK] _ otherwise google et al. let _ [UNK] _ _ [UNK] _ be the cost of having a human review a patch from trajectory _ [UNK] _. the analogous expected net value for the patch validation policy is then : _ [UNK] _ [ ∗ ] ( _ [UNK] _ _ [UNK] _ ) + ( 1 − _ [UNK] _ [ ∗ ] ) ( − _ [UNK] _ _ [UNK] _ ) − _ [UNK] _ _ [UNK] _ if _ [UNK] _ _ [UNK] _ ( _ [UNK] _ _ [UNK] _ ( _ [UNK], [UNK] _ ) ) − _ [UNK] _ _ [UNK] _ otherwise"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03215v1",
      "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language\n  Models",
      "authors": [
        "Tianyu Fu",
        "Zihan Min",
        "Hanling Zhang",
        "Jichao Yan",
        "Guohao Dai",
        "Wanli Ouyang",
        "Yu Wang"
      ],
      "summary": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.",
      "published": "2025-10-03T17:52:32Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03215v1"
    },
    "chunk_id": 0,
    "text": "preprint version # # - - c ache to - c ache : d irect s emantic c ommunica tion b etween l arge l anguage m odels * * tianyu fu * * _ [ ∗ ] _ [ 1 ] _ [, ] _ [ 2 ] * *, zihan min * * _ [ ∗ ] _ [ 1 ] * *, hanling zhang * * _ [ ∗ ] _ [ 3 ] * *, jichao yan * * [ 1 ] * *, * * * * guohao dai * * [ 5 ] _ [, ] _ [ 2 ], * * wanli ouyang * * [ 3 ] _ [, ] _ [ 4 ], * * yu wang * * _ [ † ] _ [ 1 ] 1 tsinghua university 2 infinigence ai 3 the chinese university of hong kong 4 shanghai ai laboratory 5 shanghai jiao tong university a bstract multi - llm systems harness the complementary strengths of diverse large language models, achieving performance and efficiency gains unattainable by a single model. in existing designs, llms communicate through text, forcing internal representations to be transformed into output token sequences. this process both loses rich semantic information and incurs token - by - token generation latency. motivated by these limitations, we ask : _ can llms communicate beyond text? _ oracle experiments show that enriching the kv - cache semantics can improve response quality without increasing cache size, supporting kv - cache as an effective medium for inter - model communication. thus, we propose cache - to - cache ( c2c ), a new paradigm for direct semantic communication between llms. c2c uses a neural network to project and fuse the source model ’ s kv - cache with that of the target model to enable direct semantic transfer. a learnable gating mechanism selects the target layers that benefit from cache communication. compared with text communication, c2c utilizes the deep, specialized semantics from both models, while avoiding explicit intermediate text generation. experiments show that c2c achieves 8. 5 - 10. 5 % higher average accuracy than individual models. it further outperforms the text communication paradigm by approximately 3. 0 - 5. 0 %, while delivering an average 2. 0× speedup in latency. our code is available at [ https : / / github. com / thu - nics / c2c. ] ( https : / / github. com / thu - nics / c2c ) 1 i ntroduction _ context _ _ s - prompt _ _ t _ _ 0 _ _ t _ _ n - 1 _ _ context _ _ t _ _ 0 _ _ [UNK] t _ _ n _ _ query _ _ r _ _ 0 _ _ context _ _ context _ _ query _ * * r * * [UNK] [UNK] [UNK] _ communication text : _ _ t _ _ 0 _ _ t _ _ 1 _ _ t _ _ n _ _ response text : _ figure 1 : ( a ) previous text - to - text ( t2t ) communication passes information through explicit text generation. ( b ) our cache - to - cache ( c2c ) communication directly projects and merges kv - cache with rich semantics from different llms. with the rapid progress of large language models ( llms ) ( guo et al., 2025 ; yang et al., 2025a ; openai, 2025 ), they are now applied across increasingly diverse domains and tasks. to meet versatile demands, llms are trained with distinct focuses, such as coding ( hui et al., 2024 ), mathematics ( yang et al., 2024a ), visual understanding ( bai et al., 2025 ), edge computing ( zhang et al., 2024b ), and so on. meanwhile, general - purpose llms can also simulate specialized capabilities through prompt engineering, enabling flexible role adaptation across downstream applications. leveraging the diversity of llms, many multi - llm systems are proposed to further enhance overall performance and efficiency ( guo et al., 2024 ; tran et al., 2025 ). in * * collaborative multi - llm * * _ ∗ _ equal contribution. _ † _ corresponding author : yu wang ( yu - wang @ tsinghua. edu. cn ). 1 preprint version figure 2 : conceptual comparison of t2t and c2c communication in a coder - writer collaboration example. in t2t, the coder ’ s ambiguous text instruction fails to convey the structural semantics of < p > as a paragraph separator, causing the writer to misplace the content. c2c directly projects the coder ’ s kv - cache into the writer, transferring both the semantic understanding and precise insertion location without intermediate text generation. * * systems * * ( li et al., 2023 ; wu et al., 2023 ),"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03215v1",
      "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language\n  Models",
      "authors": [
        "Tianyu Fu",
        "Zihan Min",
        "Hanling Zhang",
        "Jichao Yan",
        "Guohao Dai",
        "Wanli Ouyang",
        "Yu Wang"
      ],
      "summary": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.",
      "published": "2025-10-03T17:52:32Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03215v1"
    },
    "chunk_id": 1,
    "text": "downstream applications. leveraging the diversity of llms, many multi - llm systems are proposed to further enhance overall performance and efficiency ( guo et al., 2024 ; tran et al., 2025 ). in * * collaborative multi - llm * * _ ∗ _ equal contribution. _ † _ corresponding author : yu wang ( yu - wang @ tsinghua. edu. cn ). 1 preprint version figure 2 : conceptual comparison of t2t and c2c communication in a coder - writer collaboration example. in t2t, the coder ’ s ambiguous text instruction fails to convey the structural semantics of < p > as a paragraph separator, causing the writer to misplace the content. c2c directly projects the coder ’ s kv - cache into the writer, transferring both the semantic understanding and precise insertion location without intermediate text generation. * * systems * * ( li et al., 2023 ; wu et al., 2023 ), llms are assigned distinct roles and proactively exchange text messages. mirroring human collaboration, these systems accumulate partial understandings or sub - solutions from different agents via verbal communication. they harnessing the collective capabilities of multiple llms to solve complex problems that a single model cannot. by contrast, * * routing - based * * multi - llm inference systems rely on passive context inheritance rather than active message exchange. these systems coordinate models of varying parameter sizes or reasoning depths for more dynamic and efficient responses ( li et al., 2024 ; fu et al., 2025 ; ong et al., 2024 ; openai, 2025 ). downstream models inherit the context from preceding models in multi - round conversations, then generate follow - up responses to the new questions based on their own understanding of the conversation history. however, current text - to - text ( t2t ) interfaces restrict information exchange among llms, particularly when conveying rich or diverse semantic interpretations of a shared context. as illustrated in figure 2, these limitations arise from several inherent constraints of t2t communication. first, as a low - bandwidth medium, text introduces an information bottleneck. the high - dimensional internal representations must be repeatedly compressed into linear strings and then decompressed by the receiver llm. when models differ in knowledge or assigned roles, some signals may be irrecoverable ( e. g., interpreting < p > as a section marker ). second, natural language is inherently ambiguous, with idioms, underspecified references, and vague expressions. although recent agent protocols aim to standardize text messages ( anthropic, 2024 ; surapaneni et al., 2025 ), rigid templates remain insufficient for flexible, open - domain collaboration. third, t2t communication incurs noticeable latency. every exchange requires exhaustive, token - by - token decoding of contextual explanations in sequence. these limitations motivate a key question : _ can llms communicate beyond text? _ in this work, we explore using kv - cache as the medium for llm communication. kv - cache is a naturally richer representation than text. it also enables fully parallel communication through direct projection, avoiding the slow sequential decoding in text exchanges. our oracle experiments show that ( 1 ) enriching kv - cache under the same context length can lead to an increase in accuracy. ( 2 ) kv - cache is convertible between llms. ( 3 ) different llms encode distinct semantic understandings and contextual knowledge of the same input, reflecting their complementary strengths. encouraged by these oracles, we propose cache - to - cache ( c2c ), a new paradigm for richer and faster multi - llm communication. as shown in figure 1 ( b ), c2c projects the kv - cache from a source model into the space of a target model and merges them through a neural cache fuser. experiments show that c2c achieves 8. 5 - 10. 5 % higher average accuracy than individual models. it further outperforms the t2t paradigm by approximately 3. 0 - 5. 0 %, while delivering an average 2. 0 _ × _ speedup in latency. 2 r elated w ork 2. 1 kv - c ache s haring and r euse based on the similarity of kv - cache between layers, intra - model cache sharing methods ( yang et al., 2024b ; wu & tu, 2024 ; sun et al., 2024 ; brandon et al., 2024 ; wu et al., 2025 ) are proposed 2 preprint version to reuse shallow layers ’ kv - cache for deeper layers to accelerate single llm inference. another research focus is to reuse a portion of kv - cache ( e. g., common prefix, reference documents ) for the same model in multiple user queries ( bang, 2023 ; ye et al., 2024 ; yao et al., 2024 ; qin et al., 2024 ; yang"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03215v1",
      "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language\n  Models",
      "authors": [
        "Tianyu Fu",
        "Zihan Min",
        "Hanling Zhang",
        "Jichao Yan",
        "Guohao Dai",
        "Wanli Ouyang",
        "Yu Wang"
      ],
      "summary": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.",
      "published": "2025-10-03T17:52:32Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03215v1"
    },
    "chunk_id": 2,
    "text": ". it further outperforms the t2t paradigm by approximately 3. 0 - 5. 0 %, while delivering an average 2. 0 _ × _ speedup in latency. 2 r elated w ork 2. 1 kv - c ache s haring and r euse based on the similarity of kv - cache between layers, intra - model cache sharing methods ( yang et al., 2024b ; wu & tu, 2024 ; sun et al., 2024 ; brandon et al., 2024 ; wu et al., 2025 ) are proposed 2 preprint version to reuse shallow layers ’ kv - cache for deeper layers to accelerate single llm inference. another research focus is to reuse a portion of kv - cache ( e. g., common prefix, reference documents ) for the same model in multiple user queries ( bang, 2023 ; ye et al., 2024 ; yao et al., 2024 ; qin et al., 2024 ; yang et al., 2025b ). droidseek liu et al. ( 2024a ) extends cache reuse to models fine - tuned from the same base model. unlike existing works that focus on computational efficiency through cache reuse, our approach leverages the kv - cache as a medium for semantic transfer between llms. furthermore, unlike existing cache sharing methods that are restricted to only a single model or models with identical structure and size, our method supports sharing across different model families and varying model sizes. 2. 2 m ulti - llm s ystems * * collaborative multi - llm systems * *. collaborative systems treat multiple llms as peers that exchange information to improve collective performance. chain - of - agents ( zhang et al., 2024c ) and metagpt ( hong et al., 2023 ) create sequential message flows where agents directly communicate using natural language interfaces. mixture - of - agents wang et al. ( 2024 ) and dylan ( liu et al., 2024b ) introduce layered communication architectures. target llms aggregate messages from multiple models using voting or summarization mechanisms. multi - agent debate methods ( estornell & liu, 2024 ; liang et al., 2024 ; du et al., 2023 ) involve iterative communication rounds, letting llm agents discuss and refine responses. recent works such as mcp anthropic ( 2024 ) and a2a surapaneni et al. ( 2025 ) establish formal text protocols beyond natural language, standardizing agent interaction and tool usage in collaborative multi - llm systems. these approaches rely on text - level interfaces, where communication requires one model to generate text token - by - token and another to ingest it as input. our work explores a deeper and more efficient collaboration by directly sharing internal kv - cache representations. * * routing - based multi - llm inference systems * *. to accelerate llm inference, several systems leverage multiple models with different capabilities and costs. dynamic model selection methods ( openai, 2025 ; ong et al., 2024 ; feng et al., 2024 ) route queries to different models with varying sizes and configurations to balance efficiency and performance. token - level routing methods ( zhang et al., 2024a ; shen et al., 2024 ; zheng et al., 2025 ; fu et al., 2025 ) enable finer - grained selection, utilizing smaller models for simple token generation within the reasoning process of complex tasks. while these systems achieve efficiency through strategic model switching, they either completely drop context from other models, or simply rely on their own understandings of the context. without understanding sharing, smaller models cannot benefit from the richer representations already computed by larger models. 3 m ethod 3. 1 p reliminaries * * llm inference * *. autoregressive llm inference involves two stages : _ prefill _ and _ decode _. prefill encodes the full input to produce the first output token ; decode then generates subsequent tokens iteratively using the last token and the cached key – value ( kv ) states. formally, let _ x _ [ 0 : _ n _ ] = [ _ x _ 0 _,..., x _ _ n− _ 1 ] be the input token sequence. after prefill, llm produces a per - token kv - cache _ c _ ( _ x _ [ 0 : _ n _ ] ) = [ _ c _ 0 _,..., c _ _ n− _ 1 ] _ ∈ _ r _ [ n ] [ × ] [ d ] _. for notation brevity, _ d _ denotes the kv dimensionality that is flattened from all layers into a single vector per token. the range subscripts are omitted when clear. during decoding, with current token _ y _ _ i _ and caches from the input and the generated prefix, the next token is predicted as _ y _ _"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03215v1",
      "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language\n  Models",
      "authors": [
        "Tianyu Fu",
        "Zihan Min",
        "Hanling Zhang",
        "Jichao Yan",
        "Guohao Dai",
        "Wanli Ouyang",
        "Yu Wang"
      ],
      "summary": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.",
      "published": "2025-10-03T17:52:32Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03215v1"
    },
    "chunk_id": 3,
    "text": "to produce the first output token ; decode then generates subsequent tokens iteratively using the last token and the cached key – value ( kv ) states. formally, let _ x _ [ 0 : _ n _ ] = [ _ x _ 0 _,..., x _ _ n− _ 1 ] be the input token sequence. after prefill, llm produces a per - token kv - cache _ c _ ( _ x _ [ 0 : _ n _ ] ) = [ _ c _ 0 _,..., c _ _ n− _ 1 ] _ ∈ _ r _ [ n ] [ × ] [ d ] _. for notation brevity, _ d _ denotes the kv dimensionality that is flattened from all layers into a single vector per token. the range subscripts are omitted when clear. during decoding, with current token _ y _ _ i _ and caches from the input and the generated prefix, the next token is predicted as _ y _ _ i _ + 1 = _ p _ _ y _ _ i _ _ | c _ ( _ x _ ) _ ⊕c _ ( _ y _ [ 0 : _ i _ ] ) _, _ ( 1 ) where _ ⊕ _ denotes sequence - wise concatenation. the cache updates as _ c _ ( _ y _ [ 0 : _ i _ + 1 ] ) = _ c _ ( _ y _ [ 0 : _ i _ ] ) _ ⊕c _ ( _ y _ _ i _ ). * * llm communication * *. in llm communication scenarios, we define the llm that provides contextual understanding or knowledge as _ sharer _, and the one that utilizes it as _ receiver _. 3. 2 o racles for c ache - to - c ache c ommunication we aim to explore whether llms can have direct semantic communication through kv - cache. specifically, we design two oracle experiments to answer the following questions : ( 1 ) _ benefit _ : can 3 preprint version | col1 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | | | | | | | | | | | | | | | | | | | 40 < br > 30 < br > 20 < br > | 40 < br > 30 < br > 20 < br > | 40 < br > 30 < br > 20 < br > | 40 < br > 30 < br > 20 < br > | 0 < br > 0 < br > | 0 < br > 0 < br > | 0 < br > 20 | 0 < br > 20 | figure 3 : the t - sne representations of source, target, and transformed kv - cache. * * method * * * * cache len. cache augment acc. ( % ) * * direct _ | x | _ no 58. 42 few - shot _ | e | _ + _ | x | _ yes 63. 39 oracle _ | x | _ yes 62. 34 table 1 : cache enrichment experiment. oracle prefills on _ e _ and _ x _, then discard _ e _. | col1 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | col10 | col11 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | 2 < br > 3 < br > 4 < br > 5 < br > 6 < br > | 2 < br > 3 < br > 4 < br > 5 < br > 6 < br > | 2 < br > 3 < br > 4 < br > 5 < br > 6 < br > | 2 < br > 3 < br > 4 < br > 5 < br > 6 < br > | 2 < br > 3 < br > 4 < br > 5 < br > 6 < br > | 2 < br > 3 < br > 4 < br > 5 < br > 6 < br > | 8 < br > 9 < br > | 8 < br > 9 < br > | 8 < br > 9 < br > | 0 | figure 4 : accuracy influence of accumulatively augmenting different number of layers. * * average effective rank * * * * type * * * * sharer * * * * receiver * * * * c2c * * k cache 539 388 395 v cache 689 532 560 table 2"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03215v1",
      "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language\n  Models",
      "authors": [
        "Tianyu Fu",
        "Zihan Min",
        "Hanling Zhang",
        "Jichao Yan",
        "Guohao Dai",
        "Wanli Ouyang",
        "Yu Wang"
      ],
      "summary": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.",
      "published": "2025-10-03T17:52:32Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03215v1"
    },
    "chunk_id": 4,
    "text": "< br > | 2 < br > 3 < br > 4 < br > 5 < br > 6 < br > | 2 < br > 3 < br > 4 < br > 5 < br > 6 < br > | 2 < br > 3 < br > 4 < br > 5 < br > 6 < br > | 2 < br > 3 < br > 4 < br > 5 < br > 6 < br > | 2 < br > 3 < br > 4 < br > 5 < br > 6 < br > | 8 < br > 9 < br > | 8 < br > 9 < br > | 8 < br > 9 < br > | 0 | figure 4 : accuracy influence of accumulatively augmenting different number of layers. * * average effective rank * * * * type * * * * sharer * * * * receiver * * * * c2c * * k cache 539 388 395 v cache 689 532 560 table 2 : average effective rank of kv - cache from sharer, receiver, and the c2c fused one. a model ’ s capabilities be improved through kv - cache semantic enrichment without extending sequence length? ( 2 ) _ convertibility _ : can the kv - cache of one model be effectively utilized by another model? 3. 2. 1 c ache e nrichment o racle to validate the benefit of cache enrichment, we first explore whether the semantic quality of a _ fixed - _ _ length _ question kv - cache can be improved without increasing cache size. few - shot prompting suggests this might work : providing _ exemplars e _ before the _ question x _ often improves accuracy. but does this arise from attending to more context tokens, or from _ e _ enriching how _ x _ is embedded in kv - cache? we evaluate this via three setups : ( 1 ) _ direct _ : prefill on _ x _ only and decode with _ c _ ( _ x _ ) ; ( 2 ) _ few - shot _ : prefill on _ e ⊕x _ and decode with _ c _ ( _ e ⊕x _ ) ( longer cache ) ; ( 3 ) _ oracle _ : prefill on _ e ⊕x _ but _ discard _ the exemplar segment and keep only the question - aligned slice _ c _ _ [ ∗ ] _ ( _ x _ ) = _ c _ [ _ | e | _ : _ | e | _ + _ | x | _ ] ( _ e ⊕ _ _ x _ ) _, _ ( 2 ) so that decoding uses a question - length cache with no extra tokens. here, _ | · | _ denotes sequence length. in equation 1, this corresponds to substituting _ c _ ( _ x _ ) with _ c _ _ [ ∗ ] _ ( _ x _ ) before decoding. comparing _ direct _ and _ oracle _ isolates the effect of cache enrichment : any gain arises from the richer question embeddings induced by _ e _, not from attending to additional token caches as in _ few - shot _. as shown in table 1, the _ oracle _ setup improves response quality at the same cache length. additionally, we analyzed how cache enrichment affects different transformer layers. our findings show substantial variation across layers : while some layers benefit from cache enrichment, others experience performance degradation ( details in appendix a. 2. 1 ). furthermore, these layer - wise effects accumulate as more layers are augmented. as shown in figure 4, selectively applying cache enrichment to the top - 10 performing layers yields higher accuracy than enriching all layers, while targeting the worst - performing layers leads to accuracy decline. this finding guides the gating mechanism of our cache fuser ( section 3. 3. 2 ). 3. 2. 2 c ache t ransformation o racle to verify that one model ’ s kv - cache can be utilized by another, we conducted cross - model transformation experiments. we trained a 3 - layer mlp to map the kv - cache from a source llm ( qwen34b ) to a target llm ( qwen3 - 0. 6b ), with more setups detailed in appendix a. 3. 2. 4 preprint version | receiver < br > cache reply | col2 | col3 | | - - - | - - - | - - - | | cache < br > * * receiver * * < br > reply | cache | reply | figure 5 : c2c fuser architecture and training scheme. t - sne visualizations in figure 3 reveal that the raw kv - caches of the two llms are far apart in representation space. after transformation, the mapped kv - cache is inside the kv - cache representation space of the target model. these results demonstrate that kv - caches from different models are, in general, convertible as the transformed cache in the representation space of the target model. one thing to note is that the transformed cache occupies only a smaller"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03215v1",
      "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language\n  Models",
      "authors": [
        "Tianyu Fu",
        "Zihan Min",
        "Hanling Zhang",
        "Jichao Yan",
        "Guohao Dai",
        "Wanli Ouyang",
        "Yu Wang"
      ],
      "summary": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.",
      "published": "2025-10-03T17:52:32Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03215v1"
    },
    "chunk_id": 5,
    "text": "to map the kv - cache from a source llm ( qwen34b ) to a target llm ( qwen3 - 0. 6b ), with more setups detailed in appendix a. 3. 2. 4 preprint version | receiver < br > cache reply | col2 | col3 | | - - - | - - - | - - - | | cache < br > * * receiver * * < br > reply | cache | reply | figure 5 : c2c fuser architecture and training scheme. t - sne visualizations in figure 3 reveal that the raw kv - caches of the two llms are far apart in representation space. after transformation, the mapped kv - cache is inside the kv - cache representation space of the target model. these results demonstrate that kv - caches from different models are, in general, convertible as the transformed cache in the representation space of the target model. one thing to note is that the transformed cache occupies only a smaller subset of the target ’ s space. it indicates that the source model ’ s semantic information cannot fully cover the target ’ s, despite the source being larger. this reflects inherent differences in how each model encodes context. another observation also supports this interpretation : the correct - answer sets of different models exhibit limited overlap ( figure 7 ), despite the comparable aggregated accuracy of respective models. these findings suggest that if specialized contextual understanding from different models can be successfully projected and fused, it may harness the complementary strengths of respective models. 3. 3 c2c d esign 3. 3. 1 o verview building on the oracle experiments, we propose the c2c fuser architecture. its core objective is to extract useful contextual understanding or knowledge from one model ( the sharer ) and fuse it into another model ( the receiver ). in general, the c2c paradigm contains a set of key / value cache fusers _ f _ and a layer mapping strategy _ g _. during the prefill stage, fuser _ f _ _ n _ takes the _ n _ th layer cache of the receiver model _ c _ _ n _ ( _ x _ ) and the corresponding _ g _ ( _ n _ ) th layer cache of the sharer model _ c _ _ g _ _ [ s ] _ ( _ n _ ) [ ( ] _ [ x ] _ [ ) ] [ and and generate the corresponding ] fused cache : _ c _ _ [ f ] _ = _ { f _ _ n _ ( _ c _ _ n _ ( _ x _ ) _, c _ _ g _ _ [ s ] _ ( _ n _ ) [ ( ] _ [ x ] _ [ ) ) ] _ [ } ] _ _ n _ _ [ n ] _ = 1 ( 3 ) during decoding, with the current token _ y _ _ i _ and caches from the input and the generated prefix, the next token is predicted as : _ y _ _ i _ + 1 = _ p _ _ y _ _ i _ _ c _ _ f _ ( _ x _ ) _ ⊕c _ ( _ y _ [ 0 : _ i _ ] ) ( 4 ) 3. 3. 2 f user s tructure to enhance the receiver ’ s kvcache without destructive overwriting of its information, the fuser is designed under a residual integration principle. as shown in figure 5, it contains three key modules : ( 1 ) * * projection module * * concatenates the receiver ’ s kv - cache with the sharer ’ s kv - cache, then processes the concatenated feature through a projection layer followed by a feature fusion layer. ( 2 ) * * dynamic weighting module * * applies an input - aware head modulation layer to dynamically reweight the projected information. ( 3 ) * * learnable gate * * introduces a trainable per - layer gate value that decides whether to inject the sharer ’ s context. the value applies a gumbel - sigmoid with temperature annealing to smoothly transition from differentiable during training to binary at inference. 3. 3. 3 m odel a lignment fusing kv - caches across model families and sizes requires alignment at two levels : tokens and layers. for _ token alignment _, different tokenizers may produce slightly varied token sequences for the 5 preprint version same input. we align them by decoding each receiver token into its string form and re - encoding it using the sharer ’ s tokenizer. when one - to - many mappings occasionally occur, we select the sharer token with maximal string coverage to preserve information. for _ layer _ alignment, we adopt a terminal alignment strategy : the final layers of both models are aligned first, then the penultimate layers, and so on in reverse order until reaching the shallower model ’ s first layer. detailed specifications are provided in appendix a. 1. 3. 3. 4 t raining s cheme during training, we freeze both the sharer"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03215v1",
      "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language\n  Models",
      "authors": [
        "Tianyu Fu",
        "Zihan Min",
        "Hanling Zhang",
        "Jichao Yan",
        "Guohao Dai",
        "Wanli Ouyang",
        "Yu Wang"
      ],
      "summary": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.",
      "published": "2025-10-03T17:52:32Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03215v1"
    },
    "chunk_id": 6,
    "text": "##bel - sigmoid with temperature annealing to smoothly transition from differentiable during training to binary at inference. 3. 3. 3 m odel a lignment fusing kv - caches across model families and sizes requires alignment at two levels : tokens and layers. for _ token alignment _, different tokenizers may produce slightly varied token sequences for the 5 preprint version same input. we align them by decoding each receiver token into its string form and re - encoding it using the sharer ’ s tokenizer. when one - to - many mappings occasionally occur, we select the sharer token with maximal string coverage to preserve information. for _ layer _ alignment, we adopt a terminal alignment strategy : the final layers of both models are aligned first, then the penultimate layers, and so on in reverse order until reaching the shallower model ’ s first layer. detailed specifications are provided in appendix a. 1. 3. 3. 4 t raining s cheme during training, we freeze both the sharer and receiver models, training only the c2c module for kv - cache fusion. we employ standard next - token prediction loss on the receiver ’ s response predictions, similar to supervised fine - tuning ( sft ). the key difference is that the receiver predicts responses conditioned on fused kv - cache rather than its own. the training procedure consists of three stages : ( 1 ) forward : both models encode the input context to produce their respective kv - caches. ( 2 ) fusion : the c2c module fuses both kv - caches and replaces the receiver ’ s cache. ( 3 ) supervision : the receiver prefills the response using the fused cache, and gradients backpropagate through c2c to minimize prediction loss. 4 e xperiment 4. 1 s etup we highlight key setups here, with more details in appendix a. 3. * * models * *. we evaluate c2c across various model families, including qwen2. 5 ( yang et al., 2024a ; hui et al., 2024 ), qwen3 ( yang et al., 2025a ), llama3. 2 ( dubey et al., 2024 ), and gemma3 ( team et al., 2025 ). to test generalizability, we select different configurations for the sharer - receiver model combinations, including models of different generations ( qwen3 and qwen2. 5 ), different families ( qwen, llama, and gemma ), different sizes ( 0. 6b to 14b ), different specializations ( general, code, and math model ), and different training stages ( pretrained and instruction fine - tuned models ). for ablative and diagnostic analyses ( scaling behavior, ablation study, behavior analysis ), we fix the receiver and sharer to qwen3 models unless otherwise specified. this consistency eliminates confounders from model alignment and isolates the core impact of c2c. * * baselines * *. we compare c2c over two llm collaboration methods to contextualize performance : ( 1 ) text - to - text ( t2t ) communication : collaborate by analyze - response hand - off for each query. the sharer generates analytical text of key information to solve the input question. this text is concatenated with the original question and fed to the receiver to mirror standard collaborative pipelines. corresponding prompts are in appendix a. 3. 6. ( 2 ) query - level routing ( ong et al., 2024 ) : collaborate by selecting the appropriate llm for different queries. we also include individual model performance ( sharer or receiver alone ) to establish a lower bound for collaborative gains. * * benchmarks * *. we evaluate on four widely used benchmarks spanning reasoning, knowledge, and language domains to ensure comprehensive coverage. openbookqa ( mihaylov et al., 2018 ) for fact - based reasoning, mmlu - redux ( gema et al., 2025 ) for knowledge in the general domain, arc - challenge ( arc - c ) ( clark et al., 2018 ) for scientific and logistic reasoning, and ceval ( huang et al., 2023 ) for comprehensive knowledge in the chinese domain. * * training dataset * *. to ensure the generalizability of c2c, we utilize the first 500k samples of the openhermes2. 5 dataset ( teknium, 2023 ), a general finetuning dataset, to train c2c fusers. for budgeting training purposes, we utilize the mmlu as the trainset on scaling behavior and behavior analysis, unless specified. * * evaluation settings * *. we use average accuracy as the performance metric. we use text generation and answer extraction as the evaluation mode for c2c and baselines, with the max generation length set to 64 for multi - choice benchmarks. all experiments are conducted in the zero - shot setting with zero generation temperature"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03215v1",
      "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language\n  Models",
      "authors": [
        "Tianyu Fu",
        "Zihan Min",
        "Hanling Zhang",
        "Jichao Yan",
        "Guohao Dai",
        "Wanli Ouyang",
        "Yu Wang"
      ],
      "summary": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.",
      "published": "2025-10-03T17:52:32Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03215v1"
    },
    "chunk_id": 7,
    "text": "al., 2025 ) for knowledge in the general domain, arc - challenge ( arc - c ) ( clark et al., 2018 ) for scientific and logistic reasoning, and ceval ( huang et al., 2023 ) for comprehensive knowledge in the chinese domain. * * training dataset * *. to ensure the generalizability of c2c, we utilize the first 500k samples of the openhermes2. 5 dataset ( teknium, 2023 ), a general finetuning dataset, to train c2c fusers. for budgeting training purposes, we utilize the mmlu as the trainset on scaling behavior and behavior analysis, unless specified. * * evaluation settings * *. we use average accuracy as the performance metric. we use text generation and answer extraction as the evaluation mode for c2c and baselines, with the max generation length set to 64 for multi - choice benchmarks. all experiments are conducted in the zero - shot setting with zero generation temperature to ensure reproducibility. we use average inference time as the efficient metric, measured using a single nvidia a100 gpu ( choquette et al., 2021 ) with batch size = 1. 6 preprint version table 3 : comparison of communication methods across benchmarks. we use qwen3 - 0. 6b as the receiver model. * * sharer * * * * task * * * * metric * * * * receiver * * * * sharer * * * * routing * * * * text - to - text * * * * cache - to - cache * * acc 35. 53 38. 42 35. 58 41. 03 * * 42. 92 * * mmlu - redux time 0. 29 0. 34 0. 27 1. 52 0. 40 qwen2. 5 - 0. 5b llama3. 2 - 1b qwen3 - 4b - base acc 39. 20 45. 60 40. 80 44. 00 * * 52. 60 * * openbook time 0. 27 0. 35 0. 29 0. 81 0. 30 acc 41. 04 42. 09 40. 70 49. 48 * * 54. 52 * * arc - c time 0. 29 0. 39 0. 29 1. 00 0. 36 acc 32. 04 40. 21 34. 61 35. 88 * * 41. 77 * * c - eval time 0. 26 0. 31 0. 26 1. 51 0. 34 acc 35. 53 32. 30 33. 38 43. 32 * * 44. 42 * * mmlu - redux time 0. 29 0. 06 0. 18 0. 75 0. 50 acc 39. 20 32. 60 36. 40 41. 20 * * 47. 80 * * openbook time 0. 26 0. 07 0. 17 0. 70 0. 43 acc 41. 04 33. 57 37. 22 50. 00 * * 53. 39 * * arc - c time 0. 28 0. 07 0. 18 0. 70 0. 47 acc 32. 04 31. 31 31. 92 35. 27 * * 40. 77 * * c - eval time 0. 25 0. 04 0. 15 0. 71 0. 49 acc 35. 53 1. 03 16. 39 43. 87 * * 43. 95 * * mmlu - redux time 0. 29 2. 06 0. 28 7. 54 0. 45 acc 39. 20 2. 20 22. 20 46. 40 * * 53. 20 * * openbook time 0. 26 1. 98 0. 27 5. 08 0. 34 acc 41. 04 1. 48 19. 65 53. 91 * * 55. 39 * * arc - c time 0. 28 2. 06 0. 28 6. 56 0. 40 acc 32. 04 5. 65 15. 10 38. 92 * * 42. 79 * * c - eval time 0. 25 2. 02 0. 26 3. 59 0. 39 4. 2 p erformance and e fficiency as shown in table 8, c2c consistently improves the receiver model performance across different settings and benchmarks. after applying c2c, we see an average increase of accuracy by 11. 00 %, 9. 64 %, and 11. 88 % across three different sharers. compared with text - to - text communication, c2c achieves an average accuracy increase of 5. 36 %, 4. 15 %, and 3. 06 %. it also achieves obvious speedups of 3. 46 _ × _, 1. 51 _ × _, and 14. 41 _ × _, thanks to the waiving of intermediate text message generation. in contrast, query - level routing prioritizes efficiency but limits accuracy to the better of the two original models. notably, when using qwen3 - 4b base as the sharer, the generated text"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03215v1",
      "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language\n  Models",
      "authors": [
        "Tianyu Fu",
        "Zihan Min",
        "Hanling Zhang",
        "Jichao Yan",
        "Guohao Dai",
        "Wanli Ouyang",
        "Yu Wang"
      ],
      "summary": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.",
      "published": "2025-10-03T17:52:32Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03215v1"
    },
    "chunk_id": 8,
    "text": "eval time 0. 25 2. 02 0. 26 3. 59 0. 39 4. 2 p erformance and e fficiency as shown in table 8, c2c consistently improves the receiver model performance across different settings and benchmarks. after applying c2c, we see an average increase of accuracy by 11. 00 %, 9. 64 %, and 11. 88 % across three different sharers. compared with text - to - text communication, c2c achieves an average accuracy increase of 5. 36 %, 4. 15 %, and 3. 06 %. it also achieves obvious speedups of 3. 46 _ × _, 1. 51 _ × _, and 14. 41 _ × _, thanks to the waiving of intermediate text message generation. in contrast, query - level routing prioritizes efficiency but limits accuracy to the better of the two original models. notably, when using qwen3 - 4b base as the sharer, the generated text sometimes ignores instructions and exceeds the expected length. this results in extremely long text - to - text communication time, while c2c bypasses this issue. the setup highlights an interesting use case of c2c, where a weak sft model enables a strong pre - trained base model to follow instructions. we also observe that llama3. 2 - 1b exhibits exceptionally fast inference, analyzed in appendix a. 4. 3. 4. 3 s caling b ehavior * * scaling sequence lengths * *. we evaluate how c2c scales with respect to sequence length on longcontext tasks from the longbenchv1 benchmark. all c2c fusers are trained and tested on different sets of longbenchv1. as shown in table 4, c2c consistently outperforms text - to - text communication across all sequence - length intervals. it indicates c2c ’ s advantages across input length ranges. more detailed setups and results are in appendices a. 2. 2 and a. 3. 4. * * scaling model sizes * *. we investigate how c2c scales with respect to the sharer and receiver model sizes. all c2c fusers are trained on mmlu ’ s auxiliary train split and evaluated on mmlu - redux. 7 preprint version series, while the curves correspond to receiver models from the qwen3 series. length receiver sharer t2t c2c 0 - 4k 27. 39 21. 89 29. 47 * * 36. 64 * * 4 - 8k 24. 97 18. 55 26. 30 * * 31. 71 * * 8k + 22. 20 14. 04 24. 54 * * 25. 37 * * table 4 : longbenchv1 scores with qwen3 - 0. 6b ( receiver ) and qwen2. 50. 5b ( sharer ) across input lengths. setting # param. openbook arc - c mmlu c - eval single 596m 45. 80 47. 65 36. 81 35. 81 identical 529m 50. 60 52. 52 42. 17 40. 34 c2c 478m * * 52. 60 * * * * 54. 52 * * * * 42. 92 * * * * 41. 77 * * table 5 : performance comparison of different training settings. _ single _ directly finetunes the receiver model. _ iden - _ _ tical _ uses the same model for sharer and receiver. as shown in figure 6, the _ x _ - axis denotes sharer size ( qwen2. 5 - instruct series ), the _ y _ - axis shows accuracy gains of c2c over receiver - only baselines ( ∆ accuracy ), and each curve represents a receiver from the qwen3 series. we find that the accuracy improvements of c2c generally increase faster than t2t. this trend shows that when the sharer possesses richer knowledge, c2c is able to more effectively transmit useful information to the receiver. note that the relative gains for larger receivers are less pronounced due to their stronger baselines and higher overlap with the sharer ’ s knowledge. * * different model combinations * *. we test different sharer - receiver combinations, including different model families and different task - specific models. the result in table 6 shows that c2c outperforms text - to - text communication on all five combinations by an average increase of 8. 59 %. this supports that by employing c2c, the receiver model can effectively utilize contextual understanding from different model to enhance performance. notably, when using qwen2. 5 - math as the sharer, the inference and communication time becomes substantially longer, analyzed in appendix a. 4. 3. to further test the generalizability of c2c, we swap the sharer and receiver model. the result shows that c2c robustly brings an 5. 05 % increase in accuracy while applying"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03215v1",
      "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language\n  Models",
      "authors": [
        "Tianyu Fu",
        "Zihan Min",
        "Hanling Zhang",
        "Jichao Yan",
        "Guohao Dai",
        "Wanli Ouyang",
        "Yu Wang"
      ],
      "summary": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.",
      "published": "2025-10-03T17:52:32Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03215v1"
    },
    "chunk_id": 9,
    "text": "c2c is able to more effectively transmit useful information to the receiver. note that the relative gains for larger receivers are less pronounced due to their stronger baselines and higher overlap with the sharer ’ s knowledge. * * different model combinations * *. we test different sharer - receiver combinations, including different model families and different task - specific models. the result in table 6 shows that c2c outperforms text - to - text communication on all five combinations by an average increase of 8. 59 %. this supports that by employing c2c, the receiver model can effectively utilize contextual understanding from different model to enhance performance. notably, when using qwen2. 5 - math as the sharer, the inference and communication time becomes substantially longer, analyzed in appendix a. 4. 3. to further test the generalizability of c2c, we swap the sharer and receiver model. the result shows that c2c robustly brings an 5. 05 % increase in accuracy while applying t2t results in a 6. 3 % decrease in performance. together, these experiments support the scalability of c2c as an effective and efficient new llm communication paradigm. 4. 4 a blation s tudy * * sources of improvement * *. in table 5, we ablate the source of c2c performance gain by fixing the receiver ( qwen3 - 0. 6b ) and varying the sharer. _ single _ denotes standard full fine - tuning of the receiver without sharer. _ identical _ denotes c2c where both sharer and receiver are qwen3 - 0. 6b. our default c2c uses qwen2. 5 - 0. 5b as the sharer. under the same training configuration, c2c consistently attains higher accuracy than both _ single _ and _ identical _. this confirms that c2c improvements do not purely come from added trainable capacity or overfitting to the training set. instead, it points to complementary contextual understanding contributed by the heterogeneous sharer. identical still outperforms single, indicating that cache - level self - communication can provide useful auxiliary understanding, echoing effects observed in latent reasoning and recurrent transformers ( zeng et al., 2025 ; saunshi et al., 2025 ). 8 preprint version pair type receiver sharer metric receiver sharer t2t c2c acc 39. 20 31. 75 41. 35 * * 45. 90 * * qwen3 - 0. 6b gemma3 - 1b time 0. 27 0. 54 1. 04 0. 30 heterogeneous acc 39. 20 39. 86 43. 71 * * 46. 13 * * qwen3 - 0. 6b qwen2. 5 - math - 1. 5b time 0. 27 8. 71 6. 60 0. 27 acc 39. 20 25. 09 39. 74 * * 46. 89 * * qwen3 - 0. 6b qwen2. 5 - coder - 0. 5b time 0. 27 0. 26 1. 59 0. 27 acc 38. 42 39. 20 32. 12 * * 43. 47 * * qwen2. 5 - 0. 5b qwen3 - 0. 6b time 0. 34 0. 27 0. 98 0. 21 swap acc 39. 20 38. 42 41. 03 * * 46. 50 * * qwen3 - 0. 6b qwen2. 5 - 0. 5b time 0. 27 0. 34 1. 52 0. 26 table 6 : comparison of receiver - only, sharer - only, t2t, and c2c across accuracy and time. the pairs are grouped into _ heterogeneous _ settings ( where the receiver is paired with sharers of different capabilities ) and _ swap _ settings ( where receiver and sharer roles are exchanged ). method mmlu arc - c openbook ceval average project 20. 01 19. 57 21. 80 21. 41 20. 70 + fuse * * 43. 36 * * 51. 65 47. 60 36. 91 44. 88 + gate ( = c2c ) 42. 92 * * 54. 52 * * * * 52. 60 * * * * 41. 77 * * * * 47. 95 * * table 7 : performance comparison on mmlu, arc - c, openbook, and ceval benchmarks. * * fuser architecture * *. in table 7 we show the effect of different components in the c2c design. compared with pure projection, keeping the receiver ’ s original kv - cache and fusing with the sharer ’ s kv - cache combines ability from both model and increases the accuracy by 24. 18 %. adding a gate for fused layer selection also helps increasing the average accuracy by 3. 07 %. 4. 5 b ehavior a nalysis * * effective rank analysis * *. we analyze the"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03215v1",
      "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language\n  Models",
      "authors": [
        "Tianyu Fu",
        "Zihan Min",
        "Hanling Zhang",
        "Jichao Yan",
        "Guohao Dai",
        "Wanli Ouyang",
        "Yu Wang"
      ],
      "summary": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.",
      "published": "2025-10-03T17:52:32Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03215v1"
    },
    "chunk_id": 10,
    "text": "01 19. 57 21. 80 21. 41 20. 70 + fuse * * 43. 36 * * 51. 65 47. 60 36. 91 44. 88 + gate ( = c2c ) 42. 92 * * 54. 52 * * * * 52. 60 * * * * 41. 77 * * * * 47. 95 * * table 7 : performance comparison on mmlu, arc - c, openbook, and ceval benchmarks. * * fuser architecture * *. in table 7 we show the effect of different components in the c2c design. compared with pure projection, keeping the receiver ’ s original kv - cache and fusing with the sharer ’ s kv - cache combines ability from both model and increases the accuracy by 24. 18 %. adding a gate for fused layer selection also helps increasing the average accuracy by 3. 07 %. 4. 5 b ehavior a nalysis * * effective rank analysis * *. we analyze the effective rank of kv - cache before and after cache - tocache communication. effective rank ( roy & vetterli, 2007 ) is a common approach for measuring the intrinsic dimension of model weight or activation value ; a higher intrinsic dimension means richer semantic information, as formalized in appendix a. 4. 1. as the table. 2 shows, after cacheto - cache fusing, the k and v ’ s effective rank increased from 388 to 395 and from 532 to 560, respectively. this indicates that c2c enriches the semantic space by successfully transforming in the sharer model and injecting knowledge into the receiver model. * * progressive behavior * *. we analyze the progressive behavior of c2c by gradually increasing the percentage of context kv - cache being updated by c2c. when the percentage is above 50 %, increasing the percentage continuously yields better performance. detailed setup and analysis can be found at appendix a. 2. 4 * * gate behavior * *. we analyze the behavior of c2c ’ s learnable gates under different training regimes as detailed in appendix a. 4. 2. 5 f uture w ork as a general llm communication paradigm, c2c can be expanded to various fields. some potential scenarios include : ( 1 ) privacy - aware cloud – edge collaboration : a cloud - scale model can transmit curated kv - cache segments to an edge model to boost capability without emitting raw text, reducing bandwidth and limiting content exposure. ( 2 ) integration with current inference acceleration method : use c2c to enhance speculative decoding and enable token - level routing across heterogeneous models for lower latency and cost. ( 3 ) multimodal integration : align and fuse caches among 9 preprint version language reasoning llms, vision – language models ( vlms ), and vision – language – action ( vla ) policies so that linguistic and visual context can drive more accurate actions. 6 c onclusion in conclusion, we demonstrate that llms can communicate beyond text. we introduce cache - tocache ( c2c ), a general paradigm that transforms and fuses key – value ( kv ) caches across models to enable direct semantic communication. across diverse tasks and model configurations, c2c consistently achieves higher task performance and better efficiency than text - to - text communication. these results establish cache - to - cache as a practical alternative to token - based communication and highlight its promise for scalable, low - latency multi - llm systems. 10 preprint version r eferences [ anthropic. introducing the model context protocol. online ; nov. 25, 2024, 2024. url https : ] ( https : / / www. anthropic. com / news / model - context - protocol ) [ / / www. anthropic. com / news / model - context - protocol. accessed : 2025 - 09 - 08. ] ( https : / / www. anthropic. com / news / model - context - protocol ) shuai bai, keqin chen, xuejing liu, jialin wang, wenbin ge, sibo song, kai dang, peng wang, shijie wang, jun tang, et al. qwen2. 5 - vl technical report. _ arxiv preprint arxiv : 2502. 13923 _, 2025. fu bang. gptcache : an open - source semantic cache for llm applications enabling faster answers and cost savings. in _ proceedings of the 3rd workshop for natural language processing open _ _ source software ( nlp - oss 2023 ) _, pp. 212 – 218, 2023. william brandon, mayank mishra, aniruddha nrusimha, rameswar panda, and jonathan ragankelley. reducing transformer key - value cache size with cross - layer attention. _ advances in neural _ _ information processing systems _, 37 : 86927 – 86957, 2024. jack choquette, wishwesh"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03215v1",
      "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language\n  Models",
      "authors": [
        "Tianyu Fu",
        "Zihan Min",
        "Hanling Zhang",
        "Jichao Yan",
        "Guohao Dai",
        "Wanli Ouyang",
        "Yu Wang"
      ],
      "summary": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.",
      "published": "2025-10-03T17:52:32Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03215v1"
    },
    "chunk_id": 11,
    "text": "chen, xuejing liu, jialin wang, wenbin ge, sibo song, kai dang, peng wang, shijie wang, jun tang, et al. qwen2. 5 - vl technical report. _ arxiv preprint arxiv : 2502. 13923 _, 2025. fu bang. gptcache : an open - source semantic cache for llm applications enabling faster answers and cost savings. in _ proceedings of the 3rd workshop for natural language processing open _ _ source software ( nlp - oss 2023 ) _, pp. 212 – 218, 2023. william brandon, mayank mishra, aniruddha nrusimha, rameswar panda, and jonathan ragankelley. reducing transformer key - value cache size with cross - layer attention. _ advances in neural _ _ information processing systems _, 37 : 86927 – 86957, 2024. jack choquette, wishwesh gandhi, olivier giroux, nick stam, and ronny krashinsky. nvidia a100 tensor core gpu : performance and innovation. _ ieee micro _, 41 ( 2 ) : 29 – 35, 2021. peter clark, isaac cowhey, oren etzioni, tushar khot, ashish sabharwal, carissa schoenick, and oyvind tafjord. think you have solved question answering? try arc, the ai2 reasoning challenge. _ arxiv preprint arxiv : 1803. 05457 _, 2018. yilun du, shuang li, antonio torralba, joshua b tenenbaum, and igor mordatch. improving factuality and reasoning in language models through multiagent debate. in _ forty - first international _ _ conference on machine learning _, 2023. abhimanyu dubey, abhinav jauhri, abhinav pandey, abhishek kadian, ahmad al - dahle, aiesha letman, akhil mathur, alan schelten, amy yang, angela fan, et al. the llama 3 herd of models. _ arxiv e - prints _, pp. arxiv – 2407, 2024. andrew estornell and yang liu. multi - llm debate : framework, principals, and interventions. _ ad - _ _ vances in neural information processing systems _, 37 : 28938 – 28964, 2024. tao feng, yanzhen shen, and jiaxuan you. graphrouter : a graph - based router for llm selections. _ arxiv preprint arxiv : 2410. 03834 _, 2024. tianyu fu, yi ge, yichen you, enshu liu, zhihang yuan, guohao dai, shengen yan, huazhong yang, and yu wang. r2r : efficiently navigating divergent reasoning paths with small - large model token routing. _ arxiv preprint arxiv : 2505. 21600 _, 2025. aryo pradipta gema, joshua ong jun leang, giwon hong, alessio devoto, alberto carlo maria mancino, rohit saxena, xuanli he, yu zhao, xiaotang du, mohammad reza ghasemi madani, et al. are we done with mmlu? in _ proceedings of the 2025 conference of the nations of the amer - _ _ icas chapter of the association for computational linguistics : human language technologies _ _ ( volume 1 : long papers ) _, pp. 5069 – 5096, 2025. daya guo, dejian yang, haowei zhang, junxiao song, ruoyu zhang, runxin xu, qihao zhu, shirong ma, peiyi wang, xiao bi, et al. deepseek - r1 : incentivizing reasoning capability in llms via reinforcement learning. _ arxiv preprint arxiv : 2501. 12948 _, 2025. taicheng guo, xiuying chen, yaqi wang, ruidi chang, shichao pei, nitesh v chawla, olaf wiest, and xiangliang zhang. large language model based multi - agents : a survey of progress and challenges. _ arxiv preprint arxiv : 2402. 01680 _, 2024. sirui hong, xiawu zheng, jonathan p. chen, yuheng cheng, ceyao zhang, zili wang, steven ka shing yau, zi hen lin, liyang zhou, chenyu ran, lingfeng xiao, and chenglin wu. metagpt : meta programming for multi - agent collaborative framework. _ arxiv _, abs / 2308. 00352, [ 2023. url https : / / api. semantics"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03215v1",
      "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language\n  Models",
      "authors": [
        "Tianyu Fu",
        "Zihan Min",
        "Hanling Zhang",
        "Jichao Yan",
        "Guohao Dai",
        "Wanli Ouyang",
        "Yu Wang"
      ],
      "summary": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.",
      "published": "2025-10-03T17:52:32Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03215v1"
    },
    "chunk_id": 12,
    "text": "##seek - r1 : incentivizing reasoning capability in llms via reinforcement learning. _ arxiv preprint arxiv : 2501. 12948 _, 2025. taicheng guo, xiuying chen, yaqi wang, ruidi chang, shichao pei, nitesh v chawla, olaf wiest, and xiangliang zhang. large language model based multi - agents : a survey of progress and challenges. _ arxiv preprint arxiv : 2402. 01680 _, 2024. sirui hong, xiawu zheng, jonathan p. chen, yuheng cheng, ceyao zhang, zili wang, steven ka shing yau, zi hen lin, liyang zhou, chenyu ran, lingfeng xiao, and chenglin wu. metagpt : meta programming for multi - agent collaborative framework. _ arxiv _, abs / 2308. 00352, [ 2023. url https : / / api. semanticscholar. org / corpusid : 260351380. ] ( https : / / api. semanticscholar. org / corpusid : 260351380 ) yuzhen huang, yuzhuo bai, zhihao zhu, junlei zhang, jinghan zhang, tangjun su, junteng liu, chuancheng lv, yikai zhang, yao fu, et al. c - eval : a multi - level multi - discipline chinese evaluation suite for foundation models. _ advances in neural information processing systems _, 36 : 62991 – 63010, 2023. 11 preprint version binyuan hui, jian yang, zeyu cui, jiaxi yang, dayiheng liu, lei zhang, tianyu liu, jiajun zhang, bowen yu, keming lu, et al. qwen2. 5 - coder technical report. _ arxiv preprint arxiv : 2409. 12186 _, 2024. guohao li, hasan hammoud, hani itani, dmitrii khizbullin, and bernard ghanem. camel : communicative agents for ” mind ” exploration of large language model society. _ advances in neural _ _ information processing systems _, 36 : 51991 – 52008, 2023. yuhui li, fangyun wei, chao zhang, and hongyang zhang. eagle : speculative sampling requires rethinking feature uncertainty. _ arxiv preprint arxiv : 2401. 15077 _, 2024. tian liang, zhiwei he, wenxiang jiao, xing wang, yan wang, rui wang, yujiu yang, shuming shi, and zhaopeng tu. encouraging divergent thinking in large language models through multiagent debate. in _ proceedings of the 2024 conference on empirical methods in natural language _ _ processing _, pp. 17889 – 17904, 2024. yuhan liu, yuyang huang, jiayi yao, shaoting feng, zhuohan gu, kuntai du, hanchen li, yihua cheng, junchen jiang, shan lu, et al. droidspeak : kv cache sharing for cross - llm communication and multi - llm serving. _ arxiv preprint arxiv : 2411. 02820 _, 2024a. zijun liu, yanzhe zhang, peng li, yang liu, and diyi yang. a dynamic llm - powered agent network for task - oriented agent collaboration. in _ first conference on language modeling _, 2024b. todor mihaylov, peter clark, tushar khot, and ashish sabharwal. can a suit of armor conduct electricity? a new dataset for open book question answering. in _ proceedings of the 2018 conference _ _ on empirical methods in natural language processing _, pp. 2381 – 2391, 2018. isaac ong, amjad almahairi, vincent wu, wei - lin chiang, tianhao wu, joseph e gonzalez, m waleed kadous, and ion stoica. routellm : learning to route llms with preference data. _ arxiv _ _ preprint arxiv : 2406. 18665 _, 2024. [ openai. introducing gpt - 5. https : / / openai. com / index / introducing - gpt - 5 /, au - ] ( https : / / openai. com / index / introducing - gpt - 5 / ) gust 7 2025. accessed : 2025 - 09 - 11. ruoyu qin, zheming li, weiran he, mingxing zhang, yongwei wu, weimin zheng, and xinran xu. mooncake : a kvcache - centric disaggregated architecture for llm serving. _ arxiv preprint _ _ arxiv : 2407. 00079 _, 2024. olivier roy and martin vetter"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03215v1",
      "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language\n  Models",
      "authors": [
        "Tianyu Fu",
        "Zihan Min",
        "Hanling Zhang",
        "Jichao Yan",
        "Guohao Dai",
        "Wanli Ouyang",
        "Yu Wang"
      ],
      "summary": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.",
      "published": "2025-10-03T17:52:32Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03215v1"
    },
    "chunk_id": 13,
    "text": "##ri, vincent wu, wei - lin chiang, tianhao wu, joseph e gonzalez, m waleed kadous, and ion stoica. routellm : learning to route llms with preference data. _ arxiv _ _ preprint arxiv : 2406. 18665 _, 2024. [ openai. introducing gpt - 5. https : / / openai. com / index / introducing - gpt - 5 /, au - ] ( https : / / openai. com / index / introducing - gpt - 5 / ) gust 7 2025. accessed : 2025 - 09 - 11. ruoyu qin, zheming li, weiran he, mingxing zhang, yongwei wu, weimin zheng, and xinran xu. mooncake : a kvcache - centric disaggregated architecture for llm serving. _ arxiv preprint _ _ arxiv : 2407. 00079 _, 2024. olivier roy and martin vetterli. the effective rank : a measure of effective dimensionality. in _ 2007 _ _ 15th european signal processing conference _, pp. 606 – 610. ieee, 2007. nikunj saunshi, nishanth dikkala, zhiyuan li, sanjiv kumar, and sashank j reddi. reasoning with latent thoughts : on the power of looped transformers. _ arxiv preprint arxiv : 2502. 17416 _, 2025. zejiang shen, hunter lang, bailin wang, yoon kim, and david sontag. learning to decode collaboratively with multiple language models. in _ proceedings of the 62nd annual meeting of the _ _ association for computational linguistics ( volume 1 : long papers ) _, pp. 12974 – 12990, 2024. yutao sun, li dong, yi zhu, shaohan huang, wenhui wang, shuming ma, quanlu zhang, jianyong wang, and furu wei. you only cache once : decoder - decoder architectures for language models. _ advances in neural information processing systems _, 37 : 7339 – 7361, 2024. rao surapaneni, miku jha, michael vakoc, and todd segal. announcing the agent2agent protocol [ ( a2a ). google developers blog, april 2025. url https : / / developers. googleblog. ] ( https : / / developers. googleblog. com / en / a2a - a - new - era - of - agent - interoperability / ) [ com / en / a2a - a - new - era - of - agent - interoperability /. accessed : 2025 - 09 - 08. ] ( https : / / developers. googleblog. com / en / a2a - a - new - era - of - agent - interoperability / ) gemma team, aishwarya kamath, johan ferret, shreya pathak, nino vieillard, ramona merhej, sarah perrin, tatiana matejovicova, alexandre [UNK], morgane rivi ` ere, et al. gemma 3 technical report. _ arxiv preprint arxiv : 2503. 19786 _, 2025. teknium. openhermes 2. 5 : an open dataset of synthetic data for generalist llm assistants, 2023. [ url https : / / huggingface. co / datasets / teknium / openhermes - 2. 5. ] ( https : / / huggingface. co / datasets / teknium / openhermes - 2. 5 ) 12 preprint version khanh - tung tran, dung dao, minh - duong nguyen, quoc - viet pham, barry o ’ sullivan, and hoang d nguyen. multi - agent collaboration mechanisms : a survey of llms. _ arxiv preprint _ _ arxiv : 2501. 06322 _, 2025. junlin wang, jue wang, ben athiwaratkun, ce zhang, and james zou. mixture - of - agents enhances large language model capabilities. _ arxiv preprint arxiv : 2406. 04692 _, 2024. haoyi wu and kewei tu. layer - condensed kv cache for efficient inference of large language models. in _ proceedings of the 62nd annual meeting of the association for computational linguistics _ _ ( volume 1 : long papers ) _, pp. 11175 – 11188, 2024. qingyun wu, gagan bansal, jieyu zhang, yiran wu, shaokun zhang, erkang zhu, beibin li, li jiang, xiaoyun zhang, and chi wang. autogen : enabling next - gen llm applications via multiagent conversation framework. _ arxiv preprint arxiv : 2308. 08155"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03215v1",
      "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language\n  Models",
      "authors": [
        "Tianyu Fu",
        "Zihan Min",
        "Hanling Zhang",
        "Jichao Yan",
        "Guohao Dai",
        "Wanli Ouyang",
        "Yu Wang"
      ],
      "summary": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.",
      "published": "2025-10-03T17:52:32Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03215v1"
    },
    "chunk_id": 14,
    "text": "##ms. _ arxiv preprint _ _ arxiv : 2501. 06322 _, 2025. junlin wang, jue wang, ben athiwaratkun, ce zhang, and james zou. mixture - of - agents enhances large language model capabilities. _ arxiv preprint arxiv : 2406. 04692 _, 2024. haoyi wu and kewei tu. layer - condensed kv cache for efficient inference of large language models. in _ proceedings of the 62nd annual meeting of the association for computational linguistics _ _ ( volume 1 : long papers ) _, pp. 11175 – 11188, 2024. qingyun wu, gagan bansal, jieyu zhang, yiran wu, shaokun zhang, erkang zhu, beibin li, li jiang, xiaoyun zhang, and chi wang. autogen : enabling next - gen llm applications via multiagent conversation framework. _ arxiv preprint arxiv : 2308. 08155 _, 3 ( 4 ), 2023. you wu, haoyi wu, and kewei tu. a systematic study of cross - layer kv sharing for efficient llm inference. in _ proceedings of the 2025 conference of the nations of the americas chapter of _ _ the association for computational linguistics : human language technologies ( volume 2 : short _ _ papers ) _, pp. 396 – 403, 2025. an yang, beichen zhang, binyuan hui, bofei gao, bowen yu, chengpeng li, dayiheng liu, jianhong tu, jingren zhou, junyang lin, et al. qwen2. 5 - math technical report : toward mathematical expert model via self - improvement. _ arxiv preprint arxiv : 2409. 12122 _, 2024a. an yang, anfeng li, baosong yang, beichen zhang, binyuan hui, bo zheng, bowen yu, chang gao, chengen huang, chenxu lv, et al. qwen3 technical report. _ arxiv preprint _ _ arxiv : 2505. 09388 _, 2025a. jingbo yang, bairu hou, wei wei, yujia bao, and shiyu chang. kvlink : accelerating large language models via efficient kv cache reuse. _ arxiv preprint arxiv : 2502. 16002 _, 2025b. yifei yang, zouying cao, qiguang chen, libo qin, dongjie yang, hai zhao, and zhi chen. kvsharer : efficient inference via layer - wise dissimilar kv cache sharing. _ arxiv preprint _ _ arxiv : 2410. 18517 _, 2024b. jiayi yao, hanchen li, yuhan liu, siddhant ray, yihua cheng, qizheng zhang, kuntai du, shan lu, and junchen jiang. cacheblend : fast large language model serving with cached knowledge fusion. _ arxiv e - prints _, pp. arxiv – 2405, 2024. lu ye, ze tao, yong huang, and yang li. chunkattention : efficient self - attention with prefix - aware kv cache and two - phase partition. in _ proceedings of the 62nd annual meeting of the association _ _ for computational linguistics ( volume 1 : long papers ) _, pp. 11608 – 11620, 2024. boyi zeng, shixiang song, siyuan huang, yixuan wang, he li, ziwei he, xinbing wang, zhiyu li, and zhouhan lin. pretraining language models to ponder in continuous space. _ arxiv preprint _ _ arxiv : 2505. 20674 _, 2025. kaiyan zhang, jianyu wang, ning ding, biqing qi, ermo hua, xingtai lv, and bowen zhou. fast and slow generating : an empirical study on large and small language models collaborative decoding. _ corr _, 2024a. mingjin zhang, xiaoming shen, jiannong cao, zeyang cui, and shan jiang. edgeshard : efficient llm inference via collaborative edge computing. _ ieee internet of things journal _, 2024b. yusen zhang, ruoxi sun, yanfei chen, tomas pfister, rui zhang, and sercan arik. chain of agents : large language models collaborating on long - context tasks. _ advances in neural information _ _ processing systems _, 37 : 132208 – 132237, 2024c. wenhao zheng, yixiao chen, weitong zhang, souvik kundu, yun li, zhengzhong liu, eric p xing, hongyi wang, and huaxiu yao. citer : collaborative inference for efficient large language model decoding with token - level routing. _ arxiv preprint arxiv : 250"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03215v1",
      "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language\n  Models",
      "authors": [
        "Tianyu Fu",
        "Zihan Min",
        "Hanling Zhang",
        "Jichao Yan",
        "Guohao Dai",
        "Wanli Ouyang",
        "Yu Wang"
      ],
      "summary": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.",
      "published": "2025-10-03T17:52:32Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03215v1"
    },
    "chunk_id": 15,
    "text": ": an empirical study on large and small language models collaborative decoding. _ corr _, 2024a. mingjin zhang, xiaoming shen, jiannong cao, zeyang cui, and shan jiang. edgeshard : efficient llm inference via collaborative edge computing. _ ieee internet of things journal _, 2024b. yusen zhang, ruoxi sun, yanfei chen, tomas pfister, rui zhang, and sercan arik. chain of agents : large language models collaborating on long - context tasks. _ advances in neural information _ _ processing systems _, 37 : 132208 – 132237, 2024c. wenhao zheng, yixiao chen, weitong zhang, souvik kundu, yun li, zhengzhong liu, eric p xing, hongyi wang, and huaxiu yao. citer : collaborative inference for efficient large language model decoding with token - level routing. _ arxiv preprint arxiv : 2502. 01976 _, 2025. 13 preprint version a a ppendix a. 1 d esign c hoice e xploration we detail the designs of c2c with discussions on alternative possible design choices in this section. a. 1. 1 l ayer a lignment * * terminal alignment * *. in this strategy, the layers of the two models are aligned starting from the output side. specifically, the final layer of the smaller model is paired with the final layer of the larger model, the penultimate layer with the penultimate layer, and so on. this scheme prioritizes alignment between the deeper layers across models, which typically captures higher - level semantic representations. * * depth - normalized alignment * *. in this strategy, both models ’ layer indices are normalized to [ 0 _, _ 1 ] by dividing by ( _ l _ _ − _ 1 ), where _ l _ is the total number of layers in the model. let the model with fewer layers ( _ l _ min ) serve as the anchor. for each anchor layer _ i _ ( with normalized index _ i / _ ( _ l _ min _ − _ 1 ) ), we select the layer _ j _ in the other model ( _ l _ max ) whose normalized index _ j / _ ( _ l _ max _ − _ 1 ) is closest : _ i _ _ j _ _ j _ _ [ ⋆ ] _ = arg min _ j _ _ l _ min _ − _ 1 _ [ − ] _ _ l _ max _ − _ 1 _. _ ( 5 ) this method produces an alignment that distributes correspondences approximately uniformly across the model depth. * * c2c choice * *. in our design, we adopt * * terminal alignment * *, as it provides a simpler and more direct layer mapping strategy that empirically performs slightly better in our experiments. a. 1. 2 t okenization a lignment for dialogue inputs, we first apply the chat template of each tokenizer, which produces a sequence consisting of alternating sections of ( 1 ) _ template tokens _ and ( 2 ) _ message tokens _. these two types of sections are handled differently during alignment. * * template sections * *. template tokens are structural markers ( e. g., role delimiters, formatting tokens ) that differ across tokenizers and carry no semantic content. to preserve sequence consistency without introducing unnecessary distortions, these sections are aligned by simple length padding : the shorter side is padded with < pad > tokens until both tokenizers ’ sequences are of equal length. * * message sections * *. message tokens correspond to the actual textual content of user or assistant dialogs. each target model token in a message section is decoded into its string form and re - encoded using the source model tokenizer. special tokens ( e. g., < pad >, < eos > ) are mapped directly if possible ; otherwise, the source model unknown token is used. for regular tokens, if the re - encoding produces a single source model token, a direct one - to - one mapping is established. if multiple source model tokens are produced ( a one - to - many case ), one of the two selection strategies is applied : ( 1 ) _ first - occurrence selection _ : choose the first source model token from the candidate set, yielding a deterministic and computationally efficient mapping. ( 2 ) _ maximal - coverage selection _ : decode each candidate token, compute its string length, and select the longest ; this heuristic aims to preserve maximal surface correspondence with the original target model token. * * c2c choice * * we observed that the two selection strategies generally produce very similar results, with more than 80 % of sequences yielding identical alignments across strategies. based on this observation, we empirically adopt * * maximal - coverage selection * * as the default strategy to reduce the risk of losing information in one - to - many tokenization cases."
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03215v1",
      "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language\n  Models",
      "authors": [
        "Tianyu Fu",
        "Zihan Min",
        "Hanling Zhang",
        "Jichao Yan",
        "Guohao Dai",
        "Wanli Ouyang",
        "Yu Wang"
      ],
      "summary": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.",
      "published": "2025-10-03T17:52:32Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03215v1"
    },
    "chunk_id": 16,
    "text": "source model unknown token is used. for regular tokens, if the re - encoding produces a single source model token, a direct one - to - one mapping is established. if multiple source model tokens are produced ( a one - to - many case ), one of the two selection strategies is applied : ( 1 ) _ first - occurrence selection _ : choose the first source model token from the candidate set, yielding a deterministic and computationally efficient mapping. ( 2 ) _ maximal - coverage selection _ : decode each candidate token, compute its string length, and select the longest ; this heuristic aims to preserve maximal surface correspondence with the original target model token. * * c2c choice * * we observed that the two selection strategies generally produce very similar results, with more than 80 % of sequences yielding identical alignments across strategies. based on this observation, we empirically adopt * * maximal - coverage selection * * as the default strategy to reduce the risk of losing information in one - to - many tokenization cases. through this design, template sections are aligned structurally via padding, while message sections are aligned semantically at the token level, ensuring robust correspondences between target model and source model representations in chat - formatted inputs. a. 1. 3 f user a rchitecture beyond the c2c fuser, we also examined a more complex yet potentially more powerful variant, which we denote as * * c2c - c ( complex ) * *. the main complexity comes from the introduction of an 14 preprint version table 8 : performance comparison across benchmarks with pgr and overall normalized time. * * c - eval * * * * arc - c * * * * mmlu - redux * * * * openbook * * * * method * * acc pgr time acc pgr time acc pgr time acc pgr time q3 - 4b 68. 09 100 % 0. 24 87. 48 100 % 0. 24 71. 38 100 % 0. 24 79. 40 100 % 0. 25 q3 - 0. 6b 32. 04 0 % 0. 18 41. 04 0 % 0. 19 35. 53 0 % 0. 18 39. 20 0 % 0. 21 t2t 36. 96 14 % 0. 92 52. 00 24 % 0. 80 42. 95 21 % 0. 99 46. 40 18 % 1. 70 c2c 44. 40 34 % 0. 27 60. 17 41 % 0. 27 45. 92 29 % 0. 27 55. 20 40 % 0. 28 c2c - c 60. 63 79 % 0. 21 80. 96 86 % 0. 23 62. 78 76 % 0. 15 70. 40 78 % 0. 26 additional projection stage : instead of directly concatenating sharer and receiver caches as in c2c, sharer cache is first projected into the receiver ’ s dimensionality through a 3 - layer mlp. the concatenated representation is then processed along two familiar routes — feature fusion and dynamic weighting — to yield the final s & r cache. the main experiment results are presented in table 8. note that we fix the maximum response length to 8 tokens and the maximum communication length to 256 tokens in this experiment to reduce evaluation cost. c2c - c attains stronger performance than the default c2c, suggesting that increasing the architectural sophistication of fuser can further amplify the benefits of c2c communication. in this table, we also report performance gap recovered ( pgr ) ( ong et al., 2024 ) metric, which quantifies how much of the performance gap between a weak and a strong model is recovered. nevertheless, the focus of this work is on introducing the c2c paradigm itself. for this purpose, we adopt a simple yet effective fuser design, leaving systematic investigation of more elaborate architectures to future work. a. 2 a dditional e xperimental r esults a. 2. 1 c ache e nrichment d etail in table 9 we show the effect of single - layer cache enrichment. layer 4 and 16 benefit from the cache enrichment approach by replacing the kv - cache with the few - shot one, while cache enrichment on other layers shows performance degradation. table 9 : accuracy of single - layer cache enrichment layer acc. layer acc. 0 56. 36 14 54. 24 1 56. 36 15 58. 06 2 57. 14 16 * * 58. 45 * * 3 57. 53 17 57. 88 4 * * 58. 52 * * 18 57. 21 5 56. 45 19 56. 71 6 54. 56 20 55. 93 7 56. 82 21 57. 74 8 55. 01 22 57. 23 9 56. 78 23 55. 22 10 55. 29 24 55. 75 11 57. 05 25 56. 16 12 55. 04 26 55. 79 13 54. 83 27 55. 01 a. 2. 2 s trong - to - w ea"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03215v1",
      "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language\n  Models",
      "authors": [
        "Tianyu Fu",
        "Zihan Min",
        "Hanling Zhang",
        "Jichao Yan",
        "Guohao Dai",
        "Wanli Ouyang",
        "Yu Wang"
      ],
      "summary": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.",
      "published": "2025-10-03T17:52:32Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03215v1"
    },
    "chunk_id": 17,
    "text": "##ment d etail in table 9 we show the effect of single - layer cache enrichment. layer 4 and 16 benefit from the cache enrichment approach by replacing the kv - cache with the few - shot one, while cache enrichment on other layers shows performance degradation. table 9 : accuracy of single - layer cache enrichment layer acc. layer acc. 0 56. 36 14 54. 24 1 56. 36 15 58. 06 2 57. 14 16 * * 58. 45 * * 3 57. 53 17 57. 88 4 * * 58. 52 * * 18 57. 21 5 56. 45 19 56. 71 6 54. 56 20 55. 93 7 56. 82 21 57. 74 8 55. 01 22 57. 23 9 56. 78 23 55. 22 10 55. 29 24 55. 75 11 57. 05 25 56. 16 12 55. 04 26 55. 79 13 54. 83 27 55. 01 a. 2. 2 s trong - to - w eak c ommunication table 10 reports the results on longbenchv1 when pairing the weak receiver qwen3 - 0. 6b with a much stronger sharer, qwen3 - 4b, under different input lengths. across all length regimes, c2c consistently outperforms both the receiver alone and the t2t baseline. on average, c2c achieves a 40. 45 % pgr over the weak - to - strong gap. these results demonstrate that in strong - to - weak settings, 15 preprint version table 10 : longbenchv1 results with qwen3 - 4b as the sharer and qwen3 - 0. 6b as the receiver across different input lengths. length receiver sharer t2t c2c 0 – 4k 27. 39 48. 76 31. 71 37. 07 4 – 8k 24. 97 46. 27 27. 54 32. 08 8k + 22. 20 42. 78 26. 14 31. 00 average 25. 01 46. 12 28. 62 33. 55 ( a ) sharer : q2. 5 - math - 1. 5b, receiver : q3 - 0. 6b ( b ) sharer : q3 - 4b, receiver : q3 - 0. 6b figure 7 : venn diagrams of correctly answered questions under different model pairings. c2c can effectively transfer the stronger model ’ s contextual understanding, yielding notable gains for the weaker receiver. we additionally evaluated the strong - to - weak setting ( qwen3 - 0. 6b as receiver and qwen3 - 4b as sharer ) on other benchmarks beyond longbenchv1. the detailed results are provided in section a. 1. 3, table 8. a. 2. 3 a ccuracy b reakdown we analyze where the accuracy gains of c2c come from by using venn diagrams on the mmluredux benchmark, as illustrated in figure 7. for this analysis, we use the c2c - c variant introduced in section a. 1. 3, as it has the potential to achieve stronger performance amd provides a clearer breakdown of where c2c ’ s accuracy originates. * * models with comparable capacity * *. when the receiver ( qwen3 - 0. 6b, denoted as q3 - 0. 6b ) and the sharer ( qwen2. 5 - math - 1. 5b - instruct, denoted as q2. 5 - math - 1. 5b ) have comparable overall capacity but complementary strengths, c2c not only inherits part of the sharer ’ s ability but also solves additional questions by integrating understanding from both models. * * models with disparate capacity * *. when the sharer ( qwen3 - 4b, denoted as q3 - 4b ) is substantially stronger than the receiver ( qwen3 - 0. 6b ), c2c tends to integrate more of the stronger model ’ s understanding. quantitatively, in the disparate - capacity case ( figure 7b ), among the questions that the sharer can answer correctly, c2c also answers 72. 11 % correctly. in contrast, in the comparablecapacity case ( figure 7a ), c2c succeeds on only 50. 97 %. 16 preprint version a. 2. 4 p rogressive b ehavior | col1 | col2 | col3 | col4 | col5 | | - - - | - - - | - - - | - - - | - - - | | | | | | | | | | | | | | | | | | | | | | f | rmer | | | | | l < br > s | atter < br > harer mode | l | figure 8 : accuracy changes with c2c proportion increases to investigate the impact of fused kv - cache proportion on the accuracy of the receiver model,"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03215v1",
      "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language\n  Models",
      "authors": [
        "Tianyu Fu",
        "Zihan Min",
        "Hanling Zhang",
        "Jichao Yan",
        "Guohao Dai",
        "Wanli Ouyang",
        "Yu Wang"
      ],
      "summary": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.",
      "published": "2025-10-03T17:52:32Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03215v1"
    },
    "chunk_id": 18,
    "text": "the stronger model ’ s understanding. quantitatively, in the disparate - capacity case ( figure 7b ), among the questions that the sharer can answer correctly, c2c also answers 72. 11 % correctly. in contrast, in the comparablecapacity case ( figure 7a ), c2c succeeds on only 50. 97 %. 16 preprint version a. 2. 4 p rogressive b ehavior | col1 | col2 | col3 | col4 | col5 | | - - - | - - - | - - - | - - - | - - - | | | | | | | | | | | | | | | | | | | | | | f | rmer | | | | | l < br > s | atter < br > harer mode | l | figure 8 : accuracy changes with c2c proportion increases to investigate the impact of fused kv - cache proportion on the accuracy of the receiver model, we gradually added the proportion of fused kv - cache derived from the sharer to the receiver model before generating outputs. specifically, former and latter refer to progressively replacing the receiver ’ s kv - cache with the fused kv - cache from front to back and back to front, respectively. we observe that the overall accuracy first decreases and then increases as the replacement ratio grows. the performance reduction may stem from the gap between training and testing, where only the full receiver kv - cache is used during training. when the fused proportion goes up to over 50 %, the performance of c2c continues to increase with respect to the proportion, reflecting the progressive benefits of c2c. note that projecting using latter cache generally has larger impact than projecting the former, since it is closer to the final response. a. 3 a dditional e xperiment s etup a. 3. 1 c ache e nrichment we conducted oracle experiments with qwen3 - 0. 6b and qwen3 - 4b to examine how kv - cache enrichment influences model performance. the evaluation was performed on mmlu - redux. the few - shot examples are selected from mmlu while excluding overlaps with mmlu - redux to ensure fairness. to probe different ways of applying cache enrichment, we compared four cache enrichment strategies : all - layer cache enrichment ( apply cache enrichment on all layers ), single - layer cache enrichment ( apply cache enrichment only on single layers ), selective cache enrichment - best ( select n layers that have the highest accuracy according to single - layer cache enrichment ), selective cache enrichment - worst ( select n layers that have the lowest accuracy according to single - layer cache enrichment ). all methods utilized few - shot – optimized kv - caches while maintaining the same cache length as zero - shot, enabling a controlled evaluation of cache enrichment and its layerspecific effects. a. 3. 2 c ache t ransformation we employed the mmlu - redux dataset to train a 3 - layer mlp that maps the kv - cache of a source llm to that of a target llm. for visualization, 300 samples were randomly selected from the dataset. the source, target, and transformed kv - cache were all projected into two - dimensional space using t - sne, allowing us to examine the alignment of representations between the two models. for t - sne generation, we set perplexity to 50 and max iterations to 1000. a. 3. 3 q uery - level routing query - level routing aims to improve the performance – efficiency trade - off by dynamically assigning harder queries to a stronger llm. following prior work, we adopt a matrix factorization framework. query embeddings are obtained from the openai text - embedding - 3 - small encoder, while model embeddings are taken from pretrained vectors of gpt - 4 - 1106 - preview and mixtral - 8x7b - instructv0. 1. these embeddings are used to compute a strong win rate score for each query, which reflects 17 preprint version its relative difficulty. queries are then ranked by this score. for each evaluated model pair, we define the strong model as the one achieving higher standalone benchmark accuracy and the weak model as the lower - performing one. queries in the upper half of the ranking are routed to the strong model, while those in the lower half are routed to the weak model. a. 3. 4 e valuation m ethod * * main evaluation * *. we evaluate c2c on four multiple - choice benchmarks : openbookqa, mmluredux, arc - challenge, and c - eval. for mmlu - redux, we exclude questions annotated with the error type _ no correct answer _. for all evaluations, we adopt a deterministic generation configuration without sampling, using greedy decoding to ensure reproducibility. specifically, we use non - cot prompts, following the unified format described in section a. 3. 6. model outputs are then matched to the correct option"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03215v1",
      "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language\n  Models",
      "authors": [
        "Tianyu Fu",
        "Zihan Min",
        "Hanling Zhang",
        "Jichao Yan",
        "Guohao Dai",
        "Wanli Ouyang",
        "Yu Wang"
      ],
      "summary": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.",
      "published": "2025-10-03T17:52:32Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03215v1"
    },
    "chunk_id": 19,
    "text": ", which reflects 17 preprint version its relative difficulty. queries are then ranked by this score. for each evaluated model pair, we define the strong model as the one achieving higher standalone benchmark accuracy and the weak model as the lower - performing one. queries in the upper half of the ranking are routed to the strong model, while those in the lower half are routed to the weak model. a. 3. 4 e valuation m ethod * * main evaluation * *. we evaluate c2c on four multiple - choice benchmarks : openbookqa, mmluredux, arc - challenge, and c - eval. for mmlu - redux, we exclude questions annotated with the error type _ no correct answer _. for all evaluations, we adopt a deterministic generation configuration without sampling, using greedy decoding to ensure reproducibility. specifically, we use non - cot prompts, following the unified format described in section a. 3. 6. model outputs are then matched to the correct option labels to compute accuracy. to control evaluation cost, we set the maximum response length to 64 tokens unless otherwise specified, where the response refers to the final answer generated by the receiver, since the base models do not always follow instructions and longer limits would substantially increase inference time. for the t2t setting, we additionally set the maximum communication length to 256 tokens, where the communication refers to the messages passed from the sharer to the receiver. * * longbench evaluation * *. we evaluate c2c on the longbench - e dataset, which comprises a total of 13 individual datasets. we adopt the best - practice generation configuration of qwen3, with temperature set to 0. 6, topp to 0. 95, topk to 20, minp to 0, repetition penalty of 1. 2, and sampling enabled. the prompts and evaluation procedures are strictly aligned with the official longbench settings, with a maximum output length of 2, 048 tokens. a. 3. 5 c2c t raining * * training data * *. ( 1 ) _ performance experiment. _ the fuser was trained on the openhermes - 2. 5 dataset with a maximum sequence length of 2, 048 tokens. training used 500, 000 samples for one epoch with a macro batch size of 256, corresponding to 1, 929 total training steps. ( 2 ) _ scaling sequence lengths experiment. _ the fuser was trained on the longbench - e benchmark with a maximum sequence length of 12, 000 tokens. the data was randomly split into 3 / 4 for training and 1 / 4 for evaluation to ensure independence between training and evaluation. training used 1, 896 samples for one epoch with a macro batch size of 16, corresponding to 118 total training steps. ( 3 ) _ scaling model sizes experiment. _ the fuser was trained on the auxiliary ~ ~ t ~ ~ rain split of the mmlu dataset with a maximum sequence length of 1, 024 tokens. training used 15, 000 samples for one epoch with a macro batch size of 128, corresponding to 116 total training steps. * * training scheme * *. all experiments were conducted with a fixed random seed of 42 to ensure reproducibility. unless otherwise noted, the training configuration was as follows : optimization employed a learning rate of 1 _ × _ 10 _ [ − ] _ [ 4 ] with a linear scheduler and a 10 % warmup ratio, a weight decay of 0. 01, and a maximum gradient norm of 1. the temperature was linearly annealed from 1. 0 to 0. 001 across the total number of training steps. layer alignment was configured with the last aligned scheme across all experiments. tokenization alignment was applied only when the paired models employed different tokenizers, in which case the longest strategy was used. for data preparation, each dataset was partitioned into a training split ( 99 % ) and a small held - out validation split ( 1 % ). the validation split was not used for model updates but was monitored during training to report evaluation loss. a. 3. 6 e valuation p rompts texts 1 and 2 present the exact prompts used for the main evaluation on multiple - choice datasets. text 3 provides the prompt for the sharer model in the t2t evaluation, the receiver model uses the same prompt as in the c2c setting. text 4 shows the prompt used in cache enrichment experiment. for zero - shot method, no shots are included in the prompt. the few - shot method uses exactly the same prompt as text 4. for oracle methods, we adopt the few - shot prompt but remove the kv - cache associated with the shots after the forward pass. the prompt for longbench evaluation strictly follows its official configuration, which varies across the different sub - datasets. 18 preprint version 19 preprint version a. 4 a dditional a nalysis a. 4. 1 e ffective r ank we list the definition of effective rank that was proposed by roy & vet"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03215v1",
      "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language\n  Models",
      "authors": [
        "Tianyu Fu",
        "Zihan Min",
        "Hanling Zhang",
        "Jichao Yan",
        "Guohao Dai",
        "Wanli Ouyang",
        "Yu Wang"
      ],
      "summary": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.",
      "published": "2025-10-03T17:52:32Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03215v1"
    },
    "chunk_id": 20,
    "text": "updates but was monitored during training to report evaluation loss. a. 3. 6 e valuation p rompts texts 1 and 2 present the exact prompts used for the main evaluation on multiple - choice datasets. text 3 provides the prompt for the sharer model in the t2t evaluation, the receiver model uses the same prompt as in the c2c setting. text 4 shows the prompt used in cache enrichment experiment. for zero - shot method, no shots are included in the prompt. the few - shot method uses exactly the same prompt as text 4. for oracle methods, we adopt the few - shot prompt but remove the kv - cache associated with the shots after the forward pass. the prompt for longbench evaluation strictly follows its official configuration, which varies across the different sub - datasets. 18 preprint version 19 preprint version a. 4 a dditional a nalysis a. 4. 1 e ffective r ank we list the definition of effective rank that was proposed by roy & vetterli ( 2007 ) here as a reference. for a matrix w that has size _ m × n _, the singular value decomposition of it can be expressed as _ w _ = _ u _ σ _ v _ and the singular values _ σ _ = ( _ σ _ 1 _, σ _ 2 _,..., σ _ _ min _ ( _ m, n _ ) ) _ [ t ] _ are the non - negative diagonal entries of the matrix σ. the singular value distribution is denote as : _ σ _ _ i _ _ p _ _ i _ = ( 6 ) _ ∥σ∥ _ 1 denote the shannon entropy as : _ h _ ( _ p _ 1 _, p _ 2 _,..., p _ _ min _ ( _ m, n _ ) ) = _ − _ the effective rank is define as : _ min _ ( _ m, n _ ) _ p _ _ i _ log _ p _ _ i _ ( 7 ) _ i _ = 1 _ erank _ ( _ w _ ) = _ e _ _ [ − ] _ [ ] _ i _ _ [ min ] _ = 1 [ ( ] _ [ m, n ] _ [ ) ] _ p _ _ i _ _ logp _ _ i _ ( 8 ) in figure 9, we present the effective rank of key and value caches across all the layers. the plot shows a continuous increase in the effective rank of value caches after applying c2c, especially in the shallow layers. key caches after applying c2c also have a comparable effective rank and increase at deep layers. 20 preprint version ( a ) effective rank of the key cache. ( b ) effective rank of the value cache. figure 9 : effective rank of key and value caches across layers for qwen3 - 4b ( sharer ) and qwen30. 6b ( receiver ). a. 4. 2 g ating b ehavior we analyze the behavior of the learnable gates by contrasting models trained on general - purpose versus task - specific data. this comparison reveals markedly different gating dynamics across the two regimes. * * general - purpose training * *. when c2c is trained on the openhermes - 2. 5 dataset, the learned key and value gates remain almost fully open. across the three model combinations reported in table 3, the average gate activation ratio exceeds 98. 21 %. despite this near - complete activation, we observe that in certain layers the dynamic weights are concentrated at very small values — for example, the average key weight in some layers falls below 0. 1. this suggests that under general - purpose training, c2c leverages the dynamic weighting mechanism to modulate how much information is incorporated from the sharer on a per - query basis, effectively treating dynamic weights as the primary control signal while leaving most gates open. * * task - specific training * *. in contrast, when c2c is trained on the mmlu auxiliary ~ ~ t ~ ~ rain split, the gates exhibit a much sparser activation pattern. across model combinations shown in table 6, the average gate activation ratio drops to 52. 67 %. for the layers where gates do open, however, the dynamic weights are substantially larger, with most layers exhibiting average weights above 0. 4. this indicates that under task - specific training, the gating mechanism selects a smaller subset of layers that are consistently useful, while the dynamic weights primarily regulate the contribution strength of these selected layers. overall, these findings highlight the adaptive interplay between gates and weights : general - purpose training favors broad gate activation with fine - grained modulation via weights, whereas task - specific training favors sparse gate activation with stronger reliance on the selected layers. a. 4. 3 o utlier cases in inference time * * llama3. 2 * *. we observe that the llama3. 2 model achieves significantly lower inference time compared to other baselines in table 3"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03215v1",
      "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language\n  Models",
      "authors": [
        "Tianyu Fu",
        "Zihan Min",
        "Hanling Zhang",
        "Jichao Yan",
        "Guohao Dai",
        "Wanli Ouyang",
        "Yu Wang"
      ],
      "summary": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.",
      "published": "2025-10-03T17:52:32Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03215v1"
    },
    "chunk_id": 21,
    "text": "on the mmlu auxiliary ~ ~ t ~ ~ rain split, the gates exhibit a much sparser activation pattern. across model combinations shown in table 6, the average gate activation ratio drops to 52. 67 %. for the layers where gates do open, however, the dynamic weights are substantially larger, with most layers exhibiting average weights above 0. 4. this indicates that under task - specific training, the gating mechanism selects a smaller subset of layers that are consistently useful, while the dynamic weights primarily regulate the contribution strength of these selected layers. overall, these findings highlight the adaptive interplay between gates and weights : general - purpose training favors broad gate activation with fine - grained modulation via weights, whereas task - specific training favors sparse gate activation with stronger reliance on the selected layers. a. 4. 3 o utlier cases in inference time * * llama3. 2 * *. we observe that the llama3. 2 model achieves significantly lower inference time compared to other baselines in table 3. this improvement can be attributed to two factors. first, the llama3. 2 model itself has faster inference speed due to its implementation. second, under the noncot evaluation prompts described in section a. 3. 6, the model tends to output only a single option letter ( e. g., “ a ” or “ b ” ), rather than a longer formatted string such as “ the correct answer is a. ” the shorter outputs further reduce the average decoding time, leading to the observed advantage. * * qwen2. 5 - math * *. in contrast, the qwen2. 5 - math model exhibits considerably longer inference time, as shown in table 6. the primary cause is its tendency to ignore the non - cot evaluation and t2t prompts described in section a. 3. 6, producing verbose, step - by - step solutions rather than concise answers. to accommodate these long outputs and avoid truncation, we set both the maximum response length and the maximum communication length to 1024 tokens during evaluation. under this configuration, the model decodes substantially more tokens on average, resulting in significantly longer inference time. 21 preprint version a. 4. 4 e xample m odel o utput in this physics problem, the sharer alone introduces proportional errors in its reasoning chain, while the receiver alone skips the reasoning step. thus, both models are given the wrong answer. t2t passes reasoning through text to point out the important knowledge - _ the force between two point _ _ charges is directly proportional to the product of their charges and inversely proportional to the _ _ square of the distance between them _ - but did not provide more understanding for it and how to use the information to solve the problem. therefore, though given an important hint, the model failed to give the correct answer. in contrast, c2c directly transfers the kv - cache, allowing the receiver to gain rich contextual understanding from the sharer and thus correctly answer the question. 22 preprint version 23"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 0,
    "text": "# # joint bidding on intraday and frequency containment reserve markets yiming zhang [ ∗ ] wolfgang ridinger [ † ] david wozabal [ ‡ ] october 6, 2025 * * abstract * * as renewable energy integration increases supply variability, battery energy storage systems ( bess ) present a viable solution for balancing supply and demand. this paper proposes a novel approach for optimizing battery bess participation in multiple electricity markets. we develop a joint bidding strategy that combines participation in the primary frequency reserve market with continuous trading in the intraday market, addressing a gap in the extant literature which typically considers these markets in isolation or simplifies the continuous nature of intraday trading. our ap proach utilizes a mixed integer linear programming implementation of the rolling intrinsic algorithm for intraday decisions and state of charge recovery, alongside a learned classifier strategy ( lcs ) that determines optimal capacity allocation between markets. a comprehensive out - of - sample backtest over more than one year of historical german market data validates our approach : the lcs in creases overall profits by over 4 % compared to the best - performing static strategy and by more than 3 % over a naive dynamic benchmark. crucially, our method closes the gap to a theoretical perfect foresight strategy to just 4 %, demonstrating the effectiveness of dynamic, learning - based allocation in a complex, multi - market environment. # # # * * 1 introduction * * the increasing share of variable renewable sources of electricity ( vres ), such as wind and solar energy, changes electricity systems around the world. as a consequence, unexpected and costly imbalances caused by the unpredictability of vres output may lead to grid instability and even blackouts. electricity storage can offer flexibility to help mitigate these problems and stabilize electricity systems, thereby generating welfare gains ( sioshansi, 2010 ). traditionally, electricity storage is a scarce resource and pumped - hydro storage facilities have been the primary form of large - scale electricity storage available. these systems offer immense energy capacity, but their deployment is limited by strict geographical requirements – namely, the need for significant elevation differences between two large reservoirs. consequently, the potential for expanding the capacity of pumped hydro storage is severely limited in most electricity systems, creating a pressing need for alternative flexibility solutions to accommodate the growing share of vres. ∗ the hong kong polytechnic university, hong kong ; this work was mainly carried out at the technical university of munich and entrix gmbh, munich, germany, ` yiming1. zhang @ connect. polyu. hk ` - entrix gmbh, munich, germany, ` wolfgang. ridinger @ entrixenergy. com ` - vrije universiteit amsterdam, amsterdam, netherlands, ` d. wozabal @ vu. nl ` 1 to fill this gap, a new portfolio of flexibility technologies is emerging, including battery energy storage systems ( bess ), green hydrogen for long - duration and seasonal energy storage, and demand response programs that provide flexibility by actively managing consumption patterns. among these technologies, bess stands out for their rapid response times and locational flexibility, making them particularly suitable for short - term energy arbitrage and ancillary services. their high power - to - capacity ratio makes them well - suited for grid stabilization services, where supply - demand imbalances must be corrected on a second - to - second basis, and for participation in short - term electricity markets. due to the dramatic and ongoing reduction in battery costs, bess are becoming an increasingly viable option for grid - level electricity storage. for instance, lithium - ion battery pack prices have seen a drop of more than 75 % in the past 10 years with prices decreasing from $ 463 / kwh in 2015 to $ 115 / kwh in 2024 ( bloombergnef, 2024 ). this downward trend is projected to continue, with costs expected to drop below $ 100 / kwh well before 2030 ( cole and karmakar, 2023 ). in this paper, we propose a joint model for the participation in the market for primary frequency reserve and the intraday market ( idm ), explicitly modeling orderbook - based continuous trading to max imize the potential to reoptimize positions multiple times. while a large number of literature addresses optimal bidding strategies for electricity storage, studies that jointly consider the intraday and frequency control markets remain rare. most existing approaches, such as ( de boeck et al., 2025 ; fleten and kristoffersen, 2008 ), focus exclusively on the day - ahead market. although some papers incorporate both the day - ahead and intraday markets, the intraday market is typically represented as a single rebalancing decision. this simplification allows the decision maker to adjust positions taken in the day - ahead market but overlooks the continuous nature of intraday trading and the resulting opportunities for multiple rebalancing actions. examples of such papers include ( faria and fleten, 2011 ; [UNK] et al., 2013 ; kongelf et al.,"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 1,
    "text": "model for the participation in the market for primary frequency reserve and the intraday market ( idm ), explicitly modeling orderbook - based continuous trading to max imize the potential to reoptimize positions multiple times. while a large number of literature addresses optimal bidding strategies for electricity storage, studies that jointly consider the intraday and frequency control markets remain rare. most existing approaches, such as ( de boeck et al., 2025 ; fleten and kristoffersen, 2008 ), focus exclusively on the day - ahead market. although some papers incorporate both the day - ahead and intraday markets, the intraday market is typically represented as a single rebalancing decision. this simplification allows the decision maker to adjust positions taken in the day - ahead market but overlooks the continuous nature of intraday trading and the resulting opportunities for multiple rebalancing actions. examples of such papers include ( faria and fleten, 2011 ; [UNK] et al., 2013 ; kongelf et al., 2019 ; [UNK] and wozabal, 2023 ). wozabal and rameseder ( 2020 ) consider the problem of coordinated bidding in sequential auctions for a renewable power producer without storage in the spanish intraday market. in recent years, the intraday market has attracted an increasing number of participants seeking to correct short - term deviations from planned generation and load schedules. various trading strategies in the idm were proposed. dynamic programming approaches that model the intraday bidding process are proposed in ( jiang and powell, 2015 ) and ( [UNK] et al., 2016 ), although neither accounts for intraday products with different times to maturity ; and while [UNK] et al. ( 2016 ) model the intraday market, they do not consider storage. bertrand and papavasiliou ( 2019a, b ) train a threshold policy for a storage unit on german limit order book data using reinforcement learning. the authors report significant gains for their trading strategy over a greedy strategy. boukas et al. ( 2021 ) deploy a markov decision process – based modeling framework with a distributed fitted q - iteration algorithm to optimize to decide when to employ the rolling intrinsic algorithm to trade on the intraday market. a limited amount of research literature has been devoted to the bidding strategy in the in reserve markets. a small body of work ( dimoulkas et al., 2016 ; kraft et al., 2020 ) has concentrated on the prediction of frequency containment reserve ( fcr ) prices. the former predicted the se2 price and volume in the nordic balancing market using a hidden markov model. the latter study employed a statistical model and neural networks in a rolling one - step framework to estimate the capacity - weighted average price. the authors of both papers did not propose a bidding strategy based on their forecasts. a bidding strategy for the nordic fcr is proposed in ( divshali and evens, 2020 ), where the trading problem is modeled as a non - linear constrained optimization problem, explicitly taking into account degradation, energy, and balancing costs. thien et al. ( 2017 ) investigates the profitability of different 2 strategies for the german fcr market and brivio et al. ( 2016 ) compares revenues on the italian primary reserve market with arbitrage strategies on the wholesale market. astero and evens ( 2020 ) ; ansari et al. ( 2015 ) ; sortomme and el - sharkawi ( 2012 ) consider using electric vehicle batteries in the fcr, while broneske and wozabal ( 2017 ) consider the same problem in the secondary reserve market. an important topic when participating in the primary reserve market is the issue of state - of - charge ( soc ) recovery after a frequency excursion event. in ( zhang et al., 2016 ), a theoretical stochastic dynamic programming framework was proposed to plan and control a bess that participates in frequency reserves. xu et al. ( 2014 ) propose a soc recovery by trading on the idm. an online control mechanism was proposed in ( divshali and evens, 2020 ). in the papers reviewed so far, either the balancing market or the idm are considered. the authors in ( biggins et al., 2022 ) propose a bidding strategy in the frequency reserves and day - ahead markets in great britain based on machine learning. their results show that the firm frequency response ( ffr ) is a stronger source of revenue than the day - ahead market for battery storage and highlight that the simulta neous performance in the ffr and the day - ahead market increases profits. using machine learning - based price prediction and uncertainty metrics, three bidding strategies are devised to trade in different fre quency reserves in ( kempitiya et al., 2020 ). although multiple power markets were considered in the aforementioned papers, they do not consider the idm in their strategies. in this paper, we propose the first approach that combines a realistic representation of a"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 2,
    "text": "the idm. an online control mechanism was proposed in ( divshali and evens, 2020 ). in the papers reviewed so far, either the balancing market or the idm are considered. the authors in ( biggins et al., 2022 ) propose a bidding strategy in the frequency reserves and day - ahead markets in great britain based on machine learning. their results show that the firm frequency response ( ffr ) is a stronger source of revenue than the day - ahead market for battery storage and highlight that the simulta neous performance in the ffr and the day - ahead market increases profits. using machine learning - based price prediction and uncertainty metrics, three bidding strategies are devised to trade in different fre quency reserves in ( kempitiya et al., 2020 ). although multiple power markets were considered in the aforementioned papers, they do not consider the idm in their strategies. in this paper, we propose the first approach that combines a realistic representation of a continuous intraday market with participation on a frequency control market. we use a version of the rolling intrinsic ( ri ) strategy to make trading decisions on the idm and recovery soc and machine learning classifier to decide how much capacity to commit to which market. the aim of the overall approach is to define an algorithm that can be used for high - frequency automatized decision - making. in particular, the main contributions of the paper are : 1. we propose a mixed - integer linear programming version of the intrinsic policy that can handle orderbook - based continuous trading. furthermore, we detail a rolling intrinsic algorithm that, given commitments on the primary reserve market, coordinates the repeated re - computation of the intrinsic strategy with the necessary soc recovery necessary for participation on the primary reserve market. 2. we devise a machine learning classifier that decides how much of the available battery capacity to commit on the reserve market. the decision is based on features that are available at the time of fcr bidding and the aim is to predict the times when the ri is more profitable than the fcr market and to optimally split the bess ’ capacity between the two markets. 3. we present a comprehensive and realistic out - of - sample study that benchmarks the proposed strat egy against a battery of alternatives using two years of real market data. using detailed historical data from these two markets, our results show that using our algorithm to combine fcr and idm trading returns up to 4 % more revenue than delivering fcr only and delivers 96 % more than trading in the continuous intraday market only. our algorithm clearly outperforms naive strategies and is only 4 % worse than a clairvoyant strategy that always chooses the right mix between the two markets. the rest of the paper is structured as follows : in section 2, we will discuss the idm and fcr markets with a focus on the european and, more specifically, the german situation. we outline market rules and describe interactions in the form of constraints that bids in one market imply for the other. section 3 3 start fcr closure day - ahead auction intraday auction / continuous figure 1 : order of events on any given trading day for epex day - ahead and intraday markets and the fcr auctions in germany. * * fcr * * * * intraday * * 2020 2021 2022 2023 2020 2021 2022 2023 * * traded quantity * * 573 562 555 570 77 85 92 120 * * bidding frequency * * daily, 4 - hour blocks continuous * * pricing mechanism * * uniform price auction order book based table 1 : daily volumes auctioned in the german fcr market ( in mw ) from bundesnetzagentur ( see ` [ https : / / data. bundesnetzagentur. de / ] ( https : / / data. bundesnetzagentur. de / ) ` ), combined epex intraday annual trading volumes ( in twh ) for the cwe region ( at, be, de / lu, fr, nl ) taken from the epex spot annual reports ( epex spot se, 2020 - 2023 ). describes our implementation of the ri method, as well as the classifier that decides between the two markets. section 4 is devoted to the results of our case study. we first give some insight into stylized facts related to strategies in order to motivate our choices for the out - of - sample study and then present a detailed comparison of our proposed strategy with a set of benchmarks for the years 2023 and 2024. section 5 concludes the paper. # # # * * 2 setting & markets * * in this section, we describe the relevant features of the fcr market and the idm. to fix ideas and since our numerical study in section 4 uses germany as an example, we focus on the german situation as a typical example of a european market design. in figure 1, we show the order and clearing times for the relevant"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 3,
    "text": "region ( at, be, de / lu, fr, nl ) taken from the epex spot annual reports ( epex spot se, 2020 - 2023 ). describes our implementation of the ri method, as well as the classifier that decides between the two markets. section 4 is devoted to the results of our case study. we first give some insight into stylized facts related to strategies in order to motivate our choices for the out - of - sample study and then present a detailed comparison of our proposed strategy with a set of benchmarks for the years 2023 and 2024. section 5 concludes the paper. # # # * * 2 setting & markets * * in this section, we describe the relevant features of the fcr market and the idm. to fix ideas and since our numerical study in section 4 uses germany as an example, we focus on the german situation as a typical example of a european market design. in figure 1, we show the order and clearing times for the relevant markets. on any given day, the fcr auctions close at 8 am. the idm market opens at 3 p. m. for the hourly products and at 4 p. m. for the quarter hourly products. hence, in our setting, we have to first decide about the bids on the fcr market before the trading on the idm starts. in the following, we give a detailed description of the relevant aspects for both markets. table 1 gives a first impression in terms of size, bidding frequency, and traded volumes. * * 2. 1 * * * * the market for frequency containment reserve * * maintaining a balance between electricity production and consumption is crucial for the stability of the power grid. in a situation where production and consumption do not exactly match, the grid frequency deviates from the nominal frequency, which could damage electronic devices, lead to a failure of components, and may result in selective power cuts or even system - wide blackouts. the fcr is 4 | col1 | col2 | col3 | col4 | col5 | col6 | col7 | col8 | col9 | col10 | col11 | col12 | | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | - - - | | | | ~ ~ p ( f ) ~ ~ | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | figure 2 : required activation of reserve power for a bid of _ p _ _ bid _ mw as a function of the frequency deviation ∆ _ f _. a service organized by the transmission system operators with the goal of recovering from frequency deviations and outages by stabilizing frequencies near the nominal value. the four german transmission system operators hold a joint procurement auction for fcr capacity each day at 8am for the following day. the day is split into six blocks of four consecutive hours, so - called efa ( _ electricity forward agreement _ ) blocks. there are six simultaneous uniform - price procurement auctions, one for each efa block of the following day, in which companies offer their capacity. the minimum bid size in the auction is 1 mw with increments of 1 mw ( figgener et al., 2022 ). divisible and indivisible bids are both allowed, and the maximum size of an indivisible bid is 25 mw. successful bidders for a specific efa block are required to instantaneously provide an amount of power proportional to the size of the accepted bid and the deviation of the grid frequency _ f _ from the nominal frequency _ f _ _ [ n ] _ ( 50 hz in germany ), defined as ∆ _ f _ : = _ f − _ _ f _ _ [ n ] _. more specifically, fcr market participants have the obligation to provide upward and downward regulations if the absolute deviation ∆ _ f _ of the grid frequency exceeds a deadband of 0. 01 hz : if ∆ _ f < _ 0 upward regulation is provided, that is, additional energy must be fed into the grid. in contrast, if ∆ _ f > _ 0, that is, the frequency exceeds the nominal frequency, the fcr providers are required to increase energy consumption. the activation _ p _ resulting from an accepted bid of _ p _ bid mw is defined as ( see"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 4,
    "text": "an indivisible bid is 25 mw. successful bidders for a specific efa block are required to instantaneously provide an amount of power proportional to the size of the accepted bid and the deviation of the grid frequency _ f _ from the nominal frequency _ f _ _ [ n ] _ ( 50 hz in germany ), defined as ∆ _ f _ : = _ f − _ _ f _ _ [ n ] _. more specifically, fcr market participants have the obligation to provide upward and downward regulations if the absolute deviation ∆ _ f _ of the grid frequency exceeds a deadband of 0. 01 hz : if ∆ _ f < _ 0 upward regulation is provided, that is, additional energy must be fed into the grid. in contrast, if ∆ _ f > _ 0, that is, the frequency exceeds the nominal frequency, the fcr providers are required to increase energy consumption. the activation _ p _ resulting from an accepted bid of _ p _ bid mw is defined as ( see figure 2 ), 0 _, _ if _ | _ ∆ _ f _ _ | ≤ _ 0. 01 hz _ p _ = ∆0 _. f _ 2 _ [ · ] [ p ] _ [ bid ] _ [, ] _ 0. 01 hz _ < | _ ∆ _ f _ _ | ≤ _ 0. 2 hz ( 1 ) _ | _ ∆∆ _ ff _ _ −− _ 00 _.. _ 22 _ | _ _ [ · ] [ p ] _ [ bid ] _ [, ] _ _ | _ ∆ _ f _ _ | > _ 0. 2 hz _, _ where a positive _ p _ implies that energy has to be absorbed from the grid while a negative sign indicates that additional energy has to be provided ( thien et al., 2017 ). firms must deliver at least 50 % of activation within 15 seconds after receiving the signal ∆ _ f _ and should be fully ramped up / down after 30 seconds. furthermore, firms have to guarantee an energy capacity large enough to cover the full activation _ p _ bid for at least 15 minutes per incident ( figgener et al., 2022 ). failure to offer the promised balancing service results in a penalty. if an imbalance persists for more than 30 seconds, the tso dispatches secondary reserves that relieve the providers of primary reserve. if there is still a positive _ | _ ∆ _ f _ _ | _ after 5 minutes, the manually controlled tertiary reserve and 5 possible redispatch mechanisms are used to return the system to equilibrium. in order to guarantee the 15 - minute criterion, the energy stored in the bess has to remain in the range of [ 0 _. _ 25 _ p _ bid _, _ _ e _ [ [UNK] ] _ − _ 0 _. _ 25 _ p _ bid ], where _ e _ [ [UNK] ] is the battery ’ s energy capacity. however, there may be more than one frequency excursion event in an efa block and participants are obliged to provide the service for all incidents. therefore, after each fcr activation, the providers must restore their soc to an acceptable range that allows them to service the next event. the above also implies an upper bound 0 _. _ 25 _ p _ bid _ ≤ _ 0 _. _ 5 _ e _ [ [UNK] ] for the bid power, which is, however, rarely of practical relevance since the power capacity ( in mw ) usually does not exceed the energy capacity ( in mwh ) for bess. clearly, at the time of bidding capacities for the fcr market, the direction and magnitude of _ p _ is uncertain. for storage, this has two implications : firstly, the operators have to ensure that the soc is in a range where it is guaranteed that they can honor their commitments made on the fcr. secondly, although cumulative activations are, in most periods, close to zero, it often happens that the soc at the end of a 4 - hour efa block significantly differs from the initial soc, i. e., that activations do not average out. this effect is further exacerbated by the fact that battery efficiency losses ( charging and discharging inefficiencies ) result in a net energy loss even if positive and negative fcr activations within an efa block cancel out on average. * * 2. 2 * * * * the intraday market * * the european intraday market framework is designed around the principle of market integration and convergence toward a single european electricity market. the european commission established a target model to integrate all intraday markets based on continuous trading through the commission regulation ( eu ) 2015 / 1222 establishing guidelines on _ capacity allocation and congestion management _. this integration is facilitated by the cross - border intraday ( xbid ) platform, which operates with a shared order book that enables market participants to trade electricity continuously across european borders, provided that sufficient cross - border transmission capacity is available. the aim of this _"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 5,
    "text": "of a 4 - hour efa block significantly differs from the initial soc, i. e., that activations do not average out. this effect is further exacerbated by the fact that battery efficiency losses ( charging and discharging inefficiencies ) result in a net energy loss even if positive and negative fcr activations within an efa block cancel out on average. * * 2. 2 * * * * the intraday market * * the european intraday market framework is designed around the principle of market integration and convergence toward a single european electricity market. the european commission established a target model to integrate all intraday markets based on continuous trading through the commission regulation ( eu ) 2015 / 1222 establishing guidelines on _ capacity allocation and congestion management _. this integration is facilitated by the cross - border intraday ( xbid ) platform, which operates with a shared order book that enables market participants to trade electricity continuously across european borders, provided that sufficient cross - border transmission capacity is available. the aim of this _ single _ _ intraday coupling _ is to create a single eu cross - zonal intraday electricity market where buyers and sellers can work together across europe to trade electricity continuously on the day the energy is needed ( european commission, 2015 ). it serves as a complementary market to the day - ahead market and is used to continuously buy or sell electricity to manage short - term deviations from sudden changes in energy supply and demand. the intraday market in germany is mainly organized by the european power exchange ( epex ), the largest intraday power exchange in europe. in recent years, the intraday market has been growing steadily, as can be seen from the traded volumes in table 1. the market is organized as an order book based continuous trading market that features hourly, half - hourly, quarter - hourly, and block products. currently, market participants in germany can trade until 5 minutes before physical delivery in their control areas and until up to 30 minutes before delivery in a combined national market ( kuppelwieser and wozabal, 2023 ). each buy and sell order on the intraday market for a given product contains basic information about quantity, limit price, and validity time. a _ market order _ is cleared immediately against the best available order in the limit order book ( lob ), while a limit order is only executed with matching orders on the other side of the market up to a certain price ( the limit ). if this is not possible, the order is kept in the lob until its _ end validity date _ to be cleared with future orders. if the quantities of two matched orders do not agree, the order with the higher order quantity is only partially cleared and remains in the order 6 _ t _ = 2 _ t _ = 1 _ t _ = 2 _ t _ = 1 _ t _ = 2 figure 3 : illustration of the limit order book clearing mechanism. source ( graf et al., 2024 ). book with the remaining quantity. the minimum bid volume is 0 _. _ 1 mw, and the price per mwh ranges from _ − _ 9999 to 9999 euros. market participants can add the usual order qualifiers such as _ immediate - or - cancel _ ( ioc ) or _ fill - or - _ _ kill _ ( fok ). additionally, _ iceberg _ orders are allowed for which only a fraction of the order quantity is visible to other market participants. as soon as the visible quantity is cleared, the next part of the order is automatically placed in the limit order book. the basic mechanism of continuous trading is illustrated in figure 3 by a concrete example ( taken from graf et al., 2024 ) : in the left panel, the state of the order book at _ t _ = 1 is displayed with the orders sorted according to their limit price and organized into a _ bid stack _ and _ ask stack _. the state of the lob changes with the placement of a new order, with the modification of an order, and at the end validity - time of an active order. the limit price of the order with the lowest sell price is called _ best - ask _, while the order with the highest buy price defines the _ best - bid _, and the difference between the two prices is the _ bid - ask - spread _. in the right panel, the clearing of a new hypothetical buy order is illustrated : a new buy order with a price of 50e is added to the book at _ t _ = 2 and is then cleared against the cheapest possible offers until either the whole order is fulfilled ( as is the case in the figure ) or there are no offers with lower prices left. in this example, 22 mw out of 29 mw are cleared against the sell order with price 37e and the remaining 29 mw _ − _ 22 mw = 7 mw are cleared against the sell order with price 45e. the remaining quantity of 12 mw _ − _ 7 mw = 5 mw of the"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 6,
    "text": "an order, and at the end validity - time of an active order. the limit price of the order with the lowest sell price is called _ best - ask _, while the order with the highest buy price defines the _ best - bid _, and the difference between the two prices is the _ bid - ask - spread _. in the right panel, the clearing of a new hypothetical buy order is illustrated : a new buy order with a price of 50e is added to the book at _ t _ = 2 and is then cleared against the cheapest possible offers until either the whole order is fulfilled ( as is the case in the figure ) or there are no offers with lower prices left. in this example, 22 mw out of 29 mw are cleared against the sell order with price 37e and the remaining 29 mw _ − _ 22 mw = 7 mw are cleared against the sell order with price 45e. the remaining quantity of 12 mw _ − _ 7 mw = 5 mw of the latter order stays in the order book. note that the clearing is instantaneous, i. e., columns 2 and 3 in the right panel are purely illustrative and do not correspond to market states that can be observed by traders. # # # * * 3 a joint optimization method for intraday fcr trading * * participating in both the fcr and the idm involves ( i ) bidding in the fcr auction one day ahead of delivery and ( ii ) trading in the idm while honoring the battery ’ s fcr commitments. finding an optimal combined bidding strategy for the fcr and the idm thus involves solving a fairly complicated stochastic optimization with a large number of intraday trading stages that model the possibility of frequent rebalancing. solving this problem exactly is computationally intractable. we therefore propose a heuristic policy that selects one of finitely many fcr bidding strategies and 7 then uses the ri policy to solve the intraday bidding problem. to that end, we frame the problem of selecting an optimal fcr strategy as a classification problem that picks the strategy with the highest overall expected profits. we discuss the strategy space for the fcr market in section 3. 1, a version of the rolling intrinsic policy adapted to continuous trading in section 3. 2, and finally the classification problem for the different strategies in section 3. 3. * * 3. 1 * * * * overview of joint bidding model * * for each efa block _ i _, suppliers can bid the price ( eur / mw ) as the requested compensation for the service. in this paper, we assume that the bidding strategy only includes the quantity and that the bidding price is zero. due to the pay - as - cleared mechanism, even with the bidding price being zero, providers still get the uniform market clearing price as their final remuneration. more specifically, we use a vector _ x _ = ( _ x _ 1 _, x _ 2 _, x _ 3 _, x _ 4 _, x _ 5 _, x _ 6 ) with six components to represent a bid strategy in the six fcr markets, where _ x _ _ i _ denotes the capacity ( in mw ) that is committed to the market _ i _. for a battery with capacity _ x _ [ [UNK] ], this implies that in principle ( _ x _ [ [UNK] ] _ − _ _ x _ _ i _ ) mw are available for trading on the intraday market in the time period covered the efa block _ i _. hence, the fcr strategy determines the feasible bids on the intraday market. the regulation of the fcr market in germany stipulates that a storage can provide the maximum up - regulation or down - regulation of the full reserve bid _ x _ _ i _ for at least 15 minutes without interruptions ( see section 2 ). therefore, the storage level must be in [ _ [ x ] _ _ [ i ] _ _ / _ 4 _, _ _ e _ [ [UNK] ] _ − _ _ [ x ] _ _ [ i ] _ _ / _ 4 ] at any time during the period covered by the market _ i _. furthermore, we limit the maximum fcr bid to 80 % of the asset ’ s power capacity. note that this restriction is not required by market rules but is based on backtesting evidence, which shows that larger bids often caused soc management issues. this assumption is reasonable for bess with a power - to - energy ratio, as considered in this study ( approximately 1 ). as described in section 2. 1, admissible bids are in whole mw with a minimum bid size of 1 mw. hence, for a storage with capacity _ x _, there are _ [UNK] _ 0 _. _ 8 _ · x _ + 1 _ [UNK] _ [ 6 ] different admissible bidding strategies for the fcr markets of a single day in our setting. if _ x _ _ i _ = 0, the lower limit on stored energy in the"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 7,
    "text": "[UNK] ] _ − _ _ [ x ] _ _ [ i ] _ _ / _ 4 ] at any time during the period covered by the market _ i _. furthermore, we limit the maximum fcr bid to 80 % of the asset ’ s power capacity. note that this restriction is not required by market rules but is based on backtesting evidence, which shows that larger bids often caused soc management issues. this assumption is reasonable for bess with a power - to - energy ratio, as considered in this study ( approximately 1 ). as described in section 2. 1, admissible bids are in whole mw with a minimum bid size of 1 mw. hence, for a storage with capacity _ x _, there are _ [UNK] _ 0 _. _ 8 _ · x _ + 1 _ [UNK] _ [ 6 ] different admissible bidding strategies for the fcr markets of a single day in our setting. if _ x _ _ i _ = 0, the lower limit on stored energy in the corresponding time periods _ t _ covered by market _ i _ equals _ α _ _ × _ _ e _ [ [UNK] ] while the upper limit is ~ ~ _ α _ ~ ~ _ × _ _ e _ [ [UNK] ]. these limits are in place to preserve battery health and to avoid complete discharge as well as overcharging. in case that _ x _ _ i _ _ > _ 0 these bounds tighten according to the rules outlined above. hence, for any time _ t _ in the time span covered by market _ i _, we get that the state of charge _ c _ _ t _ has to be in the interval [ _ c _ _ t _ _, _ ~ ~ _ c _ ~ ~ _ t _ ] : = max ( _ α _ _ × _ _ e, _ [ [UNK] ] _ [ x ] _ _ [ i ] _ _ / _ 4 ) _, _ min ~ ~ ( ~ ~ ~ ~ _ α _ ~ ~ _ × _ _ e, _ [ [UNK] ] _ x _ [ [UNK] ] _ − _ _ [ x ] _ _ [ i ] _ _ / _ 4 ) _. _ ( 2 ) this limitation is incorporated into the ri as a constraint as described in the next section. if the fcr activation causes the battery charge to exceed the boundary, the constraint requires the ri to immediately restore the soc to acceptable limits by corresponding idm trades. although positive and negative deviations from activations on the fcr market tend to cancel out, participation in the market can produce a slight drift in the state of charge of a storage. this is acerbated by the efficiency losses of storage. the energy drift in the time interval [ _ t, t _ + ∆ _ t _ ] is dependent on fluctuations of the national grid frequency and can be expressed as _ kt _ [ ) ] _ [ η ] _ [ ( ] _ [ p ] _ [ ( ∆ ] _ [ f ] _ _ [ t ] _ [ + ] _ [ k ] _ [ ∆ ] _ k _ _ [ t ] _ _ t _ + ∆ _ t _ _ d _ _ t, t _ + ∆ _ t _ = _ t _ _ p _ ( ∆ _ f _ _ s _ ) _ η _ ( _ p _ ( ∆ _ f _ _ s _ ) ) _ ds ≈ _ [ ∆ ] _ [ t ] _ _ t _ _ k _ _ k _ _ [ t ] _ [ ) ) ] _ [, ] _ ( 3 ) _ k _ _ k _ _ p _ ( ∆ _ f _ _ t _ + _ k _ ∆ _ kt _ _ k _ = 1 8 where _ p _ is defined in ( 1 ) and ∆ _ f _ _ s _ is the deviation of the national frequency at time _ s _. furthermore, _ η _ maps the positive and negative deviations to the charging and discharging efficiency, respectively, and _ k _ is a positive integer defining the discretization grid in the approximation of the integral by a riemann sum. when making a bidding decision on the fcr market, the bess trades off revenues for every efa block with the revenues that can be potentially earned on the intraday market. the total daily profits _ π _ are the sum of the profits _ π _ _ f cr _ from bidding on the fcr market and the profits _ π _ _ idm _ from trading on the intraday market. _ π _ ( _ x _ ) = 6 _ p _ _ f cr _ _ [ k ] _ _ [ x ] _ _ [ k ] _ _ k _ = 1 ~ ~ ~ ~ ~ ~ ~ ~ _ π _ _ f cr _ ( _ x _ ) + _ π _ _ idm _ ( _ x _ ) _, _ ( 4 ) where _ p _ _ f cr _ _ [ k ] _ [ is the clearing price of the fcr"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 8,
    "text": "_ is a positive integer defining the discretization grid in the approximation of the integral by a riemann sum. when making a bidding decision on the fcr market, the bess trades off revenues for every efa block with the revenues that can be potentially earned on the intraday market. the total daily profits _ π _ are the sum of the profits _ π _ _ f cr _ from bidding on the fcr market and the profits _ π _ _ idm _ from trading on the intraday market. _ π _ ( _ x _ ) = 6 _ p _ _ f cr _ _ [ k ] _ _ [ x ] _ _ [ k ] _ _ k _ = 1 ~ ~ ~ ~ ~ ~ ~ ~ _ π _ _ f cr _ ( _ x _ ) + _ π _ _ idm _ ( _ x _ ) _, _ ( 4 ) where _ p _ _ f cr _ _ [ k ] _ [ is the clearing price of the fcr for the efa block ] _ [ k ] _ [ and the profits profits on the idm are ] a function of _ x _ as will be discussed in the next section. since neither _ p _ _ f cr _ _ [ k ] _ [ nor ] _ [ π ] _ _ [ idm ] _ [ ( ] _ [ x ] _ [ ) is known at ] the time of bidding on the fcr market, _ π _ ( _ x _ ) is a random quantity. therefore, in order to select an fcr strategy for the six markets of one day, we aim to solve the multi - stage stochastic optimization problem max ( 5 ) _ x∈x _ [ e ] [ [ ] _ [ π ] _ [ ( ] _ [ x ] _ [ ) ] ] _ [, ] _ where bids _ x _ are the first - stage decisions, _ x _ is the feasible set, and the bids on the idm represent the recourse decisions. since the intraday market is continuous, the problem has an excessive amount of stages and therefore solving ( 5 ) exactly is computationally intractable. * * 3. 2 * * * * the continuous rolling intrinsic strategy for intraday trading * * the intrinsic value of a storage asset is the profit that can be realized by exploiting the currently observable price spreads in the market. a static intrinsic strategy therefore determines an optimal set of buy and sell positions based on the forward curve at a single point in time. this strategy focuses on locking in guaranteed profits without speculating on future price movements. the ri policy, originally introduced in ( gray and khandelwal, 2004 ) for the evaluation of gas storage, is a dynamic extension of the intrinsic value. starting from an initial soc and a portfolio of forward positions acquired in previous periods on the intraday market, the ri repeatedly checks for chances of profitable rebalancing by re - solving the intrinsic problem. although the resulting decisions are still myopic, since the policy at no point trades on anticipated future price changes, the ri clearly represents an improvement over the static intrinsic that does not adapt positions at all. furthermore, the myopic nature of decisions has the advantage that the ri only enters immediately profitable positions and therefore does not run the risk of accumulating losses based on wrong assumptions about the future. for these reasons and because of its conceptual simplicity and low computational cost, the ri has attained widespread industry adoption. the classic version of the ri is based on a price taking intrinsic strategy. to be able to employ the algorithm to the continuous intraday market, we adapt the intrinsic algorithm to explicitly take into account the lob and corrections based on energy drift from fcr market activations when trading. in particular, for every rebalancing decision, the algorithm receives a snapshot of the current state of the order book and subsequently checks whether the positions of forward contracts built up in previous steps can be profitably updated. 9 in order to discuss the ri, we first formally define the intrinsic problem for continuous intraday markets, which is solved repeatedly in the process. to that end, we define the set of tradeable contracts _ t _ at the time the intrinsic policy is executed, as well as the order book information _ o _ = [ ] _ t∈t _ _ [ o ] _ _ [ t ] _ [, which ] contains order numbers of all bids and asks currently in the orderbook _ o _ _ t _ for contract _ t _. in addition, we define the set of contracts that go into delivery on the current day as _ t _ 0. for an order _ i ∈o _, we denote by _ p _ _ i _ its limit price ( in eur / mwh ), by _ σ _ _ i _ its direction ( _ − _ 1 for bid and 1 for ask ), and finally by _ q _ _ i _ the quantity. in order to capture the history of trading decisions, we denote by _ c _ 0 and _"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 9,
    "text": "for continuous intraday markets, which is solved repeatedly in the process. to that end, we define the set of tradeable contracts _ t _ at the time the intrinsic policy is executed, as well as the order book information _ o _ = [ ] _ t∈t _ _ [ o ] _ _ [ t ] _ [, which ] contains order numbers of all bids and asks currently in the orderbook _ o _ _ t _ for contract _ t _. in addition, we define the set of contracts that go into delivery on the current day as _ t _ 0. for an order _ i ∈o _, we denote by _ p _ _ i _ its limit price ( in eur / mwh ), by _ σ _ _ i _ its direction ( _ − _ 1 for bid and 1 for ask ), and finally by _ q _ _ i _ the quantity. in order to capture the history of trading decisions, we denote by _ c _ 0 and _ b _ [ 0 ] _ t _ [ the energy and ] power commitments resulting from previous trades where _ c _ 0 is adjusted for the energy drift that results from call offs on the fcr market and by products that go into delivery ( see below ). to model the cost of battery degradation, we use a simple linear approximation by multiplying the absolute magnitude of planned charging / discharding by the degradation cost _ κ > _ 0 ( in eur / mwh ). note that the last tradeable contract _ t _ is always the last period traded in a day. we fix a terminal storage level _ c _ _ t _ at the end of a trading day, i. e., at time _ t _ = max _ t _. with these preparations in place, we can formulate the intrinsic problem, which decides for every order _ i ∈o _ about the quantity _ q _ _ i _ ( in mw ) that is matched by the intrinsic policy as follows. max ∆ _ q _ _ i _ _, c _ _ t _ _, b _ _ t _ _, b _ _ [ ± ] _ _ t _ _ t∈t _ _ p _ _ i _ _ σ _ _ i _ _ q _ _ i _ _ − _ _ κ _ ∆ _ i∈o _ _ t _ _ t∈t _ ( _ b _ [ + ] _ t _ [ + ] _ [ b ] _ _ [ − ] _ _ t _ [ ) ] ( 6a ) _ t∈t _ s. t. 0 _ ≤ _ _ q _ _ i _ _ ≤ _ _ q _ _ i _ _, _ _ ∀i ∈o, _ ( 6b ) _ b _ _ t _ = _ b _ [ 0 ] _ t _ _ [ − ] _ _ σ _ _ i _ _ q _ _ i _ _, _ _ ∀t ∈t, _ ( 6c ) _ i∈o _ _ t _ _ b _ _ t _ = _ b _ [ + ] _ t _ _ [ − ] _ _ [ b ] _ _ [ − ] _ _ t _ _ [, ] _ _ ∀t ∈t, _ ( 6d ) _ b _ [ + ] _ t _ _ [ ≤ ] _ _ [ δ ] _ _ [ t ] _ _ [ b ] _ _ [ t ] _ _ [, ] _ _ ∀t ∈t, _ ( 6e ) _ b _ _ [ − ] _ _ t _ _ [ ≤ ] _ [ ( 1 ] _ [ − ] _ _ [ δ ] _ _ [ t ] _ [ ) ( ] _ [ − ] [ b ] _ ~ ~ _ t _ ~ ~ [ ) ] _ [, ] _ _ ∀t ∈t, _ ( 6f ) _ η _ _ ch _ _ b _ [ + ] _ a _ _ [ − ] _ [ ∆ ] _ a≤t _ _ a≤t _ _ c _ _ t _ = _ c _ 0 + ∆ _ a≤t _ 1 _ b _ _ [ − ] _ _ a _ _ [, ] _ _ ∀t ∈t, _ ( 6g ) _ η _ _ dis _ _ b _ ~ ~ _ t _ ~ ~ _ ≤ _ _ b _ _ t _ _ ≤ _ _ b _ _ t _ _, _ _ ∀t ∈t, _ ( 6h ) _ c _ ~ ~ _ t _ ~ ~ _ ≤ _ _ c _ _ t _ _ ≤ _ ~ ~ _ c _ ~ ~ _ t _ _ ∀t ∈t, _ ( 6i ) _ b _ [ + ] _ t _ _ [, b ] _ _ [ − ] _ _ t _ _ [ ≥ ] _ [ 0 ] _ [, ] _ _ ∀t ∈t _ ( 6j ) _ δ _ _"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 10,
    "text": "[ ∆ ] _ a≤t _ _ a≤t _ _ c _ _ t _ = _ c _ 0 + ∆ _ a≤t _ 1 _ b _ _ [ − ] _ _ a _ _ [, ] _ _ ∀t ∈t, _ ( 6g ) _ η _ _ dis _ _ b _ ~ ~ _ t _ ~ ~ _ ≤ _ _ b _ _ t _ _ ≤ _ _ b _ _ t _ _, _ _ ∀t ∈t, _ ( 6h ) _ c _ ~ ~ _ t _ ~ ~ _ ≤ _ _ c _ _ t _ _ ≤ _ ~ ~ _ c _ ~ ~ _ t _ _ ∀t ∈t, _ ( 6i ) _ b _ [ + ] _ t _ _ [, b ] _ _ [ − ] _ _ t _ _ [ ≥ ] _ [ 0 ] _ [, ] _ _ ∀t ∈t _ ( 6j ) _ δ _ _ t _ _ ∈ { _ 0 _, _ 1 _ }, _ _ ∀t ∈t _ ( 6k ) _ c _ _ t _ = _ c _ _ t _ _, _ ( 6l ) ∆ [ ] _ t∈t _ [ ( ] _ [ b ] _ _ t _ [ + ] [ + ] _ [ b ] _ _ [ − ] _ _ t _ [ ) ] _ ≤ _ _ c _ [ [UNK] ] [ 0 ] _, _ ( 6m ) 2 _ e _ ~ ~ [ [UNK] ] ~ ~ where ∆is the duration of the delivery period of the traded contracts ( e. g., one hour or 15 minutes ), _ b _ _ t _, ~ ~ _ c _ ~ ~ _ t _ _ ∈ _ r [ + ], _ b _ ~ ~ _ t _ ~ ~ _ ∈ _ r _ [ − ] _, _ c _ ~ ~ _ t _ ~ ~ _ ∈ _ r [ + ] are upper and lower bounds on stored energy and charged discharged power in period _ t ∈t _ ( see discussion above ), respectively and _ η _ _ ch _ _, η _ _ dis _ _ < _ 1 is the charging / discharging efficiency factor ( depending on the direction of the trade ). note that the bounds on power and energy depend on the commitments on the fcr market for the corresponding efa block ( see last section ). the variables _ b _ _ t _ defined in ( 6c ) model the accumulated power ( in mw ) of all orders with the delivery period _ t _ and depend on the corresponding values from previous trades _ b _ [ 0 ] _ t _ [ and the decisions in the current ] problem, where _ b _ [ + ] _ t _ _ [, b ] _ _ [ − ] _ _ t _ are the positive and negative parts of _ b _ _ t _, respectively, as modeled by ( 6d ) to ( 6f ), where the constraints make sure that for every product energy is either bought or sold, which is important for contracts with negative prices where simultaneous charging and discharging is potentially 10 profitable, depending on efficiencies and the observed bid / ask spread. similarly, the variables _ c _ _ t _ in ( 6g ) define the total energy stored in the storage until the end of period _ t _. note that the factor ∆translates power ( in mw ) into energy ( in mwh ). the constraints ( 6h ) and ( 6i ) represent the limits for power and energy imposed by the physical limitations of the storage as well as commitments on the fcr market. the last constraint ( 6l ) requires that the storage level is equal to _ c _ _ t _ at the end of the planning horizon. the constraint ( 6m ) enforces a daily cycling limit, where _ c _ [ [UNK] ] [ 0 ] is the number of permissible cycles left on the current day, which is updated in the ri algorithm 1. finally, the first term of the objective function ( 6a ) models the profits from trading, while the second term yields the planned losses from battery degradation. note that while on the intraday market different types of contracts are traded ( hourly, half - hourly, quarter - hourly ), we only consider one type in the above formulation. clearly, at the expense of a more involved notation, the problem could easily be extended to cover different types of contracts. however, for the sake of simplicity and because we only use one type of contract in our numerical study, we refrain from this complication. the intrinsic problem ( 6 ) is the main building block of the rolling intrinsic policy, which is detailed in algorithm 1. the ri reoptimizes a given position either periodically or every time there is a change in the lob. the policy is myopic in the sense that trades are only executed if the"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 11,
    "text": "of permissible cycles left on the current day, which is updated in the ri algorithm 1. finally, the first term of the objective function ( 6a ) models the profits from trading, while the second term yields the planned losses from battery degradation. note that while on the intraday market different types of contracts are traded ( hourly, half - hourly, quarter - hourly ), we only consider one type in the above formulation. clearly, at the expense of a more involved notation, the problem could easily be extended to cover different types of contracts. however, for the sake of simplicity and because we only use one type of contract in our numerical study, we refrain from this complication. the intrinsic problem ( 6 ) is the main building block of the rolling intrinsic policy, which is detailed in algorithm 1. the ri reoptimizes a given position either periodically or every time there is a change in the lob. the policy is myopic in the sense that trades are only executed if the resulting immediate profit is positive. this leads to profits that are guaranteed to be non - negative and a strategy that is not able to anticipate future prices foregoing potential profits of more speculative strategies but also eliminating any downside risks. note that the ri profits are not taken from the objective of the problem ( 6 ), but calculated outside of the optimization problem in algorithm 1. the reasons for this are twofold : firstly, to not count battery degradation costs for the same periods multiple times, the degradation cost is accounted for in lines 6 and 20 for the periods that are no longer traded and go into physical delivery. secondly, some of the trades found by the linear program ( 6 ) may not be feasible, since they are not forced to be multiples of the minimum bid size _ δ _. note that this happens only for the most expensive accepted ask and the cheapest accepted bid per period. we correct for these inaccuracies in line 14. on a related note, we remark that the initial schedule ( _ c _ [ 0 ] _ t _ [ ) ] _ [ t ] [ ∈t ] _ [ for any of the intrinsic solves need not ] be physically feasible due to the rounding after the solution of the last problem, as well as due to the energy drift that occurs between two consecutive runs of the intrinsic policy. everytime ( 6 ) is solved, these violations are corrected. if there are not enough orders in the lob for correction, the problem ( 6 ) is potentially infeasible. hence, the if - statement in line 13. if such as situation persists over a longer period of time, we theoretically could end up with a physically infeasible schedule that has to be corrected on the balancing market. however, in section 4, we demonstrate that this case does not occur in practice for sufficiently conservative limits to storage operation. * * 3. 3 * * * * strategy selection as a classification task * * in this section, we describe how we approximate ( 5 ). the main idea is to simplify the problem by first deciding among the finitely many feasible _ x ∈x _ and then relegating the recourse decisions to the rolling intrinsic alogrithm. to be able to choose among the strategies in _ x _, we fit a classification model with the objective of picking the strategy _ x ∈x _ that, paired with the ri trading strategy in the idm, produces the highest average profits. we base the predictor on a supervised learning method that uses a set of features and 11 * * data : * * storage level _ c _ 0, planned final storage level _ c _ _ t _, _ t _, minimal bid size _ δ _ * * 1 * * _ ∀t ∈t _ : _ b _ [ 0 ] _ t _ _ [ ← ] _ [ 0, ] _ [ c ] _ 0 _ [ ← ] _ _ [ c ] _ 0 [ ; ] * * 2 * * _ π ← _ 0, _ t _ _ [ − ] _ _ ←t _ ; * * 3 * * * * while * * _ t _ = _ ∅ _ * * do * * ` ` ` / * correct for drift and calculate realized battery degradation cost * / ` ` ` * * 4 * * set ∆ _ t ←t _ _ [ − ] _ _ \\ t _, fetch order books _ o _ _ t _ and fcr soc drift _ d _ since last optimization ; _ t∈ _ ∆ _ t _ _ [ η ] _ _ [ ch ] _ _ [ b ] _ _ t _ [ + ] _ [ − ] _ [ ∆ ] [ ] * * 5 * * _ c _ 0 _ ← _ _ c _ 0 – _ d _ + ∆ [ ] 1 _ t∈ _ ∆ _ t _ _ η _ _ dis _ _ [ b ] _ _ t _ _ [ − ] _ [ ; ] * * 6 * * _ π ← _ _ π"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 12,
    "text": "_ [ − ] _ _ ←t _ ; * * 3 * * * * while * * _ t _ = _ ∅ _ * * do * * ` ` ` / * correct for drift and calculate realized battery degradation cost * / ` ` ` * * 4 * * set ∆ _ t ←t _ _ [ − ] _ _ \\ t _, fetch order books _ o _ _ t _ and fcr soc drift _ d _ since last optimization ; _ t∈ _ ∆ _ t _ _ [ η ] _ _ [ ch ] _ _ [ b ] _ _ t _ [ + ] _ [ − ] _ [ ∆ ] [ ] * * 5 * * _ c _ 0 _ ← _ _ c _ 0 – _ d _ + ∆ [ ] 1 _ t∈ _ ∆ _ t _ _ η _ _ dis _ _ [ b ] _ _ t _ _ [ − ] _ [ ; ] * * 6 * * _ π ← _ _ π − _ ∆ _ κ _ [ ] _ t∈ _ ∆ _ t _ _ [ | ] [ b ] _ _ t _ [ 0 ] _ [ | ] _ [ ; ] ` ` ` / * update cycling limit * / ` ` ` * * 7 * * * * if * * _ a new day has started since the last solve _ * * then * * * * 8 * * _ c _ [UNK] [ 0 ] _ ← _ _ n _ _ [ cycles ] _ ; * * 9 * * * * else * * * * 10 * * _ c _ [UNK] [ 0 ] _ ← _ _ c _ [UNK] [ 0 ] _ − _ ∆ [ ] _ t∈ _ 2 _ e _ ∆ ~ ~ [ [UNK] ] ~ ~ _ t _ _ [ | ] [ b ] _ _ [ t ] _ _ [ | ] _ ; * * 11 * * * * end * * ` ` ` / * initialize new contracts * / ` ` ` * * 12 * * _ b _ [ 0 ] _ t _ _ [ ← ] _ [ 0 for all ] _ [ t \\ t ] _ _ [ − ] _ [ ; ] ` ` ` / * solve the intrinsic and round results to implementable trades * / ` ` ` * * 13 * * solve the intrinsic problem resulting in optimal ( _ b _ _ t _ ) _ t∈t _, ( _ c _ _ t _ ) _ t∈t _ and ( _ q _ _ i _ ) _ i∈o _ ; * * 14 * * * * if * * _ intrinsic is feasible _ * * then * * * * 15 * * _ q _ _ i _ _ ← _ round ( _ q _ _ i _ _ / δ _ ) _ × δ, _ _ ∀i ∈o _ ; * * 16 * * _ π ← _ _ π _ + ∆ [ ] _ i∈o _ _ [ p ] _ _ [ i ] _ _ [ σ ] _ _ [ i ] _ _ [ q ] _ _ [ i ] _ [ ; ] * * 17 * * _ b _ [ 0 ] _ t _ _ [ ← ] _ _ [ b ] _ [ 0 ] _ t _ _ [ − ] _ [ ] _ i∈o _ _ t _ _ [ σ ] _ _ [ i ] _ _ [ q ] _ _ [ i ] _ _ [, ] _ _ ∀t ∈t _ ; * * 18 * * * * end * * ` ` ` / * prepare next iteration * / ` ` ` * * 19 * * _ t _ _ [ − ] _ _ ←t _, wait for next trading time, and update _ t _ ; * * 20 * * * * end * * * * 21 * * _ π ← _ _ π − _ ∆ _ κ _ [ ] _ t∈t _ _ [ | ] [ b ] _ _ [ t ] _ _ [ | ] _ [ ; ] * * algorithm 1 : * * rolling - intrinsic algorithm for one day of trading on the intraday market. is calibrated using historical data. more specifically, for every day _ d ∈d _ in our training data, we have a feature vector _ f _ _ d _ and profits _ π _ _ d _ ( _ x _ ) as calculated in ( 4 ) dependent on the fcr strategy and on idm trading by the ri. thus, we frame the optimal strategy selection for the fcr market as a classification task where the features _ f _ _ d _ are used to forecast the labels _ x _ _ d _ _ [ ∗ ] _ [ with ] _ [ x ] _ _ d _ _ [ ∗ ] _ [ the strategy ] _ [ x ] _ [ that maximizes trading profits on ] day _ d _, i. e., _ x _ _ d _ _ [ ∗ ] _ [ = arg"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 13,
    "text": "[ t ] _ _ [ | ] _ [ ; ] * * algorithm 1 : * * rolling - intrinsic algorithm for one day of trading on the intraday market. is calibrated using historical data. more specifically, for every day _ d ∈d _ in our training data, we have a feature vector _ f _ _ d _ and profits _ π _ _ d _ ( _ x _ ) as calculated in ( 4 ) dependent on the fcr strategy and on idm trading by the ri. thus, we frame the optimal strategy selection for the fcr market as a classification task where the features _ f _ _ d _ are used to forecast the labels _ x _ _ d _ _ [ ∗ ] _ [ with ] _ [ x ] _ _ d _ _ [ ∗ ] _ [ the strategy ] _ [ x ] _ [ that maximizes trading profits on ] day _ d _, i. e., _ x _ _ d _ _ [ ∗ ] _ [ = arg max ] _ [ { ] _ [ e ] [ [ ] _ [ π ] _ _ [ d ] _ [ ( ] _ [ x ] _ [ ) ] : ] _ [ x ] [ ∈x } ] [. ] _ to do so, we fix a hypothesis class _ h _ such that _ h _ : _ f →x _ for every _ h ∈h _, where _ f _ is the feature space and solve _ l _ ( _ x _ _ d _ _ [ ∗ ] _ _ [, h ] _ [ ( ] _ [ f ] _ _ [ d ] _ [ ) ) ] _ [, ] _ ( 7 ) _ d∈d _ _ h _ _ [ ∗ ] _ = arg max _ h∈h _ 1 _ | d | _ with _ l _ the cross entropy loss. note that in order to calculate the labels of the above problem, we have to evaluate the profits _ π _ _ d _ ( _ x _ ) for every strategy _ x ∈x _ for all days _ d ∈d _ in the training data. however, evaluating idm trading with order book data for every of the _ [UNK] _ 0 _. _ 8 _ · x _ + 1 _ [UNK] _ [ 6 ] candidate fcr strategies is computationally expensive. for this reason and in order to limit the potential class imbalance in ( 7 ), we restrict the set _ x _ of possible 12 strategies. in order to do this, we proceed in two steps. in a first step, we limit the set _ x _ to a reduced set of strategies _ m ⊆x _ based on our analysis of the interaction between the revenues that can be generated in the two markets in section 4. we evaluate profits for all days _ d _ and all strategies _ x ∈m _. to further reduce class imbalance, we reduce the strategy space to _ s ⊆m _ base strategies. an approach to do this would be to simply select a fixed set of strategies from _ m _ that yield the highest average profits. however, this does not necessarily yield an optimal subset of strategies, since rather similar strategies might be chosen instead of designing _ s _ to consist of complementary strategies. [ 1 ] in order to find a well performing yet small strategy pool set of size _ s < | m | _, we pick a subset _ s ⊆m _ producing the highest overall profit on the training data under the hypothesis of perfect classification, i. e., under the assumption that for every day the best strategy _ x ∈s _ is chosen by the classifier. we do this by solving the following mixed integer linear program _ w _ _ xd _ _ π _ _ d _ ( _ x _ ) ( 8a ) _ d∈d _ max _ z _ _ x _ _, w _ _ xd _ _ x∈m _ s. t. _ z _ _ x _ _ ∈ { _ 0 _, _ 1 _ }, _ _ x ∈m _ ( 8b ) _ w _ _ xd _ _ ∈ _ [ 0 _, _ 1 ] _, _ _ ∀x ∈m, ∀d ∈d _ ( 8c ) _ w _ _ xd _ _ ≤ _ _ z _ _ x _ _, _ _ ∀x ∈m, ∀d ∈d _ ( 8d ) _ w _ _ xd _ = 1 _, _ _ ∀d ∈d _ ( 8e ) _ x∈m _ _ z _ _ x _ = _ s. _ ( 8f ) _ x∈m _ in the above problem, the variables _ z _ _ x _ determine whether a strategy is in _ s _ and constraint ( 8f ) enforces that only _ s _ strategies can be chosen. the variables _ w _ _ xd _ model whether a strategy _ x _ is chosen for day _ d _. note that since the objective is linear in _ w _ _ xd"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 14,
    "text": ", _ _ x ∈m _ ( 8b ) _ w _ _ xd _ _ ∈ _ [ 0 _, _ 1 ] _, _ _ ∀x ∈m, ∀d ∈d _ ( 8c ) _ w _ _ xd _ _ ≤ _ _ z _ _ x _ _, _ _ ∀x ∈m, ∀d ∈d _ ( 8d ) _ w _ _ xd _ = 1 _, _ _ ∀d ∈d _ ( 8e ) _ x∈m _ _ z _ _ x _ = _ s. _ ( 8f ) _ x∈m _ in the above problem, the variables _ z _ _ x _ determine whether a strategy is in _ s _ and constraint ( 8f ) enforces that only _ s _ strategies can be chosen. the variables _ w _ _ xd _ model whether a strategy _ x _ is chosen for day _ d _. note that since the objective is linear in _ w _ _ xd _ the optimal values of _ w _ _ xd _ will be in _ { _ 0 _, _ 1 _ } _ and the sum in ( 8e ) ensures that only one strategy is chosen per day. clearly, if _ z _ _ x _ = 0, _ w _ _ xd _ = 0 for any day _ d _ due to ( 8d ). given the optimal solution of the above problem, we define _ s _ = _ { x ∈m _ : _ z _ _ x _ = 1 _ } _ and define our labels as _ x _ _ d _ _ ∈ _ arg max _ { π _ _ d _ ( _ x _ ) : _ x ∈s } _. in order to solve the ensuing classification problem based on the data ( _ x _ _ d _ _, f _ _ d _ ) _ d∈d _ as our training set, we use _ xgboost _ ( chen and guestrin, 2016 ), a gradient boosting method based on decision trees. ensemble methods such as gradient boosting are the current state of the art for tabular data and often outperform other methods ( e. g. shwartz - ziv and armon, 2022 ; grinsztajn et al., 2022 ) and specifically xgboost has shown remarkable performance in machine learning competitions since its inception and offers high computational efficiency, the ability to manage class imbalance, and has powerful feature selection capabilities. 1 to see this consider the case where _ | m | _ = 3 and _ | s | _ = 2 and where there are two strategies _ x _ 1 and _ x _ 2 that perform best on average but are rather similar as well as a third strategy _ x _ [ 3 ] which yields good results on those days where _ x _ [ 1 ] and _ x _ [ 2 ] have poor performance. in this case, it is clearly advantageous to choose _ s _ = _ { x _ [ 1 ] _, x _ [ 3 ] _ } _ as a set of complementary strategies which contains a good strategy for every day rather than simply choosing the best two strategies. 13 # # # * * 4 a numerical case study * * this section discusses a numerical out - of - sample study that puts the method developed in the previous sections to the test. throughout we assume a 10mw / 10mwh battery, i. e., a battery with a power capacity of 10mw and an energy capacity of 10mwh and use _ α _ = 0 _. _ 01 and ~ ~ _ α _ ~ ~ = 0 _. _ 985 to define soc limits. we use historical limit order books from the german continuous intraday market from epex spot and historical fcr clearing prices from regelleistung. net from 01 / 01 / 2023 until 30 / 09 / 2024 for our study. we begin by investigating some static fcr strategies _ x _, which means a constant allocation of battery power to the fcr and idm markets for every day of the observation period. we show that, contrary to intuition, revenue per market does not change linearly with the allocated battery power. we also explain what drives the observed relationship. having built some intuition around the optimal allocation of battery power between fcr and idm, we then move to the results of the dynamic fcr strategy as a classification problem. * * 4. 1 * * * * decreasing intraday returns * * we start by discussing the fact that per mw revenues in the idm are a decreasing function of the amount of battery capacity left for intraday trading. there are essentially two reasons for this : firstly, limited liquidity of the idm favors strategies with less capacity, since these do not experience a large price response when trading ( kuppelwieser and wozabal, 2021 ). secondly, the less capacity is committed on the fcr market the higher the duration of the remaining"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 15,
    "text": "which means a constant allocation of battery power to the fcr and idm markets for every day of the observation period. we show that, contrary to intuition, revenue per market does not change linearly with the allocated battery power. we also explain what drives the observed relationship. having built some intuition around the optimal allocation of battery power between fcr and idm, we then move to the results of the dynamic fcr strategy as a classification problem. * * 4. 1 * * * * decreasing intraday returns * * we start by discussing the fact that per mw revenues in the idm are a decreasing function of the amount of battery capacity left for intraday trading. there are essentially two reasons for this : firstly, limited liquidity of the idm favors strategies with less capacity, since these do not experience a large price response when trading ( kuppelwieser and wozabal, 2021 ). secondly, the less capacity is committed on the fcr market the higher the duration of the remaining storage that can be traded on the intraday market, which tends to decrease profits per unit of capacity. we will discuss this less obvious aspect below. the battery power allocated to the fcr market determines not only the battery power left on for idm trading, but also the energy capacity of the battery still available for use on the idm market. in particular, the fcr regulation states that the battery must at all times be able to delivery the committed power for at least 15 minutes in both directions ( see discussion in sections 2 and 3 ). in our case this means that with a commitment of 8 mw in the fcr market the 10mw / 10mwh battery has to maintain a charge level between 2mwh and 8mwh. this leaves 2mw and 6mwh of flexibility on the idm market, increasing the energy to power ratio from 1 ( of the original 10mw / 10mwh battery ) to 3 on the idm market. the increase in total profits from intraday trading when duration changes depends on the price patterns. the two most extreme cases are depicted in figure 4 : the left panel shows a situation where the prices in the first 12 hours of the day are low, enabling the storage to continuously charge in that time and sell back the energy in the second half of the day for high prices. in this case, a perfectly efficient battery with a duration of 12 hours is optimal. contrast this with the situation in the right panel, where prices alternate between high and low prices every hour and the storage would only charge for 1 hour before discharging again and therefore durations above 1 do not yield additional profits. in reality, price patterns fall between the two extremes depicted in figure 4, showing a more nuanced effect of duration on profits. we explore this relationship in figure 5 by computing the profits of a 10mw storage with varying energy capacity resulting in different storage duration. the experiment is carried out with price data from january 2023. in the experiment, the energy capacity varies from 10 mwh, that is, a duration of 1, to 60 mwh, i. e., a duration of 6. the left panel of figure 5 shows how the duration of the storage on the idm increases with the size 14 figure 4 : two extreme price patterns for one day. figure 5 : the left panel shows the relationship between the bid size in the fcr and the duration ratio, while the right panel depicts the how the capacity to power ratio affects the profits in the idm. of the fcr bid and the right panel shows the connection between duration and overall average profits for one day of trading with the rolling intrinsic. this analysis reveals that there is a concave and increasing relationship between duration and per - mw revenue on the idm. overall, this demonstrates that due to the way power and capacity are regulated in the fcr market, revenues in the idm market fall more slowly than may naively be expected when increasing the battery power committed in the fcr market. since fcr revenues per mw are constant in the fcr bid size, it also shows that strategies with a higher power committed to fcr tend to be more attractive for the 10mw / 10mwh battery under consideration. * * 4. 2 * * * * pre - selection of fcr strategies * * in our case, there are in total 9 [ 6 ] different possible fcr bids, making it impractical to backtest all of them. the findings in the last section and initial experiments show that allocation of a large proportion of the bess ’ capacity to the fcr market is preferable. however, the afternoon and evening efa blocks four, five, and six can on some days exhibit substantial volatility with big price spikes in the intraday market. in these instances having more power capacity to trade in the idm market to benefit fully from these spikes may outweigh the lost revenue in the fcr market. based on these findings, we choose the 28 strategies listed"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 16,
    "text": "fcr market. since fcr revenues per mw are constant in the fcr bid size, it also shows that strategies with a higher power committed to fcr tend to be more attractive for the 10mw / 10mwh battery under consideration. * * 4. 2 * * * * pre - selection of fcr strategies * * in our case, there are in total 9 [ 6 ] different possible fcr bids, making it impractical to backtest all of them. the findings in the last section and initial experiments show that allocation of a large proportion of the bess ’ capacity to the fcr market is preferable. however, the afternoon and evening efa blocks four, five, and six can on some days exhibit substantial volatility with big price spikes in the intraday market. in these instances having more power capacity to trade in the idm market to benefit fully from these spikes may outweigh the lost revenue in the fcr market. based on these findings, we choose the 28 strategies listed in table 2 as the set _ m _ for backtesting. all strategies are computed by reoptimizing once every minute in the rolling intrinsic strategy with a 15 * * 2023 * * * * 2024 * * * * strategy * * * * overall * * * * idm * * * * fcr * * * * best * * * * overall * * * * idm * * * * fcr * * * * best * * ( 5, 5, 5, 8, 8, 8 ) 2815 827 1988 14 3559 750 2809 * * 19 * * ( 8, 8, 8, 5, 5, 5 ) 3079 1077 2003 3 3535 919 2616 0 ( 8, 8, 8, 0, 0, 0 ) 2992 1744 1247 23 2945 1533 1412 3 ( 8, 8, 8, 0, 0, 5 ) 3033 1601 1432 20 3057 1399 1658 4 ( 8, 8, 8, 0, 0, 8 ) 2985 1442 1543 6 3061 1256 1805 2 ( 8, 8, 8, 0, 5, 0 ) 2928 1436 1492 0 3029 1253 1777 0 ( 8, 8, 8, 0, 5, 5 ) 2969 1292 1677 1 3124 1102 2022 1 ( 8, 8, 8, 0, 5, 8 ) 2899 1111 1788 3 3128 959 2169 1 ( 8, 8, 8, 0, 8, 0 ) 2863 1224 1639 3 3046 1051 1995 1 ( 8, 8, 8, 0, 8, 5 ) 2874 1051 1824 2 3136 896 2241 0 ( 8, 8, 8, 0, 8, 8 ) 2799 865 1935 2 3143 755 2388 0 ( 8, 8, 8, 5, 0, 0 ) * * 3174 * * 1601 1573 * * 26 * * 3388 1381 2007 2 ( 8, 8, 8, 5, 0, 5 ) * * 3185 * * 1427 1758 17 3478 1226 2252 1 ( 8, 8, 8, 5, 0, 8 ) 3110 1241 1869 3 3476 1077 2399 3 ( 8, 8, 8, 5, 5, 0 ) 3090 1273 1818 4 3451 1080 2371 1 ( 8, 8, 8, 5, 5, 8 ) 2998 885 2114 0 3540 777 2763 2 ( 8, 8, 8, 5, 8, 0 ) 2989 1024 1965 1 3460 871 2589 1 ( 8, 8, 8, 5, 8, 5 ) 2973 823 2149 4 3549 714 2835 1 ( 8, 8, 8, 5, 8, 8 ) 2894 634 2260 3 3554 572 2982 1 ( 8, 8, 8, 8, 0, 0 ) * * 3242 * * 1473 1769 * * 77 * * 3604 1241 2363 * * 29 * * ( 8, 8, 8, 8, 0, 5 ) * * 3221 * * 1267 1953 * * 27 * * * * 3683 * * 1075 2608 11 ( 8, 8, 8, 8, 0, 8 ) * * 3141 * * 1076 2064 20 3682 927 2756 * * 17 * * ( 8, 8, 8, 8, 5, 0 ) 3127 1114 2013 10 3663 936 2727 8 ( 8, 8, 8, 8, 5, 5 ) 3106 908 2198 11 * * 3745 * * 773 2973 7 ( 8, 8, 8, 8, 5, 8 ) 30"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 17,
    "text": "8 ) 2894 634 2260 3 3554 572 2982 1 ( 8, 8, 8, 8, 0, 0 ) * * 3242 * * 1473 1769 * * 77 * * 3604 1241 2363 * * 29 * * ( 8, 8, 8, 8, 0, 5 ) * * 3221 * * 1267 1953 * * 27 * * * * 3683 * * 1075 2608 11 ( 8, 8, 8, 8, 0, 8 ) * * 3141 * * 1076 2064 20 3682 927 2756 * * 17 * * ( 8, 8, 8, 8, 5, 0 ) 3127 1114 2013 10 3663 936 2727 8 ( 8, 8, 8, 8, 5, 5 ) 3106 908 2198 11 * * 3745 * * 773 2973 7 ( 8, 8, 8, 8, 5, 8 ) 3025 716 2309 2 * * 3750 * * 630 3120 11 ( 8, 8, 8, 8, 8, 0 ) 3014 854 2160 9 3664 718 2946 12 ( 8, 8, 8, 8, 8, 5 ) 2999 654 2345 * * 28 * * * * 3751 * * 560 3191 * * 20 * * ( 8, 8, 8, 8, 8, 8 ) 2925 469 2456 * * 46 * * * * 3761 * * 422 3338 * * 116 * * table 2 : results of static strategies for 2023 and the first three quarters of 2024. the reported profits are in eur per day and the results of the column best indicate on how many days a strategy is the best strategy. boldface in the columns _ overall _ and _ best _ indicate the best five strategies in the respective year with regard to profits and number of times a strategy is the best strategy. snapshot of the order book that contains the best four orders in either direction. in order to separate days and get revenues per day of trading, we start trading at 7 p. m. of the previous day for every trading day and assume an initial storage level of 2 mwh, which proved to be a good choice in our tests. table 2 reveals that the best strategy in the year 2023 was ( 8, 8, 8, 8, 0, 0 ), reducing the allocation of power to fcr in the late afternoon and evening blocks to take advantage of price spikes in the idm in the corresponding hours. generally, strategies that sell less power in the fcr market in these blocks perform best in 2023. interestingly in 2024 the situation changes and the strategy ( 8, 8, 8, 8, 8 ) that commits the maximum capacity on the fcr market comes out on top with respect to average daily profits and the number of days the strategy dominates all the other strategies. 16 figure 6 : number of strategies _ s _ versus profit percentages loss relative to cv - 28. the results comes from 01 / 01 / 2023 to 30 / 09 / 2024 looking at the idm and fcr profits, we find average values of eur 1111 and eur 1905 in 2023 and eur 959 and eur 2468 in 2024. this implies that while the idm market appears to have become less profitable for storage in 2024 the opposite appears to have happened to the fcr prices, which explains the change in the type of optimal strategies between years. overall, the average profit is higher in 2024. we furthermore observe that there are strategies that are not particularly good on average but are the best strategy on a significant amount of days. examples include strategies ( 8, 8, 8, 8, 8 ) and ( 8, 8, 8, 8, 5 ) in 2023. this supports our approach of selecting _ s ⊆m _ strategies that complement each other in an optimal way, rather than simply choosing the strategies that perform best on average. although we limit the set _ m _ to a reduced strategy pool with only 28 strategies, picking up the optimal strategy for any given day from the such pool, equivalent to a classification problem of 28 classes, which is made difficult by the inherent class imbalance in the data. to this end, we propose to select a subset _ s ⊆m _ to reduce the size of the strategy pool while staying close to the revenue potential of the entire set _ m _. figure 6 shows the loss with optimal strategy selection relative to the clairvoyant strategy that always chooses the best strategy from _ m _ under the assumption that the best among the _ s _ chosen strategies is used on every day. it can be clearly seen that for a small number of strategies _ s _ the loss reduces rapidly but starts to level off around _ s _ = 4. this presents valuable insights in choosing the"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 18,
    "text": "strategies that complement each other in an optimal way, rather than simply choosing the strategies that perform best on average. although we limit the set _ m _ to a reduced strategy pool with only 28 strategies, picking up the optimal strategy for any given day from the such pool, equivalent to a classification problem of 28 classes, which is made difficult by the inherent class imbalance in the data. to this end, we propose to select a subset _ s ⊆m _ to reduce the size of the strategy pool while staying close to the revenue potential of the entire set _ m _. figure 6 shows the loss with optimal strategy selection relative to the clairvoyant strategy that always chooses the best strategy from _ m _ under the assumption that the best among the _ s _ chosen strategies is used on every day. it can be clearly seen that for a small number of strategies _ s _ the loss reduces rapidly but starts to level off around _ s _ = 4. this presents valuable insights in choosing the optimal number of strategies : too many classes not only increase the difficulty of the task, but also offer only marginally increased profits. * * 4. 3 * * * * features * * to select the most profitable fcr bidding strategy for a given day, we train our classification model on a set of features designed to capture the prevailing and expected market conditions. this feature set comprises primary predictors derived from market data and forecasts, as well as carefully selected interaction terms to model non - linear relationships between market drivers. our model is built upon a foundation of four groups of base features : 1. price of the day - ahead auction ( daa ) : naturally, the day - ahead market prices are good predictors 17 of continuous intraday prices ( uniejewski et al., 2019 ; marcjasz et al., 2020 ; narajewski and ziel, 2020 ). we incorporate day - ahead auction prices as input features, focusing on four selected regions — ‘ de - lu ’, ‘ it - north ’, ‘ no2 ’, and ‘ se4 ’ — due to their relatively low price correlations, which introduces greater regional diversity into the model. to better capture temporal market dynamics, we compute the average day - ahead prices within each efa block. in addition, we calculate the standard deviation for each efa block to reflect price volatility, which can be informative to capture risk and uncertainty in market behavior. in all this yields 4 _ × _ 6 _ × _ 2 = 48 features for our model. 2. vres producers typically sell their products on the dam on the basis of production forecasts. larger forecast res production therefore also yields to potentially larger absolute forecast errors, prompting more significant rebalancing on the intraday market. hence, renewable generation forecasts are a major driver of intraday prices and, in particular, intraday price variance. this in turn influences the profitability of trading with the storage on the intraday market and is therefore a good feature in our strategy selection. see also ( karanfil and li, 2017 ; goodarzi et al., 2019 ; kulakov and ziel, 2019 ; kuppelwieser and wozabal, 2023 ) for a discussion on the impact of renewable generation forecasts on intraday prices. therefore, we also utilize public power forecasting ( ppf ) data, which includes forecasts for solar generation, onshore wind, offshore wind, and electricity load in germany. to align with the temporal structure of our model, we calculate the average values of these forecasts within each efa block, as well as the standard deviation of hourly values within each block, which yields an additional 6 _ × _ 2 _ × _ 4 = 48 features. 3. historical fcr clearing prices serve as strong indicators of the potential profitability of the fcr market for the next day. to take advantage of this information, we include the fcr clearing price of the previous day for each of the 6 efa blocks as features in our model. this helps capture recent market conditions and short - term trends relevant to price formation. 4. we add eight dummy features to capture temporal patterns. these include the _ weekday _, ranging from 0 ( sunday ) to 6 ( saturday ) ; a _ weekend indicator _, equal to 1 for saturday and sunday and 0 otherwise. furthermore, we include the _ day of year _, denoting the _ i _ - th calendar day ( 1 – 365 ) ; and a _ trend variable _, representing the _ i _ - th day in the backtesting period ( 0 – 636 ). to account for seasonality, we further include both _ annual seasonality _ terms [ 2 ] as well as _ weekly seasonality _ terms [ 3 ]. while the base features are informative, the optimal strategy often depends on the complex interplay between different market drivers ( e. g., the impact of a high wind forecast may be different"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 19,
    "text": "##a blocks as features in our model. this helps capture recent market conditions and short - term trends relevant to price formation. 4. we add eight dummy features to capture temporal patterns. these include the _ weekday _, ranging from 0 ( sunday ) to 6 ( saturday ) ; a _ weekend indicator _, equal to 1 for saturday and sunday and 0 otherwise. furthermore, we include the _ day of year _, denoting the _ i _ - th calendar day ( 1 – 365 ) ; and a _ trend variable _, representing the _ i _ - th day in the backtesting period ( 0 – 636 ). to account for seasonality, we further include both _ annual seasonality _ terms [ 2 ] as well as _ weekly seasonality _ terms [ 3 ]. while the base features are informative, the optimal strategy often depends on the complex interplay between different market drivers ( e. g., the impact of a high wind forecast may be different on a day with high prior fcr prices versus low ones ). to model these relationships, we introduce quadratic interaction terms. however, creating all possible pairwise interactions from the base features would result in an unmanageably large feature set ( roughly 10000 interactions ), increasing the risk of overfitting and making the backtesting process computationally prohibitive. we therefore adopt a multi - step heuristic approach to construct a concise yet powerful set of interaction features : 1. focus on primary drivers : we generate interactions using only the average values of daa prices and ppf forecasts for each efa block, excluding the standard deviations to reduce the initial scope. 2 sin 2 _ π · _ day of year ~ ~ ~ ~ 365 365y of year ~ ~ ~ ~, cos ~ ~ ~ ~ 2 _ π · _ da365y of year y of year 365 ~ ~ ~ ~ 3 sin 2 _ π · _ weekday 7 7 y, cos 2 _ π · _ weekda7 y y 7 18 | 1 | train set < br > validation set | train set < br > validation set | | - - - | - - - | - - - | | | | | | 3 < br > 4 < br > | 3 < br > 4 < br > | 3 < br > 4 < br > | figure 7 : anchored walk - forward validation. 2. prioritize cross - group interactions : we hypothesize that the most significant effects arise from the interplay between different feature groups. we therefore limit the interactions to two specific types : _ day - ahead price averages × historical fcr prices _ as well as _ renewable forecast averages _ _ × historical fcr prices _ 3. remove redundancy via correlation filtering : this process results in an intermediate feature set of approximately 400 base and interaction terms. to mitigate multicollinearity and further reduce dimensionality, we perform a final filtering step. we compute the pearson correlation matrix for this expanded set of features and iteratively remove one feature from any pair with a correlation coefficient exceeding a threshold of 0. 94. this structured approach yields a final, manageable set of under 300 features that captures key linear and non - linear market dynamics. * * 4. 4 * * * * rolling horizon evaluation * * in our out - of - sample model evaluation, we mimic how the model would be used in trading practice on a day - to - day basis. for any given day in the out - of - sample window, we estimate an optimal policy to bid on the fcr market for one day with a model trained with data from the last _ n _ days. then we implement the policy and record its profits. subsequently, we refit the model for the next trading day updating the training data with the last day. we generate out - of - sample profits by rolling through our entire data in this fashion. more specifically, we evaluate the out - of - sample performance of the model in the rolling horizon fashion described above using data from january 1, 2023, to september 30, 2024. each day, a training window of _ n _ = 240 days is used. in this way, we generate a set of 396 out - of - sample daily profits covering the period from august 30, 2023, to september 30, 2024. [ 4 ] evaluating performance on this large and diverse set of days helps ensure that the results are not unduly influenced by any specific time frame or by particular patterns or anomalies that might appear in a smaller subset of the data. every time we retrain the model for a day of trading, we first solve equation ( 8 ) to select a subset of size _ s _ = 3 from _ m _ that achieves the highest average profits on the training sample, and then train an xgboost classifier to further identify the optimal strategy from this subset. the size of _ s _ = 3 strikes a 4 note that since we use lagged prices, we actually need 241 days insample data to generate"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 20,
    "text": "2023, to september 30, 2024. each day, a training window of _ n _ = 240 days is used. in this way, we generate a set of 396 out - of - sample daily profits covering the period from august 30, 2023, to september 30, 2024. [ 4 ] evaluating performance on this large and diverse set of days helps ensure that the results are not unduly influenced by any specific time frame or by particular patterns or anomalies that might appear in a smaller subset of the data. every time we retrain the model for a day of trading, we first solve equation ( 8 ) to select a subset of size _ s _ = 3 from _ m _ that achieves the highest average profits on the training sample, and then train an xgboost classifier to further identify the optimal strategy from this subset. the size of _ s _ = 3 strikes a 4 note that since we use lagged prices, we actually need 241 days insample data to generate data for 240 training days. 19 strategy fcr idm overall % of cv - 28 equals cv - 3 equals cv - 28 beats lcs cv - 28 1113 407 1520 0. 0 46. 4 100. 0 59. 3 cv - 3 1127 370 1497 - 1. 5 100. 0 46. 4 27. 8 lcs 1146 313 1459 - 4. 0 72. 2 38. 9 0. 0 db 1063 349 1412 - 7. 1 36. 9 20. 1 16. 4 sb 969 433 1402 - 7. 8 4. 3 0. 3 30. 3 only fcr 1238 170 1408 - 7. 4 57. 1 37. 1 14. 14 only idm 0 774 774 - 49. 1 0. 0 0. 0 17. 7 table 3 : overall out - of - sample profits ( thousand euro ) of all strategies split into fcr and idm profits. the last four columns give the shortfall from cv - 28 ( in % of profit ), the fraction of days ( % ) where policies take the same bidding decisions as cv - 3 and cv - 28, as well as the fraction of days where policies outperform the lcs strategies, respectively. good balance between the profit of the combined strategies and the difficulty of the ensuing classification problem ( see section 3. 1 ). when using xgboost, we optimize the hyperparameters of the method. specifically, we optimize the parameters _ eta _ ( 0 _. _ 01, 0 _. _ 05, 0 _. _ 1 ), _ gamma _ ( 0, 0 _. _ 5, 1, 2 ), _ subsample _ ( 0 _. _ 8, 1 ), _ colsample _ ~ ~ _ b _ ~ ~ _ ytree _ ( 0 _. _ 8, 1 ), _ max _ ~ ~ _ d _ ~ ~ _ epth _ ( 3, 4, 5 ), _ n _ _ estimators _ ( 200, 400 ) using cross validation. we use random grid search to find the best combination of hyperparameters selecting from the values in brackets. in particular, we randomly chose 20 possible combinations of hyperparameters without replacement and test their performance in the validation sets and additionally include the best parameter combination found for the last day in the sample. due to the periodicity and autocorrelation inherent in sequential data, traditional cross - validation may disrupt temporal dependencies, resulting in a significant discrepancy between the validation and test sets. we use anchored walk - forward validation, which preserves the sequential order by always validating on future data, to find the best set of hyperparameters, see figure 7. specifically, we employ five folds, with the last 15 days in each fold reserved for validation. note that by anchoring, the training data grows in later folds. instead of using accuracy or f - score as the criterion for hyperparameter tuning, we adopt use the negative trading profit in the validation sets as loss function for hyperparameter tuning. this is because accuracy and f - score may overlook misclassifications that have a significant negative impact on profitability, whereas a profit - based score penalizes such errors more appropriately. when generating and evaluating the generated policy for every day, we add up fcr and intraday revenues, the latter of which is the result of executing the ri on the order book data for that specific day. the total profits are calculated by subtracting the battery degradation cost as described in section 2 from these revenues. as for the training data, in order to run the rolling intrinsic, we use snapshots of the lob consisting of the top four prices for each traded product and rerun the intrinsic every minute. for every day, we start trading at 7 p. m. on the previous day and assume a starting storage level of 20 % ( 2mwh ). furthermore, we use the historical market clearing price of the fcr market to calculate the fcr revenues"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 21,
    "text": "in the validation sets as loss function for hyperparameter tuning. this is because accuracy and f - score may overlook misclassifications that have a significant negative impact on profitability, whereas a profit - based score penalizes such errors more appropriately. when generating and evaluating the generated policy for every day, we add up fcr and intraday revenues, the latter of which is the result of executing the ri on the order book data for that specific day. the total profits are calculated by subtracting the battery degradation cost as described in section 2 from these revenues. as for the training data, in order to run the rolling intrinsic, we use snapshots of the lob consisting of the top four prices for each traded product and rerun the intrinsic every minute. for every day, we start trading at 7 p. m. on the previous day and assume a starting storage level of 20 % ( 2mwh ). furthermore, we use the historical market clearing price of the fcr market to calculate the fcr revenues of the different strategies. 20 * * 4. 5 * * * * results & discussion * * in this section, we compare the results of the trained classifier strategy ( lcs ) described in the previous sections with some benchmark strategies. the first benchmark is the 8 - 8 - 8 - 8 - 0 - 5 strategy, also referred to as the static baseline ( sb ), which is the most profitable single strategy in _ m _ calculated for the whole data. in addition, we compare our policy with the strategy that selects the strategy that was most profitable for the training data associated to a specific day. we refer to this as the dynamic baseline ( db ). the perfect dynamic strategy denoted by cv - 3 denotes an ideal policy that always selects the best performing strategy from the optimal group _ s _ on any given day. finally, as another theoretical upper bound, we include the cv - 28 that always chooses the best strategy from _ m _ for every out - of - sample day. furthermore, we also evaluate the strategies to bid only on the idm and to bid the maximum amount allowed on the fcr market, that is, the strategies ( 8, 8, 8, 8, 8 ) and ( 0, 0, 0, 0, 0, 0 ). the results of this analysis are summarized in table 3, which allows for the following conclusions : first, our proposed lcs performs exceptionally well, achieving an overall profit that is only 4 _. _ 0 % lower than the theoretical maximum achievable with perfect foresight ( cv - 28 ). this gap represents the com bined loss from two distinct steps : the initial selection of the top - three strategy pool in ( 8 ) and the subsequent classification error. critically, the gap shrinks to a mere 1 _. _ 5 % when compared to cv - 3, the clairvoyant strategy restricted to the same three strategies. this demonstrates the high accuracy of the xgboost classifier in selecting the best option from the available pool on any given day. in stark contrast, the naive dynamic ( db ) and static ( sb ) benchmarks fall short of the theoretical maximum by 7 _. _ 1 % and 7 _. _ 8 %, respectively, highlighting the significant value added by the learning - based approach. furthermore, strategies focusing exclusively on a single market are clearly suboptimal ; the ’ only fcr ’ strategy underperforms the cv - 28 benchmark by 7 _. _ 4 %, while the ’ only idm ’ strategy lags by a sub stantial 49 _. _ 1 %. the later results also shows that the fcr market is more profitable than the idm in the observation period. second, a breakdown of the revenue sources reveals that the performance difference between the top strategies is primarily driven by profits from the intraday market. both cv - 28 and cv - 3 achieve higher idm revenues than our lcs. this indicates that the main challenge, and the primary source of the remaining performance gap, lies in perfectly identifying the specific days where the intraday market offers exceptionally high profit opportunities. third, the effectiveness of the classifier is further confirmed by analyzing the daily decision alignment shown in table 3. lcs selects the same strategy as cv - 3 for an impressive 72. 2 % of the days, a high hit rate that directly corresponds to its strong profit performance. the alignment with the best overall strategy ( cv - 28 ) is naturally lower at 38 _. _ 9 %, as the lcs is limited to strategies from _ s _. the fact that the cv - 3 strategy itself only matches the cv - 28 decision on 46 _. _ 4 % of days underscores the importance of the initial strategy pool selection and explains why a gap between our lcs and the theoretical maximum remains. finally, the daily decision metrics in table 3 provide further insight into the performance of the model. the cv - 3 strategy, which has perfect foresight over the same pool of three strategies available"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 22,
    "text": ", lies in perfectly identifying the specific days where the intraday market offers exceptionally high profit opportunities. third, the effectiveness of the classifier is further confirmed by analyzing the daily decision alignment shown in table 3. lcs selects the same strategy as cv - 3 for an impressive 72. 2 % of the days, a high hit rate that directly corresponds to its strong profit performance. the alignment with the best overall strategy ( cv - 28 ) is naturally lower at 38 _. _ 9 %, as the lcs is limited to strategies from _ s _. the fact that the cv - 3 strategy itself only matches the cv - 28 decision on 46 _. _ 4 % of days underscores the importance of the initial strategy pool selection and explains why a gap between our lcs and the theoretical maximum remains. finally, the daily decision metrics in table 3 provide further insight into the performance of the model. the cv - 3 strategy, which has perfect foresight over the same pool of three strategies available to our lcs, outperforms it on only 27 _. _ 8 % of the days. this implies a high classification accuracy for the xgboost model, as it correctly identifies the best strategy within its pool more than 70 % of the time. a nuanced observation arises when comparing lcs to the sb strategy. while sb outperforms lcs on a higher fraction of days ( 30. 1 % ). this occurs because sb can be the strategy outside the curated three - strategy pool used by lcs ; however, the marginal profits gained on those days are negligible, which 21 figure 8 : cumulative profits for the lcs and all benchmarking strategies over the whole oos period. figure 9 : a heatmap presents the normalized weekly profits across different strategies over the entire evaluation period. the horizontal axis denotes time ( from august 2023 to august 2024 ), while the vertical axis lists the strategies. the color scale ranges from purple ( low profits ) to yellow ( high profits ). explains why sb ’ s overall profit remains substantially lower. the data also allows to evaluate the quality of our initial strategy pool selection. the fact that the globally optimal strategy from all 28 candidates was contained within our chosen pool of three on 46 _. _ 4 % of the days confirms that our selection process effectively captures the best - performing strategy in nearly half of all trading scenarios. finally, the results reaffirm the market dynamics of the study period : the ’ only fcr ’ strategy proved to be the single best choice on a remarkable 37 _. _ 1 % of all days, underscoring the dominance of the fcr market and explaining why the top - performing strategies are heavily weighted towards fcr commitments. figure 8 shows the cumulative profits of the strategies during the out - of - sample period. we can see that _ only idm _ is clearly the worst strategy, while all mixed strategies earn profits in a comparable range. in accordance with the risk - free nature of the ri, the profits increase monotonically over time, and the slope substantially increases around the middle of the observation period, which is mainly due to the increase in profits in the fcr market. figure 9 displays normalized weekly profits of different strategies [ 5 ]. the results reveal clear temporal 5 normalized weekly profits = max ( weekly profits ) - min ( weekly profits ) weekly profits - min ( weekly profits ) 22 and strategic patterns. in particular, the dynamic strategies ( cv - 28, cv - 3, lcs ) consistently achieve higher profits compared to the other four strategies. in particular, there is a pronounced increase in profitability between may and july 2024, when most dynamic strategies reach their peak performance ( indicated by the yellow regions ). in contrast, during late 2023 and early 2024, profits remain relatively low across all strategies. furthermore, lcs exhibits a more stable and resilient performance compared to ds and sb. in particular, during the low - profit months from november 2023 to february 2024, lcs sustains higher profit levels, avoiding the sharp declines seen in ds and sb. similarly, in march and april 2024, lcs continues to outperform both strategies, maintaining moderate profitability where ds and sb weaken. moreover, during the peak period between may and july 2024, lcs tracks closely with cv 28 and cv - 3, showing consistently high profit levels ( yellow regions ), while ds and sb display greater variability. this highlights that lcs is not only more robust in low - profit phases but also competitive with the strongest combined strategies in high - profit periods. the computational requirements of our approach can be divided into two phases : the initial backtest and the daily operational deployment. the initial backtest, which involves simulating the ri performance for each fcr strategy over the entire dataset, is computationally intensive and requires approximately 7 hours per strategy. however, this process is highly parallelizable, as simulations for strategies are independent of each other. we managed this workload by performing the evaluations on 48 aws"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 23,
    "text": "##s higher profit levels, avoiding the sharp declines seen in ds and sb. similarly, in march and april 2024, lcs continues to outperform both strategies, maintaining moderate profitability where ds and sb weaken. moreover, during the peak period between may and july 2024, lcs tracks closely with cv 28 and cv - 3, showing consistently high profit levels ( yellow regions ), while ds and sb display greater variability. this highlights that lcs is not only more robust in low - profit phases but also competitive with the strongest combined strategies in high - profit periods. the computational requirements of our approach can be divided into two phases : the initial backtest and the daily operational deployment. the initial backtest, which involves simulating the ri performance for each fcr strategy over the entire dataset, is computationally intensive and requires approximately 7 hours per strategy. however, this process is highly parallelizable, as simulations for strategies are independent of each other. we managed this workload by performing the evaluations on 48 aws batch instances, each equipped with 4 vcpus and 24 gb of memory. in a live trading environment, the daily computational workflow is highly efficient. the process begins by updating the training data, which involves running a one - day backtest for each of the 28 candidate strategies using market data from the most recently completed day. this simulation step takes approximately one minute. immediately following the data update, the optimal strategy pool is re - selected and the xgboost classifier is retrained to generate a bid for the upcoming day. the entire daily process, from the initial data update to the final prediction, is completed in under two minutes on a standard desktop computer. this rapid execution time confirms that our lcs framework is not computationally prohibitive and is well suited for practical deployment in real - world trading operations. # # # * * 5 conclusion * * this paper introduces a novel hierarchical approach to optimize bess participation in the frequency containment reserve and intraday markets. our method effectively decouples the complex problem into two manageable stages : a high - frequency rolling intrinsic algorithm handles the continuous intraday trading and state of charge management, while an xgboost - based classifier selects the optimal fcr commitment from a pre - screened pool of complementary strategies. our out - of - sample backtest on historical market data validates the practical value of this approach ; the proposed _ learned classifier _ _ strategy _ substantially outperforms static and naive dynamic benchmarks, closing a significant portion of the gap to theoretical maximum profit. despite its strong performance, the framework has limitations that open clear avenues for future research. a primary constraint is the reliance on a small and curated set of fcr strategies. prevailing market conditions have heavily favored the fcr market, causing the most profitable strategies to be highly similar, allocating maximum capacity to fcr. this clustering creates a difficult classification problem with severe class imbalance, limiting the performance ceiling of the lcs. furthermore, for tractability, our model assumes zero - price bids in the pay - as - cleared fcr auction and uses the suboptimal myopic ri for intraday trading. 23 future work should directly address these limitations. first, enhancing the intraday trading algorithm is a key priority. by moving beyond the ri to more sophisticated methods such as reinforcement learning, the profitability of the idm could be increased. this would naturally lead to a more diverse set of viable strategies, mitigating the class imbalance and making the classification task more effective. second, a promising extension is to endogenize the fcr bid price. instead of assuming zero - price bids, a forecasting model could estimate the opportunity cost of fcr participation, effectively the idm profit foregone for each efa block. this would enable a more sophisticated bidding strategy that optimizes both the quantity and the price of the fcr commitment, further enhancing overall profitability. # # # * * references * * r. [UNK], p. gruet, and h. pham. an optimal trading problem in intraday electricity markets. _ mathematics _ _ and financial economics _, 10 : 49 – 85, 2016. m. ansari, a. t. al - awami, e. sortomme, and m. a. abido. coordinated bidding of ancillary services for vehicle - to - grid using fuzzy optimization. _ ieee transactions on smart grid _, 6 ( 1 ) : 261 – 270, 2015. doi : 10. 1109 / tsg. 2014. 2341625. p. astero and c. evens. stochastic bidding strategy for electrical vehicle charging stations to participate in frequency containment reserves markets. _ iet generation, transmission & distribution _, 14 ( 13 ) : 2566 – 2572, 2020. g. bertrand and a. papavasiliou. reinforcement - learning based threshold policies for continuous intraday electricity market trading. in _ 2019 ieee power & energy society general meeting ( pesgm ) _, pages 1 – 5. ieee,"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 24,
    "text": "electricity markets. _ mathematics _ _ and financial economics _, 10 : 49 – 85, 2016. m. ansari, a. t. al - awami, e. sortomme, and m. a. abido. coordinated bidding of ancillary services for vehicle - to - grid using fuzzy optimization. _ ieee transactions on smart grid _, 6 ( 1 ) : 261 – 270, 2015. doi : 10. 1109 / tsg. 2014. 2341625. p. astero and c. evens. stochastic bidding strategy for electrical vehicle charging stations to participate in frequency containment reserves markets. _ iet generation, transmission & distribution _, 14 ( 13 ) : 2566 – 2572, 2020. g. bertrand and a. papavasiliou. reinforcement - learning based threshold policies for continuous intraday electricity market trading. in _ 2019 ieee power & energy society general meeting ( pesgm ) _, pages 1 – 5. ieee, 2019a. g. bertrand and a. papavasiliou. adaptive trading in continuous intraday electricity markets for a storage unit. _ ieee transactions on power systems _, 35 ( 3 ) : 2339 – 2350, 2019b. f. biggins, s. homan, j. ejeh, and s. brown. to trade or not to trade : simultaneously optimising battery storage for arbitrage and ancillary services. _ journal of energy storage _, 50 : 104234, 2022. bloombergnef. lithium - ion battery pack prices see largest drop since 2017, falling to $ 115 per kilowatt hour. technical report, bloombergnef, 2024. url ` [ https : / / about. bnef. com / insights / commodit ] ( https : / / about. bnef. com / insights / commodities / lithium - ion - battery - pack - prices - see - largest - drop - since - 2017 - falling - to - 115 - per - kilowatt - hour - bloombergnef / ) ` ` ` ` ies / lithium - ion - battery - pack - prices - see - largest - drop - since - 2017 - falling - to - 115 - per ` ` ` ` [ - kilowatt - hour - bloombergnef / ] ( https : / / about. bnef. com / insights / commodities / lithium - ion - battery - pack - prices - see - largest - drop - since - 2017 - falling - to - 115 - per - kilowatt - hour - bloombergnef / ) `. accessed : august 23, 2025. i. boukas, d. ernst, t. [UNK], a. bolland, a. huynen, m. buchwald, c. wynants, and b. [UNK]. a deep reinforcement learning framework for continuous intraday market bidding. _ machine learning _, 110 : 2335 – 2387, 2021. c. brivio, s. mandelli, and m. merlo. battery energy storage system for primary control reserve and energy arbitrage. _ sustainable energy, grids and networks _, 6 : 152 – 165, 2016. g. broneske and d. wozabal. how do contract parameters influence the economics of vehicle - to - grid? _ manufacturing & service operations management _, 19 ( 1 ) : 150 – 164, 2017. t. chen and c. guestrin. xgboost : a scalable tree boosting system. in _ proceedings of the 22nd acm _ _ sigkdd international conference on knowledge discovery and data mining _, pages 785 – 794, 2016. 24 w. cole and a. karmakar. cost projections for utility - scale battery storage : 2023 update. technical report nrel / tp - 6a40 - 85332, national renewable energy laboratory ( nrel ), 2023. url ` [ https : ] ( https : / / docs. nrel. gov / docs / fy23osti / 85332. pdf ) ` ` [ / / docs. nrel. gov / docs / fy23osti / 85332. pdf ] ( https : / / docs. nrel. gov / docs / fy23osti / 85332. pdf ) `. j. de boeck, b. fortz, m. [UNK], e. marcotte, p. marcotte, and g. savard. bidding in day - ahead [ [UNK] ] electricity markets : a dynamic programming framework. _ computers & operations research _, 179 : 107024, 2025. i. dimoulkas, m. amelin, and m. r. hesamzadeh. forecasting balancing market prices using hidden markov models. in _ 2016 13th international conference on the european energy"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 25,
    "text": ". url ` [ https : ] ( https : / / docs. nrel. gov / docs / fy23osti / 85332. pdf ) ` ` [ / / docs. nrel. gov / docs / fy23osti / 85332. pdf ] ( https : / / docs. nrel. gov / docs / fy23osti / 85332. pdf ) `. j. de boeck, b. fortz, m. [UNK], e. marcotte, p. marcotte, and g. savard. bidding in day - ahead [ [UNK] ] electricity markets : a dynamic programming framework. _ computers & operations research _, 179 : 107024, 2025. i. dimoulkas, m. amelin, and m. r. hesamzadeh. forecasting balancing market prices using hidden markov models. in _ 2016 13th international conference on the european energy market ( eem ) _, pages 1 – 5. ieee, 2016. p. h. divshali and c. evens. optimum operation of battery storage system in frequency containment reserves markets. _ ieee transactions on smart grid _, 11 ( 6 ) : 4906 – 4915, 2020. epex spot se. epex spot annual reports, 2020 - 2023. url ` [ https : / / www. epexspot. com / ] ( https : / / www. epexspot. com / ) `. accessed : 2024 - 06 - 17. european commission. commission regulation ( eu ) 2015 / 1222 of 24 july 2015 establishing a guideline on capacity allocation and congestion management. _ official journal of the european union _, l 197 : 24 – 72, 2015. e. faria and s. - e. fleten. day - ahead market bidding for a nordic hydropower producer : taking the elbas market into account. _ computational management science _, 8 : 75 – 101, 2011. j. figgener, b. tepe, f. [UNK], i. schoeneberger, c. hecht, a. jossen, and d. u. sauer. the influence of frequency containment reserve flexibilization on the economics of electric vehicle fleet operation. _ journal of energy storage _, 53 : 105138, 2022. s. - e. fleten and t. k. kristoffersen. short - term hydropower production planning by stochastic pro gramming. _ computers & operations research _, 35 ( 8 ) : 2656 – 2671, 2008. s. goodarzi, h. n. perera, and d. bunn. the impact of renewable energy forecast errors on imbalance volumes and electricity spot prices. _ energy policy _, 134 : 110827, 2019. c. graf, t. kuppelwieser, and d. wozabal. frequent auctions for intraday electricity markets. _ the _ _ energy journal _, ( 45 ), 2024. j. gray and p. khandelwal. towards a realistic gas storage model. _ commodities now _, 7 ( 2 ) : 1 – 4, 2004. l. grinsztajn, e. oyallon, and g. varoquaux. why do tree - based models still outperform deep learning on typical tabular data? in s. koyejo, s. mohamed, a. agarwal, d. belgrave, k. cho, and a. oh, editors, _ advances in neural information processing systems _, volume 35, pages 507 – 520. curran associates, inc., 2022. d. r. jiang and w. b. powell. optimal hour - ahead bidding in the real - time electricity market with battery storage using approximate dynamic programming. _ informs journal on computing _, 27 ( 3 ) : 525 – 543, 2015. f. karanfil and y. li. the role of continuous intraday electricity markets : the integration of large - share wind power generation in denmark. _ the energy journal _, 38 ( 2 ), 2017. 25 t. kempitiya, s. sierla, d. de silva, m. yli - [UNK], d. alahakoon, and v. vyatkin. an artificial intelligence framework for bidding optimization with uncertainty in multiple frequency reserve markets. _ applied energy _, 280 : 115918, 2020. h. kongelf, k. overrein, g. klæboe, and s. - e. fleten. portfolio size ’ s effects on gains from coordinated bidding in electricity markets : a case study of a norwegian hydropower producer. _ energy systems _, 10 : 567 – 591, 2019. e. kraft, d. keles, and w. ficht"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 26,
    "text": "525 – 543, 2015. f. karanfil and y. li. the role of continuous intraday electricity markets : the integration of large - share wind power generation in denmark. _ the energy journal _, 38 ( 2 ), 2017. 25 t. kempitiya, s. sierla, d. de silva, m. yli - [UNK], d. alahakoon, and v. vyatkin. an artificial intelligence framework for bidding optimization with uncertainty in multiple frequency reserve markets. _ applied energy _, 280 : 115918, 2020. h. kongelf, k. overrein, g. klæboe, and s. - e. fleten. portfolio size ’ s effects on gains from coordinated bidding in electricity markets : a case study of a norwegian hydropower producer. _ energy systems _, 10 : 567 – 591, 2019. e. kraft, d. keles, and w. fichtner. modeling of frequency containment reserve prices with econometrics and artificial intelligence. _ journal of forecasting _, 39 ( 8 ) : 1179 – 1197, 2020. s. kulakov and f. ziel. the impact of renewable energy forecasts on intraday electricity prices. _ arxiv _ _ preprint arxiv : 1903. 09641 _, 2019. t. kuppelwieser and d. wozabal. liquidity costs on intraday power markets : continuous trading versus auctions. _ energy policy _, 154 : 112299, 2021. t. kuppelwieser and d. wozabal. intraday power trading : toward an arms race in weather forecasting? _ or spectrum _, 45 ( 1 ) : 57 – 83, 2023. n. [UNK] and d. wozabal. the value of coordination in multimarket bidding of grid energy storage. _ operations research _, 71 ( 1 ) : 1 – 22, 2023. n. [UNK], d. wozabal, and s. minner. optimizing trading decisions for hydro storage systems using approximate dual dynamic programming. _ operations research _, 61 ( 4 ) : 810 – 823, 2013. g. marcjasz, b. uniejewski, and r. weron. beating the [UNK] — combining lasso with [UNK] intraday electricity price forecasts. _ energies _, 13 ( 7 ) : 1667, 2020. m. narajewski and f. ziel. econometric modelling and forecasting of intraday electricity prices. _ journal _ _ of commodity markets _, 19 : 100107, 2020. r. shwartz - ziv and a. armon. tabular data : deep learning is not all you need. _ information fusion _, 81 : 84 – 90, 2022. r. sioshansi. welfare impacts of electricity storage and the implications of ownership structure. _ the _ _ energy journal _, 31 ( 2 ), 2010. e. sortomme and m. a. el - sharkawi. optimal scheduling of vehicle - to - grid energy and ancillary services. _ ieee transactions on smart grid _, 3 ( 1 ) : 351 – 359, 2012. doi : 10. 1109 / tsg. 2011. 2164099. t. thien, d. schweer, d. vom stein, a. moser, and d. u. sauer. real - world operating strategy and sensitivity analysis of frequency containment reserve provision with battery energy storage systems in the german market. _ journal of energy storage _, 13 : 143 – 163, 2017. b. uniejewski, g. marcjasz, and r. weron. understanding intraday electricity markets : variable selection and very short - term price forecasting using lasso. _ international journal of forecasting _, 35 ( 4 ) : 1533 – 1547, 2019. d. wozabal and g. rameseder. optimal bidding of a virtual power plant on the spanish day - ahead and intraday market for electricity. _ european journal of operational research _, 280 ( 2 ) : 639 – 655, 2020. 26 b. xu, a. oudalov, j. poland, a. ulbig, and g. andersson. bess control strategies for participating in grid frequency regulation. _ ifac proceedings volumes _, 47 ( 3 ) : 4024 – 4029, 2014. y. j. a. zhang, c. zhao, w. tang, and s. h. low. profit - maximizing planning and control of battery energy storage systems for primary frequency control. _ ieee transactions on smart grid _, 9 ( 2 ) : 712 – 723, 2016. 27"
  },
  {
    "source_id": "",
    "metadata": {
      "id": "2510.03209v1",
      "title": "Joint Bidding on Intraday and Frequency Containment Reserve Markets",
      "authors": [
        "Yiming Zhang",
        "Wolfgang Ridinger",
        "David Wozabal"
      ],
      "summary": "As renewable energy integration increases supply variability, battery energy\nstorage systems (BESS) present a viable solution for balancing supply and\ndemand. This paper proposes a novel approach for optimizing battery BESS\nparticipation in multiple electricity markets. We develop a joint bidding\nstrategy that combines participation in the primary frequency reserve market\nwith continuous trading in the intraday market, addressing a gap in the extant\nliterature which typically considers these markets in isolation or simplifies\nthe continuous nature of intraday trading. Our approach utilizes a mixed\ninteger linear programming implementation of the rolling intrinsic algorithm\nfor intraday decisions and state of charge recovery, alongside a learned\nclassifier strategy (LCS) that determines optimal capacity allocation between\nmarkets. A comprehensive out-of-sample backtest over more than one year of\nhistorical German market data validates our approach: The LCS increases overall\nprofits by over 4% compared to the best-performing static strategy and by more\nthan 3% over a naive dynamic benchmark. Crucially, our method closes the gap to\na theoretical perfect foresight strategy to just 4%, demonstrating the\neffectiveness of dynamic, learning-based allocation in a complex, multi-market\nenvironment.",
      "published": "2025-10-03T17:48:21Z",
      "pdf_url": "http://arxiv.org/pdf/2510.03209v1"
    },
    "chunk_id": 27,
    "text": "d. wozabal and g. rameseder. optimal bidding of a virtual power plant on the spanish day - ahead and intraday market for electricity. _ european journal of operational research _, 280 ( 2 ) : 639 – 655, 2020. 26 b. xu, a. oudalov, j. poland, a. ulbig, and g. andersson. bess control strategies for participating in grid frequency regulation. _ ifac proceedings volumes _, 47 ( 3 ) : 4024 – 4029, 2014. y. j. a. zhang, c. zhao, w. tang, and s. h. low. profit - maximizing planning and control of battery energy storage systems for primary frequency control. _ ieee transactions on smart grid _, 9 ( 2 ) : 712 – 723, 2016. 27"
  }
]